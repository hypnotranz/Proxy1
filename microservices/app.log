2024-08-01 14:39:18,759 custom_logger INFO This is an info message
2024-08-01 14:39:18,760 custom_logger WARNING This is a warning message
2024-08-01 14:39:18,761 custom_logger ERROR This is an error message
2024-08-01 14:39:18,872 custom_logger INFO Starting the application
2024-08-01 14:39:18,943 custom_logger INFO Entering register_service
2024-08-01 14:39:18,946 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 14:39:19,006 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 14:39:19,007 custom_logger INFO Exiting register_service
2024-08-01 14:51:03,003 custom_logger INFO This is an info message
2024-08-01 14:51:03,003 custom_logger WARNING This is a warning message
2024-08-01 14:51:03,004 custom_logger ERROR This is an error message
2024-08-01 14:51:03,100 custom_logger INFO Starting the application
2024-08-01 14:51:03,172 custom_logger INFO Entering register_service
2024-08-01 14:51:03,174 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 14:51:03,215 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 14:51:03,216 custom_logger INFO Exiting register_service
2024-08-01 16:07:37,173 custom_logger INFO Starting the application
2024-08-01 16:07:37,255 custom_logger INFO Entering register_service
2024-08-01 16:08:12,855 custom_logger INFO Starting the application
2024-08-01 16:08:12,946 custom_logger INFO Entering register_service
2024-08-01 16:08:12,948 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:08:12,999 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:08:13,001 custom_logger INFO Exiting register_service
2024-08-01 16:09:38,576 custom_logger INFO Starting the application
2024-08-01 16:09:38,646 custom_logger INFO Entering register_service
2024-08-01 16:09:38,649 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:09:38,691 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:09:38,692 custom_logger INFO Exiting register_service
2024-08-01 16:10:38,890 custom_logger INFO Starting the application
2024-08-01 16:10:38,966 custom_logger INFO Entering register_service
2024-08-01 16:10:38,969 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:10:39,018 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:10:39,019 custom_logger INFO Exiting register_service
2024-08-01 16:11:50,333 custom_logger INFO Starting the application
2024-08-01 16:11:50,410 custom_logger INFO Entering register_service
2024-08-01 16:11:50,413 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:11:50,493 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:11:50,494 custom_logger INFO Exiting register_service
2024-08-01 16:13:59,564 custom_logger INFO Starting the application
2024-08-01 16:13:59,664 custom_logger INFO Entering register_service
2024-08-01 16:13:59,666 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:13:59,717 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:13:59,717 custom_logger INFO Exiting register_service
2024-08-01 16:14:24,276 custom_logger INFO Starting the application
2024-08-01 16:14:24,355 custom_logger INFO Entering register_service
2024-08-01 16:14:24,359 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:14:24,411 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:14:24,412 custom_logger INFO Exiting register_service
2024-08-01 16:14:39,667 custom_logger INFO Starting the application
2024-08-01 16:14:39,747 custom_logger INFO Entering register_service
2024-08-01 16:14:39,749 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:14:39,800 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:14:39,801 custom_logger INFO Exiting register_service
2024-08-01 16:15:24,785 custom_logger INFO Starting the application
2024-08-01 16:15:24,856 custom_logger INFO Entering register_service
2024-08-01 16:15:24,859 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:15:24,901 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:15:24,902 custom_logger INFO Exiting register_service
2024-08-01 16:16:26,674 custom_logger INFO Starting the application
2024-08-01 16:16:26,748 custom_logger INFO Entering register_service
2024-08-01 16:16:26,751 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:16:26,805 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:16:26,806 custom_logger INFO Exiting register_service
2024-08-01 16:17:42,976 custom_logger INFO Starting the application
2024-08-01 16:17:43,072 custom_logger INFO Entering register_service
2024-08-01 16:17:43,075 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:17:43,131 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:17:43,132 custom_logger INFO Exiting register_service
2024-08-01 16:19:22,543 custom_logger INFO Starting the application
2024-08-01 16:19:22,620 custom_logger INFO Entering register_service
2024-08-01 16:19:22,623 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:19:22,672 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:19:22,673 custom_logger INFO Exiting register_service
2024-08-01 16:20:54,740 custom_logger INFO Starting the application
2024-08-01 16:20:54,825 custom_logger INFO Entering register_service
2024-08-01 16:20:54,828 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:20:54,886 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:20:54,887 custom_logger INFO Exiting register_service
2024-08-01 16:21:48,009 custom_logger INFO Starting the application
2024-08-01 16:21:48,089 custom_logger INFO Entering register_service
2024-08-01 16:21:48,092 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:21:48,140 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:21:48,141 custom_logger INFO Exiting register_service
2024-08-01 16:23:50,671 custom_logger INFO Starting the application
2024-08-01 16:23:50,758 custom_logger INFO Entering register_service
2024-08-01 16:23:50,761 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:23:50,818 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:23:50,818 custom_logger INFO Exiting register_service
2024-08-01 16:27:29,839 custom_logger INFO Starting the application
2024-08-01 16:27:29,935 custom_logger INFO Entering register_service
2024-08-01 16:27:29,938 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:27:29,992 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:27:29,993 custom_logger INFO Exiting register_service
2024-08-01 16:28:41,409 custom_logger INFO Starting the application
2024-08-01 16:28:41,496 custom_logger INFO Entering register_service
2024-08-01 16:28:41,499 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:28:41,550 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:28:41,551 custom_logger INFO Exiting register_service
2024-08-01 16:29:58,301 custom_logger INFO Starting the application
2024-08-01 16:29:58,387 custom_logger INFO Entering register_service
2024-08-01 16:29:58,390 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:29:58,445 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:29:58,446 custom_logger INFO Exiting register_service
2024-08-01 17:37:01,405 custom_logger INFO Starting the application
2024-08-01 17:37:01,490 custom_logger INFO Entering register_service
2024-08-01 17:37:01,494 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:37:01,554 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:37:01,555 custom_logger INFO Exiting register_service
2024-08-01 17:38:25,337 custom_logger INFO Starting the application
2024-08-01 17:38:25,416 custom_logger INFO Entering register_service
2024-08-01 17:38:25,419 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:38:25,476 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:38:25,477 custom_logger INFO Exiting register_service
2024-08-01 17:39:37,084 custom_logger INFO Starting the application
2024-08-01 17:39:37,161 custom_logger INFO Entering register_service
2024-08-01 17:39:37,164 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:39:37,210 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:39:37,211 custom_logger INFO Exiting register_service
2024-08-01 17:42:44,292 custom_logger INFO Starting the application
2024-08-01 17:42:44,380 custom_logger INFO Entering register_service
2024-08-01 17:42:44,383 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:42:44,436 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:42:44,437 custom_logger INFO Exiting register_service
2024-08-01 17:43:00,893 custom_logger INFO Starting the application
2024-08-01 17:43:00,974 custom_logger INFO Entering register_service
2024-08-01 17:43:00,977 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:43:01,026 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:43:01,027 custom_logger INFO Exiting register_service
2024-08-01 17:43:24,348 custom_logger INFO Starting the application
2024-08-01 17:43:24,437 custom_logger INFO Entering register_service
2024-08-01 17:43:24,440 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:43:24,484 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:43:24,485 custom_logger INFO Exiting register_service
2024-08-01 17:44:52,844 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 17:44:53,434 custom_logger INFO Query succeeded: {'took': 575, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 10, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'logs', '_type': '_doc', '_id': '2bZzD5EBTfLFZNqTWBYQ', '_score': 1.0, '_source': {'message': 'This is a test log', 'level': 'INFO', 'timestamp': '2023-01-01T00:00:00Z'}}, {'_index': 'logs', '_type': '_doc', '_id': '3LabD5EBTfLFZNqT_xaL', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '3bbhD5EBTfLFZNqTmxYu', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '3rbiD5EBTfLFZNqTQRbs', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '37blD5EBTfLFZNqTzRbF', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.349199', 'message': '2024-08-01 17:43:24,348 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4LblD5EBTfLFZNqTzhYd', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.440422', 'message': '2024-08-01 17:43:24,437 custom_logger INFO Entering register_service', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4bblD5EBTfLFZNqTzhZN', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.486857', 'message': "2024-08-01 17:43:24,440 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}", 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4rblD5EBTfLFZNqTzhZe', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.504368', 'message': '2024-08-01 17:43:24,484 custom_logger INFO Service registered successfully with the proxy.', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '47blD5EBTfLFZNqTzhZx', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.523865', 'message': '2024-08-01 17:43:24,485 custom_logger INFO Exiting register_service', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '5LbnD5EBTfLFZNqTJxZ1', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:44:52.847122', 'message': '2024-08-01 17:44:52,844 custom_logger INFO Handling elastic: http://localhost:9200', 'level': 'INFO', 'logger_name': 'custom_logger'}}]}}
2024-08-01 17:52:30,554 custom_logger INFO Starting the application
2024-08-01 17:52:30,648 custom_logger INFO Entering register_service
2024-08-01 17:52:30,651 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:52:30,706 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:52:30,707 custom_logger INFO Exiting register_service
2024-08-01 17:52:59,525 custom_logger INFO Starting the application
2024-08-01 17:52:59,603 custom_logger INFO Entering register_service
2024-08-01 17:52:59,606 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:52:59,649 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:52:59,650 custom_logger INFO Exiting register_service
2024-08-01 17:53:13,403 custom_logger INFO Starting the application
2024-08-01 17:53:13,481 custom_logger INFO Entering register_service
2024-08-01 17:53:13,485 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:53:13,529 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:53:13,532 custom_logger INFO Exiting register_service
2024-08-01 17:57:20,094 custom_logger INFO Handling command: ls -R in path: ./command_service
2024-08-01 17:57:20,095 custom_logger INFO Running command: ls -R in path: ./command_service
2024-08-01 17:57:20,167 custom_logger INFO Command succeeded: stdout: .:
__init__.py
__pycache__
config
controllers
main.py
models
services

./__pycache__:
__init__.cpython-38.pyc
main.cpython-38.pyc

./config:
__init__.py
__pycache__
config.json
config.py

./config/__pycache__:
__init__.cpython-38.pyc
config.cpython-38.pyc

./controllers:
__init__.py
__pycache__
command_controller.py

./controllers/__pycache__:
__init__.cpython-38.pyc
command_controller.cpython-38.pyc

./models:
__init__.py
__pycache__
command_message.py
register_request.py

./models/__pycache__:
__init__.cpython-38.pyc
command_message.cpython-38.pyc
register_request.cpython-38.pyc

./services:
__init__.py
__pycache__
command_service.py
logger.py
registration_service.py

./services/__pycache__:
__init__.cpython-38.pyc
command_service.cpython-38.pyc
logger.cpython-38.pyc
registration_service.cpython-38.pyc
, stderr: 
2024-08-01 17:58:14,656 custom_logger INFO Handling command: find ./command_service -name '*.py' in path: .
2024-08-01 17:58:14,657 custom_logger INFO Running command: find ./command_service -name '*.py' in path: .
2024-08-01 17:58:14,765 custom_logger INFO Command succeeded: stdout: ./command_service/config/config.py
./command_service/config/__init__.py
./command_service/controllers/command_controller.py
./command_service/controllers/__init__.py
./command_service/main.py
./command_service/models/command_message.py
./command_service/models/register_request.py
./command_service/models/__init__.py
./command_service/services/command_service.py
./command_service/services/logger.py
./command_service/services/registration_service.py
./command_service/services/__init__.py
./command_service/__init__.py
, stderr: 
2024-08-01 18:42:37,823 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 18:42:37,951 custom_logger INFO Query succeeded: {'took': 75, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 32, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'logs', '_type': '_doc', '_id': '2bZzD5EBTfLFZNqTWBYQ', '_score': 1.0, '_source': {'message': 'This is a test log', 'level': 'INFO', 'timestamp': '2023-01-01T00:00:00Z'}}, {'_index': 'logs', '_type': '_doc', '_id': '3LabD5EBTfLFZNqT_xaL', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '3bbhD5EBTfLFZNqTmxYu', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '3rbiD5EBTfLFZNqTQRbs', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '37blD5EBTfLFZNqTzRbF', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.349199', 'message': '2024-08-01 17:43:24,348 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4LblD5EBTfLFZNqTzhYd', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.440422', 'message': '2024-08-01 17:43:24,437 custom_logger INFO Entering register_service', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4bblD5EBTfLFZNqTzhZN', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.486857', 'message': "2024-08-01 17:43:24,440 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}", 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4rblD5EBTfLFZNqTzhZe', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.504368', 'message': '2024-08-01 17:43:24,484 custom_logger INFO Service registered successfully with the proxy.', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '47blD5EBTfLFZNqTzhZx', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.523865', 'message': '2024-08-01 17:43:24,485 custom_logger INFO Exiting register_service', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '5LbnD5EBTfLFZNqTJxZ1', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:44:52.847122', 'message': '2024-08-01 17:44:52,844 custom_logger INFO Handling elastic: http://localhost:9200', 'level': 'INFO', 'logger_name': 'custom_logger'}}]}}
2024-08-01 20:56:42,803 custom_logger INFO Handling command: for file in *; do echo BEGIN $file; cat $file; echo END $file; done in path: .
2024-08-01 20:56:42,813 custom_logger INFO Running command: for file in *; do echo BEGIN $file; cat $file; echo END $file; done in path: .
2024-08-01 20:56:42,906 custom_logger ERROR Command execution failed: cat: __pycache__: Is a directory
cat: command_service: Is a directory
cat: tests: Is a directory

2024-08-01 20:58:32,283 custom_logger INFO Handling command: find ./command_service -name '*.py' | xargs cat in path: .
2024-08-01 20:58:32,284 custom_logger INFO Running command: find ./command_service -name '*.py' | xargs cat in path: .
2024-08-01 20:58:32,513 custom_logger INFO Command succeeded: stdout: import logging
import json
from concurrent.futures import ThreadPoolExecutor
import requests
import os
from pydantic import BaseSettings

class Settings(BaseSettings):
    proxy_url: str
    host: str
    port: int
    service_name: str
    logging_level: str
    logging_format: str
    logging_sinks: list
    elastic_url: str

def load_config():
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    with open(config_path) as config_file:
        config_data = json.load(config_file)
        return Settings(
            proxy_url=config_data['proxy_url'],
            host=config_data['host'],
            port=config_data['port'],
            service_name=config_data['service_name'],
            logging_level=config_data['logging']['level'],
            logging_format=config_data['logging']['format'],
            logging_sinks=config_data['logging']['sinks'],
            elastic_url=config_data['logging']['elastic_url']
        )



settings = load_config()
from fastapi import APIRouter, HTTPException, Depends
from command_service.models.command_message import CommandMessage
from command_service.services.command_service import run_command
from command_service.services.logger import CustomLogger, log_decorator
from command_service.services.logger import get_logger
from command_service.config.config import Settings, load_config
from command_service.services.logger import CustomLogger
from pydantic import BaseModel
import logging
import requests
import traceback

router = APIRouter()

@router.post('/execute-bash')
async def command_service(message: CommandMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling command: {message.command} in path: {message.path}')

    try:
        stdout, stderr = await run_command(message.command, message.path, settings, logger)

        if stderr:
            logger.error(f'Command execution failed: {stderr}')
            return {'stdout': stdout, 'stderr': stderr}

        logger.info(f'Command succeeded: stdout: {stdout}, stderr: {stderr}')
        return {'stdout': stdout, 'stderr': stderr}

    except Exception as e:
        logger.error(f'Failed to execute command: {str(e)}')
        return {'stdout': '', 'stderr': str(e)}

class ElasticQueryMessage(BaseModel):
    connection_string: str
    index: str
    query: dict

class ElasticLogMessage(BaseModel):
    connection_string: str
    index: str
    log: dict

@router.post('/elastic-query')
async def handle_elastic(message: ElasticQueryMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling elastic: {message.connection_string}')

    try:
        query_url = f"{message.connection_string}/{message.index}/_search"
        logger.debug(f"Query URL: {query_url}")
        logger.debug(f"Query Body: {message.query}")

        response = requests.post(query_url, json={"query": message.query})
        logger.debug(f"Response: {response.text}")
        response.raise_for_status()

        logger.info(f"Query succeeded: {response.json()}")
        return response.json()
    except requests.RequestException as e:
        error_message = f"Failed to execute ElasticSearch query: {str(e)}"
        logger.error(error_message)
        traceback_str = ''.join(traceback.format_tb(e.__traceback__))
        return {"error": error_message, "traceback": traceback_str}

@router.post('/elastic-log')
async def handle_elastic_log(message: ElasticLogMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling elastic log: {message.connection_string}')

    try:
        log_url = f"{message.connection_string}/{message.index}/_doc"
        logger.debug(f"Log URL: {log_url}")
        logger.debug(f"Log Body: {message.log}")

        response = requests.post(log_url, json=message.log)
        logger.debug(f"Response: {response.text}")
        response.raise_for_status()

        logger.info(f"Log succeeded: {response.json()}")
        return response.json()
    except requests.RequestException as e:
        error_message = f"Failed to send log to Elasticsearch: {str(e)}"
        logger.error(error_message)
        traceback_str = ''.join(traceback.format_tb(e.__traceback__))
        return {"error": error_message, "traceback": traceback_str}
from fastapi import FastAPI
from contextlib import asynccontextmanager
from command_service.services.registration_service import RegistrationService
from command_service.config.config import settings
from command_service.controllers import command_controller
from command_service.services.logger import CustomLogger
import logging
import asyncio

# Initialize the logger using CustomLogger
custom_logger = CustomLogger(settings)
logger = custom_logger

@asynccontextmanager
async def lifespan(app: FastAPI):
    openapi_schema = app.openapi()

    # Hardcoding the servers field
    openapi_schema['servers'] = [{"url": f"http://{settings.host}:{settings.port}"}]
    app.openapi_schema = openapi_schema

    registration_service = RegistrationService(settings, logger)
    # Start the service registration process as a background task
    asyncio.create_task(registration_service.register_service())
    yield
    # Any cleanup logic here if needed

app = FastAPI(lifespan=lifespan)
app.include_router(command_controller.router)

if __name__ == "__main__":
    logger.info("Starting the application")
    import uvicorn
    uvicorn.run(app, host=settings.host, port=settings.port)
from pydantic import BaseModel

class CommandMessage(BaseModel):
    command: str
    path: str = ""
from typing import Optional, Dict, Any
from pydantic import BaseModel

class RegisterRequest(BaseModel):
    service_name: str
    openapi_url: Optional[str] = None  # Make this field optional
    openapi_json: Optional[Dict[str, Any]] = None  # Make this field optional and ensure it's a dictionary
import asyncio
import logging
import os
from command_service.config.config import Settings

async def run_command(command: str, path: str, settings: Settings, logger: logging.Logger):
    logger.info(f"Running command: {command} in path: {path}")

    full_path = os.path.abspath(path) if path else os.getcwd()

    process = await asyncio.create_subprocess_shell(
        command,
        cwd=full_path,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )

    stdout, stderr = await process.communicate()

    return stdout.decode(), stderr.decode()
import logging
from datetime import datetime
import json
from concurrent.futures import ThreadPoolExecutor
import requests

class ElasticsearchHandler(logging.Handler):
    def __init__(self, elastic_url):
        super().__init__()
        self.elastic_url = elastic_url
        self.executor = ThreadPoolExecutor(max_workers=1)

    def emit(self, record):
        log_entry = self.format(record)
        self.executor.submit(self.send_to_elasticsearch, log_entry, record)

    def send_to_elasticsearch(self, log_entry, record):
        try:
            log_message = {
                "@timestamp": datetime.utcnow().isoformat(),
                "message": log_entry,
                "level": record.levelname,
                "logger_name": record.name
            }
            print(f"Sending log to Elasticsearch: {json.dumps(log_message, indent=2)}")  # Debug print
            response = requests.post(
                f"{self.elastic_url}/logs/_doc",  # Corrected URL
                headers={"Content-Type": "application/json"},
                json=log_message
            )
            response.raise_for_status()
        except requests.HTTPError as e:
            print(f"Failed to send log to Elasticsearch: {e.response.status_code} {e.response.reason}")
            print(f"Response content: {e.response.content}")
        except json.JSONDecodeError as e:
            print(f"JSON decoding error: {e}")
        except Exception as e:
            print(f"Unexpected error: {e}")

class CustomLogger:
    def __init__(self, settings):
        self.logger = logging.getLogger('custom_logger')
        if not self.logger.hasHandlers():
            self.logger.setLevel(settings.logging_level)
            formatter = logging.Formatter(settings.logging_format, style='{')

            if 'console' in settings.logging_sinks:
                console_handler = logging.StreamHandler()
                console_handler.setFormatter(formatter)
                self.logger.addHandler(console_handler)

            if 'file' in settings.logging_sinks:
                file_handler = logging.FileHandler('app.log')
                file_handler.setFormatter(formatter)
                self.logger.addHandler(file_handler)

            if 'elastic' in settings.logging_sinks:
                elastic_handler = ElasticsearchHandler(settings.elastic_url)
                elastic_handler.setFormatter(formatter)
                self.logger.addHandler(elastic_handler)

    def log(self, level, msg, *args, **kwargs):
        self.logger.log(level, msg, *args, **kwargs)

    def debug(self, msg, *args, **kwargs):
        self.logger.debug(msg, *args, **kwargs)

    def info(self, msg, *args, **kwargs):
        self.logger.info(msg, *args, **kwargs)

    def warning(self, msg, *args, **kwargs):
        self.logger.warning(msg, *args, **kwargs)

    def error(self, msg, *args, **kwargs):
        self.logger.error(msg, *args, **kwargs)

    def critical(self, msg, *args, **kwargs):
        self.logger.critical(msg, *args, **kwargs)

def get_logger(settings):
    return CustomLogger(settings)

def log_decorator(log_parameters=True):
    def decorator(func):
        async def wrapper(*args, **kwargs):
            logger = kwargs.get('logger', None)
            if not logger:
                logger = logging.getLogger('custom_logger')
                if not logger.hasHandlers():
                    logger.setLevel(logging.INFO)
                    console_handler = logging.StreamHandler()
                    formatter = logging.Formatter('{asctime} {message}', style='{')
                    console_handler.setFormatter(formatter)
                    logger.addHandler(console_handler)
            if log_parameters:
                params = {**kwargs}
            else:
                params = {}
            logger.info(f'Entering {func.__name__}')
            result = await func(*args, **kwargs)
            logger.info(f'Exiting {func.__name__}')
            return result
        return wrapper
    return decorator
import httpx
from fastapi import HTTPException
from command_service.services.logger import CustomLogger, log_decorator
from command_service.config.config import Settings
import logging
from command_service.models.register_request import RegisterRequest

class RegistrationService:
    def __init__(self, settings: Settings, logger: CustomLogger):
        self.settings = settings
        self.logger = logger

    @log_decorator()
    async def register_service(self):
        registration_data = RegisterRequest(
            service_name=self.settings.service_name,
            openapi_url=f'http://{self.settings.host}:{self.settings.port}/openapi.json'
        )

        timeout = httpx.Timeout(10.0, connect=10.0)  # Define timeout

        try:
            self.logger.log(logging.INFO, f'Registering service with the proxy...{registration_data.dict()}')
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(self.settings.proxy_url, json=registration_data.dict())
                response.raise_for_status()
            self.logger.log(logging.INFO, 'Service registered successfully with the proxy.')
        except httpx.RequestError as e:
            self.logger.log(logging.ERROR, f'Failed to register service with proxy: {e}')
            raise HTTPException(status_code=500, detail='Failed to register service with proxy')
, stderr: 
2024-08-01 21:21:31,241 custom_logger INFO Handling command: mkdir -p project-root/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .
2024-08-01 21:21:31,242 custom_logger INFO Running command: mkdir -p project-root/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .
2024-08-01 21:21:31,273 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:21:38,591 custom_logger INFO Handling command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .
2024-08-01 21:21:38,593 custom_logger INFO Running command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .
2024-08-01 21:21:38,671 custom_logger ERROR Command execution failed: touch: cannot touch 'project-root/command_service/Dockerfile': No such file or directory
touch: cannot touch 'project-root/websocket_listener_service/Dockerfile': No such file or directory
touch: cannot touch 'project-root/proxy_service/Dockerfile': No such file or directory
touch: cannot touch 'project-root/elasticsearch/command_service-elasticsearch.yaml': No such file or directory
touch: cannot touch 'project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/command_service-deployment.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/command_service-service.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/websocket_listener_service-deployment.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/websocket_listener_service-service.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/proxy_service-deployment.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/proxy_service-service.yaml': No such file or directory

2024-08-01 21:21:44,985 custom_logger INFO Handling command: mkdir -p project-root/command_service && mkdir -p project-root/websocket_listener_service && mkdir -p project-root/proxy_service && mkdir -p project-root/elasticsearch && mkdir -p project-root/kubernetes in path: .
2024-08-01 21:21:44,985 custom_logger INFO Running command: mkdir -p project-root/command_service && mkdir -p project-root/websocket_listener_service && mkdir -p project-root/proxy_service && mkdir -p project-root/elasticsearch && mkdir -p project-root/kubernetes in path: .
2024-08-01 21:21:45,027 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:21:52,720 custom_logger INFO Handling command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .
2024-08-01 21:21:52,721 custom_logger INFO Running command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .
2024-08-01 21:21:52,815 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:21:59,088 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8001\n\nCMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]' > project-root/command_service/Dockerfile in path: .
2024-08-01 21:21:59,088 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8001\n\nCMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]' > project-root/command_service/Dockerfile in path: .
2024-08-01 21:21:59,108 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:05,131 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8002\n\nCMD ["uvicorn", "websocket_listener_service.main:app", "--host", "0.0.0.0", "--port", "8002"]' > project-root/websocket_listener_service/Dockerfile in path: .
2024-08-01 21:22:05,132 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8002\n\nCMD ["uvicorn", "websocket_listener_service.main:app", "--host", "0.0.0.0", "--port", "8002"]' > project-root/websocket_listener_service/Dockerfile in path: .
2024-08-01 21:22:05,149 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:10,956 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8000\n\nCMD ["python", "proxy.py"]' > project-root/proxy_service/Dockerfile in path: .
2024-08-01 21:22:10,957 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8000\n\nCMD ["python", "proxy.py"]' > project-root/proxy_service/Dockerfile in path: .
2024-08-01 21:22:10,972 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:21,715 custom_logger INFO Handling command: echo 'version: "3.8"\n\nservices:\n  command_service:\n    build: ./command_service\n    ports:\n      - "8001:8001"\n    environment:\n      - ELASTIC_URL=http://command_service_elasticsearch:9200\n\n  websocket_listener_service:\n    build: ./websocket_listener_service\n    ports:\n      - "8002:8002"\n    environment:\n      - ELASTIC_URL=http://websocket_listener_elasticsearch:9200\n\n  proxy_service:\n    build: ./proxy_service\n    ports:\n      - "8000:8000"\n\n  command_service_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9201:9200"\n\n  websocket_listener_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9202:9200"' > project-root/docker-compose.yaml in path: .
2024-08-01 21:22:21,716 custom_logger INFO Running command: echo 'version: "3.8"\n\nservices:\n  command_service:\n    build: ./command_service\n    ports:\n      - "8001:8001"\n    environment:\n      - ELASTIC_URL=http://command_service_elasticsearch:9200\n\n  websocket_listener_service:\n    build: ./websocket_listener_service\n    ports:\n      - "8002:8002"\n    environment:\n      - ELASTIC_URL=http://websocket_listener_elasticsearch:9200\n\n  proxy_service:\n    build: ./proxy_service\n    ports:\n      - "8000:8000"\n\n  command_service_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9201:9200"\n\n  websocket_listener_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9202:9200"' > project-root/docker-compose.yaml in path: .
2024-08-01 21:22:21,738 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:29,112 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: ELASTIC_URL\n          value: "http://command-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > project-root/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:22:29,113 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: ELASTIC_URL\n          value: "http://command-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > project-root/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:22:29,128 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:39,284 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: ELASTIC_URL\n          value: "http://websocket-listener-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > project-root/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:22:39,285 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: ELASTIC_URL\n          value: "http://websocket-listener-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > project-root/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:22:39,303 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:48,742 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: proxy-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-service\n  template:\n    metadata:\n      labels:\n        app: proxy-service\n    spec:\n      containers:\n      - name: proxy-service\n        image: your_dockerhub_username/proxy-service:latest\n        ports:\n        - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: proxy-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8000\n    targetPort: 8000\n  selector:\n    app: proxy-service' > project-root/kubernetes/proxy_service-deployment.yaml in path: .
2024-08-01 21:22:48,743 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: proxy-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-service\n  template:\n    metadata:\n      labels:\n        app: proxy-service\n    spec:\n      containers:\n      - name: proxy-service\n        image: your_dockerhub_username/proxy-service:latest\n        ports:\n        - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: proxy-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8000\n    targetPort: 8000\n  selector:\n    app: proxy-service' > project-root/kubernetes/proxy_service-deployment.yaml in path: .
2024-08-01 21:22:48,762 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:59,181 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: command-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: command-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: command-service-elasticsearch' > project-root/elasticsearch/command_service-elasticsearch.yaml in path: .
2024-08-01 21:22:59,182 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: command-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: command-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: command-service-elasticsearch' > project-root/elasticsearch/command_service-elasticsearch.yaml in path: .
2024-08-01 21:22:59,198 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:23:08,323 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: websocket-listener-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: websocket-listener-service-elasticsearch' > project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml in path: .
2024-08-01 21:23:08,324 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: websocket-listener-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: websocket-listener-service-elasticsearch' > project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml in path: .
2024-08-01 21:23:08,341 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:28:33,963 custom_logger INFO Handling command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} && mv project-root/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && mv project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && mv project-root/elasticsearch/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/ && mv project-root/kubernetes/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/ in path: .
2024-08-01 21:28:33,964 custom_logger INFO Running command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} && mv project-root/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && mv project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && mv project-root/elasticsearch/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/ && mv project-root/kubernetes/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/ in path: .
2024-08-01 21:28:34,107 custom_logger ERROR Command execution failed: mv: cannot move 'project-root/proxy_service' to '/mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service': Directory not empty
mv: cannot move 'project-root/websocket_listener_service' to '/mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service': Directory not empty

2024-08-01 21:28:42,785 custom_logger INFO Handling command: cp -r project-root/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && cp project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && cp -r project-root/elasticsearch/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/ && cp -r project-root/kubernetes/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/ in path: .
2024-08-01 21:28:42,786 custom_logger INFO Running command: cp -r project-root/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && cp project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && cp -r project-root/elasticsearch/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/ && cp -r project-root/kubernetes/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/ in path: .
2024-08-01 21:28:42,888 custom_logger ERROR Command execution failed: cp: cannot stat 'project-root/docker-compose.yaml': No such file or directory

2024-08-01 21:28:47,503 custom_logger INFO Handling command: cp project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ in path: .
2024-08-01 21:28:47,504 custom_logger INFO Running command: cp project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ in path: .
2024-08-01 21:28:47,517 custom_logger ERROR Command execution failed: cp: cannot stat 'project-root/docker-compose.yaml': No such file or directory

2024-08-01 21:29:24,708 custom_logger INFO Handling command: cp project-root/command_service/Dockerfile /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 21:29:24,709 custom_logger INFO Running command: cp project-root/command_service/Dockerfile /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 21:29:24,725 custom_logger ERROR Command execution failed: cp: cannot stat 'project-root/command_service/Dockerfile': No such file or directory

2024-08-01 21:29:37,007 custom_logger INFO Handling command: ls -R project-root in path: .
2024-08-01 21:29:37,008 custom_logger INFO Running command: ls -R project-root in path: .
2024-08-01 21:29:37,039 custom_logger INFO Command succeeded: stdout: project-root:
proxy_service
websocket_listener_service

project-root/proxy_service:
Dockerfile

project-root/websocket_listener_service:
Dockerfile
, stderr: 
2024-08-01 21:31:51,786 custom_logger INFO Handling command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .
2024-08-01 21:31:51,787 custom_logger INFO Running command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .
2024-08-01 21:31:51,805 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:31:58,626 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8001\n\nCMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 21:31:58,626 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8001\n\nCMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 21:31:58,641 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:05,196 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8002\n\nCMD ["uvicorn", "websocket_listener_service.main:app", "--host", "0.0.0.0", "--port", "8002"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/Dockerfile in path: .
2024-08-01 21:32:05,197 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8002\n\nCMD ["uvicorn", "websocket_listener_service.main:app", "--host", "0.0.0.0", "--port", "8002"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/Dockerfile in path: .
2024-08-01 21:32:05,216 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:11,481 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8000\n\nCMD ["python", "proxy.py"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/Dockerfile in path: .
2024-08-01 21:32:11,481 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8000\n\nCMD ["python", "proxy.py"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/Dockerfile in path: .
2024-08-01 21:32:11,498 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:22,344 custom_logger INFO Handling command: echo 'version: "3.8"\n\nservices:\n  command_service:\n    build: ./command_service\n    ports:\n      - "8001:8001"\n    environment:\n      - ELASTIC_URL=http://command_service_elasticsearch:9200\n\n  websocket_listener_service:\n    build: ./websocket_listener_service\n    ports:\n      - "8002:8002"\n    environment:\n      - ELASTIC_URL=http://websocket_listener_elasticsearch:9200\n\n  proxy_service:\n    build: ./proxy_service\n    ports:\n      - "8000:8000"\n\n  command_service_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9201:9200"\n\n  websocket_listener_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9202:9200"' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/docker-compose.yaml in path: .
2024-08-01 21:32:22,345 custom_logger INFO Running command: echo 'version: "3.8"\n\nservices:\n  command_service:\n    build: ./command_service\n    ports:\n      - "8001:8001"\n    environment:\n      - ELASTIC_URL=http://command_service_elasticsearch:9200\n\n  websocket_listener_service:\n    build: ./websocket_listener_service\n    ports:\n      - "8002:8002"\n    environment:\n      - ELASTIC_URL=http://websocket_listener_elasticsearch:9200\n\n  proxy_service:\n    build: ./proxy_service\n    ports:\n      - "8000:8000"\n\n  command_service_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9201:9200"\n\n  websocket_listener_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9202:9200"' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/docker-compose.yaml in path: .
2024-08-01 21:32:22,359 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:32,737 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: ELASTIC_URL\n          value: "http://command-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:32:32,738 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: ELASTIC_URL\n          value: "http://command-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:32:32,755 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:43,197 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: ELASTIC_URL\n          value: "http://websocket-listener-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:32:43,198 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: ELASTIC_URL\n          value: "http://websocket-listener-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:32:43,213 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:51,264 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: proxy-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-service\n  template:\n    metadata:\n      labels:\n        app: proxy-service\n    spec:\n      containers:\n      - name: proxy-service\n        image: your_dockerhub_username/proxy-service:latest\n        ports:\n        - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: proxy-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8000\n    targetPort: 8000\n  selector:\n    app: proxy-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/proxy_service-deployment.yaml in path: .
2024-08-01 21:32:51,265 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: proxy-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-service\n  template:\n    metadata:\n      labels:\n        app: proxy-service\n    spec:\n      containers:\n      - name: proxy-service\n        image: your_dockerhub_username/proxy-service:latest\n        ports:\n        - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: proxy-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8000\n    targetPort: 8000\n  selector:\n    app: proxy-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/proxy_service-deployment.yaml in path: .
2024-08-01 21:32:51,279 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:59,660 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: command-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: command-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: command-service-elasticsearch' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/command_service-elasticsearch.yaml in path: .
2024-08-01 21:32:59,662 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: command-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: command-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: command-service-elasticsearch' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/command_service-elasticsearch.yaml in path: .
2024-08-01 21:32:59,682 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:33:09,495 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: websocket-listener-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: websocket-listener-service-elasticsearch' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/websocket_listener_service-elasticsearch.yaml in path: .
2024-08-01 21:33:09,496 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: websocket-listener-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: websocket-listener-service-elasticsearch' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/websocket_listener_service-elasticsearch.yaml in path: .
2024-08-01 21:33:09,512 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:36:11,710 custom_logger INFO Handling command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts && echo '#!/bin/bash\n\n# Set your Docker Hub username\nDOCKER_HUB_USERNAME="your_dockerhub_username"\n\n# Build Docker images\ndocker build -t $DOCKER_HUB_USERNAME/command-service:latest ./command_service\ndocker build -t $DOCKER_HUB_USERNAME/websocket-listener-service:latest ./websocket_listener_service\ndocker build -t $DOCKER_HUB_USERNAME/proxy-service:latest ./proxy_service\n\n# Push Docker images to Docker Hub\ndocker push $DOCKER_HUB_USERNAME/command-service:latest\ndocker push $DOCKER_HUB_USERNAME/websocket-listener-service:latest\ndocker push $DOCKER_HUB_USERNAME/proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh in path: .
2024-08-01 21:36:11,711 custom_logger INFO Running command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts && echo '#!/bin/bash\n\n# Set your Docker Hub username\nDOCKER_HUB_USERNAME="your_dockerhub_username"\n\n# Build Docker images\ndocker build -t $DOCKER_HUB_USERNAME/command-service:latest ./command_service\ndocker build -t $DOCKER_HUB_USERNAME/websocket-listener-service:latest ./websocket_listener_service\ndocker build -t $DOCKER_HUB_USERNAME/proxy-service:latest ./proxy_service\n\n# Push Docker images to Docker Hub\ndocker push $DOCKER_HUB_USERNAME/command-service:latest\ndocker push $DOCKER_HUB_USERNAME/websocket-listener-service:latest\ndocker push $DOCKER_HUB_USERNAME/proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh in path: .
2024-08-01 21:36:11,747 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:36:17,133 custom_logger INFO Handling command: echo '#!/bin/bash\n\n# Apply Elasticsearch deployments\nkubectl apply -f ./elasticsearch/command_service-elasticsearch.yaml\nkubectl apply -f ./elasticsearch/websocket_listener_service-elasticsearch.yaml\n\n# Apply service deployments\nkubectl apply -f ./kubernetes/command_service-deployment.yaml\nkubectl apply -f ./kubernetes/websocket_listener_service-deployment.yaml\nkubectl apply -f ./kubernetes/proxy_service-deployment.yaml\n\n# List all pods and services to verify\nkubectl get pods\nkubectl get services' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/deploy_k8s.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/deploy_k8s.sh in path: .
2024-08-01 21:36:17,134 custom_logger INFO Running command: echo '#!/bin/bash\n\n# Apply Elasticsearch deployments\nkubectl apply -f ./elasticsearch/command_service-elasticsearch.yaml\nkubectl apply -f ./elasticsearch/websocket_listener_service-elasticsearch.yaml\n\n# Apply service deployments\nkubectl apply -f ./kubernetes/command_service-deployment.yaml\nkubectl apply -f ./kubernetes/websocket_listener_service-deployment.yaml\nkubectl apply -f ./kubernetes/proxy_service-deployment.yaml\n\n# List all pods and services to verify\nkubectl get pods\nkubectl get services' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/deploy_k8s.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/deploy_k8s.sh in path: .
2024-08-01 21:36:17,155 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:36:24,436 custom_logger INFO Handling command: echo 'import requests\n\n# Replace with the actual IPs of your deployed services\nproxy_service_ip = "PROXY_SERVICE_IP"\ncommand_service_ip = "COMMAND_SERVICE_IP"\nwebsocket_listener_service_ip = "WEBSOCKET_LISTENER_SERVICE_IP"\n\n# URLs for registration\nregister_url = f"http://{proxy_service_ip}:8000/register"\n\n# Service data\nservices = [\n    {\n        "service_name": "command-service",\n        "openapi_url": f"http://{command_service_ip}:8001/openapi.json"\n    },\n    {\n        "service_name": "websocket-listener-service",\n        "openapi_url": f"http://{websocket_listener_service_ip}:8002/openapi.json"\n    }\n]\n\n# Register each service\nfor service_data in services:\n    response = requests.post(register_url, json=service_data)\n    print(f"Registering {service_data['service_name']}: {response.json()}")' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/register_services.py in path: .
2024-08-01 21:36:24,437 custom_logger INFO Running command: echo 'import requests\n\n# Replace with the actual IPs of your deployed services\nproxy_service_ip = "PROXY_SERVICE_IP"\ncommand_service_ip = "COMMAND_SERVICE_IP"\nwebsocket_listener_service_ip = "WEBSOCKET_LISTENER_SERVICE_IP"\n\n# URLs for registration\nregister_url = f"http://{proxy_service_ip}:8000/register"\n\n# Service data\nservices = [\n    {\n        "service_name": "command-service",\n        "openapi_url": f"http://{command_service_ip}:8001/openapi.json"\n    },\n    {\n        "service_name": "websocket-listener-service",\n        "openapi_url": f"http://{websocket_listener_service_ip}:8002/openapi.json"\n    }\n]\n\n# Register each service\nfor service_data in services:\n    response = requests.post(register_url, json=service_data)\n    print(f"Registering {service_data['service_name']}: {response.json()}")' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/register_services.py in path: .
2024-08-01 21:36:24,452 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:37:59,537 custom_logger INFO Handling command: chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/*.sh in path: .
2024-08-01 21:37:59,538 custom_logger INFO Running command: chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/*.sh in path: .
2024-08-01 21:37:59,579 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:38:13,141 custom_logger INFO Handling command: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh in path: .
2024-08-01 21:38:13,142 custom_logger INFO Running command: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh in path: .
2024-08-01 21:38:18,751 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:db41bd8f062c8404feb0e0533da63a7047e751b8aa3c36e907910201de372cbb
#1 transferring context: 0.0s
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:f06f12159254c9d920b7f602e89d329089a53d8470fb7b75c61a657c3ab89f64
#2 transferring dockerfile: 2B 0.1s done
#2 DONE 0.1s
failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount4101396976/Dockerfile: no such file or directory
unable to prepare context: path "./websocket_listener_service" not found
unable to prepare context: path "./proxy_service" not found
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 21:42:16,479 custom_logger INFO Handling command: echo 'import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("COMMAND_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "command-service",
        "openapi_url": f"http://{service_ip}:8001/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering command-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8001)' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 21:42:16,480 custom_logger INFO Running command: echo 'import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("COMMAND_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "command-service",
        "openapi_url": f"http://{service_ip}:8001/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering command-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8001)' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 21:42:16,502 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:42:24,344 custom_logger INFO Handling command: echo 'import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("WEBSOCKET_LISTENER_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "websocket-listener-service",
        "openapi_url": f"http://{service_ip}:8002/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering websocket-listener-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8002)' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/main.py in path: .
2024-08-01 21:42:24,346 custom_logger INFO Running command: echo 'import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("WEBSOCKET_LISTENER_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "websocket-listener-service",
        "openapi_url": f"http://{service_ip}:8002/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering websocket-listener-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8002)' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/main.py in path: .
2024-08-01 21:42:24,369 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:42:33,025 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: PROXY_SERVICE_IP\n          value: "proxy_service_ip"  # Replace with actual proxy service IP\n        - name: COMMAND_SERVICE_IP\n          value: "command_service_ip"  # Replace with actual command service IP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:42:33,026 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: PROXY_SERVICE_IP\n          value: "proxy_service_ip"  # Replace with actual proxy service IP\n        - name: COMMAND_SERVICE_IP\n          value: "command_service_ip"  # Replace with actual command service IP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:42:33,041 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:42:40,789 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: PROXY_SERVICE_IP\n          value: "proxy_service_ip"  # Replace with actual proxy service IP\n        - name: WEBSOCKET_LISTENER_SERVICE_IP\n          value: "websocket_listener_service_ip"  # Replace with actual websocket listener service IP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:42:40,790 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: PROXY_SERVICE_IP\n          value: "proxy_service_ip"  # Replace with actual proxy service IP\n        - name: WEBSOCKET_LISTENER_SERVICE_IP\n          value: "websocket_listener_service_ip"  # Replace with actual websocket listener service IP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:42:40,806 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:43:14,095 custom_logger INFO Handling command: ./scripts/build_push_images.sh your_dockerhub_username in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 21:43:14,096 custom_logger INFO Running command: ./scripts/build_push_images.sh your_dockerhub_username in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 21:44:06,431 custom_logger ERROR Command execution failed: #2 [internal] load .dockerignore
#2 sha256:423cc67d4594ec90a9f3d63675645b422ecb34359dbe4161f0b992c07138af81
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:fc0080760fbb2b12137730fe25c34e850d010d557df314d41426af69088506c8
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 2.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 resolve docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104 0.0s done
#4 ...

#6 [internal] load build context
#6 sha256:b130204185fdff5df7c18f5079c00102f5e97631394ef674f7b0fb54ecf4ecd2
#6 transferring context: 935B 0.0s done
#6 DONE 0.1s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 0B / 11.67MB 0.1s
#4 sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104 10.41kB / 10.41kB done
#4 sha256:b2d6266a63eafff4fcee6a9149b80686ff6c17b0e4556d0320198ce85e9aa41d 1.94kB / 1.94kB done
#4 sha256:5208c64e1783e15b2d0ee357a3979688ae3faa21c6a43f4965e3530d68abbcfc 6.93kB / 6.93kB done
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 0B / 29.13MB 0.1s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 0B / 3.51MB 0.1s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 2.10MB / 29.13MB 1.7s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 1.05MB / 11.67MB 2.2s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 4.19MB / 29.13MB 2.8s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 2.10MB / 11.67MB 3.1s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 1.05MB / 3.51MB 3.4s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 3.15MB / 11.67MB 4.4s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 1.61MB / 3.51MB 5.0s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 5.80MB / 29.13MB 5.2s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 2.10MB / 3.51MB 5.2s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 4.19MB / 11.67MB 5.5s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 7.34MB / 29.13MB 6.2s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 5.24MB / 11.67MB 6.7s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 3.13MB / 3.51MB 6.7s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 3.51MB / 3.51MB 7.2s done
#4 sha256:e5635d0cdd4c514a4e76d97174785a452a1e81b87b6a8bd8ce09c5ac2d135df8 0B / 230B 7.4s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 5.97MB / 11.67MB 7.7s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 9.44MB / 29.13MB 7.7s
#4 sha256:e5635d0cdd4c514a4e76d97174785a452a1e81b87b6a8bd8ce09c5ac2d135df8 230B / 230B 7.7s done
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 0B / 2.78MB 7.9s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 6.86MB / 11.67MB 9.2s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 11.53MB / 29.13MB 9.6s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 327.68kB / 2.78MB 10.0s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 1.05MB / 2.78MB 10.1s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 7.73MB / 11.67MB 10.5s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 8.39MB / 11.67MB 10.7s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 13.45MB / 29.13MB 11.8s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 1.79MB / 2.78MB 11.9s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 9.44MB / 11.67MB 12.1s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 2.10MB / 2.78MB 12.1s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 2.53MB / 2.78MB 12.5s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 2.78MB / 2.78MB 12.5s done
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 10.49MB / 11.67MB 13.0s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 15.12MB / 29.13MB 13.3s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 16.78MB / 29.13MB 14.1s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 11.49MB / 11.67MB 14.2s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 11.67MB / 11.67MB 14.5s done
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 18.70MB / 29.13MB 15.3s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 20.97MB / 29.13MB 16.3s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 22.95MB / 29.13MB 17.2s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 25.17MB / 29.13MB 17.9s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 27.17MB / 29.13MB 18.8s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 29.13MB / 29.13MB 19.7s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 29.13MB / 29.13MB 19.7s done
#4 extracting sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559
#4 extracting sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 5.1s
#4 extracting sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 7.3s done
#4 extracting sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962
#4 extracting sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 0.8s done
#4 extracting sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742
#4 extracting sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 2.7s done
#4 extracting sha256:e5635d0cdd4c514a4e76d97174785a452a1e81b87b6a8bd8ce09c5ac2d135df8
#4 extracting sha256:e5635d0cdd4c514a4e76d97174785a452a1e81b87b6a8bd8ce09c5ac2d135df8 done
#4 extracting sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83
#4 extracting sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 0.8s done
#4 DONE 33.6s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 DONE 0.4s

#7 [3/4] COPY . /app
#7 sha256:9f21875d8b39616c573241ac46a74685e5094a3ebf7e351a968c7c32441fbf72
#7 DONE 0.1s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:52251284d6827448d91ce633f992d9f93fcbc39e4dac298e5e87b71f88c5b6e1
#8 3.653 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.282 
#8 4.282 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.282 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load build definition from Dockerfile
#1 sha256:ca3625be8ec35e90e43295b9e178e444af6df72454e4c41568a9f8f1272ff15e
#1 transferring dockerfile: 253B 0.0s done
#1 DONE 0.1s

#2 [internal] load .dockerignore
#2 sha256:bf7ac910a2ed1318fb8a6742850e2d16fa432f8e6a2551468131c5d5ba9830c1
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:fb4e1aacf3a129eddb86bd98eb8cf8e5d17c729c19f3ea9dd8e925f44b9c02c8
#6 transferring context: 48.53kB 0.3s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:f8a120ccf27ee1c14f8ab40b00e8d6497dff9a96b644f45f4db84de90ede15ee
#7 DONE 0.1s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:c5339b00101dfc2d184ac1b582e2fe7e11126c1c63b26e17d245f92b22821fd6
#8 3.301 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.898 
#8 3.898 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.898 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:d22a5ace0a37f5c6fc42b1e4fc4ee74be977a3556bf876b63794f736a7a4533a
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:6361b1b40c73f15fae1929c1c946120dd1f2306d84fce6745b27087a92e829ff
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:562fbb7c0808ee16a3fc3c927ebc9d60f0d9ada518d3e7dd7d056085a7ab7e68
#6 transferring context: 5.87kB 0.0s done
#6 DONE 0.1s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:e8001d0ea1700be1b0a144e09060cc8b4526b293699c4d90ecd9ee74dc5c2c3e
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:3c76002cb7e4ac8ce83b2b3e89e32ebc8c933fbe2f4ba477b38a3661454db6e1
#8 3.513 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.120 
#8 4.120 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.120 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 21:45:48,181 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 21:45:48,182 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 21:46:04,472 custom_logger ERROR Command execution failed: #2 [internal] load .dockerignore
#2 sha256:630262fea31749448d87e24dc4d65a347a0557714e7b44489272cc216f34b9e6
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:4947e7d568436d7b51da711a41a6c052092395f5d233833f4feefa7b27ddecc6
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.6s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:8f41802c4e99619783e24e0fa5337ea167954cf20ea5fc8bd98d6561169cf4bb
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:0b5b2af9f340a3733cb0e9955f74cd89d99dc285c1a51019b246a1edfd0e8d89
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:00c69a3eca9aa9163c99f87e483a773c847561b8afd8618a1af27b5d08e240ff
#8 3.184 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.807 
#8 3.807 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.807 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:d7f97c40f684cfa90c828f8b74a0ac070e4d34db7f09b885cf84d986467ccf4c
#2 transferring context: 2B 0.1s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:811dca8d5a3e20c1f2c7fba2fa73fcb7d766db02c861bbd9b47089b32a615db9
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:987e56e8ae8dd8cf955d3b51b7a6580c8c39fa5a1c1b8e7ea29d18875a8338da
#6 transferring context: 2.27kB 0.3s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:317127f22f3d8db302254194917d0c2a2ed76bf538fb128d983fc9eeef2b1973
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:449e8f1593e75134d66e7b0428646e86303a8bf6d3578ab33ab609fef0cc98a8
#8 3.479 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.140 
#8 4.140 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.140 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:42d3d1f3da7369af3d4657adc634291032eba8665dc9fc7012d9795d32f31fa2
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:a3b73180b2b766ac9dae983214f3495e4ae6f4b1a3c7e3361bce67a38033ab51
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:95dbad62ff19fc2bbfadbb8b8d14ae6f7ef1e8382be3817ebabc3932f39f13b1
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:9d05ecec2f1f7982f0f3c89ba5e2e3f5695d4d16c34df38ecc46798dab023638
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:396a46027ae0b96da1833e573092a1b5d1628cc68609ec7578f0a6a5f97b022e
#8 3.446 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.084 
#8 4.084 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.084 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 21:47:55,334 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:47:55,366 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/proxy-service-logs/_search
2024-08-01 21:48:06,420 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:48:06,431 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/proxy-service-logs/_search
2024-08-01 21:48:19,681 custom_logger INFO Handling command: curl -X GET 'http://localhost:9200/_cat/indices?v' in path: .
2024-08-01 21:48:19,682 custom_logger INFO Running command: curl -X GET 'http://localhost:9200/_cat/indices?v' in path: .
2024-08-01 21:48:19,792 custom_logger ERROR Command execution failed:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   448  100   448    0     0   9142      0 --:--:-- --:--:-- --:--:--  9333

2024-08-01 21:48:28,665 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:48:28,674 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/logs/_search
2024-08-01 21:48:37,488 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:48:37,576 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/logs/_search
2024-08-01 21:48:45,806 custom_logger INFO Handling command: curl -X GET 'http://localhost:9200/logs/_search?pretty' -H 'Content-Type: application/json' -d'{"query":{"match_all":{}}}' in path: .
2024-08-01 21:48:45,807 custom_logger INFO Running command: curl -X GET 'http://localhost:9200/logs/_search?pretty' -H 'Content-Type: application/json' -d'{"query":{"match_all":{}}}' in path: .
2024-08-01 21:48:45,998 custom_logger ERROR Command execution failed:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  4194  100  4168  100    26  23817    148 --:--:-- --:--:-- --:--:-- 23965

2024-08-01 21:52:06,069 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:52:06,084 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/logs/_search
2024-08-01 21:58:58,293 custom_logger INFO Handling command: curl -X GET 'http://localhost:9200/_cluster/health?pretty' in path: .
2024-08-01 21:58:58,294 custom_logger INFO Running command: curl -X GET 'http://localhost:9200/_cluster/health?pretty' in path: .
2024-08-01 21:58:58,375 custom_logger ERROR Command execution failed:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   480  100   480    0     0   7868      0 --:--:-- --:--:-- --:--:--  7868

2024-08-01 21:59:12,146 custom_logger INFO Handling command: curl -X GET 'http://localhost:9200/logs/_mapping?pretty' in path: .
2024-08-01 21:59:12,147 custom_logger INFO Running command: curl -X GET 'http://localhost:9200/logs/_mapping?pretty' in path: .
2024-08-01 21:59:12,171 custom_logger ERROR Command execution failed:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   813  100   813    0     0   113k      0 --:--:-- --:--:-- --:--:--  113k

2024-08-01 22:01:02,356 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:01:02,357 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:01:19,232 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:f18e91c5538985998a0e79bc653712a371b083408d2429ed661e2d15a0b62121
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:6845d955862e2a92e3513dabd7dd7b28e95ccd557764850340cddd4e319a9af8
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 1.2s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:052075bca5b5baa98a4e53aa0c634cf7f88a13d03ff5f0d213078e9fdc1c9973
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:7b8241d9abab545c2d0cb471b4c7b045a48334f43e6860052766051716eea4ea
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:e0444e66612f2cfcf6a3c15208232456b58df6ffc7bbfdc1ef15744eca46cb03
#8 3.224 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.839 
#8 3.839 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.839 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:8537b0b67ab15ff344bb1b2ea912075b128be51621795c8ba4ad213032d1eb11
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:af4a88677f5b1c960856aba733233325a970369db630ae88b872a78172246067
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:728d9acb348cc568ba4e551c767a806b2bdf0ceb4e936da03a62a5ebc03e86e5
#6 transferring context: 2.27kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:76be8553a3a1429a36c6b8976c00566cea633b76f9c982d5e7961d311f373363
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:35de6ff426b7e3a5e510120171d66354b1d4412a32afddc58af5bfda57bfbedb
#8 3.622 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.239 
#8 4.239 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.239 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:0e1c5c798cbf61542b7a865c97742854a1f031fb65b92087b9d3b1ccf13d00fe
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:d6bea577fbaa6096d66c294fa68c433a1765044dcd93d6f756641f878c31e49b
#1 transferring dockerfile: 186B 0.0s done
#1 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:ae163c6f049c144ea09b38a85a5f43e2c4253f62f03c8f76557b9cc37c3e2380
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:8b381885217b81909d209da3cd8b6a86e18e1f3f3e5cb4db8f0f8e1a651f99a4
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:4731ca212e5be7332e6a5a8504ab7f92a3250dd2f3705a6c081d9f711b31e5c9
#8 3.453 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.093 
#8 4.093 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.093 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:01:31,323 custom_logger INFO Handling command: kubectl logs <command-service-pod-name> in path: .
2024-08-01 22:01:31,324 custom_logger INFO Running command: kubectl logs <command-service-pod-name> in path: .
2024-08-01 22:01:31,336 custom_logger ERROR Command execution failed: /bin/sh: 1: Syntax error: end of file unexpected

2024-08-01 22:01:41,393 custom_logger INFO Handling command: kubectl get pods --selector=app=command-service -o jsonpath='{.items[0].metadata.name}' in path: .
2024-08-01 22:01:41,393 custom_logger INFO Running command: kubectl get pods --selector=app=command-service -o jsonpath='{.items[0].metadata.name}' in path: .
2024-08-01 22:01:41,766 custom_logger ERROR Command execution failed: error: the server doesn't have a resource type "pods"

2024-08-01 22:01:51,872 custom_logger INFO Handling command: kubectl config current-context in path: .
2024-08-01 22:01:51,873 custom_logger INFO Running command: kubectl config current-context in path: .
2024-08-01 22:01:51,967 custom_logger ERROR Command execution failed: error: current-context is not set

2024-08-01 22:02:05,323 custom_logger INFO Handling command: kubectl config get-contexts in path: .
2024-08-01 22:02:05,324 custom_logger INFO Running command: kubectl config get-contexts in path: .
2024-08-01 22:02:05,411 custom_logger INFO Command succeeded: stdout: CURRENT   NAME   CLUSTER   AUTHINFO   NAMESPACE
, stderr: 
2024-08-01 22:06:07,185 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:06:07,185 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:06:28,581 custom_logger ERROR Command execution failed: #2 [internal] load .dockerignore
#2 sha256:5e7a113dd5ec9d1f55632e31c5b84b8712b868e83670a274eec6d168203e0e7d
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:cb392bc8a55e29d4dc5da53d2c8c83ad1d1e252d3c7ad8d4d485cb3b30fbf6d0
#1 transferring dockerfile: 242B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 4.0s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:6353394908da1e252fdcd8c6fffce9f89b28b2faa3c8cb06ce923708aba7ac2a
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:c6721b9061f97ebf1f02fc62db9c842adb35ea4cf5a36812c426109f665ea3ea
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:c23a8c0fb23c28b3ac2f4f9a343457833cc0c02873778dc794fc7a6d6710f301
#8 3.371 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.054 
#8 4.054 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.054 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load build definition from Dockerfile
#1 sha256:eb3a722e028ab9e8b2ba9dd21d2883ad63aed1d6777e9e1fb5886cde80f0230c
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#2 [internal] load .dockerignore
#2 sha256:52df5267bfd28b37a8f6da8c2fe91e6330e184e8428fb2cdf845850c499bb4d4
#2 transferring context: 2B 0.1s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:2b6ffce933a2dbfc22cc7ad949a7542a27bab20399d69976122ad518fb9698d6
#6 transferring context: 2.27kB 0.5s done
#6 DONE 0.5s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:25e4786e30149e61fe2f9092a25244cef189a11d47c9ae1a6cd28f887b404fbd
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:ed3700e1e267ddb9834fae9022f0bbdce264379f1c28c18c280a024754165244
#8 3.745 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.448 
#8 4.448 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.448 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:8da12fca767239d10942d8e3145f75d4f3468f381902802cfec9685659488217
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:986bd6c4b34a6368c881f9ba68562ad10843820d17a8a5166ec8f614e25c994c
#1 transferring dockerfile: 186B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:f707259fc9e03faf93990821207f984115b439f173ef4614149011a281e3ba0c
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:b7ee4ba630e8fb030edb3049f1fe3673da6a039d560a73fa5b9d837443eba973
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:213b7d834a00799cc379ad433b4281c5c882df5dbc219bd1854b956a6c6bfff7
#8 4.280 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.978 
#8 4.978 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.978 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:06:55,847 custom_logger INFO Handling command: docker images | grep hypntranz in path: .
2024-08-01 22:06:55,848 custom_logger INFO Running command: docker images | grep hypntranz in path: .
2024-08-01 22:06:56,036 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:07:19,175 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:07:19,175 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:07:41,406 custom_logger ERROR Command execution failed: #2 [internal] load .dockerignore
#2 sha256:90d7ad369f74fb7a3fd75ff7987d27dcb180a88ee5fcbc6da7fce7dc24ff20f5
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:c569aae4671dee546a4296b96c0a22842d228f4eb5be700da936e42f592bd332
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:7900752096230a5618fae0b04a509556909d579aca2eeec20f16d8ae2cae0204
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:04b1af1129ed68acb886ac4ed5a970fb10413624c1c06a04012bf375d62efc82
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:84393d1091c0ac3c58c7535adba426cc79676327d46ded88a56d34c5b1493941
#8 3.110 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.803 
#8 3.803 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.803 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:bf8f3e70c4a20c2c9427339604024390e0c5665dbbb87197ea23d97545e8fb71
#1 transferring context: 2B 0.1s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:fbe274ec89b5b8bd136f9cf017090274cc9e1565f58ede15c5f5e0818921a141
#2 transferring dockerfile: 253B 0.1s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:5a1bb0209555c4591ce67112662b57d56f4b915f9de497813208bb7a9e1c96c3
#6 transferring context: 2.27kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:197f01f98d500ef18a83130dfc030f6796f4000d52a32b19cf5cb37a664593ee
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:8c3af48c46c5adb0da055712fe6badaf1413ab81cad6b947a3d5187ac3ea8e35
#8 3.372 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.020 
#8 4.020 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.020 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:b88e3f1d965287bf1211f235bce6349df48a8312862ea73bca144d7bf6ae378b
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:13be310dba8a93602a475c0ead6abb40fb2f3c334847b7b8a715102ae0bbd763
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:5afd212eccf032e960b0585058b770cc42c9776d04c32333cc3f1554591af2ac
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:33bc160a92cc917c614ae2f523bd3d1e9ad39612cf6f70b573f0eebc90ecb44a
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:ef46e43119f7408ca8cee91572f08e26065c81015c2299a35541b50e0a356054
#8 3.666 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.343 
#8 4.343 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.343 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:08:05,750 custom_logger INFO Handling command: docker images | grep hypntranz in path: .
2024-08-01 22:08:05,751 custom_logger INFO Running command: docker images | grep hypntranz in path: .
2024-08-01 22:08:05,901 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:08:27,198 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:08:27,199 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:08:49,053 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:ffd1a31752015b24e34dae2d881b0f054ca70c6632245120ad42686b0650a423
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:294ab6da5c36d63cf00e3491db738c158cabb8eff6e6531f0a1997d33c363ad1
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:329131d5bb00611042d0ab4a354a0567027c0c6e7f8a479b1d38baf473129bb5
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:c7d5522303e493ecf9d45b578528e70595983d070ee6b47158abe2407a780a0c
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:9519823bf186326b4122c4aba29ff2f309729ce90b235d62a8cbff46ab6b9f77
#8 3.190 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.165 
#8 4.165 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.165 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:8794b4ea2a31ce6c7dca5a93e19a8419e4daeec9a00ac68f30e5aca198c326cc
#2 transferring context: 2B 0.1s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:e19813218a5f83981247f74a62e40f8652ca7ffad84bf9cd4aaa654902f0e7d3
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:608bfee4eeaf14e5785a31c88a944fa034b435a6c16c30af8cd0f9de9af9ea04
#6 transferring context: 2.27kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:f5f11257e98aac9b8dc4a48e7585b84375c5d8008de97e1333a4ea4f65b8f169
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:1f656c8f8a8f4050306bdc280e5df1839fae55e58632028611a8a7bf71cddfbc
#8 3.601 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.208 
#8 4.208 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.208 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:cecdd80cd90a701b7ed8b37650bade5535fd33a6d8e12e3524b7bacf349c5355
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:20f29ea23de27b6143c7fa750ff0a770f09f033c8bc89d2a22870ebf3f60ce39
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:97355ae13efb62d39cf4e4ec9faebc05909c3b86e013f499e1cdf2b6739dabeb
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:2efe6a4d5ae350f2a71e057555bf1f033ed9e42b90d4bbeb96742a8f305a0819
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:27d845f07b01cbdc8e0a445ae9d76de4a22d36f578a5e5fd1ce7ff332067e143
#8 3.012 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.605 
#8 3.605 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.605 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:09:04,952 custom_logger INFO Handling command: docker images | grep hypntranz in path: .
2024-08-01 22:09:04,960 custom_logger INFO Running command: docker images | grep hypntranz in path: .
2024-08-01 22:09:05,113 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:09:24,188 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:09:24,189 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:09:39,229 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:8bcae1c3ab341f8646b1b6d42173ec223ee2ca52331f58bdabbfaee73de69c37
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:6fd19992cdbba5c6991843b8d15218ecff8dc63ea2dbdf60b9ceeff355f30184
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:3b0df02a35dc8a83420dc4215f3a461f03ddf52beeebb8a351096db058d30dad
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:4c2200d7230c5c35390150946d1d107f67e93a94186fdd2f6acd59b56b5d2173
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:e5cfa9130e2ea1dcc44328b0c4f6adda08ea8404da25bbd4558d94b356f20a5e
#8 3.068 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.705 
#8 3.705 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.705 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:62529b7fef8f894829c799c77b790263a3e53f26f8a382fba9db80bf1499609e
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:62b2d45b45e3e9e62f2a8a5200a75a210c1c325655096f7be8cf69f60611172a
#2 transferring dockerfile: 253B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:dfb2c1a8e3fc6e88036663fb52dcc4fd9892ef11099e647da3f091fd88d50466
#6 transferring context: 2.27kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:486af7c615027d71a222873440b97aff337eb7c6a3938fd11b85aa56abef06e1
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:8d1818ce5286b2da3893499122750de13e7e971f1f58f07100423dd01a120cad
#8 3.287 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.929 
#8 3.929 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.929 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:d0006127578f804af76bfa77bf29b266a664af06e6adaaa7841014e00969ce55
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:5bb37a3a520815c2a487d2e2439f83ffe6819966f16fb3df88a7e380a4ad7e8a
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:bcb7024ef5c0a801b85b9d73828e45a026be329a7bcca4ee1f0aaf85af2c33ca
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:45b5f65322b73b0c969ce389b067257f775094c5a3291fc9c1f6d893e209f697
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:d6cd8cd0883e5c1229fce93b34f019599a63f4410b79687d4b2d1e6f9d087eb7
#8 3.301 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.956 
#8 3.956 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.956 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:37:32,861 custom_logger INFO Handling command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service
2024-08-01 22:37:32,862 custom_logger INFO Running command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service
2024-08-01 22:37:32,899 custom_logger INFO Command succeeded: stdout: ./main.py:import requests
./main.py:import uvicorn
./main.py:import os
./main.py:from fastapi import FastAPI
, stderr: 
2024-08-01 22:37:56,570 custom_logger INFO Handling command: echo 'requests
uvicorn
fastapi' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: .
2024-08-01 22:37:56,571 custom_logger INFO Running command: echo 'requests
uvicorn
fastapi' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: .
2024-08-01 22:37:56,586 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:38:01,619 custom_logger INFO Handling command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service
2024-08-01 22:38:01,619 custom_logger INFO Running command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service
2024-08-01 22:38:02,175 custom_logger INFO Command succeeded: stdout: ./controllers/listener_controller.py:import logging
./controllers/listener_controller.py:import httpx
./main.py:import requests
./main.py:import uvicorn
./main.py:import os
./services/config_service.py:import json
./services/config_service.py:import logging
./services/config_service.py:import os
./services/config_service.py:import uuid
./services/forward_service.py:import httpx
./services/forward_service.py:import logging
./services/registry_service.py:import logging
./services/registry_service.py:import httpx
./services/registry_service.py:import asyncio
./tests/test_config_service.py:import os
./tests/test_config_service.py:import json
./tests/test_config_service.py:import pytest
./websocket/websocket_handler.py:import asyncio
./websocket/websocket_handler.py:import httpx
./websocket/websocket_handler.py:import json
./websocket/websocket_handler.py:import websockets
./websocket/websocket_handler.py:import logging
./controllers/listener_controller.py:from fastapi import APIRouter, HTTPException, Depends, Request
./controllers/listener_controller.py:from websocket_listener_service.models.envelope import Envelope
./controllers/listener_controller.py:from websocket_listener_service.models.register_request import RegisterRequest
./controllers/listener_controller.py:from websocket_listener_service.models.deregister_request import DeregisterRequest
./controllers/listener_controller.py:from websocket_listener_service.services.forward_service import ForwardService
./controllers/listener_controller.py:from websocket_listener_service.services.registry_service import RegistryService
./main.py:from fastapi import FastAPI
./models/deregister_request.py:from pydantic import BaseModel
./models/envelope.py:from pydantic import BaseModel, Field
./models/envelope.py:from typing import Any, Optional
./models/register_request.py:from typing import Optional, Dict, Any
./models/register_request.py:from pydantic import BaseModel
./services/forward_service.py:from fastapi import HTTPException
./services/forward_service.py:from websocket_listener_service.models.envelope import Envelope
./services/registry_service.py:from fastapi import HTTPException
./services/registry_service.py:from websocket_listener_service.models.register_request import RegisterRequest
./services/registry_service.py:from websocket_listener_service.models.deregister_request import DeregisterRequest
./tests/test_config_service.py:from unittest.mock import patch, mock_open
./tests/test_config_service.py:from websocket_listener_service.services.config_service import ConfigService
./websocket/websocket_handler.py:from fastapi import WebSocket, WebSocketDisconnect, HTTPException
./websocket/websocket_handler.py:from websocket_listener_service.models.envelope import Envelope
./websocket/websocket_handler.py:from websocket_listener_service.services.forward_service import ForwardService
./websocket/websocket_handler.py:from websocket_listener_service.services.config_service import ConfigService
, stderr: 
2024-08-01 22:38:17,886 custom_logger INFO Handling command: echo 'httpx
requests
uvicorn
websockets
fastapi
pydantic' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: .
2024-08-01 22:38:17,887 custom_logger INFO Running command: echo 'httpx
requests
uvicorn
websockets
fastapi
pydantic' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: .
2024-08-01 22:38:17,901 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:38:21,147 custom_logger INFO Handling command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service
2024-08-01 22:38:21,148 custom_logger INFO Running command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service
2024-08-01 22:38:21,176 custom_logger INFO Command succeeded: stdout: ./proxy.py:import requests
./proxy.py:import asyncio
./proxy.py:import yaml
./proxy.py:import logging
./proxy.py:from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Body
./proxy.py:from pydantic import BaseModel, Field
./proxy.py:from typing import Any, Optional
./proxy.py:from fastapi.openapi.utils import get_openapi
./proxy.py:from contextlib import asynccontextmanager
, stderr: 
2024-08-01 22:38:43,624 custom_logger INFO Handling command: echo 'requests
yaml
fastapi
pydantic' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: .
2024-08-01 22:38:43,625 custom_logger INFO Running command: echo 'requests
yaml
fastapi
pydantic' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: .
2024-08-01 22:38:43,636 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:39:18,236 custom_logger INFO Handling command: pip install pipreqs in path: .
2024-08-01 22:39:18,236 custom_logger INFO Running command: pip install pipreqs in path: .
2024-08-01 22:39:30,023 custom_logger INFO Handling command: pipreqs /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service --force in path: .
2024-08-01 22:39:30,024 custom_logger INFO Running command: pipreqs /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service --force in path: .
2024-08-01 22:39:30,211 custom_logger ERROR Command execution failed: /bin/sh: 1: pipreqs: not found

2024-08-01 22:39:31,786 custom_logger ERROR Command execution failed: ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
spyder 4.2.5 requires pyqt5<5.13, which is not installed.
spyder 4.2.5 requires pyqtwebengine<5.13, which is not installed.
spyder 4.2.5 requires jedi==0.17.2, but you have jedi 0.18.2 which is incompatible.
spyder 4.2.5 requires parso==0.7.0, but you have parso 0.8.3 which is incompatible.
spyder 4.2.5 requires watchdog<2.0.0,>=0.10.3, but you have watchdog 2.1.2 which is incompatible.

2024-08-01 22:39:51,500 custom_logger INFO Handling command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service
2024-08-01 22:39:51,501 custom_logger INFO Running command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service
2024-08-01 22:39:52,630 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:40:01,196 custom_logger INFO Handling command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service
2024-08-01 22:40:01,197 custom_logger INFO Running command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service
2024-08-01 22:40:02,159 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:40:11,069 custom_logger INFO Handling command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service
2024-08-01 22:40:11,070 custom_logger INFO Running command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service
2024-08-01 22:40:12,132 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:40:36,532 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:40:36,533 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:40:57,350 custom_logger INFO Handling command: kubectl logs $(kubectl get pods --selector=app=command-service -o jsonpath='{.items[0].metadata.name}') in path: .
2024-08-01 22:40:57,351 custom_logger INFO Running command: kubectl logs $(kubectl get pods --selector=app=command-service -o jsonpath='{.items[0].metadata.name}') in path: .
2024-08-01 22:40:57,590 custom_logger ERROR Command execution failed: error: the server doesn't have a resource type "pods"
error: expected 'logs [-f] [-p] (POD | TYPE/NAME) [-c CONTAINER]'.
POD or TYPE/NAME is a required argument for the logs command
See 'kubectl logs -h' for help and examples

2024-08-01 22:40:59,798 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:eb55b1895e647f800cc2ecff8573b949f0a883a8a0b7539851f87bf319601c0c
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:01e09ab64c9f16cfb7355a14d138cd294e03406ba50c4697d4520782412d2974
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 4.0s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:09d02caa0a9a46c648ada179537efbdfefa9211aad2594e2fed30afc623af091
#6 transferring context: 13.59kB 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:e9d6fe7b98d9379083c6b3393c214163508748ebd3d6d6c5a15cea5c96235f8a
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:c76de0fa84643b48be3c50c6f19eb794947030ac444e4b76bd4f6d3313c2caf3
#8 3.625 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.628 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.628 
#8 4.246 
#8 4.246 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.246 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:516dbf75e5a7f175439d6beb89bca0f4a430c95885aa05ff0e85726a443c81ba
#2 transferring context: 2B 0.1s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:5127e601eac906c0d43b02781b4ce45c63ffa77142d39c25a7343303e2ae1d61
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:731dc1b1dd36ab1318978eadca2b22202ae62f1c73009793f4ff9621208e1c5a
#6 transferring context: 15.80kB 0.5s done
#6 DONE 0.5s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:6fa39320635ac459c18795852b2b9a73573e0c0f83f0bb9dbec0356173f0d48f
#7 DONE 0.1s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:b0215efdcdd4d2e5e6d68e432e83f5a3d59242ed64dcf515b43e6708a3cfdd84
#8 3.762 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.765 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.765 
#8 4.376 
#8 4.376 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.376 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:454cccd6e9538ae00931592d85e4d2bd00ffc7e2a8938ff3e4f4e4be4b403c40
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:e60393f8b0becd7ec12a1eb28314e8c3db5f6d9bce7b05a1c11b550157a6de41
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:3f70cf6c5095c72388fdd0b131e267ee3f007c8975289a56847c29433496dfb1
#6 transferring context: 13.60kB 0.0s done
#6 DONE 0.1s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:ede4537b464133f9430941557ed548fbc6f446237399ff18bdac1e2e127c812f
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:7f2f44310ba09a72d6a543befe54373d2b0396f11a0add19a2f0fcb9df96fcb7
#8 3.505 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.508 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.508 
#8 4.102 
#8 4.102 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.102 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:42:52,366 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:42:52,367 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:43:12,400 custom_logger INFO Handling command: docker logs $(docker ps -qf "name=command-service") in path: .
2024-08-01 22:43:12,401 custom_logger INFO Running command: docker logs $(docker ps -qf "name=command-service") in path: .
2024-08-01 22:43:12,653 custom_logger ERROR Command execution failed: "docker logs" requires exactly 1 argument.
See 'docker logs --help'.

Usage:  docker logs [OPTIONS] CONTAINER

Fetch the logs of a container

2024-08-01 22:43:17,297 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:d4cc4ec3acc2c945fe0716ed68f69ed4fda71070b18a795218a20f5d0bf65167
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:de23d5ae0c2babff9a188101068c601cff73b7ddaa855b29ff766f01f16fcd07
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:f74c5fabe618a05d3ffe7811dd108f1f24ad2abc451fa1d420475a2427028a20
#6 transferring context: 95B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:7c3d447ba2a5be5d6b140f6595992557a6c7307970c60c299bae25054e7f144b
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:60ac872e138313bed5557f1e08076376634aad55c7d332104ae88225b33f5f39
#8 4.087 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.089 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.089 
#8 4.747 
#8 4.747 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.747 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load build definition from Dockerfile
#2 sha256:2d6a469031dacd2cb827c5fd2e0c4aa3c5d0e9e80fe2baf0cef48a49a7b7fe40
#2 transferring dockerfile: 253B 0.1s done
#2 DONE 0.1s

#1 [internal] load .dockerignore
#1 sha256:0971b23ec8853b49e922deac84215f43658d0e8bdd6a1307af2a8913863b1868
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:97d2aa4a33f822a80abd7463bd50a10479963f7e101a733136588a2c4b101d7c
#6 transferring context: 2.30kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:7c89554227d7d1a26de68adc4e97db6bb6339fcc2ff5f9947549286bf4944823
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:7ab4a171020cfd189cb157b61ae0f24ee9b1e14a731ed46adb76aabad18d4ee8
#8 4.524 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.527 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.527 
#8 5.161 
#8 5.161 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 5.161 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:f1dbc96e7285f429de7311dc296522c51dc5ef58cacf43ed23e3375d6f5892c0
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:6f1ef6f79f6d6afbb6c4f9405e7acdeb7a9a4148df18571b9a4ecab10be7386d
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.6s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:4787e667869aa0b0a9f01874ed4de61b17ff4171e986df4f56cebcbc671881ed
#6 transferring context: 96B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:a41ddb40ee30b27de3ad52d26cef98d755ee21f55fa73647bdb26ae67f7d56e9
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:7db2478da4de567e1ed582789ed59f953dce58a3887c13f9bd3ec802f8bae9e7
#8 4.114 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.126 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.126 
#8 4.928 
#8 4.928 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.928 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:44:00,573 custom_logger INFO Handling command: docker ps in path: .
2024-08-01 22:44:00,575 custom_logger INFO Running command: docker ps in path: .
2024-08-01 22:44:00,757 custom_logger INFO Command succeeded: stdout: CONTAINER ID   IMAGE                                                  COMMAND                  CREATED      STATUS      PORTS                                            NAMES
a2d0680f6b55   docker.elastic.co/elasticsearch/elasticsearch:7.17.0   "/bin/tini -- /usr/l…"   6 days ago   Up 6 days   0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp   elasticsearch
, stderr: 
2024-08-01 22:44:15,803 custom_logger INFO Handling command: docker run -d --name command-service hypntranz/command-service:latest in path: .
2024-08-01 22:44:15,804 custom_logger INFO Running command: docker run -d --name command-service hypntranz/command-service:latest in path: .
2024-08-01 22:44:22,046 custom_logger ERROR Command execution failed: Unable to find image 'hypntranz/command-service:latest' locally
docker: Error response from daemon: pull access denied for hypntranz/command-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.

2024-08-01 22:44:34,790 custom_logger INFO Handling command: docker logs --tail 50 command-service in path: .
2024-08-01 22:44:34,791 custom_logger INFO Running command: docker logs --tail 50 command-service in path: .
2024-08-01 22:44:34,971 custom_logger ERROR Command execution failed: Error: No such container: command-service

2024-08-01 22:44:48,512 custom_logger INFO Handling command: docker images | grep hypntranz/command-service in path: .
2024-08-01 22:44:48,513 custom_logger INFO Running command: docker images | grep hypntranz/command-service in path: .
2024-08-01 22:44:48,694 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:45:38,216 custom_logger INFO Handling command: echo -e '#!/bin/bash\n\n# Build Docker images\ndocker build -t command-service:latest ./command_service\ndocker build -t websocket-listener-service:latest ./websocket_listener_service\ndocker build -t proxy-service:latest ./proxy_service\n\n# Run Docker containers\ndocker run -d --name command-service -p 8000:8000 command-service:latest\ndocker run -d --name websocket-listener-service -p 8001:8000 websocket-listener-service:latest\ndocker run -d --name proxy-service -p 8002:8000 proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh in path: .
2024-08-01 22:45:38,217 custom_logger INFO Running command: echo -e '#!/bin/bash\n\n# Build Docker images\ndocker build -t command-service:latest ./command_service\ndocker build -t websocket-listener-service:latest ./websocket_listener_service\ndocker build -t proxy-service:latest ./proxy_service\n\n# Run Docker containers\ndocker run -d --name command-service -p 8000:8000 command-service:latest\ndocker run -d --name websocket-listener-service -p 8001:8000 websocket-listener-service:latest\ndocker run -d --name proxy-service -p 8002:8000 proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh in path: .
2024-08-01 22:45:38,258 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:45:47,477 custom_logger INFO Handling command: ./scripts/build_and_run.sh in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:45:47,478 custom_logger INFO Running command: ./scripts/build_and_run.sh in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:09,606 custom_logger INFO Handling command: docker images | grep command-service in path: .
2024-08-01 22:46:09,607 custom_logger INFO Running command: docker images | grep command-service in path: .
2024-08-01 22:46:09,796 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:46:19,680 custom_logger ERROR Command execution failed: ./scripts/build_and_run.sh: 1: -e: not found
#1 [internal] load .dockerignore
#1 sha256:a5086bcea17e7684f50660ef47fa1e8df451bba0e8a551914209dbd3d728b821
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:015354273fce0560d0ab4c9aa02cac167ddf7a71c10dbcc17e058ed6e0ffca6b
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.9s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:5d4b96d1cc1a696467d7f5ff3d9f5eeebbbc12527f863fd9ca22e2e477ffe9d8
#6 transferring context: 95B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:7d7ad989e3f41d0bacca27b34f0b21e8dbe770c6029cc5d3e6681bf0782fede7
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:3294e1ea41e8522e14226721d97bae64bad74273b1a254d61ab11537e25b1d64
#8 4.132 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.134 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.134 
#8 5.186 
#8 5.186 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 5.186 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:b4aaaedbfa145eb9044e3cd7b145ca5e90db80534927b7da76853de08011573c
#1 transferring context: 2B 0.1s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:93f00de8f4a5d18167d61540656a450547ea288c5fd750d519233e2999e1514e
#2 transferring dockerfile: 253B 0.1s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.6s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:69435f649b3f4e82c8b584570deb579ffa85d77acbfe37e364bf46b05f96bc04
#6 transferring context: 2.30kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:3dae05d1bfab1c73e5f667469dcdb079d0126599ed94766d6333f77d9b50db02
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:a3451d7cb4274b4adbfa552866254f3adbced42cbd713a2d9969aa3744f21b56
#8 4.373 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.376 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.376 
#8 5.018 
#8 5.018 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 5.018 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:36711a594b7a70e3b60ac22daca5f2a76d67898e02b04231627e57ca300fc24c
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:7612ff1efaa3165c38753797592e8071fbe825912b77b76541d5614c0f728eaf
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:255127a7cfb69135999daae5e7c2eec6b4abda818e8ec7edf1b8b159248972e1
#6 transferring context: 96B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:ba713c3141b2ee10d2d9f0ba0833d21de547ef044782afc5a2280e8c99ace0aa
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:391baf39b65757599ca40376b3b41509a898ab07bf8248cf9a4d71e1e0969967
#8 4.296 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.301 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.301 
#8 4.969 
#8 4.969 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.969 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
Unable to find image 'command-service:latest' locally
docker: Error response from daemon: pull access denied for command-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.
Unable to find image 'websocket-listener-service:latest' locally
docker: Error response from daemon: pull access denied for websocket-listener-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.
Unable to find image 'proxy-service:latest' locally
docker: Error response from daemon: pull access denied for proxy-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.

2024-08-01 22:46:23,308 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:23,308 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:28,826 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:a4e85b2e4c45f030c382e7c13726783b9779ac4a83a7f6628f012315cdf60fef
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:d4f03ff1201dd33b619de0fbd3acf60a2dd54d1f05d8f900288eb455a983cb4a
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:557e04a74341f7532d3d395692131752faf35fef395c872640d92e88baeca7ed
#6 transferring context: 95B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:c1cf35c8432336acbe08f48299e1a8186caf9b8b985ebd2a4bef10ab8adbb461
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:c8c5de3dc4e91b3f55067a1f5083166391e80b24d78fc6e8bd05063a0fd7fa59
#8 3.930 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.932 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.932 
#8 4.570 
#8 4.570 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.570 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1

2024-08-01 22:46:38,430 custom_logger INFO Handling command: docker images | grep command-service in path: .
2024-08-01 22:46:38,431 custom_logger INFO Running command: docker images | grep command-service in path: .
2024-08-01 22:46:38,581 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:46:51,208 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:51,209 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:56,431 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:21765cf650564978919a13c753fad995a28edc8944c6dbd2d8480f4c9caea6d3
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:5e773a57748610c950553027b7e17fd0dcd53951ed6cd78ebf92dda08ac4fb05
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.6s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:da64db11d775531b08ae0cc29bcab105796b5313cbc81f0c7af53b2babb31958
#6 transferring context: 95B 0.0s done
#6 DONE 0.1s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:5e96a4701744cefd20c34a713bff41f16fbe1185f7302652154e38d572301482
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:e33aac638abea9b0c791fab4e5f43e613f226499f0df1184371221982188a998
#8 3.560 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.562 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.562 
#8 4.172 
#8 4.172 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.172 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1

2024-08-01 22:47:06,959 custom_logger INFO Handling command: docker run -d --name command-service-test command-service:latest && docker logs --tail 50 command-service-test in path: .
2024-08-01 22:47:06,960 custom_logger INFO Running command: docker run -d --name command-service-test command-service:latest && docker logs --tail 50 command-service-test in path: .
2024-08-01 22:47:08,224 custom_logger ERROR Command execution failed: Unable to find image 'command-service:latest' locally
docker: Error response from daemon: pull access denied for command-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.

2024-08-01 22:47:33,779 custom_logger INFO Handling command: echo -e '#!/bin/bash\n\n# Build Docker images\ndocker build -t command-service:latest ./command_service\ndocker build -t websocket-listener-service:latest ./websocket_listener_service\ndocker build -t proxy-service:latest ./proxy_service\n\n# Run Docker containers\ndocker run -d --name command-service -p 8000:8000 command-service:latest\ndocker run -d --name websocket-listener-service -p 8001:8000 websocket-listener-service:latest\ndocker run -d --name proxy-service -p 8002:8000 proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh in path: .
2024-08-01 22:47:33,780 custom_logger INFO Running command: echo -e '#!/bin/bash\n\n# Build Docker images\ndocker build -t command-service:latest ./command_service\ndocker build -t websocket-listener-service:latest ./websocket_listener_service\ndocker build -t proxy-service:latest ./proxy_service\n\n# Run Docker containers\ndocker run -d --name command-service -p 8000:8000 command-service:latest\ndocker run -d --name websocket-listener-service -p 8001:8000 websocket-listener-service:latest\ndocker run -d --name proxy-service -p 8002:8000 proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh in path: .
2024-08-01 22:47:33,802 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:47:46,816 custom_logger INFO Handling command: ./scripts/build_and_run.sh in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:47:46,817 custom_logger INFO Running command: ./scripts/build_and_run.sh in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:48:03,584 custom_logger INFO Handling command: docker logs --tail 50 command-service in path: .
2024-08-01 22:48:03,585 custom_logger INFO Running command: docker logs --tail 50 command-service in path: .
2024-08-01 22:48:03,725 custom_logger ERROR Command execution failed: Error: No such container: command-service

2024-08-01 22:48:17,354 custom_logger INFO Handling command: docker images | grep command-service in path: .
2024-08-01 22:48:17,355 custom_logger INFO Running command: docker images | grep command-service in path: .
2024-08-01 22:48:17,436 custom_logger ERROR Command execution failed: ./scripts/build_and_run.sh: 1: -e: not found
#2 [internal] load .dockerignore
#2 sha256:9b548e62aea996ccdbfaa10f5038ecb213fbb90cbeba181f1abdbb50931d7e5b
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:598fd453dbfacec083da5d92152d38060ba444f3d900453237d46cc9df736f86
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:a03b6b3bb9061be7bdb8f30c55a4aff935af3bf6a1cd9286b0a8f8c8aeeb82be
#6 transferring context: 95B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:2968417412a9534406009fec6b336710bec63612dc55586648ac0d9ac2f6fd07
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:855af60f9747ebf604b0418661d55d7a65379cfa31ece492f6057cd8892f48e2
#8 4.017 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.020 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.020 
#8 4.659 
#8 4.659 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.659 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load build definition from Dockerfile
#1 sha256:0c4dae49e4438949af66212fd90fa9e92cfdba8378a6c86055e29d42dd2e4cfb
#1 transferring dockerfile: 253B 0.0s done
#1 DONE 0.1s

#2 [internal] load .dockerignore
#2 sha256:787fae2fbfb5b9a40277e7f1bba0eef9354ed18fed9bb082813be8d17169890a
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:23b280f5dd30696dbe9524e8b90a0ac519bf95f813b2a2bb88351207fcd6bbf3
#6 transferring context: 2.30kB 0.4s done
#6 DONE 0.5s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:824040fd247c020223babb559ad45428512be44584cb90378040ed5459891cb0
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:3de2209a84a3b09e89663768c47f22518be75f17387462f059a1a3fc7b35e4a0
#8 4.098 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.103 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.103 
#8 4.749 
#8 4.749 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.749 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:237e1025a77d1f3a43b84c588444061a50ff5e5f96e085f7a80dd72d1e05ce36
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:ecf9e586c96bd647f0504c72f92b04d07d17f33e0b0094e8cd922bb383471cf8
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:d122466ece22dc0bf7c3f2a0ca9480ca551cdba78a48e4efc04bab292f9450a3
#6 transferring context: 96B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:9615a251b5be09ed96163abc225e310ce353661822eeed90028ada40b46c8b78
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:40056e36c6151d172a6b97717eaa4536fdcdbb941142bf9ae1b2e00ecb06131a
#8 4.085 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.088 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.088 
#8 4.711 
#8 4.711 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.711 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
Unable to find image 'command-service:latest' locally
docker: Error response from daemon: pull access denied for command-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.
Unable to find image 'websocket-listener-service:latest' locally
docker: Error response from daemon: pull access denied for websocket-listener-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.
Unable to find image 'proxy-service:latest' locally
docker: Error response from daemon: pull access denied for proxy-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.

2024-08-01 22:48:17,521 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:49:29,019 custom_logger INFO Handling command: for file in *; do echo BEGIN $file; cat $file; echo END $file; done in path: .
2024-08-01 22:49:29,020 custom_logger INFO Running command: for file in *; do echo BEGIN $file; cat $file; echo END $file; done in path: .
2024-08-01 22:49:29,095 custom_logger ERROR Command execution failed: cat: __pycache__: Is a directory
cat: command_service: Is a directory
cat: tests: Is a directory

2024-08-01 22:49:32,963 custom_logger INFO Handling command: ls in path: .
2024-08-01 22:49:32,964 custom_logger INFO Running command: ls in path: .
2024-08-01 22:49:32,993 custom_logger INFO Command succeeded: stdout: __init__.py
__pycache__
app.log
command_service
tests
, stderr: 
2024-08-01 22:49:35,448 custom_logger INFO Handling command: cat __init__.py in path: .
2024-08-01 22:49:35,449 custom_logger INFO Running command: cat __init__.py in path: .
2024-08-01 22:49:35,464 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:49:38,219 custom_logger INFO Handling command: ls __pycache__ in path: .
2024-08-01 22:49:38,219 custom_logger INFO Running command: ls __pycache__ in path: .
2024-08-01 22:49:38,236 custom_logger INFO Command succeeded: stdout: __init__.cpython-38.pyc
, stderr: 
2024-08-01 22:49:40,650 custom_logger INFO Handling command: cat __pycache__/__init__.cpython-38.pyc in path: .
2024-08-01 22:49:40,651 custom_logger INFO Running command: cat __pycache__/__init__.cpython-38.pyc in path: .
2024-08-01 22:49:40,697 custom_logger ERROR Failed to execute command: 'utf-8' codec can't decode byte 0xa7 in position 10: invalid start byte
2024-08-01 22:49:45,539 custom_logger INFO Handling command: cat app.log in path: .
2024-08-01 22:49:45,540 custom_logger INFO Running command: cat app.log in path: .
2024-08-01 22:49:45,574 custom_logger INFO Command succeeded: stdout: 2024-08-01 14:39:18,759 custom_logger INFO This is an info message
2024-08-01 14:39:18,760 custom_logger WARNING This is a warning message
2024-08-01 14:39:18,761 custom_logger ERROR This is an error message
2024-08-01 14:39:18,872 custom_logger INFO Starting the application
2024-08-01 14:39:18,943 custom_logger INFO Entering register_service
2024-08-01 14:39:18,946 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 14:39:19,006 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 14:39:19,007 custom_logger INFO Exiting register_service
2024-08-01 14:51:03,003 custom_logger INFO This is an info message
2024-08-01 14:51:03,003 custom_logger WARNING This is a warning message
2024-08-01 14:51:03,004 custom_logger ERROR This is an error message
2024-08-01 14:51:03,100 custom_logger INFO Starting the application
2024-08-01 14:51:03,172 custom_logger INFO Entering register_service
2024-08-01 14:51:03,174 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 14:51:03,215 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 14:51:03,216 custom_logger INFO Exiting register_service
2024-08-01 16:07:37,173 custom_logger INFO Starting the application
2024-08-01 16:07:37,255 custom_logger INFO Entering register_service
2024-08-01 16:08:12,855 custom_logger INFO Starting the application
2024-08-01 16:08:12,946 custom_logger INFO Entering register_service
2024-08-01 16:08:12,948 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:08:12,999 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:08:13,001 custom_logger INFO Exiting register_service
2024-08-01 16:09:38,576 custom_logger INFO Starting the application
2024-08-01 16:09:38,646 custom_logger INFO Entering register_service
2024-08-01 16:09:38,649 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:09:38,691 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:09:38,692 custom_logger INFO Exiting register_service
2024-08-01 16:10:38,890 custom_logger INFO Starting the application
2024-08-01 16:10:38,966 custom_logger INFO Entering register_service
2024-08-01 16:10:38,969 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:10:39,018 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:10:39,019 custom_logger INFO Exiting register_service
2024-08-01 16:11:50,333 custom_logger INFO Starting the application
2024-08-01 16:11:50,410 custom_logger INFO Entering register_service
2024-08-01 16:11:50,413 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:11:50,493 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:11:50,494 custom_logger INFO Exiting register_service
2024-08-01 16:13:59,564 custom_logger INFO Starting the application
2024-08-01 16:13:59,664 custom_logger INFO Entering register_service
2024-08-01 16:13:59,666 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:13:59,717 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:13:59,717 custom_logger INFO Exiting register_service
2024-08-01 16:14:24,276 custom_logger INFO Starting the application
2024-08-01 16:14:24,355 custom_logger INFO Entering register_service
2024-08-01 16:14:24,359 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:14:24,411 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:14:24,412 custom_logger INFO Exiting register_service
2024-08-01 16:14:39,667 custom_logger INFO Starting the application
2024-08-01 16:14:39,747 custom_logger INFO Entering register_service
2024-08-01 16:14:39,749 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:14:39,800 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:14:39,801 custom_logger INFO Exiting register_service
2024-08-01 16:15:24,785 custom_logger INFO Starting the application
2024-08-01 16:15:24,856 custom_logger INFO Entering register_service
2024-08-01 16:15:24,859 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:15:24,901 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:15:24,902 custom_logger INFO Exiting register_service
2024-08-01 16:16:26,674 custom_logger INFO Starting the application
2024-08-01 16:16:26,748 custom_logger INFO Entering register_service
2024-08-01 16:16:26,751 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:16:26,805 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:16:26,806 custom_logger INFO Exiting register_service
2024-08-01 16:17:42,976 custom_logger INFO Starting the application
2024-08-01 16:17:43,072 custom_logger INFO Entering register_service
2024-08-01 16:17:43,075 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:17:43,131 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:17:43,132 custom_logger INFO Exiting register_service
2024-08-01 16:19:22,543 custom_logger INFO Starting the application
2024-08-01 16:19:22,620 custom_logger INFO Entering register_service
2024-08-01 16:19:22,623 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:19:22,672 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:19:22,673 custom_logger INFO Exiting register_service
2024-08-01 16:20:54,740 custom_logger INFO Starting the application
2024-08-01 16:20:54,825 custom_logger INFO Entering register_service
2024-08-01 16:20:54,828 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:20:54,886 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:20:54,887 custom_logger INFO Exiting register_service
2024-08-01 16:21:48,009 custom_logger INFO Starting the application
2024-08-01 16:21:48,089 custom_logger INFO Entering register_service
2024-08-01 16:21:48,092 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:21:48,140 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:21:48,141 custom_logger INFO Exiting register_service
2024-08-01 16:23:50,671 custom_logger INFO Starting the application
2024-08-01 16:23:50,758 custom_logger INFO Entering register_service
2024-08-01 16:23:50,761 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:23:50,818 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:23:50,818 custom_logger INFO Exiting register_service
2024-08-01 16:27:29,839 custom_logger INFO Starting the application
2024-08-01 16:27:29,935 custom_logger INFO Entering register_service
2024-08-01 16:27:29,938 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:27:29,992 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:27:29,993 custom_logger INFO Exiting register_service
2024-08-01 16:28:41,409 custom_logger INFO Starting the application
2024-08-01 16:28:41,496 custom_logger INFO Entering register_service
2024-08-01 16:28:41,499 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:28:41,550 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:28:41,551 custom_logger INFO Exiting register_service
2024-08-01 16:29:58,301 custom_logger INFO Starting the application
2024-08-01 16:29:58,387 custom_logger INFO Entering register_service
2024-08-01 16:29:58,390 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:29:58,445 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:29:58,446 custom_logger INFO Exiting register_service
2024-08-01 17:37:01,405 custom_logger INFO Starting the application
2024-08-01 17:37:01,490 custom_logger INFO Entering register_service
2024-08-01 17:37:01,494 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:37:01,554 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:37:01,555 custom_logger INFO Exiting register_service
2024-08-01 17:38:25,337 custom_logger INFO Starting the application
2024-08-01 17:38:25,416 custom_logger INFO Entering register_service
2024-08-01 17:38:25,419 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:38:25,476 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:38:25,477 custom_logger INFO Exiting register_service
2024-08-01 17:39:37,084 custom_logger INFO Starting the application
2024-08-01 17:39:37,161 custom_logger INFO Entering register_service
2024-08-01 17:39:37,164 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:39:37,210 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:39:37,211 custom_logger INFO Exiting register_service
2024-08-01 17:42:44,292 custom_logger INFO Starting the application
2024-08-01 17:42:44,380 custom_logger INFO Entering register_service
2024-08-01 17:42:44,383 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:42:44,436 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:42:44,437 custom_logger INFO Exiting register_service
2024-08-01 17:43:00,893 custom_logger INFO Starting the application
2024-08-01 17:43:00,974 custom_logger INFO Entering register_service
2024-08-01 17:43:00,977 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:43:01,026 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:43:01,027 custom_logger INFO Exiting register_service
2024-08-01 17:43:24,348 custom_logger INFO Starting the application
2024-08-01 17:43:24,437 custom_logger INFO Entering register_service
2024-08-01 17:43:24,440 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:43:24,484 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:43:24,485 custom_logger INFO Exiting register_service
2024-08-01 17:44:52,844 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 17:44:53,434 custom_logger INFO Query succeeded: {'took': 575, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 10, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'logs', '_type': '_doc', '_id': '2bZzD5EBTfLFZNqTWBYQ', '_score': 1.0, '_source': {'message': 'This is a test log', 'level': 'INFO', 'timestamp': '2023-01-01T00:00:00Z'}}, {'_index': 'logs', '_type': '_doc', '_id': '3LabD5EBTfLFZNqT_xaL', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '3bbhD5EBTfLFZNqTmxYu', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '3rbiD5EBTfLFZNqTQRbs', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '37blD5EBTfLFZNqTzRbF', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.349199', 'message': '2024-08-01 17:43:24,348 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4LblD5EBTfLFZNqTzhYd', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.440422', 'message': '2024-08-01 17:43:24,437 custom_logger INFO Entering register_service', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4bblD5EBTfLFZNqTzhZN', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.486857', 'message': "2024-08-01 17:43:24,440 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}", 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4rblD5EBTfLFZNqTzhZe', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.504368', 'message': '2024-08-01 17:43:24,484 custom_logger INFO Service registered successfully with the proxy.', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '47blD5EBTfLFZNqTzhZx', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.523865', 'message': '2024-08-01 17:43:24,485 custom_logger INFO Exiting register_service', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '5LbnD5EBTfLFZNqTJxZ1', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:44:52.847122', 'message': '2024-08-01 17:44:52,844 custom_logger INFO Handling elastic: http://localhost:9200', 'level': 'INFO', 'logger_name': 'custom_logger'}}]}}
2024-08-01 17:52:30,554 custom_logger INFO Starting the application
2024-08-01 17:52:30,648 custom_logger INFO Entering register_service
2024-08-01 17:52:30,651 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:52:30,706 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:52:30,707 custom_logger INFO Exiting register_service
2024-08-01 17:52:59,525 custom_logger INFO Starting the application
2024-08-01 17:52:59,603 custom_logger INFO Entering register_service
2024-08-01 17:52:59,606 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:52:59,649 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:52:59,650 custom_logger INFO Exiting register_service
2024-08-01 17:53:13,403 custom_logger INFO Starting the application
2024-08-01 17:53:13,481 custom_logger INFO Entering register_service
2024-08-01 17:53:13,485 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 17:53:13,529 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 17:53:13,532 custom_logger INFO Exiting register_service
2024-08-01 17:57:20,094 custom_logger INFO Handling command: ls -R in path: ./command_service
2024-08-01 17:57:20,095 custom_logger INFO Running command: ls -R in path: ./command_service
2024-08-01 17:57:20,167 custom_logger INFO Command succeeded: stdout: .:
__init__.py
__pycache__
config
controllers
main.py
models
services

./__pycache__:
__init__.cpython-38.pyc
main.cpython-38.pyc

./config:
__init__.py
__pycache__
config.json
config.py

./config/__pycache__:
__init__.cpython-38.pyc
config.cpython-38.pyc

./controllers:
__init__.py
__pycache__
command_controller.py

./controllers/__pycache__:
__init__.cpython-38.pyc
command_controller.cpython-38.pyc

./models:
__init__.py
__pycache__
command_message.py
register_request.py

./models/__pycache__:
__init__.cpython-38.pyc
command_message.cpython-38.pyc
register_request.cpython-38.pyc

./services:
__init__.py
__pycache__
command_service.py
logger.py
registration_service.py

./services/__pycache__:
__init__.cpython-38.pyc
command_service.cpython-38.pyc
logger.cpython-38.pyc
registration_service.cpython-38.pyc
, stderr: 
2024-08-01 17:58:14,656 custom_logger INFO Handling command: find ./command_service -name '*.py' in path: .
2024-08-01 17:58:14,657 custom_logger INFO Running command: find ./command_service -name '*.py' in path: .
2024-08-01 17:58:14,765 custom_logger INFO Command succeeded: stdout: ./command_service/config/config.py
./command_service/config/__init__.py
./command_service/controllers/command_controller.py
./command_service/controllers/__init__.py
./command_service/main.py
./command_service/models/command_message.py
./command_service/models/register_request.py
./command_service/models/__init__.py
./command_service/services/command_service.py
./command_service/services/logger.py
./command_service/services/registration_service.py
./command_service/services/__init__.py
./command_service/__init__.py
, stderr: 
2024-08-01 18:42:37,823 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 18:42:37,951 custom_logger INFO Query succeeded: {'took': 75, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 32, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'logs', '_type': '_doc', '_id': '2bZzD5EBTfLFZNqTWBYQ', '_score': 1.0, '_source': {'message': 'This is a test log', 'level': 'INFO', 'timestamp': '2023-01-01T00:00:00Z'}}, {'_index': 'logs', '_type': '_doc', '_id': '3LabD5EBTfLFZNqT_xaL', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '3bbhD5EBTfLFZNqTmxYu', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '3rbiD5EBTfLFZNqTQRbs', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T20:21:48.010730', 'message': '2024-08-01 16:21:48,009 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '37blD5EBTfLFZNqTzRbF', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.349199', 'message': '2024-08-01 17:43:24,348 custom_logger INFO Starting the application', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4LblD5EBTfLFZNqTzhYd', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.440422', 'message': '2024-08-01 17:43:24,437 custom_logger INFO Entering register_service', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4bblD5EBTfLFZNqTzhZN', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.486857', 'message': "2024-08-01 17:43:24,440 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}", 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '4rblD5EBTfLFZNqTzhZe', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.504368', 'message': '2024-08-01 17:43:24,484 custom_logger INFO Service registered successfully with the proxy.', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '47blD5EBTfLFZNqTzhZx', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:43:24.523865', 'message': '2024-08-01 17:43:24,485 custom_logger INFO Exiting register_service', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '5LbnD5EBTfLFZNqTJxZ1', '_score': 1.0, '_source': {'@timestamp': '2024-08-01T21:44:52.847122', 'message': '2024-08-01 17:44:52,844 custom_logger INFO Handling elastic: http://localhost:9200', 'level': 'INFO', 'logger_name': 'custom_logger'}}]}}
2024-08-01 20:56:42,803 custom_logger INFO Handling command: for file in *; do echo BEGIN $file; cat $file; echo END $file; done in path: .
2024-08-01 20:56:42,813 custom_logger INFO Running command: for file in *; do echo BEGIN $file; cat $file; echo END $file; done in path: .
2024-08-01 20:56:42,906 custom_logger ERROR Command execution failed: cat: __pycache__: Is a directory
cat: command_service: Is a directory
cat: tests: Is a directory

2024-08-01 20:58:32,283 custom_logger INFO Handling command: find ./command_service -name '*.py' | xargs cat in path: .
2024-08-01 20:58:32,284 custom_logger INFO Running command: find ./command_service -name '*.py' | xargs cat in path: .
2024-08-01 20:58:32,513 custom_logger INFO Command succeeded: stdout: import logging
import json
from concurrent.futures import ThreadPoolExecutor
import requests
import os
from pydantic import BaseSettings

class Settings(BaseSettings):
    proxy_url: str
    host: str
    port: int
    service_name: str
    logging_level: str
    logging_format: str
    logging_sinks: list
    elastic_url: str

def load_config():
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    with open(config_path) as config_file:
        config_data = json.load(config_file)
        return Settings(
            proxy_url=config_data['proxy_url'],
            host=config_data['host'],
            port=config_data['port'],
            service_name=config_data['service_name'],
            logging_level=config_data['logging']['level'],
            logging_format=config_data['logging']['format'],
            logging_sinks=config_data['logging']['sinks'],
            elastic_url=config_data['logging']['elastic_url']
        )



settings = load_config()
from fastapi import APIRouter, HTTPException, Depends
from command_service.models.command_message import CommandMessage
from command_service.services.command_service import run_command
from command_service.services.logger import CustomLogger, log_decorator
from command_service.services.logger import get_logger
from command_service.config.config import Settings, load_config
from command_service.services.logger import CustomLogger
from pydantic import BaseModel
import logging
import requests
import traceback

router = APIRouter()

@router.post('/execute-bash')
async def command_service(message: CommandMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling command: {message.command} in path: {message.path}')

    try:
        stdout, stderr = await run_command(message.command, message.path, settings, logger)

        if stderr:
            logger.error(f'Command execution failed: {stderr}')
            return {'stdout': stdout, 'stderr': stderr}

        logger.info(f'Command succeeded: stdout: {stdout}, stderr: {stderr}')
        return {'stdout': stdout, 'stderr': stderr}

    except Exception as e:
        logger.error(f'Failed to execute command: {str(e)}')
        return {'stdout': '', 'stderr': str(e)}

class ElasticQueryMessage(BaseModel):
    connection_string: str
    index: str
    query: dict

class ElasticLogMessage(BaseModel):
    connection_string: str
    index: str
    log: dict

@router.post('/elastic-query')
async def handle_elastic(message: ElasticQueryMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling elastic: {message.connection_string}')

    try:
        query_url = f"{message.connection_string}/{message.index}/_search"
        logger.debug(f"Query URL: {query_url}")
        logger.debug(f"Query Body: {message.query}")

        response = requests.post(query_url, json={"query": message.query})
        logger.debug(f"Response: {response.text}")
        response.raise_for_status()

        logger.info(f"Query succeeded: {response.json()}")
        return response.json()
    except requests.RequestException as e:
        error_message = f"Failed to execute ElasticSearch query: {str(e)}"
        logger.error(error_message)
        traceback_str = ''.join(traceback.format_tb(e.__traceback__))
        return {"error": error_message, "traceback": traceback_str}

@router.post('/elastic-log')
async def handle_elastic_log(message: ElasticLogMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling elastic log: {message.connection_string}')

    try:
        log_url = f"{message.connection_string}/{message.index}/_doc"
        logger.debug(f"Log URL: {log_url}")
        logger.debug(f"Log Body: {message.log}")

        response = requests.post(log_url, json=message.log)
        logger.debug(f"Response: {response.text}")
        response.raise_for_status()

        logger.info(f"Log succeeded: {response.json()}")
        return response.json()
    except requests.RequestException as e:
        error_message = f"Failed to send log to Elasticsearch: {str(e)}"
        logger.error(error_message)
        traceback_str = ''.join(traceback.format_tb(e.__traceback__))
        return {"error": error_message, "traceback": traceback_str}
from fastapi import FastAPI
from contextlib import asynccontextmanager
from command_service.services.registration_service import RegistrationService
from command_service.config.config import settings
from command_service.controllers import command_controller
from command_service.services.logger import CustomLogger
import logging
import asyncio

# Initialize the logger using CustomLogger
custom_logger = CustomLogger(settings)
logger = custom_logger

@asynccontextmanager
async def lifespan(app: FastAPI):
    openapi_schema = app.openapi()

    # Hardcoding the servers field
    openapi_schema['servers'] = [{"url": f"http://{settings.host}:{settings.port}"}]
    app.openapi_schema = openapi_schema

    registration_service = RegistrationService(settings, logger)
    # Start the service registration process as a background task
    asyncio.create_task(registration_service.register_service())
    yield
    # Any cleanup logic here if needed

app = FastAPI(lifespan=lifespan)
app.include_router(command_controller.router)

if __name__ == "__main__":
    logger.info("Starting the application")
    import uvicorn
    uvicorn.run(app, host=settings.host, port=settings.port)
from pydantic import BaseModel

class CommandMessage(BaseModel):
    command: str
    path: str = ""
from typing import Optional, Dict, Any
from pydantic import BaseModel

class RegisterRequest(BaseModel):
    service_name: str
    openapi_url: Optional[str] = None  # Make this field optional
    openapi_json: Optional[Dict[str, Any]] = None  # Make this field optional and ensure it's a dictionary
import asyncio
import logging
import os
from command_service.config.config import Settings

async def run_command(command: str, path: str, settings: Settings, logger: logging.Logger):
    logger.info(f"Running command: {command} in path: {path}")

    full_path = os.path.abspath(path) if path else os.getcwd()

    process = await asyncio.create_subprocess_shell(
        command,
        cwd=full_path,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )

    stdout, stderr = await process.communicate()

    return stdout.decode(), stderr.decode()
import logging
from datetime import datetime
import json
from concurrent.futures import ThreadPoolExecutor
import requests

class ElasticsearchHandler(logging.Handler):
    def __init__(self, elastic_url):
        super().__init__()
        self.elastic_url = elastic_url
        self.executor = ThreadPoolExecutor(max_workers=1)

    def emit(self, record):
        log_entry = self.format(record)
        self.executor.submit(self.send_to_elasticsearch, log_entry, record)

    def send_to_elasticsearch(self, log_entry, record):
        try:
            log_message = {
                "@timestamp": datetime.utcnow().isoformat(),
                "message": log_entry,
                "level": record.levelname,
                "logger_name": record.name
            }
            print(f"Sending log to Elasticsearch: {json.dumps(log_message, indent=2)}")  # Debug print
            response = requests.post(
                f"{self.elastic_url}/logs/_doc",  # Corrected URL
                headers={"Content-Type": "application/json"},
                json=log_message
            )
            response.raise_for_status()
        except requests.HTTPError as e:
            print(f"Failed to send log to Elasticsearch: {e.response.status_code} {e.response.reason}")
            print(f"Response content: {e.response.content}")
        except json.JSONDecodeError as e:
            print(f"JSON decoding error: {e}")
        except Exception as e:
            print(f"Unexpected error: {e}")

class CustomLogger:
    def __init__(self, settings):
        self.logger = logging.getLogger('custom_logger')
        if not self.logger.hasHandlers():
            self.logger.setLevel(settings.logging_level)
            formatter = logging.Formatter(settings.logging_format, style='{')

            if 'console' in settings.logging_sinks:
                console_handler = logging.StreamHandler()
                console_handler.setFormatter(formatter)
                self.logger.addHandler(console_handler)

            if 'file' in settings.logging_sinks:
                file_handler = logging.FileHandler('app.log')
                file_handler.setFormatter(formatter)
                self.logger.addHandler(file_handler)

            if 'elastic' in settings.logging_sinks:
                elastic_handler = ElasticsearchHandler(settings.elastic_url)
                elastic_handler.setFormatter(formatter)
                self.logger.addHandler(elastic_handler)

    def log(self, level, msg, *args, **kwargs):
        self.logger.log(level, msg, *args, **kwargs)

    def debug(self, msg, *args, **kwargs):
        self.logger.debug(msg, *args, **kwargs)

    def info(self, msg, *args, **kwargs):
        self.logger.info(msg, *args, **kwargs)

    def warning(self, msg, *args, **kwargs):
        self.logger.warning(msg, *args, **kwargs)

    def error(self, msg, *args, **kwargs):
        self.logger.error(msg, *args, **kwargs)

    def critical(self, msg, *args, **kwargs):
        self.logger.critical(msg, *args, **kwargs)

def get_logger(settings):
    return CustomLogger(settings)

def log_decorator(log_parameters=True):
    def decorator(func):
        async def wrapper(*args, **kwargs):
            logger = kwargs.get('logger', None)
            if not logger:
                logger = logging.getLogger('custom_logger')
                if not logger.hasHandlers():
                    logger.setLevel(logging.INFO)
                    console_handler = logging.StreamHandler()
                    formatter = logging.Formatter('{asctime} {message}', style='{')
                    console_handler.setFormatter(formatter)
                    logger.addHandler(console_handler)
            if log_parameters:
                params = {**kwargs}
            else:
                params = {}
            logger.info(f'Entering {func.__name__}')
            result = await func(*args, **kwargs)
            logger.info(f'Exiting {func.__name__}')
            return result
        return wrapper
    return decorator
import httpx
from fastapi import HTTPException
from command_service.services.logger import CustomLogger, log_decorator
from command_service.config.config import Settings
import logging
from command_service.models.register_request import RegisterRequest

class RegistrationService:
    def __init__(self, settings: Settings, logger: CustomLogger):
        self.settings = settings
        self.logger = logger

    @log_decorator()
    async def register_service(self):
        registration_data = RegisterRequest(
            service_name=self.settings.service_name,
            openapi_url=f'http://{self.settings.host}:{self.settings.port}/openapi.json'
        )

        timeout = httpx.Timeout(10.0, connect=10.0)  # Define timeout

        try:
            self.logger.log(logging.INFO, f'Registering service with the proxy...{registration_data.dict()}')
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(self.settings.proxy_url, json=registration_data.dict())
                response.raise_for_status()
            self.logger.log(logging.INFO, 'Service registered successfully with the proxy.')
        except httpx.RequestError as e:
            self.logger.log(logging.ERROR, f'Failed to register service with proxy: {e}')
            raise HTTPException(status_code=500, detail='Failed to register service with proxy')
, stderr: 
2024-08-01 21:21:31,241 custom_logger INFO Handling command: mkdir -p project-root/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .
2024-08-01 21:21:31,242 custom_logger INFO Running command: mkdir -p project-root/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .
2024-08-01 21:21:31,273 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:21:38,591 custom_logger INFO Handling command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .
2024-08-01 21:21:38,593 custom_logger INFO Running command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .
2024-08-01 21:21:38,671 custom_logger ERROR Command execution failed: touch: cannot touch 'project-root/command_service/Dockerfile': No such file or directory
touch: cannot touch 'project-root/websocket_listener_service/Dockerfile': No such file or directory
touch: cannot touch 'project-root/proxy_service/Dockerfile': No such file or directory
touch: cannot touch 'project-root/elasticsearch/command_service-elasticsearch.yaml': No such file or directory
touch: cannot touch 'project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/command_service-deployment.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/command_service-service.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/websocket_listener_service-deployment.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/websocket_listener_service-service.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/proxy_service-deployment.yaml': No such file or directory
touch: cannot touch 'project-root/kubernetes/proxy_service-service.yaml': No such file or directory

2024-08-01 21:21:44,985 custom_logger INFO Handling command: mkdir -p project-root/command_service && mkdir -p project-root/websocket_listener_service && mkdir -p project-root/proxy_service && mkdir -p project-root/elasticsearch && mkdir -p project-root/kubernetes in path: .
2024-08-01 21:21:44,985 custom_logger INFO Running command: mkdir -p project-root/command_service && mkdir -p project-root/websocket_listener_service && mkdir -p project-root/proxy_service && mkdir -p project-root/elasticsearch && mkdir -p project-root/kubernetes in path: .
2024-08-01 21:21:45,027 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:21:52,720 custom_logger INFO Handling command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .
2024-08-01 21:21:52,721 custom_logger INFO Running command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .
2024-08-01 21:21:52,815 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:21:59,088 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8001\n\nCMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]' > project-root/command_service/Dockerfile in path: .
2024-08-01 21:21:59,088 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8001\n\nCMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]' > project-root/command_service/Dockerfile in path: .
2024-08-01 21:21:59,108 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:05,131 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8002\n\nCMD ["uvicorn", "websocket_listener_service.main:app", "--host", "0.0.0.0", "--port", "8002"]' > project-root/websocket_listener_service/Dockerfile in path: .
2024-08-01 21:22:05,132 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8002\n\nCMD ["uvicorn", "websocket_listener_service.main:app", "--host", "0.0.0.0", "--port", "8002"]' > project-root/websocket_listener_service/Dockerfile in path: .
2024-08-01 21:22:05,149 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:10,956 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8000\n\nCMD ["python", "proxy.py"]' > project-root/proxy_service/Dockerfile in path: .
2024-08-01 21:22:10,957 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8000\n\nCMD ["python", "proxy.py"]' > project-root/proxy_service/Dockerfile in path: .
2024-08-01 21:22:10,972 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:21,715 custom_logger INFO Handling command: echo 'version: "3.8"\n\nservices:\n  command_service:\n    build: ./command_service\n    ports:\n      - "8001:8001"\n    environment:\n      - ELASTIC_URL=http://command_service_elasticsearch:9200\n\n  websocket_listener_service:\n    build: ./websocket_listener_service\n    ports:\n      - "8002:8002"\n    environment:\n      - ELASTIC_URL=http://websocket_listener_elasticsearch:9200\n\n  proxy_service:\n    build: ./proxy_service\n    ports:\n      - "8000:8000"\n\n  command_service_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9201:9200"\n\n  websocket_listener_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9202:9200"' > project-root/docker-compose.yaml in path: .
2024-08-01 21:22:21,716 custom_logger INFO Running command: echo 'version: "3.8"\n\nservices:\n  command_service:\n    build: ./command_service\n    ports:\n      - "8001:8001"\n    environment:\n      - ELASTIC_URL=http://command_service_elasticsearch:9200\n\n  websocket_listener_service:\n    build: ./websocket_listener_service\n    ports:\n      - "8002:8002"\n    environment:\n      - ELASTIC_URL=http://websocket_listener_elasticsearch:9200\n\n  proxy_service:\n    build: ./proxy_service\n    ports:\n      - "8000:8000"\n\n  command_service_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9201:9200"\n\n  websocket_listener_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9202:9200"' > project-root/docker-compose.yaml in path: .
2024-08-01 21:22:21,738 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:29,112 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: ELASTIC_URL\n          value: "http://command-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > project-root/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:22:29,113 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: ELASTIC_URL\n          value: "http://command-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > project-root/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:22:29,128 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:39,284 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: ELASTIC_URL\n          value: "http://websocket-listener-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > project-root/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:22:39,285 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: ELASTIC_URL\n          value: "http://websocket-listener-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > project-root/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:22:39,303 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:48,742 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: proxy-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-service\n  template:\n    metadata:\n      labels:\n        app: proxy-service\n    spec:\n      containers:\n      - name: proxy-service\n        image: your_dockerhub_username/proxy-service:latest\n        ports:\n        - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: proxy-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8000\n    targetPort: 8000\n  selector:\n    app: proxy-service' > project-root/kubernetes/proxy_service-deployment.yaml in path: .
2024-08-01 21:22:48,743 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: proxy-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-service\n  template:\n    metadata:\n      labels:\n        app: proxy-service\n    spec:\n      containers:\n      - name: proxy-service\n        image: your_dockerhub_username/proxy-service:latest\n        ports:\n        - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: proxy-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8000\n    targetPort: 8000\n  selector:\n    app: proxy-service' > project-root/kubernetes/proxy_service-deployment.yaml in path: .
2024-08-01 21:22:48,762 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:22:59,181 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: command-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: command-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: command-service-elasticsearch' > project-root/elasticsearch/command_service-elasticsearch.yaml in path: .
2024-08-01 21:22:59,182 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: command-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: command-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: command-service-elasticsearch' > project-root/elasticsearch/command_service-elasticsearch.yaml in path: .
2024-08-01 21:22:59,198 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:23:08,323 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: websocket-listener-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: websocket-listener-service-elasticsearch' > project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml in path: .
2024-08-01 21:23:08,324 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: websocket-listener-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: websocket-listener-service-elasticsearch' > project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml in path: .
2024-08-01 21:23:08,341 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:28:33,963 custom_logger INFO Handling command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} && mv project-root/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && mv project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && mv project-root/elasticsearch/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/ && mv project-root/kubernetes/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/ in path: .
2024-08-01 21:28:33,964 custom_logger INFO Running command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} && mv project-root/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && mv project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && mv project-root/elasticsearch/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/ && mv project-root/kubernetes/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/ in path: .
2024-08-01 21:28:34,107 custom_logger ERROR Command execution failed: mv: cannot move 'project-root/proxy_service' to '/mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service': Directory not empty
mv: cannot move 'project-root/websocket_listener_service' to '/mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service': Directory not empty

2024-08-01 21:28:42,785 custom_logger INFO Handling command: cp -r project-root/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && cp project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && cp -r project-root/elasticsearch/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/ && cp -r project-root/kubernetes/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/ in path: .
2024-08-01 21:28:42,786 custom_logger INFO Running command: cp -r project-root/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && cp project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ && cp -r project-root/elasticsearch/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/ && cp -r project-root/kubernetes/* /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/ in path: .
2024-08-01 21:28:42,888 custom_logger ERROR Command execution failed: cp: cannot stat 'project-root/docker-compose.yaml': No such file or directory

2024-08-01 21:28:47,503 custom_logger INFO Handling command: cp project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ in path: .
2024-08-01 21:28:47,504 custom_logger INFO Running command: cp project-root/docker-compose.yaml /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/ in path: .
2024-08-01 21:28:47,517 custom_logger ERROR Command execution failed: cp: cannot stat 'project-root/docker-compose.yaml': No such file or directory

2024-08-01 21:29:24,708 custom_logger INFO Handling command: cp project-root/command_service/Dockerfile /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 21:29:24,709 custom_logger INFO Running command: cp project-root/command_service/Dockerfile /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 21:29:24,725 custom_logger ERROR Command execution failed: cp: cannot stat 'project-root/command_service/Dockerfile': No such file or directory

2024-08-01 21:29:37,007 custom_logger INFO Handling command: ls -R project-root in path: .
2024-08-01 21:29:37,008 custom_logger INFO Running command: ls -R project-root in path: .
2024-08-01 21:29:37,039 custom_logger INFO Command succeeded: stdout: project-root:
proxy_service
websocket_listener_service

project-root/proxy_service:
Dockerfile

project-root/websocket_listener_service:
Dockerfile
, stderr: 
2024-08-01 21:31:51,786 custom_logger INFO Handling command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .
2024-08-01 21:31:51,787 custom_logger INFO Running command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .
2024-08-01 21:31:51,805 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:31:58,626 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8001\n\nCMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 21:31:58,626 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8001\n\nCMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 21:31:58,641 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:05,196 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8002\n\nCMD ["uvicorn", "websocket_listener_service.main:app", "--host", "0.0.0.0", "--port", "8002"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/Dockerfile in path: .
2024-08-01 21:32:05,197 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8002\n\nCMD ["uvicorn", "websocket_listener_service.main:app", "--host", "0.0.0.0", "--port", "8002"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/Dockerfile in path: .
2024-08-01 21:32:05,216 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:11,481 custom_logger INFO Handling command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8000\n\nCMD ["python", "proxy.py"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/Dockerfile in path: .
2024-08-01 21:32:11,481 custom_logger INFO Running command: echo 'FROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nEXPOSE 8000\n\nCMD ["python", "proxy.py"]' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/Dockerfile in path: .
2024-08-01 21:32:11,498 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:22,344 custom_logger INFO Handling command: echo 'version: "3.8"\n\nservices:\n  command_service:\n    build: ./command_service\n    ports:\n      - "8001:8001"\n    environment:\n      - ELASTIC_URL=http://command_service_elasticsearch:9200\n\n  websocket_listener_service:\n    build: ./websocket_listener_service\n    ports:\n      - "8002:8002"\n    environment:\n      - ELASTIC_URL=http://websocket_listener_elasticsearch:9200\n\n  proxy_service:\n    build: ./proxy_service\n    ports:\n      - "8000:8000"\n\n  command_service_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9201:9200"\n\n  websocket_listener_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9202:9200"' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/docker-compose.yaml in path: .
2024-08-01 21:32:22,345 custom_logger INFO Running command: echo 'version: "3.8"\n\nservices:\n  command_service:\n    build: ./command_service\n    ports:\n      - "8001:8001"\n    environment:\n      - ELASTIC_URL=http://command_service_elasticsearch:9200\n\n  websocket_listener_service:\n    build: ./websocket_listener_service\n    ports:\n      - "8002:8002"\n    environment:\n      - ELASTIC_URL=http://websocket_listener_elasticsearch:9200\n\n  proxy_service:\n    build: ./proxy_service\n    ports:\n      - "8000:8000"\n\n  command_service_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9201:9200"\n\n  websocket_listener_elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n    environment:\n      - discovery.type=single-node\n    ports:\n      - "9202:9200"' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/docker-compose.yaml in path: .
2024-08-01 21:32:22,359 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:32,737 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: ELASTIC_URL\n          value: "http://command-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:32:32,738 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: ELASTIC_URL\n          value: "http://command-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:32:32,755 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:43,197 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: ELASTIC_URL\n          value: "http://websocket-listener-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:32:43,198 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: ELASTIC_URL\n          value: "http://websocket-listener-service-elasticsearch:9200"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:32:43,213 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:51,264 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: proxy-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-service\n  template:\n    metadata:\n      labels:\n        app: proxy-service\n    spec:\n      containers:\n      - name: proxy-service\n        image: your_dockerhub_username/proxy-service:latest\n        ports:\n        - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: proxy-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8000\n    targetPort: 8000\n  selector:\n    app: proxy-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/proxy_service-deployment.yaml in path: .
2024-08-01 21:32:51,265 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: proxy-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: proxy-service\n  template:\n    metadata:\n      labels:\n        app: proxy-service\n    spec:\n      containers:\n      - name: proxy-service\n        image: your_dockerhub_username/proxy-service:latest\n        ports:\n        - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: proxy-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8000\n    targetPort: 8000\n  selector:\n    app: proxy-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/proxy_service-deployment.yaml in path: .
2024-08-01 21:32:51,279 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:32:59,660 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: command-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: command-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: command-service-elasticsearch' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/command_service-elasticsearch.yaml in path: .
2024-08-01 21:32:59,662 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: command-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: command-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: command-service-elasticsearch' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/command_service-elasticsearch.yaml in path: .
2024-08-01 21:32:59,682 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:33:09,495 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: websocket-listener-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: websocket-listener-service-elasticsearch' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/websocket_listener_service-elasticsearch.yaml in path: .
2024-08-01 21:33:09,496 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: websocket-listener-service-elasticsearch\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service-elasticsearch\n    spec:\n      containers:\n      - name: elasticsearch\n        image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0\n        ports:\n        - containerPort: 9200\n        env:\n        - name: discovery.type\n          value: "single-node"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service-elasticsearch\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 9200\n    targetPort: 9200\n  selector:\n    app: websocket-listener-service-elasticsearch' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/elasticsearch/websocket_listener_service-elasticsearch.yaml in path: .
2024-08-01 21:33:09,512 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:36:11,710 custom_logger INFO Handling command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts && echo '#!/bin/bash\n\n# Set your Docker Hub username\nDOCKER_HUB_USERNAME="your_dockerhub_username"\n\n# Build Docker images\ndocker build -t $DOCKER_HUB_USERNAME/command-service:latest ./command_service\ndocker build -t $DOCKER_HUB_USERNAME/websocket-listener-service:latest ./websocket_listener_service\ndocker build -t $DOCKER_HUB_USERNAME/proxy-service:latest ./proxy_service\n\n# Push Docker images to Docker Hub\ndocker push $DOCKER_HUB_USERNAME/command-service:latest\ndocker push $DOCKER_HUB_USERNAME/websocket-listener-service:latest\ndocker push $DOCKER_HUB_USERNAME/proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh in path: .
2024-08-01 21:36:11,711 custom_logger INFO Running command: mkdir -p /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts && echo '#!/bin/bash\n\n# Set your Docker Hub username\nDOCKER_HUB_USERNAME="your_dockerhub_username"\n\n# Build Docker images\ndocker build -t $DOCKER_HUB_USERNAME/command-service:latest ./command_service\ndocker build -t $DOCKER_HUB_USERNAME/websocket-listener-service:latest ./websocket_listener_service\ndocker build -t $DOCKER_HUB_USERNAME/proxy-service:latest ./proxy_service\n\n# Push Docker images to Docker Hub\ndocker push $DOCKER_HUB_USERNAME/command-service:latest\ndocker push $DOCKER_HUB_USERNAME/websocket-listener-service:latest\ndocker push $DOCKER_HUB_USERNAME/proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh in path: .
2024-08-01 21:36:11,747 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:36:17,133 custom_logger INFO Handling command: echo '#!/bin/bash\n\n# Apply Elasticsearch deployments\nkubectl apply -f ./elasticsearch/command_service-elasticsearch.yaml\nkubectl apply -f ./elasticsearch/websocket_listener_service-elasticsearch.yaml\n\n# Apply service deployments\nkubectl apply -f ./kubernetes/command_service-deployment.yaml\nkubectl apply -f ./kubernetes/websocket_listener_service-deployment.yaml\nkubectl apply -f ./kubernetes/proxy_service-deployment.yaml\n\n# List all pods and services to verify\nkubectl get pods\nkubectl get services' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/deploy_k8s.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/deploy_k8s.sh in path: .
2024-08-01 21:36:17,134 custom_logger INFO Running command: echo '#!/bin/bash\n\n# Apply Elasticsearch deployments\nkubectl apply -f ./elasticsearch/command_service-elasticsearch.yaml\nkubectl apply -f ./elasticsearch/websocket_listener_service-elasticsearch.yaml\n\n# Apply service deployments\nkubectl apply -f ./kubernetes/command_service-deployment.yaml\nkubectl apply -f ./kubernetes/websocket_listener_service-deployment.yaml\nkubectl apply -f ./kubernetes/proxy_service-deployment.yaml\n\n# List all pods and services to verify\nkubectl get pods\nkubectl get services' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/deploy_k8s.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/deploy_k8s.sh in path: .
2024-08-01 21:36:17,155 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:36:24,436 custom_logger INFO Handling command: echo 'import requests\n\n# Replace with the actual IPs of your deployed services\nproxy_service_ip = "PROXY_SERVICE_IP"\ncommand_service_ip = "COMMAND_SERVICE_IP"\nwebsocket_listener_service_ip = "WEBSOCKET_LISTENER_SERVICE_IP"\n\n# URLs for registration\nregister_url = f"http://{proxy_service_ip}:8000/register"\n\n# Service data\nservices = [\n    {\n        "service_name": "command-service",\n        "openapi_url": f"http://{command_service_ip}:8001/openapi.json"\n    },\n    {\n        "service_name": "websocket-listener-service",\n        "openapi_url": f"http://{websocket_listener_service_ip}:8002/openapi.json"\n    }\n]\n\n# Register each service\nfor service_data in services:\n    response = requests.post(register_url, json=service_data)\n    print(f"Registering {service_data['service_name']}: {response.json()}")' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/register_services.py in path: .
2024-08-01 21:36:24,437 custom_logger INFO Running command: echo 'import requests\n\n# Replace with the actual IPs of your deployed services\nproxy_service_ip = "PROXY_SERVICE_IP"\ncommand_service_ip = "COMMAND_SERVICE_IP"\nwebsocket_listener_service_ip = "WEBSOCKET_LISTENER_SERVICE_IP"\n\n# URLs for registration\nregister_url = f"http://{proxy_service_ip}:8000/register"\n\n# Service data\nservices = [\n    {\n        "service_name": "command-service",\n        "openapi_url": f"http://{command_service_ip}:8001/openapi.json"\n    },\n    {\n        "service_name": "websocket-listener-service",\n        "openapi_url": f"http://{websocket_listener_service_ip}:8002/openapi.json"\n    }\n]\n\n# Register each service\nfor service_data in services:\n    response = requests.post(register_url, json=service_data)\n    print(f"Registering {service_data['service_name']}: {response.json()}")' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/register_services.py in path: .
2024-08-01 21:36:24,452 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:37:59,537 custom_logger INFO Handling command: chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/*.sh in path: .
2024-08-01 21:37:59,538 custom_logger INFO Running command: chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/*.sh in path: .
2024-08-01 21:37:59,579 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:38:13,141 custom_logger INFO Handling command: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh in path: .
2024-08-01 21:38:13,142 custom_logger INFO Running command: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_push_images.sh in path: .
2024-08-01 21:38:18,751 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:db41bd8f062c8404feb0e0533da63a7047e751b8aa3c36e907910201de372cbb
#1 transferring context: 0.0s
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:f06f12159254c9d920b7f602e89d329089a53d8470fb7b75c61a657c3ab89f64
#2 transferring dockerfile: 2B 0.1s done
#2 DONE 0.1s
failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount4101396976/Dockerfile: no such file or directory
unable to prepare context: path "./websocket_listener_service" not found
unable to prepare context: path "./proxy_service" not found
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 21:42:16,479 custom_logger INFO Handling command: echo 'import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("COMMAND_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "command-service",
        "openapi_url": f"http://{service_ip}:8001/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering command-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8001)' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 21:42:16,480 custom_logger INFO Running command: echo 'import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("COMMAND_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "command-service",
        "openapi_url": f"http://{service_ip}:8001/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering command-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8001)' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 21:42:16,502 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:42:24,344 custom_logger INFO Handling command: echo 'import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("WEBSOCKET_LISTENER_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "websocket-listener-service",
        "openapi_url": f"http://{service_ip}:8002/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering websocket-listener-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8002)' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/main.py in path: .
2024-08-01 21:42:24,346 custom_logger INFO Running command: echo 'import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("WEBSOCKET_LISTENER_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "websocket-listener-service",
        "openapi_url": f"http://{service_ip}:8002/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering websocket-listener-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8002)' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/main.py in path: .
2024-08-01 21:42:24,369 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:42:33,025 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: PROXY_SERVICE_IP\n          value: "proxy_service_ip"  # Replace with actual proxy service IP\n        - name: COMMAND_SERVICE_IP\n          value: "command_service_ip"  # Replace with actual command service IP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:42:33,026 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: command-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: command-service\n  template:\n    metadata:\n      labels:\n        app: command-service\n    spec:\n      containers:\n      - name: command-service\n        image: your_dockerhub_username/command-service:latest\n        ports:\n        - containerPort: 8001\n        env:\n        - name: PROXY_SERVICE_IP\n          value: "proxy_service_ip"  # Replace with actual proxy service IP\n        - name: COMMAND_SERVICE_IP\n          value: "command_service_ip"  # Replace with actual command service IP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: command-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8001\n    targetPort: 8001\n  selector:\n    app: command-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/command_service-deployment.yaml in path: .
2024-08-01 21:42:33,041 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:42:40,789 custom_logger INFO Handling command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: PROXY_SERVICE_IP\n          value: "proxy_service_ip"  # Replace with actual proxy service IP\n        - name: WEBSOCKET_LISTENER_SERVICE_IP\n          value: "websocket_listener_service_ip"  # Replace with actual websocket listener service IP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:42:40,790 custom_logger INFO Running command: echo 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: websocket-listener-service\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: websocket-listener-service\n  template:\n    metadata:\n      labels:\n        app: websocket-listener-service\n    spec:\n      containers:\n      - name: websocket-listener-service\n        image: your_dockerhub_username/websocket-listener-service:latest\n        ports:\n        - containerPort: 8002\n        env:\n        - name: PROXY_SERVICE_IP\n          value: "proxy_service_ip"  # Replace with actual proxy service IP\n        - name: WEBSOCKET_LISTENER_SERVICE_IP\n          value: "websocket_listener_service_ip"  # Replace with actual websocket listener service IP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: websocket-listener-service\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8002\n    targetPort: 8002\n  selector:\n    app: websocket-listener-service' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/kubernetes/websocket_listener_service-deployment.yaml in path: .
2024-08-01 21:42:40,806 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 21:43:14,095 custom_logger INFO Handling command: ./scripts/build_push_images.sh your_dockerhub_username in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 21:43:14,096 custom_logger INFO Running command: ./scripts/build_push_images.sh your_dockerhub_username in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 21:44:06,431 custom_logger ERROR Command execution failed: #2 [internal] load .dockerignore
#2 sha256:423cc67d4594ec90a9f3d63675645b422ecb34359dbe4161f0b992c07138af81
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:fc0080760fbb2b12137730fe25c34e850d010d557df314d41426af69088506c8
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 2.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 resolve docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104 0.0s done
#4 ...

#6 [internal] load build context
#6 sha256:b130204185fdff5df7c18f5079c00102f5e97631394ef674f7b0fb54ecf4ecd2
#6 transferring context: 935B 0.0s done
#6 DONE 0.1s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 0B / 11.67MB 0.1s
#4 sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104 10.41kB / 10.41kB done
#4 sha256:b2d6266a63eafff4fcee6a9149b80686ff6c17b0e4556d0320198ce85e9aa41d 1.94kB / 1.94kB done
#4 sha256:5208c64e1783e15b2d0ee357a3979688ae3faa21c6a43f4965e3530d68abbcfc 6.93kB / 6.93kB done
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 0B / 29.13MB 0.1s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 0B / 3.51MB 0.1s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 2.10MB / 29.13MB 1.7s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 1.05MB / 11.67MB 2.2s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 4.19MB / 29.13MB 2.8s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 2.10MB / 11.67MB 3.1s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 1.05MB / 3.51MB 3.4s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 3.15MB / 11.67MB 4.4s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 1.61MB / 3.51MB 5.0s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 5.80MB / 29.13MB 5.2s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 2.10MB / 3.51MB 5.2s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 4.19MB / 11.67MB 5.5s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 7.34MB / 29.13MB 6.2s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 5.24MB / 11.67MB 6.7s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 3.13MB / 3.51MB 6.7s
#4 sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 3.51MB / 3.51MB 7.2s done
#4 sha256:e5635d0cdd4c514a4e76d97174785a452a1e81b87b6a8bd8ce09c5ac2d135df8 0B / 230B 7.4s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 5.97MB / 11.67MB 7.7s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 9.44MB / 29.13MB 7.7s
#4 sha256:e5635d0cdd4c514a4e76d97174785a452a1e81b87b6a8bd8ce09c5ac2d135df8 230B / 230B 7.7s done
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 0B / 2.78MB 7.9s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 6.86MB / 11.67MB 9.2s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 11.53MB / 29.13MB 9.6s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 327.68kB / 2.78MB 10.0s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 1.05MB / 2.78MB 10.1s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 7.73MB / 11.67MB 10.5s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 8.39MB / 11.67MB 10.7s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 13.45MB / 29.13MB 11.8s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 1.79MB / 2.78MB 11.9s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 9.44MB / 11.67MB 12.1s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 2.10MB / 2.78MB 12.1s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 2.53MB / 2.78MB 12.5s
#4 sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 2.78MB / 2.78MB 12.5s done
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 10.49MB / 11.67MB 13.0s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 15.12MB / 29.13MB 13.3s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 16.78MB / 29.13MB 14.1s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 11.49MB / 11.67MB 14.2s
#4 sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 11.67MB / 11.67MB 14.5s done
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 18.70MB / 29.13MB 15.3s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 20.97MB / 29.13MB 16.3s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 22.95MB / 29.13MB 17.2s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 25.17MB / 29.13MB 17.9s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 27.17MB / 29.13MB 18.8s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 29.13MB / 29.13MB 19.7s
#4 sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 29.13MB / 29.13MB 19.7s done
#4 extracting sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559
#4 extracting sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 5.1s
#4 extracting sha256:efc2b5ad9eec05befa54239d53feeae3569ccbef689aa5e5dbfc25da6c4df559 7.3s done
#4 extracting sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962
#4 extracting sha256:0d935f02ede5b557e3899b4161a3a7f7dd8461fd62d558451b3884172a710962 0.8s done
#4 extracting sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742
#4 extracting sha256:fea4f2170757fa9e87b6421086bf5d32880bd009555941641108ea89519b5742 2.7s done
#4 extracting sha256:e5635d0cdd4c514a4e76d97174785a452a1e81b87b6a8bd8ce09c5ac2d135df8
#4 extracting sha256:e5635d0cdd4c514a4e76d97174785a452a1e81b87b6a8bd8ce09c5ac2d135df8 done
#4 extracting sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83
#4 extracting sha256:ebe530eb534fda723884e0b61fa4633bb792a9600f452a779301c8a7e4216d83 0.8s done
#4 DONE 33.6s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 DONE 0.4s

#7 [3/4] COPY . /app
#7 sha256:9f21875d8b39616c573241ac46a74685e5094a3ebf7e351a968c7c32441fbf72
#7 DONE 0.1s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:52251284d6827448d91ce633f992d9f93fcbc39e4dac298e5e87b71f88c5b6e1
#8 3.653 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.282 
#8 4.282 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.282 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load build definition from Dockerfile
#1 sha256:ca3625be8ec35e90e43295b9e178e444af6df72454e4c41568a9f8f1272ff15e
#1 transferring dockerfile: 253B 0.0s done
#1 DONE 0.1s

#2 [internal] load .dockerignore
#2 sha256:bf7ac910a2ed1318fb8a6742850e2d16fa432f8e6a2551468131c5d5ba9830c1
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:fb4e1aacf3a129eddb86bd98eb8cf8e5d17c729c19f3ea9dd8e925f44b9c02c8
#6 transferring context: 48.53kB 0.3s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:f8a120ccf27ee1c14f8ab40b00e8d6497dff9a96b644f45f4db84de90ede15ee
#7 DONE 0.1s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:c5339b00101dfc2d184ac1b582e2fe7e11126c1c63b26e17d245f92b22821fd6
#8 3.301 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.898 
#8 3.898 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.898 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:d22a5ace0a37f5c6fc42b1e4fc4ee74be977a3556bf876b63794f736a7a4533a
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:6361b1b40c73f15fae1929c1c946120dd1f2306d84fce6745b27087a92e829ff
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:562fbb7c0808ee16a3fc3c927ebc9d60f0d9ada518d3e7dd7d056085a7ab7e68
#6 transferring context: 5.87kB 0.0s done
#6 DONE 0.1s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:e8001d0ea1700be1b0a144e09060cc8b4526b293699c4d90ecd9ee74dc5c2c3e
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:3c76002cb7e4ac8ce83b2b3e89e32ebc8c933fbe2f4ba477b38a3661454db6e1
#8 3.513 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.120 
#8 4.120 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.120 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 21:45:48,181 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 21:45:48,182 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 21:46:04,472 custom_logger ERROR Command execution failed: #2 [internal] load .dockerignore
#2 sha256:630262fea31749448d87e24dc4d65a347a0557714e7b44489272cc216f34b9e6
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:4947e7d568436d7b51da711a41a6c052092395f5d233833f4feefa7b27ddecc6
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.6s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:8f41802c4e99619783e24e0fa5337ea167954cf20ea5fc8bd98d6561169cf4bb
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:0b5b2af9f340a3733cb0e9955f74cd89d99dc285c1a51019b246a1edfd0e8d89
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:00c69a3eca9aa9163c99f87e483a773c847561b8afd8618a1af27b5d08e240ff
#8 3.184 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.807 
#8 3.807 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.807 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:d7f97c40f684cfa90c828f8b74a0ac070e4d34db7f09b885cf84d986467ccf4c
#2 transferring context: 2B 0.1s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:811dca8d5a3e20c1f2c7fba2fa73fcb7d766db02c861bbd9b47089b32a615db9
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:987e56e8ae8dd8cf955d3b51b7a6580c8c39fa5a1c1b8e7ea29d18875a8338da
#6 transferring context: 2.27kB 0.3s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:317127f22f3d8db302254194917d0c2a2ed76bf538fb128d983fc9eeef2b1973
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:449e8f1593e75134d66e7b0428646e86303a8bf6d3578ab33ab609fef0cc98a8
#8 3.479 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.140 
#8 4.140 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.140 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:42d3d1f3da7369af3d4657adc634291032eba8665dc9fc7012d9795d32f31fa2
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:a3b73180b2b766ac9dae983214f3495e4ae6f4b1a3c7e3361bce67a38033ab51
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:95dbad62ff19fc2bbfadbb8b8d14ae6f7ef1e8382be3817ebabc3932f39f13b1
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:9d05ecec2f1f7982f0f3c89ba5e2e3f5695d4d16c34df38ecc46798dab023638
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:396a46027ae0b96da1833e573092a1b5d1628cc68609ec7578f0a6a5f97b022e
#8 3.446 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.084 
#8 4.084 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.084 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 21:47:55,334 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:47:55,366 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/proxy-service-logs/_search
2024-08-01 21:48:06,420 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:48:06,431 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/proxy-service-logs/_search
2024-08-01 21:48:19,681 custom_logger INFO Handling command: curl -X GET 'http://localhost:9200/_cat/indices?v' in path: .
2024-08-01 21:48:19,682 custom_logger INFO Running command: curl -X GET 'http://localhost:9200/_cat/indices?v' in path: .
2024-08-01 21:48:19,792 custom_logger ERROR Command execution failed:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   448  100   448    0     0   9142      0 --:--:-- --:--:-- --:--:--  9333

2024-08-01 21:48:28,665 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:48:28,674 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/logs/_search
2024-08-01 21:48:37,488 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:48:37,576 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/logs/_search
2024-08-01 21:48:45,806 custom_logger INFO Handling command: curl -X GET 'http://localhost:9200/logs/_search?pretty' -H 'Content-Type: application/json' -d'{"query":{"match_all":{}}}' in path: .
2024-08-01 21:48:45,807 custom_logger INFO Running command: curl -X GET 'http://localhost:9200/logs/_search?pretty' -H 'Content-Type: application/json' -d'{"query":{"match_all":{}}}' in path: .
2024-08-01 21:48:45,998 custom_logger ERROR Command execution failed:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  4194  100  4168  100    26  23817    148 --:--:-- --:--:-- --:--:-- 23965

2024-08-01 21:52:06,069 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 21:52:06,084 custom_logger ERROR Failed to execute ElasticSearch query: 400 Client Error: Bad Request for url: http://localhost:9200/logs/_search
2024-08-01 21:58:58,293 custom_logger INFO Handling command: curl -X GET 'http://localhost:9200/_cluster/health?pretty' in path: .
2024-08-01 21:58:58,294 custom_logger INFO Running command: curl -X GET 'http://localhost:9200/_cluster/health?pretty' in path: .
2024-08-01 21:58:58,375 custom_logger ERROR Command execution failed:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   480  100   480    0     0   7868      0 --:--:-- --:--:-- --:--:--  7868

2024-08-01 21:59:12,146 custom_logger INFO Handling command: curl -X GET 'http://localhost:9200/logs/_mapping?pretty' in path: .
2024-08-01 21:59:12,147 custom_logger INFO Running command: curl -X GET 'http://localhost:9200/logs/_mapping?pretty' in path: .
2024-08-01 21:59:12,171 custom_logger ERROR Command execution failed:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   813  100   813    0     0   113k      0 --:--:-- --:--:-- --:--:--  113k

2024-08-01 22:01:02,356 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:01:02,357 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:01:19,232 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:f18e91c5538985998a0e79bc653712a371b083408d2429ed661e2d15a0b62121
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:6845d955862e2a92e3513dabd7dd7b28e95ccd557764850340cddd4e319a9af8
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 1.2s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:052075bca5b5baa98a4e53aa0c634cf7f88a13d03ff5f0d213078e9fdc1c9973
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:7b8241d9abab545c2d0cb471b4c7b045a48334f43e6860052766051716eea4ea
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:e0444e66612f2cfcf6a3c15208232456b58df6ffc7bbfdc1ef15744eca46cb03
#8 3.224 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.839 
#8 3.839 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.839 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:8537b0b67ab15ff344bb1b2ea912075b128be51621795c8ba4ad213032d1eb11
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:af4a88677f5b1c960856aba733233325a970369db630ae88b872a78172246067
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:728d9acb348cc568ba4e551c767a806b2bdf0ceb4e936da03a62a5ebc03e86e5
#6 transferring context: 2.27kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:76be8553a3a1429a36c6b8976c00566cea633b76f9c982d5e7961d311f373363
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:35de6ff426b7e3a5e510120171d66354b1d4412a32afddc58af5bfda57bfbedb
#8 3.622 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.239 
#8 4.239 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.239 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:0e1c5c798cbf61542b7a865c97742854a1f031fb65b92087b9d3b1ccf13d00fe
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:d6bea577fbaa6096d66c294fa68c433a1765044dcd93d6f756641f878c31e49b
#1 transferring dockerfile: 186B 0.0s done
#1 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:ae163c6f049c144ea09b38a85a5f43e2c4253f62f03c8f76557b9cc37c3e2380
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:8b381885217b81909d209da3cd8b6a86e18e1f3f3e5cb4db8f0f8e1a651f99a4
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:4731ca212e5be7332e6a5a8504ab7f92a3250dd2f3705a6c081d9f711b31e5c9
#8 3.453 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.093 
#8 4.093 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.093 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:01:31,323 custom_logger INFO Handling command: kubectl logs <command-service-pod-name> in path: .
2024-08-01 22:01:31,324 custom_logger INFO Running command: kubectl logs <command-service-pod-name> in path: .
2024-08-01 22:01:31,336 custom_logger ERROR Command execution failed: /bin/sh: 1: Syntax error: end of file unexpected

2024-08-01 22:01:41,393 custom_logger INFO Handling command: kubectl get pods --selector=app=command-service -o jsonpath='{.items[0].metadata.name}' in path: .
2024-08-01 22:01:41,393 custom_logger INFO Running command: kubectl get pods --selector=app=command-service -o jsonpath='{.items[0].metadata.name}' in path: .
2024-08-01 22:01:41,766 custom_logger ERROR Command execution failed: error: the server doesn't have a resource type "pods"

2024-08-01 22:01:51,872 custom_logger INFO Handling command: kubectl config current-context in path: .
2024-08-01 22:01:51,873 custom_logger INFO Running command: kubectl config current-context in path: .
2024-08-01 22:01:51,967 custom_logger ERROR Command execution failed: error: current-context is not set

2024-08-01 22:02:05,323 custom_logger INFO Handling command: kubectl config get-contexts in path: .
2024-08-01 22:02:05,324 custom_logger INFO Running command: kubectl config get-contexts in path: .
2024-08-01 22:02:05,411 custom_logger INFO Command succeeded: stdout: CURRENT   NAME   CLUSTER   AUTHINFO   NAMESPACE
, stderr: 
2024-08-01 22:06:07,185 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:06:07,185 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:06:28,581 custom_logger ERROR Command execution failed: #2 [internal] load .dockerignore
#2 sha256:5e7a113dd5ec9d1f55632e31c5b84b8712b868e83670a274eec6d168203e0e7d
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:cb392bc8a55e29d4dc5da53d2c8c83ad1d1e252d3c7ad8d4d485cb3b30fbf6d0
#1 transferring dockerfile: 242B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 4.0s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:6353394908da1e252fdcd8c6fffce9f89b28b2faa3c8cb06ce923708aba7ac2a
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:c6721b9061f97ebf1f02fc62db9c842adb35ea4cf5a36812c426109f665ea3ea
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:c23a8c0fb23c28b3ac2f4f9a343457833cc0c02873778dc794fc7a6d6710f301
#8 3.371 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.054 
#8 4.054 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.054 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load build definition from Dockerfile
#1 sha256:eb3a722e028ab9e8b2ba9dd21d2883ad63aed1d6777e9e1fb5886cde80f0230c
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#2 [internal] load .dockerignore
#2 sha256:52df5267bfd28b37a8f6da8c2fe91e6330e184e8428fb2cdf845850c499bb4d4
#2 transferring context: 2B 0.1s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:2b6ffce933a2dbfc22cc7ad949a7542a27bab20399d69976122ad518fb9698d6
#6 transferring context: 2.27kB 0.5s done
#6 DONE 0.5s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:25e4786e30149e61fe2f9092a25244cef189a11d47c9ae1a6cd28f887b404fbd
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:ed3700e1e267ddb9834fae9022f0bbdce264379f1c28c18c280a024754165244
#8 3.745 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.448 
#8 4.448 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.448 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:8da12fca767239d10942d8e3145f75d4f3468f381902802cfec9685659488217
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:986bd6c4b34a6368c881f9ba68562ad10843820d17a8a5166ec8f614e25c994c
#1 transferring dockerfile: 186B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:f707259fc9e03faf93990821207f984115b439f173ef4614149011a281e3ba0c
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:b7ee4ba630e8fb030edb3049f1fe3673da6a039d560a73fa5b9d837443eba973
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:213b7d834a00799cc379ad433b4281c5c882df5dbc219bd1854b956a6c6bfff7
#8 4.280 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.978 
#8 4.978 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.978 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:06:55,847 custom_logger INFO Handling command: docker images | grep hypntranz in path: .
2024-08-01 22:06:55,848 custom_logger INFO Running command: docker images | grep hypntranz in path: .
2024-08-01 22:06:56,036 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:07:19,175 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:07:19,175 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:07:41,406 custom_logger ERROR Command execution failed: #2 [internal] load .dockerignore
#2 sha256:90d7ad369f74fb7a3fd75ff7987d27dcb180a88ee5fcbc6da7fce7dc24ff20f5
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:c569aae4671dee546a4296b96c0a22842d228f4eb5be700da936e42f592bd332
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:7900752096230a5618fae0b04a509556909d579aca2eeec20f16d8ae2cae0204
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:04b1af1129ed68acb886ac4ed5a970fb10413624c1c06a04012bf375d62efc82
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:84393d1091c0ac3c58c7535adba426cc79676327d46ded88a56d34c5b1493941
#8 3.110 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.803 
#8 3.803 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.803 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:bf8f3e70c4a20c2c9427339604024390e0c5665dbbb87197ea23d97545e8fb71
#1 transferring context: 2B 0.1s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:fbe274ec89b5b8bd136f9cf017090274cc9e1565f58ede15c5f5e0818921a141
#2 transferring dockerfile: 253B 0.1s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:5a1bb0209555c4591ce67112662b57d56f4b915f9de497813208bb7a9e1c96c3
#6 transferring context: 2.27kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:197f01f98d500ef18a83130dfc030f6796f4000d52a32b19cf5cb37a664593ee
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:8c3af48c46c5adb0da055712fe6badaf1413ab81cad6b947a3d5187ac3ea8e35
#8 3.372 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.020 
#8 4.020 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.020 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:b88e3f1d965287bf1211f235bce6349df48a8312862ea73bca144d7bf6ae378b
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:13be310dba8a93602a475c0ead6abb40fb2f3c334847b7b8a715102ae0bbd763
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:5afd212eccf032e960b0585058b770cc42c9776d04c32333cc3f1554591af2ac
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:33bc160a92cc917c614ae2f523bd3d1e9ad39612cf6f70b573f0eebc90ecb44a
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:ef46e43119f7408ca8cee91572f08e26065c81015c2299a35541b50e0a356054
#8 3.666 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.343 
#8 4.343 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.343 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:08:05,750 custom_logger INFO Handling command: docker images | grep hypntranz in path: .
2024-08-01 22:08:05,751 custom_logger INFO Running command: docker images | grep hypntranz in path: .
2024-08-01 22:08:05,901 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:08:27,198 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:08:27,199 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:08:49,053 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:ffd1a31752015b24e34dae2d881b0f054ca70c6632245120ad42686b0650a423
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:294ab6da5c36d63cf00e3491db738c158cabb8eff6e6531f0a1997d33c363ad1
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:329131d5bb00611042d0ab4a354a0567027c0c6e7f8a479b1d38baf473129bb5
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:c7d5522303e493ecf9d45b578528e70595983d070ee6b47158abe2407a780a0c
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:9519823bf186326b4122c4aba29ff2f309729ce90b235d62a8cbff46ab6b9f77
#8 3.190 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.165 
#8 4.165 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.165 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:8794b4ea2a31ce6c7dca5a93e19a8419e4daeec9a00ac68f30e5aca198c326cc
#2 transferring context: 2B 0.1s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:e19813218a5f83981247f74a62e40f8652ca7ffad84bf9cd4aaa654902f0e7d3
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:608bfee4eeaf14e5785a31c88a944fa034b435a6c16c30af8cd0f9de9af9ea04
#6 transferring context: 2.27kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:f5f11257e98aac9b8dc4a48e7585b84375c5d8008de97e1333a4ea4f65b8f169
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:1f656c8f8a8f4050306bdc280e5df1839fae55e58632028611a8a7bf71cddfbc
#8 3.601 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 4.208 
#8 4.208 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.208 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:cecdd80cd90a701b7ed8b37650bade5535fd33a6d8e12e3524b7bacf349c5355
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:20f29ea23de27b6143c7fa750ff0a770f09f033c8bc89d2a22870ebf3f60ce39
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:97355ae13efb62d39cf4e4ec9faebc05909c3b86e013f499e1cdf2b6739dabeb
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:2efe6a4d5ae350f2a71e057555bf1f033ed9e42b90d4bbeb96742a8f305a0819
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:27d845f07b01cbdc8e0a445ae9d76de4a22d36f578a5e5fd1ce7ff332067e143
#8 3.012 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.605 
#8 3.605 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.605 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:09:04,952 custom_logger INFO Handling command: docker images | grep hypntranz in path: .
2024-08-01 22:09:04,960 custom_logger INFO Running command: docker images | grep hypntranz in path: .
2024-08-01 22:09:05,113 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:09:24,188 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:09:24,189 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:09:39,229 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:8bcae1c3ab341f8646b1b6d42173ec223ee2ca52331f58bdabbfaee73de69c37
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:6fd19992cdbba5c6991843b8d15218ecff8dc63ea2dbdf60b9ceeff355f30184
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:3b0df02a35dc8a83420dc4215f3a461f03ddf52beeebb8a351096db058d30dad
#6 transferring context: 59B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:4c2200d7230c5c35390150946d1d107f67e93a94186fdd2f6acd59b56b5d2173
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:e5cfa9130e2ea1dcc44328b0c4f6adda08ea8404da25bbd4558d94b356f20a5e
#8 3.068 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.705 
#8 3.705 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.705 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:62529b7fef8f894829c799c77b790263a3e53f26f8a382fba9db80bf1499609e
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:62b2d45b45e3e9e62f2a8a5200a75a210c1c325655096f7be8cf69f60611172a
#2 transferring dockerfile: 253B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:dfb2c1a8e3fc6e88036663fb52dcc4fd9892ef11099e647da3f091fd88d50466
#6 transferring context: 2.27kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:486af7c615027d71a222873440b97aff337eb7c6a3938fd11b85aa56abef06e1
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:8d1818ce5286b2da3893499122750de13e7e971f1f58f07100423dd01a120cad
#8 3.287 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.929 
#8 3.929 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.929 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:d0006127578f804af76bfa77bf29b266a664af06e6adaaa7841014e00969ce55
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:5bb37a3a520815c2a487d2e2439f83ffe6819966f16fb3df88a7e380a4ad7e8a
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:bcb7024ef5c0a801b85b9d73828e45a026be329a7bcca4ee1f0aaf85af2c33ca
#6 transferring context: 60B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:45b5f65322b73b0c969ce389b067257f775094c5a3291fc9c1f6d893e209f697
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:d6cd8cd0883e5c1229fce93b34f019599a63f4410b79687d4b2d1e6f9d087eb7
#8 3.301 ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'
#8 3.956 
#8 3.956 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 3.956 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:37:32,861 custom_logger INFO Handling command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service
2024-08-01 22:37:32,862 custom_logger INFO Running command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service
2024-08-01 22:37:32,899 custom_logger INFO Command succeeded: stdout: ./main.py:import requests
./main.py:import uvicorn
./main.py:import os
./main.py:from fastapi import FastAPI
, stderr: 
2024-08-01 22:37:56,570 custom_logger INFO Handling command: echo 'requests
uvicorn
fastapi' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: .
2024-08-01 22:37:56,571 custom_logger INFO Running command: echo 'requests
uvicorn
fastapi' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: .
2024-08-01 22:37:56,586 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:38:01,619 custom_logger INFO Handling command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service
2024-08-01 22:38:01,619 custom_logger INFO Running command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service
2024-08-01 22:38:02,175 custom_logger INFO Command succeeded: stdout: ./controllers/listener_controller.py:import logging
./controllers/listener_controller.py:import httpx
./main.py:import requests
./main.py:import uvicorn
./main.py:import os
./services/config_service.py:import json
./services/config_service.py:import logging
./services/config_service.py:import os
./services/config_service.py:import uuid
./services/forward_service.py:import httpx
./services/forward_service.py:import logging
./services/registry_service.py:import logging
./services/registry_service.py:import httpx
./services/registry_service.py:import asyncio
./tests/test_config_service.py:import os
./tests/test_config_service.py:import json
./tests/test_config_service.py:import pytest
./websocket/websocket_handler.py:import asyncio
./websocket/websocket_handler.py:import httpx
./websocket/websocket_handler.py:import json
./websocket/websocket_handler.py:import websockets
./websocket/websocket_handler.py:import logging
./controllers/listener_controller.py:from fastapi import APIRouter, HTTPException, Depends, Request
./controllers/listener_controller.py:from websocket_listener_service.models.envelope import Envelope
./controllers/listener_controller.py:from websocket_listener_service.models.register_request import RegisterRequest
./controllers/listener_controller.py:from websocket_listener_service.models.deregister_request import DeregisterRequest
./controllers/listener_controller.py:from websocket_listener_service.services.forward_service import ForwardService
./controllers/listener_controller.py:from websocket_listener_service.services.registry_service import RegistryService
./main.py:from fastapi import FastAPI
./models/deregister_request.py:from pydantic import BaseModel
./models/envelope.py:from pydantic import BaseModel, Field
./models/envelope.py:from typing import Any, Optional
./models/register_request.py:from typing import Optional, Dict, Any
./models/register_request.py:from pydantic import BaseModel
./services/forward_service.py:from fastapi import HTTPException
./services/forward_service.py:from websocket_listener_service.models.envelope import Envelope
./services/registry_service.py:from fastapi import HTTPException
./services/registry_service.py:from websocket_listener_service.models.register_request import RegisterRequest
./services/registry_service.py:from websocket_listener_service.models.deregister_request import DeregisterRequest
./tests/test_config_service.py:from unittest.mock import patch, mock_open
./tests/test_config_service.py:from websocket_listener_service.services.config_service import ConfigService
./websocket/websocket_handler.py:from fastapi import WebSocket, WebSocketDisconnect, HTTPException
./websocket/websocket_handler.py:from websocket_listener_service.models.envelope import Envelope
./websocket/websocket_handler.py:from websocket_listener_service.services.forward_service import ForwardService
./websocket/websocket_handler.py:from websocket_listener_service.services.config_service import ConfigService
, stderr: 
2024-08-01 22:38:17,886 custom_logger INFO Handling command: echo 'httpx
requests
uvicorn
websockets
fastapi
pydantic' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: .
2024-08-01 22:38:17,887 custom_logger INFO Running command: echo 'httpx
requests
uvicorn
websockets
fastapi
pydantic' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: .
2024-08-01 22:38:17,901 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:38:21,147 custom_logger INFO Handling command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service
2024-08-01 22:38:21,148 custom_logger INFO Running command: grep '^import ' -R ./*; grep '^from ' -R ./* in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service
2024-08-01 22:38:21,176 custom_logger INFO Command succeeded: stdout: ./proxy.py:import requests
./proxy.py:import asyncio
./proxy.py:import yaml
./proxy.py:import logging
./proxy.py:from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Body
./proxy.py:from pydantic import BaseModel, Field
./proxy.py:from typing import Any, Optional
./proxy.py:from fastapi.openapi.utils import get_openapi
./proxy.py:from contextlib import asynccontextmanager
, stderr: 
2024-08-01 22:38:43,624 custom_logger INFO Handling command: echo 'requests
yaml
fastapi
pydantic' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: .
2024-08-01 22:38:43,625 custom_logger INFO Running command: echo 'requests
yaml
fastapi
pydantic' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: .
2024-08-01 22:38:43,636 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:39:18,236 custom_logger INFO Handling command: pip install pipreqs in path: .
2024-08-01 22:39:18,236 custom_logger INFO Running command: pip install pipreqs in path: .
2024-08-01 22:39:30,023 custom_logger INFO Handling command: pipreqs /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service --force in path: .
2024-08-01 22:39:30,024 custom_logger INFO Running command: pipreqs /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service --force in path: .
2024-08-01 22:39:30,211 custom_logger ERROR Command execution failed: /bin/sh: 1: pipreqs: not found

2024-08-01 22:39:31,786 custom_logger ERROR Command execution failed: ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
spyder 4.2.5 requires pyqt5<5.13, which is not installed.
spyder 4.2.5 requires pyqtwebengine<5.13, which is not installed.
spyder 4.2.5 requires jedi==0.17.2, but you have jedi 0.18.2 which is incompatible.
spyder 4.2.5 requires parso==0.7.0, but you have parso 0.8.3 which is incompatible.
spyder 4.2.5 requires watchdog<2.0.0,>=0.10.3, but you have watchdog 2.1.2 which is incompatible.

2024-08-01 22:39:51,500 custom_logger INFO Handling command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service
2024-08-01 22:39:51,501 custom_logger INFO Running command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service
2024-08-01 22:39:52,630 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:40:01,196 custom_logger INFO Handling command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service
2024-08-01 22:40:01,197 custom_logger INFO Running command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service
2024-08-01 22:40:02,159 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:40:11,069 custom_logger INFO Handling command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service
2024-08-01 22:40:11,070 custom_logger INFO Running command: pip freeze > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service
2024-08-01 22:40:12,132 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:40:36,532 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:40:36,533 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:40:57,350 custom_logger INFO Handling command: kubectl logs $(kubectl get pods --selector=app=command-service -o jsonpath='{.items[0].metadata.name}') in path: .
2024-08-01 22:40:57,351 custom_logger INFO Running command: kubectl logs $(kubectl get pods --selector=app=command-service -o jsonpath='{.items[0].metadata.name}') in path: .
2024-08-01 22:40:57,590 custom_logger ERROR Command execution failed: error: the server doesn't have a resource type "pods"
error: expected 'logs [-f] [-p] (POD | TYPE/NAME) [-c CONTAINER]'.
POD or TYPE/NAME is a required argument for the logs command
See 'kubectl logs -h' for help and examples

2024-08-01 22:40:59,798 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:eb55b1895e647f800cc2ecff8573b949f0a883a8a0b7539851f87bf319601c0c
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:01e09ab64c9f16cfb7355a14d138cd294e03406ba50c4697d4520782412d2974
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 4.0s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:09d02caa0a9a46c648ada179537efbdfefa9211aad2594e2fed30afc623af091
#6 transferring context: 13.59kB 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:e9d6fe7b98d9379083c6b3393c214163508748ebd3d6d6c5a15cea5c96235f8a
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:c76de0fa84643b48be3c50c6f19eb794947030ac444e4b76bd4f6d3313c2caf3
#8 3.625 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.628 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.628 
#8 4.246 
#8 4.246 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.246 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load .dockerignore
#2 sha256:516dbf75e5a7f175439d6beb89bca0f4a430c95885aa05ff0e85726a443c81ba
#2 transferring context: 2B 0.1s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:5127e601eac906c0d43b02781b4ce45c63ffa77142d39c25a7343303e2ae1d61
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:731dc1b1dd36ab1318978eadca2b22202ae62f1c73009793f4ff9621208e1c5a
#6 transferring context: 15.80kB 0.5s done
#6 DONE 0.5s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:6fa39320635ac459c18795852b2b9a73573e0c0f83f0bb9dbec0356173f0d48f
#7 DONE 0.1s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:b0215efdcdd4d2e5e6d68e432e83f5a3d59242ed64dcf515b43e6708a3cfdd84
#8 3.762 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.765 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.765 
#8 4.376 
#8 4.376 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.376 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:454cccd6e9538ae00931592d85e4d2bd00ffc7e2a8938ff3e4f4e4be4b403c40
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:e60393f8b0becd7ec12a1eb28314e8c3db5f6d9bce7b05a1c11b550157a6de41
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:3f70cf6c5095c72388fdd0b131e267ee3f007c8975289a56847c29433496dfb1
#6 transferring context: 13.60kB 0.0s done
#6 DONE 0.1s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:ede4537b464133f9430941557ed548fbc6f446237399ff18bdac1e2e127c812f
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:7f2f44310ba09a72d6a543befe54373d2b0396f11a0add19a2f0fcb9df96fcb7
#8 3.505 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.508 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.508 
#8 4.102 
#8 4.102 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.102 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:42:52,366 custom_logger INFO Handling command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:42:52,367 custom_logger INFO Running command: ./scripts/build_push_images.sh hypntranz in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:43:12,400 custom_logger INFO Handling command: docker logs $(docker ps -qf "name=command-service") in path: .
2024-08-01 22:43:12,401 custom_logger INFO Running command: docker logs $(docker ps -qf "name=command-service") in path: .
2024-08-01 22:43:12,653 custom_logger ERROR Command execution failed: "docker logs" requires exactly 1 argument.
See 'docker logs --help'.

Usage:  docker logs [OPTIONS] CONTAINER

Fetch the logs of a container

2024-08-01 22:43:17,297 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:d4cc4ec3acc2c945fe0716ed68f69ed4fda71070b18a795218a20f5d0bf65167
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:de23d5ae0c2babff9a188101068c601cff73b7ddaa855b29ff766f01f16fcd07
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:f74c5fabe618a05d3ffe7811dd108f1f24ad2abc451fa1d420475a2427028a20
#6 transferring context: 95B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:7c3d447ba2a5be5d6b140f6595992557a6c7307970c60c299bae25054e7f144b
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:60ac872e138313bed5557f1e08076376634aad55c7d332104ae88225b33f5f39
#8 4.087 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.089 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.089 
#8 4.747 
#8 4.747 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.747 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#2 [internal] load build definition from Dockerfile
#2 sha256:2d6a469031dacd2cb827c5fd2e0c4aa3c5d0e9e80fe2baf0cef48a49a7b7fe40
#2 transferring dockerfile: 253B 0.1s done
#2 DONE 0.1s

#1 [internal] load .dockerignore
#1 sha256:0971b23ec8853b49e922deac84215f43658d0e8bdd6a1307af2a8913863b1868
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:97d2aa4a33f822a80abd7463bd50a10479963f7e101a733136588a2c4b101d7c
#6 transferring context: 2.30kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:7c89554227d7d1a26de68adc4e97db6bb6339fcc2ff5f9947549286bf4944823
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:7ab4a171020cfd189cb157b61ae0f24ee9b1e14a731ed46adb76aabad18d4ee8
#8 4.524 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.527 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.527 
#8 5.161 
#8 5.161 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 5.161 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:f1dbc96e7285f429de7311dc296522c51dc5ef58cacf43ed23e3375d6f5892c0
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:6f1ef6f79f6d6afbb6c4f9405e7acdeb7a9a4148df18571b9a4ecab10be7386d
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.6s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:4787e667869aa0b0a9f01874ed4de61b17ff4171e986df4f56cebcbc671881ed
#6 transferring context: 96B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:a41ddb40ee30b27de3ad52d26cef98d755ee21f55fa73647bdb26ae67f7d56e9
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:7db2478da4de567e1ed582789ed59f953dce58a3887c13f9bd3ec802f8bae9e7
#8 4.114 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.126 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.126 
#8 4.928 
#8 4.928 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.928 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
An image does not exist locally with the tag: your_dockerhub_username/command-service
An image does not exist locally with the tag: your_dockerhub_username/websocket-listener-service
An image does not exist locally with the tag: your_dockerhub_username/proxy-service

2024-08-01 22:44:00,573 custom_logger INFO Handling command: docker ps in path: .
2024-08-01 22:44:00,575 custom_logger INFO Running command: docker ps in path: .
2024-08-01 22:44:00,757 custom_logger INFO Command succeeded: stdout: CONTAINER ID   IMAGE                                                  COMMAND                  CREATED      STATUS      PORTS                                            NAMES
a2d0680f6b55   docker.elastic.co/elasticsearch/elasticsearch:7.17.0   "/bin/tini -- /usr/l…"   6 days ago   Up 6 days   0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp   elasticsearch
, stderr: 
2024-08-01 22:44:15,803 custom_logger INFO Handling command: docker run -d --name command-service hypntranz/command-service:latest in path: .
2024-08-01 22:44:15,804 custom_logger INFO Running command: docker run -d --name command-service hypntranz/command-service:latest in path: .
2024-08-01 22:44:22,046 custom_logger ERROR Command execution failed: Unable to find image 'hypntranz/command-service:latest' locally
docker: Error response from daemon: pull access denied for hypntranz/command-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.

2024-08-01 22:44:34,790 custom_logger INFO Handling command: docker logs --tail 50 command-service in path: .
2024-08-01 22:44:34,791 custom_logger INFO Running command: docker logs --tail 50 command-service in path: .
2024-08-01 22:44:34,971 custom_logger ERROR Command execution failed: Error: No such container: command-service

2024-08-01 22:44:48,512 custom_logger INFO Handling command: docker images | grep hypntranz/command-service in path: .
2024-08-01 22:44:48,513 custom_logger INFO Running command: docker images | grep hypntranz/command-service in path: .
2024-08-01 22:44:48,694 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:45:38,216 custom_logger INFO Handling command: echo -e '#!/bin/bash\n\n# Build Docker images\ndocker build -t command-service:latest ./command_service\ndocker build -t websocket-listener-service:latest ./websocket_listener_service\ndocker build -t proxy-service:latest ./proxy_service\n\n# Run Docker containers\ndocker run -d --name command-service -p 8000:8000 command-service:latest\ndocker run -d --name websocket-listener-service -p 8001:8000 websocket-listener-service:latest\ndocker run -d --name proxy-service -p 8002:8000 proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh in path: .
2024-08-01 22:45:38,217 custom_logger INFO Running command: echo -e '#!/bin/bash\n\n# Build Docker images\ndocker build -t command-service:latest ./command_service\ndocker build -t websocket-listener-service:latest ./websocket_listener_service\ndocker build -t proxy-service:latest ./proxy_service\n\n# Run Docker containers\ndocker run -d --name command-service -p 8000:8000 command-service:latest\ndocker run -d --name websocket-listener-service -p 8001:8000 websocket-listener-service:latest\ndocker run -d --name proxy-service -p 8002:8000 proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh in path: .
2024-08-01 22:45:38,258 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:45:47,477 custom_logger INFO Handling command: ./scripts/build_and_run.sh in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:45:47,478 custom_logger INFO Running command: ./scripts/build_and_run.sh in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:09,606 custom_logger INFO Handling command: docker images | grep command-service in path: .
2024-08-01 22:46:09,607 custom_logger INFO Running command: docker images | grep command-service in path: .
2024-08-01 22:46:09,796 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:46:19,680 custom_logger ERROR Command execution failed: ./scripts/build_and_run.sh: 1: -e: not found
#1 [internal] load .dockerignore
#1 sha256:a5086bcea17e7684f50660ef47fa1e8df451bba0e8a551914209dbd3d728b821
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:015354273fce0560d0ab4c9aa02cac167ddf7a71c10dbcc17e058ed6e0ffca6b
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.9s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:5d4b96d1cc1a696467d7f5ff3d9f5eeebbbc12527f863fd9ca22e2e477ffe9d8
#6 transferring context: 95B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:7d7ad989e3f41d0bacca27b34f0b21e8dbe770c6029cc5d3e6681bf0782fede7
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:3294e1ea41e8522e14226721d97bae64bad74273b1a254d61ab11537e25b1d64
#8 4.132 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.134 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.134 
#8 5.186 
#8 5.186 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 5.186 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:b4aaaedbfa145eb9044e3cd7b145ca5e90db80534927b7da76853de08011573c
#1 transferring context: 2B 0.1s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:93f00de8f4a5d18167d61540656a450547ea288c5fd750d519233e2999e1514e
#2 transferring dockerfile: 253B 0.1s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.6s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:69435f649b3f4e82c8b584570deb579ffa85d77acbfe37e364bf46b05f96bc04
#6 transferring context: 2.30kB 0.4s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:3dae05d1bfab1c73e5f667469dcdb079d0126599ed94766d6333f77d9b50db02
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:a3451d7cb4274b4adbfa552866254f3adbced42cbd713a2d9969aa3744f21b56
#8 4.373 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.376 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.376 
#8 5.018 
#8 5.018 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 5.018 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:36711a594b7a70e3b60ac22daca5f2a76d67898e02b04231627e57ca300fc24c
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:7612ff1efaa3165c38753797592e8071fbe825912b77b76541d5614c0f728eaf
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:255127a7cfb69135999daae5e7c2eec6b4abda818e8ec7edf1b8b159248972e1
#6 transferring context: 96B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:ba713c3141b2ee10d2d9f0ba0833d21de547ef044782afc5a2280e8c99ace0aa
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:391baf39b65757599ca40376b3b41509a898ab07bf8248cf9a4d71e1e0969967
#8 4.296 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.301 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.301 
#8 4.969 
#8 4.969 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.969 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
Unable to find image 'command-service:latest' locally
docker: Error response from daemon: pull access denied for command-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.
Unable to find image 'websocket-listener-service:latest' locally
docker: Error response from daemon: pull access denied for websocket-listener-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.
Unable to find image 'proxy-service:latest' locally
docker: Error response from daemon: pull access denied for proxy-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.

2024-08-01 22:46:23,308 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:23,308 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:28,826 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:a4e85b2e4c45f030c382e7c13726783b9779ac4a83a7f6628f012315cdf60fef
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:d4f03ff1201dd33b619de0fbd3acf60a2dd54d1f05d8f900288eb455a983cb4a
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.4s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:557e04a74341f7532d3d395692131752faf35fef395c872640d92e88baeca7ed
#6 transferring context: 95B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:c1cf35c8432336acbe08f48299e1a8186caf9b8b985ebd2a4bef10ab8adbb461
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:c8c5de3dc4e91b3f55067a1f5083166391e80b24d78fc6e8bd05063a0fd7fa59
#8 3.930 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.932 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.932 
#8 4.570 
#8 4.570 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.570 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1

2024-08-01 22:46:38,430 custom_logger INFO Handling command: docker images | grep command-service in path: .
2024-08-01 22:46:38,431 custom_logger INFO Running command: docker images | grep command-service in path: .
2024-08-01 22:46:38,581 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:46:51,208 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:51,209 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:46:56,431 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:21765cf650564978919a13c753fad995a28edc8944c6dbd2d8480f4c9caea6d3
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:5e773a57748610c950553027b7e17fd0dcd53951ed6cd78ebf92dda08ac4fb05
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.6s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:da64db11d775531b08ae0cc29bcab105796b5313cbc81f0c7af53b2babb31958
#6 transferring context: 95B 0.0s done
#6 DONE 0.1s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:5e96a4701744cefd20c34a713bff41f16fbe1185f7302652154e38d572301482
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:e33aac638abea9b0c791fab4e5f43e613f226499f0df1184371221982188a998
#8 3.560 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 3.562 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 3.562 
#8 4.172 
#8 4.172 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.172 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1

2024-08-01 22:47:06,959 custom_logger INFO Handling command: docker run -d --name command-service-test command-service:latest && docker logs --tail 50 command-service-test in path: .
2024-08-01 22:47:06,960 custom_logger INFO Running command: docker run -d --name command-service-test command-service:latest && docker logs --tail 50 command-service-test in path: .
2024-08-01 22:47:08,224 custom_logger ERROR Command execution failed: Unable to find image 'command-service:latest' locally
docker: Error response from daemon: pull access denied for command-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.

2024-08-01 22:47:33,779 custom_logger INFO Handling command: echo -e '#!/bin/bash\n\n# Build Docker images\ndocker build -t command-service:latest ./command_service\ndocker build -t websocket-listener-service:latest ./websocket_listener_service\ndocker build -t proxy-service:latest ./proxy_service\n\n# Run Docker containers\ndocker run -d --name command-service -p 8000:8000 command-service:latest\ndocker run -d --name websocket-listener-service -p 8001:8000 websocket-listener-service:latest\ndocker run -d --name proxy-service -p 8002:8000 proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh in path: .
2024-08-01 22:47:33,780 custom_logger INFO Running command: echo -e '#!/bin/bash\n\n# Build Docker images\ndocker build -t command-service:latest ./command_service\ndocker build -t websocket-listener-service:latest ./websocket_listener_service\ndocker build -t proxy-service:latest ./proxy_service\n\n# Run Docker containers\ndocker run -d --name command-service -p 8000:8000 command-service:latest\ndocker run -d --name websocket-listener-service -p 8001:8000 websocket-listener-service:latest\ndocker run -d --name proxy-service -p 8002:8000 proxy-service:latest' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh && chmod +x /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/scripts/build_and_run.sh in path: .
2024-08-01 22:47:33,802 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:47:46,816 custom_logger INFO Handling command: ./scripts/build_and_run.sh in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:47:46,817 custom_logger INFO Running command: ./scripts/build_and_run.sh in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:48:03,584 custom_logger INFO Handling command: docker logs --tail 50 command-service in path: .
2024-08-01 22:48:03,585 custom_logger INFO Running command: docker logs --tail 50 command-service in path: .
2024-08-01 22:48:03,725 custom_logger ERROR Command execution failed: Error: No such container: command-service

2024-08-01 22:48:17,354 custom_logger INFO Handling command: docker images | grep command-service in path: .
2024-08-01 22:48:17,355 custom_logger INFO Running command: docker images | grep command-service in path: .
2024-08-01 22:48:17,436 custom_logger ERROR Command execution failed: ./scripts/build_and_run.sh: 1: -e: not found
#2 [internal] load .dockerignore
#2 sha256:9b548e62aea996ccdbfaa10f5038ecb213fbb90cbeba181f1abdbb50931d7e5b
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#1 [internal] load build definition from Dockerfile
#1 sha256:598fd453dbfacec083da5d92152d38060ba444f3d900453237d46cc9df736f86
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:a03b6b3bb9061be7bdb8f30c55a4aff935af3bf6a1cd9286b0a8f8c8aeeb82be
#6 transferring context: 95B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:2968417412a9534406009fec6b336710bec63612dc55586648ac0d9ac2f6fd07
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:855af60f9747ebf604b0418661d55d7a65379cfa31ece492f6057cd8892f48e2
#8 4.017 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.020 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.020 
#8 4.659 
#8 4.659 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.659 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load build definition from Dockerfile
#1 sha256:0c4dae49e4438949af66212fd90fa9e92cfdba8378a6c86055e29d42dd2e4cfb
#1 transferring dockerfile: 253B 0.0s done
#1 DONE 0.1s

#2 [internal] load .dockerignore
#2 sha256:787fae2fbfb5b9a40277e7f1bba0eef9354ed18fed9bb082813be8d17169890a
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:23b280f5dd30696dbe9524e8b90a0ac519bf95f813b2a2bb88351207fcd6bbf3
#6 transferring context: 2.30kB 0.4s done
#6 DONE 0.5s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:824040fd247c020223babb559ad45428512be44584cb90378040ed5459891cb0
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:3de2209a84a3b09e89663768c47f22518be75f17387462f059a1a3fc7b35e4a0
#8 4.098 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.103 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.103 
#8 4.749 
#8 4.749 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.749 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
#1 [internal] load .dockerignore
#1 sha256:237e1025a77d1f3a43b84c588444061a50ff5e5f96e085f7a80dd72d1e05ce36
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:ecf9e586c96bd647f0504c72f92b04d07d17f33e0b0094e8cd922bb383471cf8
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:d122466ece22dc0bf7c3f2a0ca9480ca551cdba78a48e4efc04bab292f9450a3
#6 transferring context: 96B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:9615a251b5be09ed96163abc225e310ce353661822eeed90028ada40b46c8b78
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:40056e36c6151d172a6b97717eaa4536fdcdbb941142bf9ae1b2e00ecb06131a
#8 4.085 Processing /home/ktietz/src/ci/alabaster_1611921544520/work
#8 4.088 ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ktietz/src/ci/alabaster_1611921544520/work'
#8 4.088 
#8 4.711 
#8 4.711 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 4.711 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
Unable to find image 'command-service:latest' locally
docker: Error response from daemon: pull access denied for command-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.
Unable to find image 'websocket-listener-service:latest' locally
docker: Error response from daemon: pull access denied for websocket-listener-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.
Unable to find image 'proxy-service:latest' locally
docker: Error response from daemon: pull access denied for proxy-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.
See 'docker run --help'.

2024-08-01 22:48:17,521 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:49:29,019 custom_logger INFO Handling command: for file in *; do echo BEGIN $file; cat $file; echo END $file; done in path: .
2024-08-01 22:49:29,020 custom_logger INFO Running command: for file in *; do echo BEGIN $file; cat $file; echo END $file; done in path: .
2024-08-01 22:49:29,095 custom_logger ERROR Command execution failed: cat: __pycache__: Is a directory
cat: command_service: Is a directory
cat: tests: Is a directory

2024-08-01 22:49:32,963 custom_logger INFO Handling command: ls in path: .
2024-08-01 22:49:32,964 custom_logger INFO Running command: ls in path: .
2024-08-01 22:49:32,993 custom_logger INFO Command succeeded: stdout: __init__.py
__pycache__
app.log
command_service
tests
, stderr: 
2024-08-01 22:49:35,448 custom_logger INFO Handling command: cat __init__.py in path: .
2024-08-01 22:49:35,449 custom_logger INFO Running command: cat __init__.py in path: .
2024-08-01 22:49:35,464 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:49:38,219 custom_logger INFO Handling command: ls __pycache__ in path: .
2024-08-01 22:49:38,219 custom_logger INFO Running command: ls __pycache__ in path: .
2024-08-01 22:49:38,236 custom_logger INFO Command succeeded: stdout: __init__.cpython-38.pyc
, stderr: 
2024-08-01 22:49:40,650 custom_logger INFO Handling command: cat __pycache__/__init__.cpython-38.pyc in path: .
2024-08-01 22:49:40,651 custom_logger INFO Running command: cat __pycache__/__init__.cpython-38.pyc in path: .
2024-08-01 22:49:40,697 custom_logger ERROR Failed to execute command: 'utf-8' codec can't decode byte 0xa7 in position 10: invalid start byte
2024-08-01 22:49:45,539 custom_logger INFO Handling command: cat app.log in path: .
2024-08-01 22:49:45,540 custom_logger INFO Running command: cat app.log in path: .
, stderr: 
2024-08-01 22:49:50,361 custom_logger INFO Handling command: head -n 100 app.log in path: .
2024-08-01 22:49:50,362 custom_logger INFO Running command: head -n 100 app.log in path: .
2024-08-01 22:49:50,392 custom_logger INFO Command succeeded: stdout: 2024-08-01 14:39:18,759 custom_logger INFO This is an info message
2024-08-01 14:39:18,760 custom_logger WARNING This is a warning message
2024-08-01 14:39:18,761 custom_logger ERROR This is an error message
2024-08-01 14:39:18,872 custom_logger INFO Starting the application
2024-08-01 14:39:18,943 custom_logger INFO Entering register_service
2024-08-01 14:39:18,946 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 14:39:19,006 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 14:39:19,007 custom_logger INFO Exiting register_service
2024-08-01 14:51:03,003 custom_logger INFO This is an info message
2024-08-01 14:51:03,003 custom_logger WARNING This is a warning message
2024-08-01 14:51:03,004 custom_logger ERROR This is an error message
2024-08-01 14:51:03,100 custom_logger INFO Starting the application
2024-08-01 14:51:03,172 custom_logger INFO Entering register_service
2024-08-01 14:51:03,174 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 14:51:03,215 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 14:51:03,216 custom_logger INFO Exiting register_service
2024-08-01 16:07:37,173 custom_logger INFO Starting the application
2024-08-01 16:07:37,255 custom_logger INFO Entering register_service
2024-08-01 16:08:12,855 custom_logger INFO Starting the application
2024-08-01 16:08:12,946 custom_logger INFO Entering register_service
2024-08-01 16:08:12,948 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:08:12,999 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:08:13,001 custom_logger INFO Exiting register_service
2024-08-01 16:09:38,576 custom_logger INFO Starting the application
2024-08-01 16:09:38,646 custom_logger INFO Entering register_service
2024-08-01 16:09:38,649 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:09:38,691 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:09:38,692 custom_logger INFO Exiting register_service
2024-08-01 16:10:38,890 custom_logger INFO Starting the application
2024-08-01 16:10:38,966 custom_logger INFO Entering register_service
2024-08-01 16:10:38,969 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:10:39,018 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:10:39,019 custom_logger INFO Exiting register_service
2024-08-01 16:11:50,333 custom_logger INFO Starting the application
2024-08-01 16:11:50,410 custom_logger INFO Entering register_service
2024-08-01 16:11:50,413 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:11:50,493 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:11:50,494 custom_logger INFO Exiting register_service
2024-08-01 16:13:59,564 custom_logger INFO Starting the application
2024-08-01 16:13:59,664 custom_logger INFO Entering register_service
2024-08-01 16:13:59,666 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:13:59,717 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:13:59,717 custom_logger INFO Exiting register_service
2024-08-01 16:14:24,276 custom_logger INFO Starting the application
2024-08-01 16:14:24,355 custom_logger INFO Entering register_service
2024-08-01 16:14:24,359 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:14:24,411 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:14:24,412 custom_logger INFO Exiting register_service
2024-08-01 16:14:39,667 custom_logger INFO Starting the application
2024-08-01 16:14:39,747 custom_logger INFO Entering register_service
2024-08-01 16:14:39,749 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:14:39,800 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:14:39,801 custom_logger INFO Exiting register_service
2024-08-01 16:15:24,785 custom_logger INFO Starting the application
2024-08-01 16:15:24,856 custom_logger INFO Entering register_service
2024-08-01 16:15:24,859 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:15:24,901 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:15:24,902 custom_logger INFO Exiting register_service
2024-08-01 16:16:26,674 custom_logger INFO Starting the application
2024-08-01 16:16:26,748 custom_logger INFO Entering register_service
2024-08-01 16:16:26,751 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:16:26,805 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:16:26,806 custom_logger INFO Exiting register_service
2024-08-01 16:17:42,976 custom_logger INFO Starting the application
2024-08-01 16:17:43,072 custom_logger INFO Entering register_service
2024-08-01 16:17:43,075 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:17:43,131 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:17:43,132 custom_logger INFO Exiting register_service
2024-08-01 16:19:22,543 custom_logger INFO Starting the application
2024-08-01 16:19:22,620 custom_logger INFO Entering register_service
2024-08-01 16:19:22,623 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:19:22,672 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:19:22,673 custom_logger INFO Exiting register_service
2024-08-01 16:20:54,740 custom_logger INFO Starting the application
2024-08-01 16:20:54,825 custom_logger INFO Entering register_service
2024-08-01 16:20:54,828 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:20:54,886 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:20:54,887 custom_logger INFO Exiting register_service
2024-08-01 16:21:48,009 custom_logger INFO Starting the application
2024-08-01 16:21:48,089 custom_logger INFO Entering register_service
2024-08-01 16:21:48,092 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:21:48,140 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:21:48,141 custom_logger INFO Exiting register_service
2024-08-01 16:23:50,671 custom_logger INFO Starting the application
2024-08-01 16:23:50,758 custom_logger INFO Entering register_service
2024-08-01 16:23:50,761 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:23:50,818 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:23:50,818 custom_logger INFO Exiting register_service
2024-08-01 16:27:29,839 custom_logger INFO Starting the application
2024-08-01 16:27:29,935 custom_logger INFO Entering register_service
2024-08-01 16:27:29,938 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:27:29,992 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:27:29,993 custom_logger INFO Exiting register_service
2024-08-01 16:28:41,409 custom_logger INFO Starting the application
2024-08-01 16:28:41,496 custom_logger INFO Entering register_service
2024-08-01 16:28:41,499 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-01 16:28:41,550 custom_logger INFO Service registered successfully with the proxy.
2024-08-01 16:28:41,551 custom_logger INFO Exiting register_service
2024-08-01 16:29:58,301 custom_logger INFO Starting the application
2024-08-01 16:29:58,387 custom_logger INFO Entering register_service
, stderr: 
2024-08-01 22:49:57,196 custom_logger INFO Handling command: ls command_service in path: .
2024-08-01 22:49:57,197 custom_logger INFO Running command: ls command_service in path: .
2024-08-01 22:49:57,219 custom_logger INFO Command succeeded: stdout: __init__.py
__pycache__
config
controllers
main.py
models
services
, stderr: 
2024-08-01 22:50:00,039 custom_logger INFO Handling command: ls tests in path: .
2024-08-01 22:50:00,040 custom_logger INFO Running command: ls tests in path: .
2024-08-01 22:50:00,057 custom_logger INFO Command succeeded: stdout: __pycache__
result.log
test_command_service.py
test_config.py
test_logger.py
test_registration_service.py
, stderr: 
2024-08-01 22:53:06,880 custom_logger INFO Handling command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: .
2024-08-01 22:53:06,881 custom_logger INFO Running command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: .
2024-08-01 22:53:06,902 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:53:18,881 custom_logger INFO Handling command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1
websockets==9.1
httpx==0.16.1
pydantic==1.7.2' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: .
2024-08-01 22:53:18,882 custom_logger INFO Running command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1
websockets==9.1
httpx==0.16.1
pydantic==1.7.2' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: .
2024-08-01 22:53:18,901 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:53:31,459 custom_logger INFO Handling command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1
pydantic==1.7.2
yaml==5.4.1' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: .
2024-08-01 22:53:31,460 custom_logger INFO Running command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1
pydantic==1.7.2
yaml==5.4.1' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: .
2024-08-01 22:53:31,474 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 22:53:47,203 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:53:47,204 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 22:54:03,136 custom_logger INFO Handling command: docker logs --tail 50 command-service in path: .
2024-08-01 22:54:03,137 custom_logger INFO Running command: docker logs --tail 50 command-service in path: .
2024-08-01 22:54:03,335 custom_logger ERROR Command execution failed: Error: No such container: command-service

2024-08-01 22:54:15,782 custom_logger INFO Handling command: docker images | grep command-service in path: .
2024-08-01 22:54:15,782 custom_logger INFO Running command: docker images | grep command-service in path: .
2024-08-01 22:54:15,963 custom_logger INFO Command succeeded: stdout: command-service                                 latest      700195eddd3b   6 seconds ago   147MB
, stderr: 
2024-08-01 22:54:25,454 custom_logger ERROR Command execution failed: #1 [internal] load build definition from Dockerfile
#1 sha256:bc1cf3df6311e7c461073b2301b60ac3c601474694b322461edd741d0115e24b
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.1s

#2 [internal] load .dockerignore
#2 sha256:cae449e0dbf43f415ac65cd07cc42da2c1955506660f99340306af1f54906420
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 3.9s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:c271f90bec764f1311d4a4deca7d351f64594b32f6d069d5f3644f657546eb95
#6 transferring context: 153B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:aeef9633c7ebf3ef1b382eb2b234b0f875585c86f42443f82c4ba48e505628ee
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:457e841feefb33b5a67cee0fd2d87800102a6b92ff07700055089ccfbe3fd257
#8 4.393 Collecting fastapi==0.65.2
#8 7.853   Downloading fastapi-0.65.2-py3-none-any.whl (51 kB)
#8 7.973      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.2/51.2 kB 401.6 kB/s eta 0:00:00
#8 8.225 Collecting uvicorn==0.13.4
#8 8.344   Downloading uvicorn-0.13.4-py3-none-any.whl (46 kB)
#8 8.374      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 2.0 MB/s eta 0:00:00
#8 8.725 Collecting requests==2.25.1
#8 8.844   Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)
#8 8.882      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 1.9 MB/s eta 0:00:00
#8 10.22 Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2
#8 10.34   Downloading pydantic-1.10.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)
#8 11.60      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 2.6 MB/s eta 0:00:00
#8 11.91 Collecting starlette==0.14.2
#8 12.02   Downloading starlette-0.14.2-py3-none-any.whl (60 kB)
#8 12.04      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 6.2 MB/s eta 0:00:00
#8 12.26 Collecting click==7.*
#8 12.38   Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
#8 12.39      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 kB 11.1 MB/s eta 0:00:00
#8 12.54 Collecting h11>=0.8
#8 12.66   Downloading h11-0.14.0-py3-none-any.whl (58 kB)
#8 12.67      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 30.9 MB/s eta 0:00:00
#8 12.85 Collecting idna<3,>=2.5
#8 12.96   Downloading idna-2.10-py2.py3-none-any.whl (58 kB)
#8 12.98      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 18.4 MB/s eta 0:00:00
#8 13.14 Collecting chardet<5,>=3.0.2
#8 13.26   Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)
#8 13.30      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.7/178.7 kB 5.4 MB/s eta 0:00:00
#8 13.56 Collecting urllib3<1.27,>=1.21.1
#8 13.68   Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)
#8 13.70      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.9/143.9 kB 11.0 MB/s eta 0:00:00
#8 13.98 Collecting certifi>=2017.4.17
#8 14.09   Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)
#8 14.13      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.0/163.0 kB 5.8 MB/s eta 0:00:00
#8 14.38 Collecting typing-extensions>=4.2.0
#8 14.50   Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)
#8 14.94 Installing collected packages: urllib3, typing-extensions, starlette, idna, h11, click, chardet, certifi, uvicorn, requests, pydantic, fastapi
#8 16.68 Successfully installed certifi-2024.7.4 chardet-4.0.0 click-7.1.2 fastapi-0.65.2 h11-0.14.0 idna-2.10 pydantic-1.10.17 requests-2.25.1 starlette-0.14.2 typing-extensions-4.12.2 urllib3-1.26.19 uvicorn-0.13.4
#8 16.69 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#8 17.34 
#8 17.34 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 17.34 [notice] To update, run: pip install --upgrade pip
#8 DONE 17.6s

#9 exporting to image
#9 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00
#9 exporting layers
#9 exporting layers 0.4s done
#9 writing image sha256:700195eddd3ba7a2405627a6125813689eb8e0312e405948e4c85cf7eac95d7c done
#9 naming to docker.io/library/command-service:latest 0.0s done
#9 DONE 0.4s
#1 [internal] load build definition from Dockerfile
#1 sha256:d5d0abecd6cca515ff7ad74f7be65d1a29f5ffe5137f0548bc93c0a8f973b5f5
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.3s

#2 [internal] load .dockerignore
#2 sha256:d60c4dc76df952dac82c3d71ad11baf6958399364f4ebaa75cbf68e6f01b3788
#2 transferring context: 2B 0.1s done
#2 DONE 0.4s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:99dc2f8adefdcdd31d77adf90d95881864a1342ffe1f6830aa8269ad07be920e
#6 transferring context: 2.41kB 0.3s done
#6 DONE 0.4s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:81e39a9a66cc90d70f9104a973ffeb47d721a12e832ae244adae70ef4eab53ba
#7 DONE 0.1s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:6a464977c293c7e379c24f06762c0e92ec35d3b98fc3c94e2bd049df682d14b1
#8 4.203 Collecting fastapi==0.65.2
#8 4.634   Downloading fastapi-0.65.2-py3-none-any.whl (51 kB)
#8 4.753      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.2/51.2 kB 382.9 kB/s eta 0:00:00
#8 5.020 Collecting uvicorn==0.13.4
#8 5.135   Downloading uvicorn-0.13.4-py3-none-any.whl (46 kB)
#8 5.164      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 2.1 MB/s eta 0:00:00
#8 5.416 Collecting requests==2.25.1
#8 5.530   Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)
#8 5.566      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 1.9 MB/s eta 0:00:00
#8 6.257 Collecting websockets==9.1
#8 6.496   Downloading websockets-9.1-cp38-cp38-manylinux2010_x86_64.whl (102 kB)
#8 6.542      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.3/102.3 kB 2.5 MB/s eta 0:00:00
#8 6.810 Collecting httpx==0.16.1
#8 6.929   Downloading httpx-0.16.1-py3-none-any.whl (65 kB)
#8 6.953      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.6/65.6 kB 3.4 MB/s eta 0:00:00
#8 8.201 Collecting pydantic==1.7.2
#8 8.449   Downloading pydantic-1.7.2-cp38-cp38-manylinux2014_x86_64.whl (12.2 MB)
#8 12.90      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 2.6 MB/s eta 0:00:00
#8 13.19 ERROR: Cannot install -r requirements.txt (line 1) and pydantic==1.7.2 because these package versions have conflicting dependencies.
#8 13.20 
#8 13.20 The conflict is caused by:
#8 13.20     The user requested pydantic==1.7.2
#8 13.20     fastapi 0.65.2 depends on pydantic!=1.7, !=1.7.1, !=1.7.2, !=1.7.3, !=1.8, !=1.8.1, <2.0.0 and >=1.6.2
#8 13.20 
#8 13.20 To fix this you could try to:
#8 13.20 1. loosen the range of package versions you've specified
#8 13.20 2. remove package versions to allow pip attempt to solve the dependency conflict
#8 13.20 
#8 13.20 ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts
#8 13.85 
#8 13.85 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 13.85 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/4] RUN pip install --no-cache-dir -r requirements.txt:
------
process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1

2024-08-01 22:54:25,762 custom_logger INFO Handling command: docker run -d --name command-service-test -p 8000:8000 command-service:latest in path: .
2024-08-01 22:54:25,763 custom_logger INFO Running command: docker run -d --name command-service-test -p 8000:8000 command-service:latest in path: .
2024-08-01 22:54:27,685 custom_logger INFO Command succeeded: stdout: f41ce58be1334eccd2281dc753954b4129268a002590a2b3fadef4bfa5414f1d
, stderr: 
2024-08-01 22:54:36,220 custom_logger INFO Handling command: docker logs --tail 50 command-service-test in path: .
2024-08-01 22:54:36,220 custom_logger INFO Running command: docker logs --tail 50 command-service-test in path: .
2024-08-01 22:54:36,402 custom_logger ERROR Command execution failed: Traceback (most recent call last):
  File "/usr/local/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 362, in main
    run(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 386, in run
    server.run()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 49, in run
    loop.run_until_complete(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 56, in serve
    config.load()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/config.py", line 308, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 23, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 20, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'command_service'

2024-08-01 22:57:44,283 custom_logger INFO Handling command: find . -type f \( -name "*.py" -o -name "*.json" -o -name "*.md" \) in path: .
2024-08-01 22:57:44,284 custom_logger INFO Running command: find . -type f \( -name "*.py" -o -name "*.json" -o -name "*.md" \) in path: .
2024-08-01 22:57:44,393 custom_logger INFO Command succeeded: stdout: ./command_service/.pytest_cache/README.md
./command_service/config/config.json
./command_service/config/config.py
./command_service/config/__init__.py
./command_service/controllers/command_controller.py
./command_service/controllers/__init__.py
./command_service/main.py
./command_service/models/command_message.py
./command_service/models/register_request.py
./command_service/models/__init__.py
./command_service/services/command_service.py
./command_service/services/logger.py
./command_service/services/registration_service.py
./command_service/services/__init__.py
./command_service/__init__.py
./tests/.pytest_cache/README.md
./tests/test_command_service.py
./tests/test_config.py
./tests/test_logger.py
./tests/test_registration_service.py
./__init__.py
, stderr: 
2024-08-01 22:57:47,249 custom_logger INFO Handling command: cat ./command_service/config/config.json in path: .
2024-08-01 22:57:47,250 custom_logger INFO Running command: cat ./command_service/config/config.json in path: .
2024-08-01 22:57:47,269 custom_logger INFO Command succeeded: stdout: {
  "proxy_url": "http://localhost:8010/register",
  "host": "0.0.0.0",
  "port": 8014,
  "service_name": "command-service",
  "logging": {
    "level": "INFO",
    "format": "{asctime} {name} {levelname} {message}",
    "sinks": ["console", "file", "elastic"],
    "elastic_url": "http://localhost:9200"
  }
}
, stderr: 
2024-08-01 22:57:50,060 custom_logger INFO Handling command: cat ./command_service/config/config.py in path: .
2024-08-01 22:57:50,061 custom_logger INFO Running command: cat ./command_service/config/config.py in path: .
2024-08-01 22:57:50,081 custom_logger INFO Command succeeded: stdout: import logging
import json
from concurrent.futures import ThreadPoolExecutor
import requests
import os
from pydantic import BaseSettings

class Settings(BaseSettings):
    proxy_url: str
    host: str
    port: int
    service_name: str
    logging_level: str
    logging_format: str
    logging_sinks: list
    elastic_url: str

def load_config():
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    with open(config_path) as config_file:
        config_data = json.load(config_file)
        return Settings(
            proxy_url=config_data['proxy_url'],
            host=config_data['host'],
            port=config_data['port'],
            service_name=config_data['service_name'],
            logging_level=config_data['logging']['level'],
            logging_format=config_data['logging']['format'],
            logging_sinks=config_data['logging']['sinks'],
            elastic_url=config_data['logging']['elastic_url']
        )



settings = load_config()
, stderr: 
2024-08-01 22:57:53,113 custom_logger INFO Handling command: cat ./command_service/controllers/command_controller.py in path: .
2024-08-01 22:57:53,113 custom_logger INFO Running command: cat ./command_service/controllers/command_controller.py in path: .
2024-08-01 22:57:53,132 custom_logger INFO Command succeeded: stdout: from fastapi import APIRouter, HTTPException, Depends
from command_service.models.command_message import CommandMessage
from command_service.services.command_service import run_command
from command_service.services.logger import CustomLogger, log_decorator
from command_service.services.logger import get_logger
from command_service.config.config import Settings, load_config
from command_service.services.logger import CustomLogger
from pydantic import BaseModel
import logging
import requests
import traceback

router = APIRouter()

@router.post('/execute-bash')
async def command_service(message: CommandMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling command: {message.command} in path: {message.path}')

    try:
        stdout, stderr = await run_command(message.command, message.path, settings, logger)

        if stderr:
            logger.error(f'Command execution failed: {stderr}')
            return {'stdout': stdout, 'stderr': stderr}

        logger.info(f'Command succeeded: stdout: {stdout}, stderr: {stderr}')
        return {'stdout': stdout, 'stderr': stderr}

    except Exception as e:
        logger.error(f'Failed to execute command: {str(e)}')
        return {'stdout': '', 'stderr': str(e)}

class ElasticQueryMessage(BaseModel):
    connection_string: str
    index: str
    query: dict

class ElasticLogMessage(BaseModel):
    connection_string: str
    index: str
    log: dict

@router.post('/elastic-query')
async def handle_elastic(message: ElasticQueryMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling elastic: {message.connection_string}')

    try:
        query_url = f"{message.connection_string}/{message.index}/_search"
        logger.debug(f"Query URL: {query_url}")
        logger.debug(f"Query Body: {message.query}")

        response = requests.post(query_url, json={"query": message.query})
        logger.debug(f"Response: {response.text}")
        response.raise_for_status()

        logger.info(f"Query succeeded: {response.json()}")
        return response.json()
    except requests.RequestException as e:
        error_message = f"Failed to execute ElasticSearch query: {str(e)}"
        logger.error(error_message)
        traceback_str = ''.join(traceback.format_tb(e.__traceback__))
        return {"error": error_message, "traceback": traceback_str}

@router.post('/elastic-log')
async def handle_elastic_log(message: ElasticLogMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling elastic log: {message.connection_string}')

    try:
        log_url = f"{message.connection_string}/{message.index}/_doc"
        logger.debug(f"Log URL: {log_url}")
        logger.debug(f"Log Body: {message.log}")

        response = requests.post(log_url, json=message.log)
        logger.debug(f"Response: {response.text}")
        response.raise_for_status()

        logger.info(f"Log succeeded: {response.json()}")
        return response.json()
    except requests.RequestException as e:
        error_message = f"Failed to send log to Elasticsearch: {str(e)}"
        logger.error(error_message)
        traceback_str = ''.join(traceback.format_tb(e.__traceback__))
        return {"error": error_message, "traceback": traceback_str}
, stderr: 
2024-08-01 22:58:18,956 custom_logger INFO Handling command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service && cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 22:58:18,957 custom_logger INFO Running command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service && cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 22:58:18,982 custom_logger INFO Command succeeded: stdout: Dockerfile
main.py
requirements.txt
import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("COMMAND_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "command-service",
        "openapi_url": f"http://{service_ip}:8001/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering command-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8001)
, stderr: 
2024-08-01 22:58:32,115 custom_logger INFO Handling command: cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 22:58:32,116 custom_logger INFO Running command: cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 22:58:32,132 custom_logger INFO Command succeeded: stdout: FROM python:3.8-slim

WORKDIR /app

COPY . /app

RUN pip install --no-cache-dir -r requirements.txt

EXPOSE 8001

CMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]
, stderr: 
2024-08-01 22:58:47,006 custom_logger INFO Handling command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 22:58:47,007 custom_logger INFO Running command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 22:58:47,227 custom_logger ERROR Command execution failed: docker: Error response from daemon: Conflict. The container name "/command-service-test" is already in use by container "f41ce58be1334eccd2281dc753954b4129268a002590a2b3fadef4bfa5414f1d". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.

2024-08-01 22:59:00,970 custom_logger INFO Handling command: docker rm -f command-service-test in path: .
2024-08-01 22:59:00,971 custom_logger INFO Running command: docker rm -f command-service-test in path: .
2024-08-01 22:59:01,162 custom_logger INFO Command succeeded: stdout: command-service-test
, stderr: 
2024-08-01 22:59:07,020 custom_logger INFO Handling command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 22:59:07,021 custom_logger INFO Running command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 22:59:07,948 custom_logger INFO Command succeeded: stdout: 08d40f55103934ac06cfd88a7a47a0cc79ca54d6b69c9afa7c306650e7a50ae7
, stderr: 
2024-08-01 22:59:21,207 custom_logger INFO Handling command: docker logs --tail 50 command-service-test in path: .
2024-08-01 22:59:21,208 custom_logger INFO Running command: docker logs --tail 50 command-service-test in path: .
2024-08-01 22:59:21,354 custom_logger ERROR Command execution failed: Traceback (most recent call last):
  File "/usr/local/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 362, in main
    run(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 386, in run
    server.run()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 49, in run
    loop.run_until_complete(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 56, in serve
    config.load()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/config.py", line 308, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 23, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 20, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'command_service'

2024-08-01 22:59:33,926 custom_logger INFO Handling command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service in path: .
2024-08-01 22:59:33,927 custom_logger INFO Running command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service in path: .
2024-08-01 22:59:33,945 custom_logger INFO Command succeeded: stdout: Dockerfile
main.py
requirements.txt
, stderr: 
2024-08-01 22:59:46,550 custom_logger INFO Handling command: touch /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/__init__.py in path: .
2024-08-01 22:59:46,551 custom_logger INFO Running command: touch /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/__init__.py in path: .
2024-08-01 22:59:46,572 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 23:00:01,779 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 23:00:01,780 custom_logger INFO Running command: docker build -t command-service:latest ./command_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 23:00:20,675 custom_logger INFO Handling command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:00:20,678 custom_logger INFO Running command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:00:20,856 custom_logger ERROR Command execution failed: docker: Error response from daemon: Conflict. The container name "/command-service-test" is already in use by container "08d40f55103934ac06cfd88a7a47a0cc79ca54d6b69c9afa7c306650e7a50ae7". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.

2024-08-01 23:00:21,864 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:d09879e18648c1bfa990149bb7295c0c20df9a870f6b265d2d680cacadba8d28
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:215a475e20b3341944d265c6366a05cc53a290e563ccdb6b2fba5a5203ed10ab
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 4.1s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:a0eccfae85f3eac148ee3abbce99e1b6a8d0b3c6d0ceb00f8e14c074d08d4c00
#6 transferring context: 126B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:98109a28c875a822d552cd91003d06591ad43e787f07e825209002861120c4f6
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:b5714c567f63a0c9d19c081700360542ff9c66550699ed602dc0ef2841d83035
#8 5.392 Collecting fastapi==0.65.2
#8 5.929   Downloading fastapi-0.65.2-py3-none-any.whl (51 kB)
#8 6.046      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.2/51.2 kB 378.1 kB/s eta 0:00:00
#8 6.284 Collecting uvicorn==0.13.4
#8 6.397   Downloading uvicorn-0.13.4-py3-none-any.whl (46 kB)
#8 6.425      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 2.0 MB/s eta 0:00:00
#8 6.659 Collecting requests==2.25.1
#8 6.771   Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)
#8 6.806      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 2.0 MB/s eta 0:00:00
#8 7.141 Collecting starlette==0.14.2
#8 7.254   Downloading starlette-0.14.2-py3-none-any.whl (60 kB)
#8 7.280      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 2.9 MB/s eta 0:00:00
#8 8.355 Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2
#8 8.469   Downloading pydantic-1.10.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)
#8 9.582      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 2.9 MB/s eta 0:00:00
#8 9.768 Collecting h11>=0.8
#8 9.881   Downloading h11-0.14.0-py3-none-any.whl (58 kB)
#8 9.893      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 9.3 MB/s eta 0:00:00
#8 10.08 Collecting click==7.*
#8 10.20   Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
#8 10.21      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 kB 14.3 MB/s eta 0:00:00
#8 10.41 Collecting certifi>=2017.4.17
#8 10.52   Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)
#8 10.55      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.0/163.0 kB 8.2 MB/s eta 0:00:00
#8 10.70 Collecting idna<3,>=2.5
#8 10.82   Downloading idna-2.10-py2.py3-none-any.whl (58 kB)
#8 10.83      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 16.7 MB/s eta 0:00:00
#8 10.97 Collecting chardet<5,>=3.0.2
#8 11.09   Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)
#8 11.11      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.7/178.7 kB 9.9 MB/s eta 0:00:00
#8 11.38 Collecting urllib3<1.27,>=1.21.1
#8 11.49   Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)
#8 11.51      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.9/143.9 kB 11.6 MB/s eta 0:00:00
#8 11.77 Collecting typing-extensions>=4.2.0
#8 11.89   Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)
#8 12.31 Installing collected packages: urllib3, typing-extensions, starlette, idna, h11, click, chardet, certifi, uvicorn, requests, pydantic, fastapi
#8 14.02 Successfully installed certifi-2024.7.4 chardet-4.0.0 click-7.1.2 fastapi-0.65.2 h11-0.14.0 idna-2.10 pydantic-1.10.17 requests-2.25.1 starlette-0.14.2 typing-extensions-4.12.2 urllib3-1.26.19 uvicorn-0.13.4
#8 14.02 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#8 14.81 
#8 14.81 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 14.81 [notice] To update, run: pip install --upgrade pip
#8 DONE 15.1s

#9 exporting to image
#9 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00
#9 exporting layers
#9 exporting layers 0.5s done
#9 writing image sha256:43d088e0f6d590414c6f83aaf83bfa212a4e7a5b46e08b10138bb0fd93254527 done
#9 naming to docker.io/library/command-service:latest done
#9 DONE 0.5s

2024-08-01 23:00:40,321 custom_logger INFO Handling command: docker rm -f command-service-test in path: .
2024-08-01 23:00:40,321 custom_logger INFO Running command: docker rm -f command-service-test in path: .
2024-08-01 23:00:40,493 custom_logger INFO Command succeeded: stdout: command-service-test
, stderr: 
2024-08-01 23:00:44,682 custom_logger INFO Handling command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:00:44,683 custom_logger INFO Running command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:00:45,690 custom_logger INFO Command succeeded: stdout: e388474a7a6564e9c1ec5cfa7a30f61be1fe6b8cae783ede393073a33cadd1b8
, stderr: 
2024-08-01 23:06:06,776 custom_logger INFO Handling command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: .
2024-08-01 23:06:06,777 custom_logger INFO Running command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/requirements.txt in path: .
2024-08-01 23:06:06,794 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 23:06:23,824 custom_logger INFO Handling command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1
websockets==9.1
httpx==0.16.1
pydantic==1.6.2' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: .
2024-08-01 23:06:23,825 custom_logger INFO Running command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1
websockets==9.1
httpx==0.16.1
pydantic==1.6.2' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/websocket_listener_service/requirements.txt in path: .
2024-08-01 23:06:23,841 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 23:06:36,541 custom_logger INFO Handling command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1
pydantic==1.6.2
PyYAML==5.4.1' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: .
2024-08-01 23:06:36,542 custom_logger INFO Running command: echo 'fastapi==0.65.2
uvicorn==0.13.4
requests==2.25.1
pydantic==1.6.2
PyYAML==5.4.1' > /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/proxy_service/requirements.txt in path: .
2024-08-01 23:06:36,557 custom_logger INFO Command succeeded: stdout: , stderr: 
2024-08-01 23:06:50,675 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 23:06:50,676 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 23:07:06,777 custom_logger INFO Handling command: docker logs --tail 50 command-service in path: .
2024-08-01 23:07:06,778 custom_logger INFO Running command: docker logs --tail 50 command-service in path: .
2024-08-01 23:07:07,002 custom_logger ERROR Command execution failed: Traceback (most recent call last):
  File "/usr/local/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 362, in main
    run(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 386, in run
    server.run()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 49, in run
    loop.run_until_complete(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 56, in serve
    config.load()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/config.py", line 308, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 23, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 20, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'command_service'

2024-08-01 23:07:50,802 custom_logger ERROR Command execution failed: #1 [internal] load build definition from Dockerfile
#1 sha256:3c35dd94d52471bd16c36e4c4479a11305ced5272a75cf68f8a6a2dce07950bb
#1 transferring dockerfile: 242B 0.0s done
#1 DONE 0.1s

#2 [internal] load .dockerignore
#2 sha256:d9cc30b5a75aa089978c882e6578191fa89f3588f5caf767b20daa6712f788c9
#2 transferring context: 2B 0.0s done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 1.1s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:51755bde767def37f6c2ae68f2cfcefcdccfbfbb074cb7948e6da23dfb8cd8f1
#6 transferring context: 181B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:af9db808823227d5d6221635fa70699f09b9f07d59e2537f7f2de485fbe8ac1b
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:275add6adc590b5e59f33cffad643411e584385e3cacb575ee9f863668659423
#8 CACHED

#9 exporting to image
#9 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00
#9 exporting layers done
#9 writing image sha256:43d088e0f6d590414c6f83aaf83bfa212a4e7a5b46e08b10138bb0fd93254527 done
#9 naming to docker.io/library/command-service:latest done
#9 DONE 0.0s
#2 [internal] load .dockerignore
#2 sha256:b39849bb93d6476cb108917a418c5fe31c72406db023f2a98ccb062a0fc2c807
#2 transferring context: 2B 0.0s done
#2 DONE 0.1s

#1 [internal] load build definition from Dockerfile
#1 sha256:e2200253ae817b0817930ce118a2ffcacf17452efd5f1d65e95cad0321a60665
#1 transferring dockerfile: 253B 0.1s done
#1 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.3s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:2c3f129a29bdabd524dffbbec5f0842bc5e3210f2c7345c3a5178725bb8f082d
#6 transferring context: 2.41kB 0.3s done
#6 DONE 0.3s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:a74f311e74609d88d105a326dbd6731623cd55dc1199b1fbd69950821caa6a7d
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:4243d4a9500eea3449e9a95e0b9b30144f2c4deb865e5b37e17822be5678aba1
#8 4.426 Collecting fastapi==0.65.2
#8 4.967   Downloading fastapi-0.65.2-py3-none-any.whl (51 kB)
#8 5.084      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.2/51.2 kB 377.4 kB/s eta 0:00:00
#8 5.442 Collecting uvicorn==0.13.4
#8 5.557   Downloading uvicorn-0.13.4-py3-none-any.whl (46 kB)
#8 5.585      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 2.2 MB/s eta 0:00:00
#8 5.849 Collecting requests==2.25.1
#8 5.966   Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)
#8 6.000      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 2.1 MB/s eta 0:00:00
#8 6.569 Collecting websockets==9.1
#8 6.684   Downloading websockets-9.1-cp38-cp38-manylinux2010_x86_64.whl (102 kB)
#8 6.728      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.3/102.3 kB 2.7 MB/s eta 0:00:00
#8 6.949 Collecting httpx==0.16.1
#8 7.065   Downloading httpx-0.16.1-py3-none-any.whl (65 kB)
#8 7.085      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.6/65.6 kB 4.5 MB/s eta 0:00:00
#8 8.018 Collecting pydantic==1.6.2
#8 8.867   Downloading pydantic-1.6.2-cp38-cp38-manylinux2014_x86_64.whl (11.5 MB)
#8 13.01      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.5/11.5 MB 2.7 MB/s eta 0:00:00
#8 13.55 Collecting starlette==0.14.2
#8 13.67   Downloading starlette-0.14.2-py3-none-any.whl (60 kB)
#8 13.69      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 3.7 MB/s eta 0:00:00
#8 13.90 Collecting h11>=0.8
#8 14.01   Downloading h11-0.14.0-py3-none-any.whl (58 kB)
#8 14.03      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 10.1 MB/s eta 0:00:00
#8 14.23 Collecting click==7.*
#8 14.34   Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
#8 14.36      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 kB 6.6 MB/s eta 0:00:00
#8 14.53 Collecting chardet<5,>=3.0.2
#8 14.65   Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)
#8 14.69      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.7/178.7 kB 4.9 MB/s eta 0:00:00
#8 14.87 Collecting certifi>=2017.4.17
#8 14.99   Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)
#8 15.02      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.0/163.0 kB 5.5 MB/s eta 0:00:00
#8 15.22 Collecting idna<3,>=2.5
#8 15.33   Downloading idna-2.10-py2.py3-none-any.whl (58 kB)
#8 15.34      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 5.9 MB/s eta 0:00:00
#8 15.67 Collecting urllib3<1.27,>=1.21.1
#8 15.79   Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)
#8 15.82      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.9/143.9 kB 6.1 MB/s eta 0:00:00
#8 16.01 Collecting sniffio
#8 16.13   Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)
#8 16.38 Collecting httpcore==0.12.*
#8 16.50   Downloading httpcore-0.12.3-py3-none-any.whl (55 kB)
#8 16.51      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 7.7 MB/s eta 0:00:00
#8 16.77 Collecting rfc3986[idna2008]<2,>=1.3
#8 16.89   Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)
#8 17.46 Installing collected packages: rfc3986, websockets, urllib3, starlette, sniffio, pydantic, idna, h11, click, chardet, certifi, uvicorn, requests, httpcore, fastapi, httpx
#8 21.29 Successfully installed certifi-2024.7.4 chardet-4.0.0 click-7.1.2 fastapi-0.65.2 h11-0.14.0 httpcore-0.12.3 httpx-0.16.1 idna-2.10 pydantic-1.6.2 requests-2.25.1 rfc3986-1.5.0 sniffio-1.3.1 starlette-0.14.2 urllib3-1.26.19 uvicorn-0.13.4 websockets-9.1
#8 21.29 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#8 22.00 
#8 22.00 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 22.00 [notice] To update, run: pip install --upgrade pip
#8 DONE 22.4s

#9 exporting to image
#9 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00
#9 exporting layers
#9 exporting layers 1.3s done
#9 writing image sha256:87d8d0f4ef95855aa1366bb4e7ca5e2bbb21d51c06ab3d47750833a09672b89e done
#9 naming to docker.io/library/websocket-listener-service:latest 0.0s done
#9 DONE 1.3s
#1 [internal] load .dockerignore
#1 sha256:355470d1b28edee0a4c7673825b7210dc52e922e3d0536c5c00a3db658ead77f
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:51af9bd172be36b18882960ab282599c1482735a96a313186f65ac2e9fe5f2fe
#2 transferring dockerfile: 186B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 0.5s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:a730233de17ec08308d4be3f17961d3d14e18830e44c95aaec5ce4cfcaef8104
#4 sha256:dbdcd44f4e308fcbe7bb3c8388b83be5892717e8677498cdecc70c5769715777
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:5fd4f79bf9a2197c880d423af9743bb7f564f074c606c1d086f7d08739bfaf04
#6 transferring context: 184B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:c79e60accba96707e7d0fd01e29d5308ec503a964b8cea900042b9ffcd1e93e8
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:3c05389c97668e1e8336f9379925db6eda21504578018b5466cf492bff67428b
#7 DONE 0.0s

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:cd30f4fcf08326ba2b2ff1830670c5fcb1853ec4cfe32b26a20ecb544b16aecc
#8 7.927 Collecting fastapi==0.65.2
#8 8.477   Downloading fastapi-0.65.2-py3-none-any.whl (51 kB)
#8 8.604      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.2/51.2 kB 351.6 kB/s eta 0:00:00
#8 8.908 Collecting uvicorn==0.13.4
#8 9.080   Downloading uvicorn-0.13.4-py3-none-any.whl (46 kB)
#8 9.089      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.1/46.1 kB 34.9 MB/s eta 0:00:00
#8 9.418 Collecting requests==2.25.1
#8 9.562   Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)
#8 9.575      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 10.9 MB/s eta 0:00:00
#8 11.50 Collecting pydantic==1.6.2
#8 11.69   Downloading pydantic-1.6.2-cp38-cp38-manylinux2014_x86_64.whl (11.5 MB)
#8 19.61      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.5/11.5 MB 1.5 MB/s eta 0:00:00
#8 20.01 Collecting PyYAML==5.4.1
#8 20.13   Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)
#8 20.52      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 662.4/662.4 kB 1.7 MB/s eta 0:00:00
#8 20.86 Collecting starlette==0.14.2
#8 20.98   Downloading starlette-0.14.2-py3-none-any.whl (60 kB)
#8 21.01      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 2.2 MB/s eta 0:00:00
#8 21.33 Collecting h11>=0.8
#8 21.45   Downloading h11-0.14.0-py3-none-any.whl (58 kB)
#8 21.48      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 2.2 MB/s eta 0:00:00
#8 21.66 Collecting click==7.*
#8 21.78   Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)
#8 21.82      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 kB 2.1 MB/s eta 0:00:00
#8 22.10 Collecting urllib3<1.27,>=1.21.1
#8 22.22   Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)
#8 22.29      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.9/143.9 kB 2.1 MB/s eta 0:00:00
#8 22.47 Collecting certifi>=2017.4.17
#8 22.59   Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)
#8 22.67      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.0/163.0 kB 2.1 MB/s eta 0:00:00
#8 22.82 Collecting chardet<5,>=3.0.2
#8 22.93   Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)
#8 23.04      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.7/178.7 kB 1.7 MB/s eta 0:00:00
#8 23.20 Collecting idna<3,>=2.5
#8 23.32   Downloading idna-2.10-py2.py3-none-any.whl (58 kB)
#8 23.35      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 2.3 MB/s eta 0:00:00
#8 23.84 Installing collected packages: urllib3, starlette, PyYAML, pydantic, idna, h11, click, chardet, certifi, uvicorn, requests, fastapi
#8 28.84 Successfully installed PyYAML-5.4.1 certifi-2024.7.4 chardet-4.0.0 click-7.1.2 fastapi-0.65.2 h11-0.14.0 idna-2.10 pydantic-1.6.2 requests-2.25.1 starlette-0.14.2 urllib3-1.26.19 uvicorn-0.13.4
#8 28.84 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
#8 29.54 
#8 29.54 [notice] A new release of pip is available: 23.0.1 -> 24.2
#8 29.54 [notice] To update, run: pip install --upgrade pip
#8 DONE 31.8s

#9 exporting to image
#9 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00
#9 exporting layers
#9 exporting layers 1.0s done
#9 writing image sha256:4b91115c46f2531087f9bbb29bbe8cf24533c0b1e5975b146439fa794f815f64 done
#9 naming to docker.io/library/proxy-service:latest done
#9 DONE 1.0s

2024-08-01 23:10:47,931 custom_logger INFO Handling command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service in path: .
2024-08-01 23:10:47,932 custom_logger INFO Running command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service in path: .
2024-08-01 23:10:47,950 custom_logger INFO Command succeeded: stdout: Dockerfile
__init__.py
main.py
requirements.txt
, stderr: 
2024-08-01 23:11:02,840 custom_logger INFO Handling command: cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 23:11:02,842 custom_logger INFO Running command: cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 23:11:02,862 custom_logger INFO Command succeeded: stdout: import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("COMMAND_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "command-service",
        "openapi_url": f"http://{service_ip}:8001/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering command-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8001)
, stderr: 
2024-08-01 23:11:21,841 custom_logger INFO Handling command: docker logs --tail 50 command-service in path: .
2024-08-01 23:11:21,841 custom_logger INFO Running command: docker logs --tail 50 command-service in path: .
2024-08-01 23:11:22,021 custom_logger ERROR Command execution failed: Traceback (most recent call last):
  File "/usr/local/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 362, in main
    run(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 386, in run
    server.run()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 49, in run
    loop.run_until_complete(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 56, in serve
    config.load()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/config.py", line 308, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 23, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 20, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'command_service'

2024-08-01 23:11:32,296 custom_logger INFO Handling elastic log: your_connection_string
2024-08-01 23:11:32,301 custom_logger ERROR Failed to send log to Elasticsearch: Invalid URL 'your_connection_string/logs_index/_doc': No scheme supplied. Perhaps you meant https://your_connection_string/logs_index/_doc?
2024-08-01 23:11:42,995 custom_logger INFO Handling command: pwd && ls /app in path: .
2024-08-01 23:11:42,996 custom_logger INFO Running command: pwd && ls /app in path: .
2024-08-01 23:11:43,011 custom_logger ERROR Command execution failed: ls: cannot access '/app': No such file or directory

2024-08-01 23:12:09,141 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 23:12:09,142 custom_logger INFO Running command: docker build -t command-service:latest ./command_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 23:12:13,772 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:d5696f7dbe15a753c797c8530796b487355f169f9192133ffddb59ee23f9cf2f
#1 transferring context: 2B 0.0s done
#1 DONE 0.1s

#2 [internal] load build definition from Dockerfile
#2 sha256:9dd35dd2170e1367fc6018702454dd3137063eddfb9ce8b1e7d2281f2ec82fbb
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 4.2s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:5d7e72b7a83c9fbe54fb13d95345de538e93adc943c642cfb1b2eba312606bc4
#4 sha256:469c74e7c436ccb78e7314351de453295974ae88cecb3414ae5047294d0fea88
#4 resolve docker.io/library/python:3.8-slim@sha256:5d7e72b7a83c9fbe54fb13d95345de538e93adc943c642cfb1b2eba312606bc4 0.0s done
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:982574f27a5573975496fabe5c972c8023a0a00e6351f79cc11569e50e15d193
#6 transferring context: 122B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:063b6dbb6b5766bd78b1e5a35c4d0d52cdf727910cead74352f5eed8f655dc2e
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:2ab9ec7e728f8c88ff361f4283a2bf06a626f4b58bd72ceb730a80b2f71528ee
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:20375c117caa5245fc3611c51b3e36dedc3b2e3c6b368f30910f4d8f4150ce9a
#8 CACHED

#9 exporting to image
#9 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00
#9 exporting layers done
#9 writing image sha256:0feec16aea7c1da74508dc740208391e0c0204284526ecfcbbca511e4eb24d81 done
#9 naming to docker.io/library/command-service:latest 0.0s done
#9 DONE 0.0s

2024-08-01 23:12:37,332 custom_logger INFO Handling command: docker run -d --name command-service -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:12:37,332 custom_logger INFO Running command: docker run -d --name command-service -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:12:37,499 custom_logger ERROR Command execution failed: docker: Error response from daemon: Conflict. The container name "/command-service" is already in use by container "1e91c47bf7d0ad67b27a6744de26e351f164ce78175c14b8d6751ae7ac276b4c". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.

2024-08-01 23:12:57,491 custom_logger INFO Handling command: docker rm -f command-service in path: .
2024-08-01 23:12:57,492 custom_logger INFO Running command: docker rm -f command-service in path: .
2024-08-01 23:12:57,665 custom_logger INFO Command succeeded: stdout: command-service
, stderr: 
2024-08-01 23:13:03,563 custom_logger INFO Handling command: docker run -d --name command-service -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:13:03,564 custom_logger INFO Running command: docker run -d --name command-service -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:13:04,929 custom_logger INFO Command succeeded: stdout: f110be972edfc6182d1f132143dd3b9df378f263dd803b5a1afb2b9fd00a1086
, stderr: 
2024-08-01 23:13:19,858 custom_logger INFO Handling command: docker logs --tail 50 command-service in path: .
2024-08-01 23:13:19,859 custom_logger INFO Running command: docker logs --tail 50 command-service in path: .
2024-08-01 23:13:20,037 custom_logger ERROR Command execution failed: Traceback (most recent call last):
  File "/usr/local/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 362, in main
    run(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 386, in run
    server.run()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 49, in run
    loop.run_until_complete(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 56, in serve
    config.load()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/config.py", line 308, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 23, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 20, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'command_service'

2024-08-01 23:13:35,016 custom_logger INFO Handling command: find . -name '*.py' -exec grep -H 'connection_string' {} \; in path: .
2024-08-01 23:13:35,017 custom_logger INFO Running command: find . -name '*.py' -exec grep -H 'connection_string' {} \; in path: .
2024-08-01 23:13:35,245 custom_logger INFO Command succeeded: stdout: ./command_service/controllers/command_controller.py:    connection_string: str
./command_service/controllers/command_controller.py:    connection_string: str
./command_service/controllers/command_controller.py:    logger.info(f'Handling elastic: {message.connection_string}')
./command_service/controllers/command_controller.py:        query_url = f"{message.connection_string}/{message.index}/_search"
./command_service/controllers/command_controller.py:    logger.info(f'Handling elastic log: {message.connection_string}')
./command_service/controllers/command_controller.py:        log_url = f"{message.connection_string}/{message.index}/_doc"
, stderr: 
2024-08-01 23:13:37,861 custom_logger INFO Handling command: grep -A 5 'def handle_elastic_log' ./command_service/controllers/command_controller.py in path: .
2024-08-01 23:13:37,861 custom_logger INFO Running command: grep -A 5 'def handle_elastic_log' ./command_service/controllers/command_controller.py in path: .
2024-08-01 23:13:37,879 custom_logger INFO Command succeeded: stdout: async def handle_elastic_log(message: ElasticLogMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling elastic log: {message.connection_string}')

, stderr: 
2024-08-01 23:13:39,180 custom_logger INFO Handling command: cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 23:13:39,181 custom_logger INFO Running command: cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/Dockerfile in path: .
2024-08-01 23:13:39,197 custom_logger INFO Command succeeded: stdout: FROM python:3.8-slim

WORKDIR /app

COPY . /app

RUN pip install --no-cache-dir -r requirements.txt

EXPOSE 8001

CMD ["uvicorn", "command_service.main:app", "--host", "0.0.0.0", "--port", "8001"]
, stderr: 
2024-08-01 23:13:40,433 custom_logger INFO Handling command: grep -A 5 'load_config' ./command_service/controllers/command_controller.py in path: .
2024-08-01 23:13:40,434 custom_logger INFO Running command: grep -A 5 'load_config' ./command_service/controllers/command_controller.py in path: .
2024-08-01 23:13:40,454 custom_logger INFO Command succeeded: stdout: from command_service.config.config import Settings, load_config
from command_service.services.logger import CustomLogger
from pydantic import BaseModel
import logging
import requests
import traceback
--
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling command: {message.command} in path: {message.path}')

    try:
--
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling elastic: {message.connection_string}')

    try:
--
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling elastic log: {message.connection_string}')

    try:
, stderr: 
2024-08-01 23:13:45,098 custom_logger INFO Handling command: grep -A 10 'def load_config' ./command_service/config/config.py in path: .
2024-08-01 23:13:45,099 custom_logger INFO Running command: grep -A 10 'def load_config' ./command_service/config/config.py in path: .
2024-08-01 23:13:45,120 custom_logger INFO Command succeeded: stdout: def load_config():
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    with open(config_path) as config_file:
        config_data = json.load(config_file)
        return Settings(
            proxy_url=config_data['proxy_url'],
            host=config_data['host'],
            port=config_data['port'],
            service_name=config_data['service_name'],
            logging_level=config_data['logging']['level'],
            logging_format=config_data['logging']['format'],
, stderr: 
2024-08-01 23:13:47,950 custom_logger INFO Handling command: cat ./command_service/config/config.json in path: .
2024-08-01 23:13:47,951 custom_logger INFO Running command: cat ./command_service/config/config.json in path: .
2024-08-01 23:13:47,978 custom_logger INFO Command succeeded: stdout: {
  "proxy_url": "http://localhost:8010/register",
  "host": "0.0.0.0",
  "port": 8014,
  "service_name": "command-service",
  "logging": {
    "level": "INFO",
    "format": "{asctime} {name} {levelname} {message}",
    "sinks": ["console", "file", "elastic"],
    "elastic_url": "http://localhost:9200"
  }
}
, stderr: 
2024-08-01 23:13:57,294 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 23:13:57,324 custom_logger ERROR Failed to execute ElasticSearch query: 404 Client Error: Not Found for url: http://localhost:9200/logs_index/_search
2024-08-01 23:13:58,788 custom_logger INFO Handling command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:13:58,789 custom_logger INFO Running command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:13:58,968 custom_logger ERROR Command execution failed: docker: Error response from daemon: Conflict. The container name "/command-service-test" is already in use by container "e388474a7a6564e9c1ec5cfa7a30f61be1fe6b8cae783ede393073a33cadd1b8". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.

2024-08-01 23:14:02,529 custom_logger INFO Handling command: curl -X GET 'http://localhost:9200/_cat/indices?v' in path: .
2024-08-01 23:14:02,531 custom_logger INFO Running command: curl -X GET 'http://localhost:9200/_cat/indices?v' in path: .
2024-08-01 23:14:02,628 custom_logger ERROR Command execution failed:   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   448  100   448    0     0   8296      0 --:--:-- --:--:-- --:--:--  8452

2024-08-01 23:14:06,136 custom_logger INFO Handling command: docker rm -f command-service-test in path: .
2024-08-01 23:14:06,137 custom_logger INFO Running command: docker rm -f command-service-test in path: .
2024-08-01 23:14:06,388 custom_logger INFO Command succeeded: stdout: command-service-test
, stderr: 
2024-08-01 23:14:07,337 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 23:14:08,241 custom_logger INFO Query succeeded: {'took': 884, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 479, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'logs', '_type': '_doc', '_id': 'A7atEJEBTfLFZNqTfheV', '_score': 1.0, '_source': {'@timestamp': '2024-08-02T01:21:31.242954', 'message': '2024-08-01 21:21:31,241 custom_logger INFO Handling command: mkdir -p project-root/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'BLatEJEBTfLFZNqTfhfE', '_score': 1.0, '_source': {'@timestamp': '2024-08-02T01:21:31.323307', 'message': '2024-08-01 21:21:31,242 custom_logger INFO Running command: mkdir -p project-root/{command_service,websocket_listener_service,proxy_service,elasticsearch,kubernetes} in path: .', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'BbatEJEBTfLFZNqTfhfZ', '_score': 1.0, '_source': {'@timestamp': '2024-08-02T01:21:31.347290', 'message': '2024-08-01 21:21:31,273 custom_logger INFO Command succeeded: stdout: , stderr: ', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'BratEJEBTfLFZNqTmxdG', '_score': 1.0, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T01:21:38.593401', 'message': '2024-08-01 21:21:38,591 custom_logger INFO Handling command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'B7atEJEBTfLFZNqTmxdc', '_score': 1.0, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T01:21:38.644748', 'message': '2024-08-01 21:21:38,593 custom_logger INFO Running command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'CLatEJEBTfLFZNqTmxd7', '_score': 1.0, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T01:21:38.672638', 'message': "2024-08-01 21:21:38,671 custom_logger ERROR Command execution failed: touch: cannot touch 'project-root/command_service/Dockerfile': No such file or directory\ntouch: cannot touch 'project-root/websocket_listener_service/Dockerfile': No such file or directory\ntouch: cannot touch 'project-root/proxy_service/Dockerfile': No such file or directory\ntouch: cannot touch 'project-root/elasticsearch/command_service-elasticsearch.yaml': No such file or directory\ntouch: cannot touch 'project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml': No such file or directory\ntouch: cannot touch 'project-root/kubernetes/command_service-deployment.yaml': No such file or directory\ntouch: cannot touch 'project-root/kubernetes/command_service-service.yaml': No such file or directory\ntouch: cannot touch 'project-root/kubernetes/websocket_listener_service-deployment.yaml': No such file or directory\ntouch: cannot touch 'project-root/kubernetes/websocket_listener_service-service.yaml': No such file or directory\ntouch: cannot touch 'project-root/kubernetes/proxy_service-deployment.yaml': No such file or directory\ntouch: cannot touch 'project-root/kubernetes/proxy_service-service.yaml': No such file or directory\n", 'level': 'ERROR', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'CbatEJEBTfLFZNqTtBck', '_score': 1.0, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T01:21:44.986230', 'message': '2024-08-01 21:21:44,985 custom_logger INFO Handling command: mkdir -p project-root/command_service && mkdir -p project-root/websocket_listener_service && mkdir -p project-root/proxy_service && mkdir -p project-root/elasticsearch && mkdir -p project-root/kubernetes in path: .', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'CratEJEBTfLFZNqTtBdM', '_score': 1.0, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T01:21:45.026416', 'message': '2024-08-01 21:21:44,985 custom_logger INFO Running command: mkdir -p project-root/command_service && mkdir -p project-root/websocket_listener_service && mkdir -p project-root/proxy_service && mkdir -p project-root/elasticsearch && mkdir -p project-root/kubernetes in path: .', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'C7atEJEBTfLFZNqTtBde', '_score': 1.0, '_source': {'@timestamp': '2024-08-02T01:21:45.048832', 'message': '2024-08-01 21:21:45,027 custom_logger INFO Command succeeded: stdout: , stderr: ', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'DLatEJEBTfLFZNqT0hds', '_score': 1.0, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T01:21:52.722340', 'message': '2024-08-01 21:21:52,720 custom_logger INFO Handling command: touch project-root/command_service/Dockerfile project-root/websocket_listener_service/Dockerfile project-root/proxy_service/Dockerfile project-root/docker-compose.yaml project-root/elasticsearch/command_service-elasticsearch.yaml project-root/elasticsearch/websocket_listener_service-elasticsearch.yaml project-root/kubernetes/command_service-deployment.yaml project-root/kubernetes/command_service-service.yaml project-root/kubernetes/websocket_listener_service-deployment.yaml project-root/kubernetes/websocket_listener_service-service.yaml project-root/kubernetes/proxy_service-deployment.yaml project-root/kubernetes/proxy_service-service.yaml in path: .', 'level': 'INFO', 'logger_name': 'custom_logger'}}]}}
2024-08-01 23:17:23,209 custom_logger INFO Handling command: docker logs --tail 50 command-service-test in path: .
2024-08-01 23:17:23,210 custom_logger INFO Running command: docker logs --tail 50 command-service-test in path: .
2024-08-01 23:17:23,375 custom_logger ERROR Command execution failed: Traceback (most recent call last):
  File "/usr/local/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 362, in main
    run(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 386, in run
    server.run()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 49, in run
    loop.run_until_complete(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 56, in serve
    config.load()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/config.py", line 308, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 23, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 20, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'command_service'

2024-08-01 23:17:46,371 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 23:17:46,372 custom_logger INFO Running command: docker build -t command-service:latest ./command_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-01 23:17:50,785 custom_logger ERROR Command execution failed: #1 [internal] load .dockerignore
#1 sha256:6301d3aadae49cad736d16c6542b25a68e0e670cf38a7145a217643eaad11372
#1 transferring context: 2B 0.0s done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 sha256:c928b82f30b22612b6963f0166f869e04e0b74b1b4dc5832c5504ef604236a5a
#2 transferring dockerfile: 242B 0.0s done
#2 DONE 0.1s

#3 [internal] load metadata for docker.io/library/python:3.8-slim
#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065
#3 DONE 4.1s

#4 [1/4] FROM docker.io/library/python:3.8-slim@sha256:5d7e72b7a83c9fbe54fb13d95345de538e93adc943c642cfb1b2eba312606bc4
#4 sha256:469c74e7c436ccb78e7314351de453295974ae88cecb3414ae5047294d0fea88
#4 resolve docker.io/library/python:3.8-slim@sha256:5d7e72b7a83c9fbe54fb13d95345de538e93adc943c642cfb1b2eba312606bc4 0.0s done
#4 DONE 0.0s

#6 [internal] load build context
#6 sha256:537d42071c85b7f0d7d58de0ce2a3edc21ea84c1c37f151b2954f3bcdcc7f6cc
#6 transferring context: 122B 0.0s done
#6 DONE 0.0s

#5 [2/4] WORKDIR /app
#5 sha256:063b6dbb6b5766bd78b1e5a35c4d0d52cdf727910cead74352f5eed8f655dc2e
#5 CACHED

#7 [3/4] COPY . /app
#7 sha256:2e997bba1962eef4dbd582a6c746fcb10e361593d9bccf7dcacc9bd3af9c756e
#7 CACHED

#8 [4/4] RUN pip install --no-cache-dir -r requirements.txt
#8 sha256:d47881080114ef695957a5bac35a670b9aa035a7d7b0bf3e50803b2c8abbadcf
#8 CACHED

#9 exporting to image
#9 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00
#9 exporting layers done
#9 writing image sha256:0feec16aea7c1da74508dc740208391e0c0204284526ecfcbbca511e4eb24d81 done
#9 naming to docker.io/library/command-service:latest done
#9 DONE 0.0s

2024-08-01 23:17:57,163 custom_logger INFO Handling command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:17:57,163 custom_logger INFO Running command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:17:57,323 custom_logger ERROR Command execution failed: docker: Error response from daemon: Conflict. The container name "/command-service-test" is already in use by container "926c13eab5796acb26b6309f441c367358e5b27e6de56834ffe321bca64e6735". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.

2024-08-01 23:18:05,027 custom_logger INFO Handling command: docker rm -f command-service-test in path: .
2024-08-01 23:18:05,027 custom_logger INFO Running command: docker rm -f command-service-test in path: .
2024-08-01 23:18:05,224 custom_logger INFO Command succeeded: stdout: command-service-test
, stderr: 
2024-08-01 23:18:08,203 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 23:18:08,543 custom_logger INFO Query succeeded: {'took': 306, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 119, 'relation': 'eq'}, 'max_score': 2.6350815, 'hits': [{'_index': 'logs', '_type': '_doc', '_id': '3rb4EJEBTfLFZNqTSBeU', '_score': 2.6350815, '_source': {'@timestamp': '2024-08-02T02:43:12.655128', 'message': '2024-08-01 22:43:12,653 custom_logger ERROR Command execution failed: "docker logs" requires exactly 1 argument.\nSee \'docker logs --help\'.\n\nUsage:  docker logs [OPTIONS] CONTAINER\n\nFetch the logs of a container\n', 'level': 'ERROR', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '9bb7EJEBTfLFZNqTMRdX', '_score': 2.6059098, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T02:46:23.308964', 'message': '2024-08-01 22:46:23,308 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '9rb7EJEBTfLFZNqTMRd1', '_score': 2.6059098, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T02:46:23.341596', 'message': '2024-08-01 22:46:23,308 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '-7b7EJEBTfLFZNqTnhdW', '_score': 2.6059098, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T02:46:51.209332', 'message': '2024-08-01 22:46:51,208 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '_Lb7EJEBTfLFZNqTnhdy', '_score': 2.6059098, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T02:46:51.244185', 'message': '2024-08-01 22:46:51,209 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'MbYBEZEBTfLFZNqT9xhS', '_score': 2.6059098, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T02:53:47.204758', 'message': '2024-08-01 22:53:47,203 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'MrYBEZEBTfLFZNqT9xhz', '_score': 2.6059098, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T02:53:47.244982', 'message': '2024-08-01 22:53:47,204 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'ebYNEZEBTfLFZNqT6xi_', '_score': 2.6059098, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T03:06:50.676464', 'message': '2024-08-01 23:06:50,675 custom_logger INFO Handling command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'erYNEZEBTfLFZNqT6xjb', '_score': 2.6059098, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T03:06:50.709366', 'message': '2024-08-01 23:06:50,676 custom_logger INFO Running command: docker build -t command-service:latest ./command_service && docker build -t websocket-listener-service:latest ./websocket_listener_service && docker build -t proxy-service:latest ./proxy_service in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': '3Lb4EJEBTfLFZNqTRxef', '_score': 2.5392985, '_source': {'@timestamp': '2024-08-02T02:43:12.401200', 'message': '2024-08-01 22:43:12,400 custom_logger INFO Handling command: docker logs $(docker ps -qf "name=command-service") in path: .', 'level': 'INFO', 'logger_name': 'custom_logger'}}]}}
2024-08-01 23:18:12,008 custom_logger INFO Handling command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:18:12,011 custom_logger INFO Running command: docker run -d --name command-service-test -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest in path: .
2024-08-01 23:18:13,250 custom_logger INFO Command succeeded: stdout: d903edb741e03a3d5416341b89ff7ae59f051d1c89986e3ca7fff767c29aae49
, stderr: 
2024-08-01 23:18:27,268 custom_logger INFO Handling command: docker logs --tail 50 command-service-test in path: .
2024-08-01 23:18:27,269 custom_logger INFO Running command: docker logs --tail 50 command-service-test in path: .
2024-08-01 23:18:27,410 custom_logger ERROR Command execution failed: Traceback (most recent call last):
  File "/usr/local/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 362, in main
    run(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 386, in run
    server.run()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 49, in run
    loop.run_until_complete(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 56, in serve
    config.load()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/config.py", line 308, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 23, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 20, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'command_service'

2024-08-01 23:18:48,088 custom_logger INFO Handling command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service in path: .
2024-08-01 23:18:48,088 custom_logger INFO Running command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service in path: .
2024-08-01 23:18:48,107 custom_logger INFO Command succeeded: stdout: Dockerfile
__init__.py
main.py
requirements.txt
, stderr: 
2024-08-01 23:19:03,842 custom_logger INFO Handling command: cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 23:19:03,843 custom_logger INFO Running command: cat /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service/main.py in path: .
2024-08-01 23:19:03,858 custom_logger INFO Command succeeded: stdout: import requests
import uvicorn
from fastapi import FastAPI
import os

app = FastAPI()

# Define your endpoints here

def register_service():
    proxy_service_ip = os.getenv("PROXY_SERVICE_IP")
    service_ip = os.getenv("COMMAND_SERVICE_IP")
    register_url = f"http://{proxy_service_ip}:8000/register"
    service_data = {
        "service_name": "command-service",
        "openapi_url": f"http://{service_ip}:8001/openapi.json"
    }
    response = requests.post(register_url, json=service_data)
    print(f"Registering command-service: {response.json()}")

if __name__ == "__main__":
    register_service()
    uvicorn.run(app, host="0.0.0.0", port=8001)
, stderr: 
2024-08-01 23:19:29,117 custom_logger INFO Handling command: docker logs --tail 50 command-service-test in path: .
2024-08-01 23:19:29,118 custom_logger INFO Running command: docker logs --tail 50 command-service-test in path: .
2024-08-01 23:19:29,283 custom_logger ERROR Command execution failed: Traceback (most recent call last):
  File "/usr/local/bin/uvicorn", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/usr/local/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 362, in main
    run(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/main.py", line 386, in run
    server.run()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 49, in run
    loop.run_until_complete(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/server.py", line 56, in serve
    config.load()
  File "/usr/local/lib/python3.8/site-packages/uvicorn/config.py", line 308, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 23, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.8/site-packages/uvicorn/importer.py", line 20, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'command_service'

2024-08-01 23:19:53,499 custom_logger INFO Handling command: docker exec command-service-test ls /app in path: .
2024-08-01 23:19:53,500 custom_logger INFO Running command: docker exec command-service-test ls /app in path: .
2024-08-01 23:19:53,671 custom_logger ERROR Command execution failed: Error response from daemon: Container d903edb741e03a3d5416341b89ff7ae59f051d1c89986e3ca7fff767c29aae49 is not running

2024-08-01 23:20:15,444 custom_logger INFO Handling command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service in path: .
2024-08-01 23:20:15,445 custom_logger INFO Running command: ls /mnt/c/Users/Richa/PycharmProjects/Proxy_Services/command_service in path: .
2024-08-01 23:20:15,463 custom_logger INFO Command succeeded: stdout: Dockerfile
__init__.py
main.py
requirements.txt
, stderr: 
2024-08-01 23:20:31,595 custom_logger INFO Handling command: docker run -it --name command-service-interactive -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest /bin/sh in path: .
2024-08-01 23:20:31,597 custom_logger INFO Running command: docker run -it --name command-service-interactive -p 8001:8001 -e PROXY_SERVICE_IP=127.0.0.1 -e COMMAND_SERVICE_IP=127.0.0.1 command-service:latest /bin/sh in path: .
2024-08-01 23:21:52,213 custom_logger INFO Handling command: find . -type f -mmin -60 in path: .
2024-08-01 23:21:52,213 custom_logger INFO Running command: find . -type f -mmin -60 in path: .
2024-08-01 23:21:52,436 custom_logger INFO Command succeeded: stdout: ./app.log
, stderr: 
2024-08-01 23:39:26,478 custom_logger INFO Handling elastic: http://localhost:9200
2024-08-01 23:39:26,525 custom_logger INFO Query succeeded: {'took': 27, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 2, 'relation': 'eq'}, 'max_score': 7.2260413, 'hits': [{'_index': 'logs', '_type': '_doc', '_id': 'rbYUEZEBTfLFZNqTSRj2', '_score': 7.2260413, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T03:13:48.015131', 'message': '2024-08-01 23:13:47,978 custom_logger INFO Command succeeded: stdout: {\n  "proxy_url": "http://localhost:8010/register",\n  "host": "0.0.0.0",\n  "port": 8014,\n  "service_name": "command-service",\n  "logging": {\n    "level": "INFO",\n    "format": "{asctime} {name} {levelname} {message}",\n    "sinks": ["console", "file", "elastic"],\n    "elastic_url": "http://localhost:9200"\n  }\n}\n, stderr: ', 'level': 'INFO', 'logger_name': 'custom_logger'}}, {'_index': 'logs', '_type': '_doc', '_id': 'RbYFEZEBTfLFZNqToRgk', '_score': 7.2260413, '_ignored': ['message.keyword'], '_source': {'@timestamp': '2024-08-02T02:57:47.294771', 'message': '2024-08-01 22:57:47,269 custom_logger INFO Command succeeded: stdout: {\n  "proxy_url": "http://localhost:8010/register",\n  "host": "0.0.0.0",\n  "port": 8014,\n  "service_name": "command-service",\n  "logging": {\n    "level": "INFO",\n    "format": "{asctime} {name} {levelname} {message}",\n    "sinks": ["console", "file", "elastic"],\n    "elastic_url": "http://localhost:9200"\n  }\n}\n, stderr: ', 'level': 'INFO', 'logger_name': 'custom_logger'}}]}}
2024-08-02 00:06:21,071 custom_logger INFO Starting the application
2024-08-02 00:06:21,215 custom_logger INFO Entering register_service
2024-08-02 00:06:21,216 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-02 00:06:34,735 custom_logger INFO Starting the application
2024-08-02 00:06:34,848 custom_logger INFO Entering register_service
2024-08-02 00:06:34,852 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-02 00:06:34,908 custom_logger INFO Service registered successfully with the proxy.
2024-08-02 00:06:34,909 custom_logger INFO Exiting register_service
2024-08-02 11:54:09,627 custom_logger INFO Starting the application
2024-08-02 11:54:09,762 custom_logger INFO Entering register_service
2024-08-02 11:54:09,766 custom_logger INFO Registering service with the proxy...{'service_name': 'command-service', 'openapi_url': 'http://0.0.0.0:8014/openapi.json', 'openapi_json': None}
2024-08-02 11:54:09,873 custom_logger INFO Service registered successfully with the proxy.
2024-08-02 11:54:09,874 custom_logger INFO Exiting register_service
2024-08-02 11:56:46,529 custom_logger INFO Handling command: find . -type f \( -name '*.py' -o -name '*.json' -o -name '*.yaml' -o -name '*.yml' \) -exec echo FILE: {} \; -exec head -n 50 {} \; in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:56:46,530 custom_logger INFO Running command: find . -type f \( -name '*.py' -o -name '*.json' -o -name '*.yaml' -o -name '*.yml' \) -exec echo FILE: {} \; -exec head -n 50 {} \; in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:57:02,111 custom_logger INFO Command succeeded: stdout: FILE: ./docker-compose.yaml
version: "3.8"

services:
  command_service:
    build: ./command_service
    ports:
      - "8001:8001"
    environment:
      - ELASTIC_URL=http://command_service_elasticsearch:9200

  websocket_listener_service:
    build: ./websocket_listener_service
    ports:
      - "8002:8002"
    environment:
      - ELASTIC_URL=http://websocket_listener_elasticsearch:9200

  proxy_service:
    build: ./proxy_service
    ports:
      - "8000:8000"

  command_service_elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    environment:
      - discovery.type=single-node
    ports:
      - "9201:9200"

  websocket_listener_elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    environment:
      - discovery.type=single-node
    ports:
      - "9202:9200"
FILE: ./legacy/handle_base.py
from fastapi import APIRouter

class HandleBase:
    def __init__(self):
        self.router = APIRouter()

        @self.router.get("/example")
        async def example_endpoint():
            return {"message": "This is an example endpoint"}
FILE: ./legacy/handle_command.py
from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
import asyncio
import logging
import os
import requests
from contextlib import asynccontextmanager
from handle_base import HandleBase

app = FastAPI()
logging.basicConfig(level=logging.INFO)

class CommandMessage(BaseModel):
    command: str
    path: str = ""

class RegisterRequest(BaseModel):
    service_name: str
    url: str

PROXY_URL = "http://localhost:8010/register"

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Registration logic
    registration_data = {
        "service_name": "handle-command",
        "url": "http://localhost:8003"
    }
    try:
        logging.info(f"Registering service with the proxy...{registration_data}")
        response = requests.post(PROXY_URL, json=registration_data)
        response.raise_for_status()
        logging.info("Service registered successfully with the proxy.")
    except requests.RequestException as e:
        logging.error(f"Failed to register service with proxy: {e}")
        raise HTTPException(status_code=500, detail="Failed to register service with proxy")
    yield
    # Any cleanup logic here if needed

app = FastAPI(lifespan=lifespan)

async def run_command(command: str, path: str):
    logger = logging.getLogger(__name__)
    logger.info(f"Running command: {command} in path: {path}")

    full_path = os.path.abspath(path) if path else os.getcwd()

    process = await asyncio.create_subprocess_shell(
        command,
FILE: ./legacy/handle_command_dev.py
from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
import subprocess
import logging
import os
import requests
from contextlib import asynccontextmanager
from handle_base import HandleBase

app = FastAPI()
logging.basicConfig(level=logging.INFO)

class CommandMessage(BaseModel):
    command: str
    path: str = ""

class RegisterRequest(BaseModel):
    service_name: str
    url: str

PROXY_URL = "http://localhost:8005/register"

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Registration logic
    registration_data = {
        "service_name": "handle-command-dev",
        "url": "http://localhost:8004"
    }
    try:
        logging.info("Registering service with the proxy...")
        response = requests.post(PROXY_URL, json=registration_data)
        response.raise_for_status()
        logging.info("Service registered successfully with the proxy.")
    except requests.RequestException as e:
        logging.error(f"Failed to register service with proxy: {e}")
        raise HTTPException(status_code=500, detail="Failed to register service with proxy")
    yield
    # Any cleanup logic here if needed

app = FastAPI(lifespan=lifespan)

@app.post("/handle-command-dev")
async def handle_command(message: CommandMessage):
    logger = logging.getLogger(__name__)
    logger.info(f"Handling command: {message} ")


    logger.info(f"Handling command: {message.command} in path: {message.path}")

FILE: ./legacy/handle_elastic.py
from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
import logging
import requests
import traceback

app = FastAPI()
logging.basicConfig(level=logging.DEBUG)


class ElasticQueryMessage(BaseModel):
    connection_string: str
    index: str
    query: dict


class RegisterRequest(BaseModel):
    service_name: str
    url: str


PROXY_URL = "http://localhost:8080/register"


@app.on_event("startup")
async def startup_event():
    registration_data = {
        "service_name": "handle-elastic",
        "url": "http://localhost:8007"
    }
    try:
        logging.info("Registering service with the proxy...")
        response = requests.post(PROXY_URL, json=registration_data)
        response.raise_for_status()
        logging.info("Service registered successfully with the proxy.")
    except requests.RequestException as e:
        logging.error(f"Failed to register service with proxy: {e}")
        raise HTTPException(status_code=500, detail="Failed to register service with proxy")


@app.post("/handle-elastic")
async def handle_elastic(message: ElasticQueryMessage):
    logger = logging.getLogger(__name__)
    logger.info(f"Handling ElasticSearch query: {message}")

    try:
        query_url = f"{message.connection_string}/{message.index}/_search"
        logger.debug(f"Query URL: {query_url}")
        logger.debug(f"Query Body: {message.query}")

FILE: ./legacy/handle_piston.py
import requests
from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
import json

app = FastAPI()

class CodeExecutionRequest(BaseModel):
    language: str
    version: str
    code: str

@app.post("/execute")
def execute_code(request: CodeExecutionRequest):
    url = "https://emkc.org/api/v2/piston/execute"
    payload = {
        "language": request.language,
        "version": request.version,
        "files": [{"name": "main", "content": request.code}]
    }
    headers = {"Content-Type": "application/json"}

    response = requests.post(url, json=payload, headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        raise HTTPException(status_code=response.status_code, detail="Error executing code")


def register_service():
    service_name = "handle_piston"
    service_url = "http://localhost:8002"
    proxy_url = "http://localhost:8080/register_service"
    payload = {
        "service_name": service_name,
        "url": service_url
    }
    headers = {"Content-Type": "application/json"}
    response = requests.post(proxy_url, json=payload, headers=headers)
    if response.status_code == 200:
        print(f"Service {service_name} registered successfully.")
    else:
        print(f"Failed to register service {service_name}: {response.status_code}")

if __name__ == "__main__":
    register_service()
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)
FILE: ./legacy/handle_replit.py
from fastapi import FastAPI, HTTPException, File, UploadFile, Form
from pydantic import BaseModel
import logging
import os
import traceback
import requests
from contextlib import asynccontextmanager

app = FastAPI()
logging.basicConfig(level=logging.INFO)

class RegisterRequest(BaseModel):
    service_name: str
    url: str

PROXY_URL = "http://localhost:8001/register"

@asynccontextmanager
async def lifespan(app: FastAPI):
    registration_data = {
        "service_name": "handle-replit",
        "url": "http://localhost:8007/handle-replit"
    }
    try:
        logging.info("Registering service with the proxy...")
        response = requests.post(PROXY_URL, json=registration_data)
        response.raise_for_status()
        logging.info("Service registered successfully with the proxy.")
    except requests.RequestException as e:
        logging.error(f"Failed to register service with proxy: {e}")
        raise HTTPException(status_code=500, detail="Failed to register service with proxy")

    yield
    logging.info("Shutting down...")

app = FastAPI(lifespan=lifespan)

@app.post("/handle-replit")
async def handle_replit(file: UploadFile = File(...), repl_name: str = Form(...), repl_url: str = Form(...)):
    logger = logging.getLogger(__name__)
    logger.info(f"Handling file upload: {file.filename}")
    logger.info(f"Received repl_name: {repl_name}")
    logger.info(f"Received repl_url: {repl_url}")

    try:
        file_path = os.path.join(f"/home/runner/{repl_name}/", file.filename)
        with open(file_path, "wb") as buffer:
            buffer.write(file.file.read())

        file_url = f"https://{repl_url}/{file.filename}"
FILE: ./legacy/listener.py
import asyncio
import websockets
import json
import logging
import requests
import os
import uuid
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from pydantic import BaseModel, Field
from typing import Any, Optional
from contextlib import asynccontextmanager
from fastapi.openapi.utils import get_openapi
import yaml

logging.basicConfig(level=logging.DEBUG)
app = FastAPI()

service_registry = {}

PROXY_URL = "http://localhost:8080/register"
DEREGISTER_PROXY_URL = "http://localhost:8080/deregister"
CONFIG_FILE = "listener_config.json"

class Envelope(BaseModel):
    endpoint_service_name: str = Field(..., description="Name of the service to forward the request to")
    endpoint_request_type: str = Field(..., description="HTTP method of the request (GET, POST, etc.)")
    endpoint_headers: Any = Field(default={}, description="Headers to include in the forwarded request")
    endpoint_params: Any = Field(default={}, description="Query parameters to include in the forwarded request")
    endpoint_body: Any = Field(default={}, description="Body of the forwarded request")
    connection_id: Optional[str] = Field(None, description="Connection ID for WebSocket listener")
    endpoint_url: str = Field(..., description="URL of the service to register")

class RegisterRequest(BaseModel):
    service_name: str
    url: str

class DeregisterRequest(BaseModel):
    service_name: str

def load_config():
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, "r") as file:
            logging.info("Loading configuration from file")
            return json.load(file)
    return {}

def save_config(config):
    with open(CONFIG_FILE, "w") as file:
        json.dump(config, file)

FILE: ./legacy/listener_config.json
{"connection_id": "d2034830-8096-4d0e-8a68-bdea3fe8c77d"}FILE: ./legacy/listener_dev.py
import asyncio
import websockets
import json
import logging
import requests
import os
import uuid
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from pydantic import BaseModel, Field
from typing import Any, Optional
from contextlib import asynccontextmanager
from fastapi.openapi.utils import get_openapi
import yaml

logging.basicConfig(level=logging.DEBUG)
app = FastAPI()

service_registry = {}

PROXY_URL = "http://localhost:8080/register"
DEREGISTER_PROXY_URL = "http://localhost:8080/deregister"
CONFIG_FILE = "listener_dev_config.json"

class Envelope(BaseModel):
    endpoint_service_name: str = Field(..., description="Name of the service to forward the request to")
    endpoint_request_type: str = Field(..., description="HTTP method of the request (GET, POST, etc.)")
    endpoint_headers: Any = Field(default={}, description="Headers to include in the forwarded request")
    endpoint_params: Any = Field(default={}, description="Query parameters to include in the forwarded request")
    endpoint_body: Any = Field(default={}, description="Body of the forwarded request")
    connection_id: Optional[str] = Field(None, description="Connection ID for WebSocket listener")
    endpoint_url: str = Field(..., description="URL of the service to register")

class RegisterRequest(BaseModel):
    service_name: str
    url: str

class DeregisterRequest(BaseModel):
    service_name: str

def load_config():
    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, "r") as file:
            logging.info("Loading configuration from file")
            return json.load(file)
    return {}

def save_config(config):
    with open(CONFIG_FILE, "w") as file:
        json.dump(config, file)

FILE: ./legacy/listener_dev_config.json
{"connection_id": "new-unique-connection-id"}
FILE: ./legacy/logging_config.py
import logging
from elasticsearch import Elasticsearch
from datetime import datetime

class ElasticsearchHandler(logging.Handler):
    def __init__(self, hosts, index):
        super().__init__()
        self.es = Elasticsearch(hosts)
        self.index = index

    def emit(self, record):
        log_entry = self.format(record)
        self.es.index(index=self.index, body={
            '@timestamp': datetime.utcnow().isoformat(),
            'message': log_entry,
            'level': record.levelname,
            'logger': record.name,
        })

def configure_logging(logger_name, es_hosts, es_index):
    logger = logging.getLogger(logger_name)
    logger.setLevel(logging.INFO)

    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)

    # Elasticsearch handler
    es_handler = ElasticsearchHandler(es_hosts, es_index)
    es_handler.setLevel(logging.INFO)
    es_handler.setFormatter(console_formatter)
    logger.addHandler(es_handler)

    return logger
FILE: ./legacy/openapi.json
{"openapi":"3.1.0","info":{"title":"FastAPI","version":"0.1.0"},"paths":{"/execute-bash":{"post":{"summary":"Command Service","operationId":"command_service_command_service_post","requestBody":{"content":{"application/json":{"schema":{"$ref":"#/components/schemas/CommandMessage"}}},"required":true},"responses":{"200":{"description":"Successful Response","content":{"application/json":{"schema":{}}}},"422":{"description":"Validation Error","content":{"application/json":{"schema":{"$ref":"#/components/schemas/HTTPValidationError"}}}}}}}},"components":{"schemas":{"CommandMessage":{"properties":{"command":{"type":"string","title":"Command"},"path":{"type":"string","title":"Path","default":""}},"type":"object","required":["command"],"title":"CommandMessage"},"HTTPValidationError":{"properties":{"detail":{"items":{"$ref":"#/components/schemas/ValidationError"},"type":"array","title":"Detail"}},"type":"object","title":"HTTPValidationError"},"ValidationError":{"properties":{"loc":{"items":{"anyOf":[{"type":"string"},{"type":"integer"}]},"type":"array","title":"Location"},"msg":{"type":"string","title":"Message"},"type":{"type":"string","title":"Error Type"}},"type":"object","required":["loc","msg","type"],"title":"ValidationError"}}}}FILE: ./legacy/proxy.py
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Body
from pydantic import BaseModel, Field
from typing import Any, Optional
import requests
import asyncio
import yaml
from fastapi.openapi.utils import get_openapi
import logging
from contextlib import asynccontextmanager

logging.basicConfig(level=logging.INFO)

app = FastAPI(
    title="Proxy Service API",
    description="API for the Proxy Service to forward requests to registered services",
    version="1.0.0",
)

class Envelope(BaseModel):
    endpoint_service_name: str = Field(..., description="Name of the service to forward the request to")
    endpoint_path: str = Field(..., description="Path of the service endpoint")
    endpoint_request_type: str = Field(..., description="HTTP method of the request (GET, POST, etc.)")
    endpoint_headers: Any = Field(default={}, description="Headers to include in the forwarded request")
    endpoint_params: Any = Field(default={}, description="Query parameters to include in the forwarded request")
    endpoint_body: Any = Field(default={}, description="Body of the forwarded request")
    connection_id: Optional[str] = Field(None, description="Connection ID for WebSocket listener")
    endpoint_url: str = Field(..., description="URL of the service to register")

class RegisterRequest(BaseModel):
    service_name: str = Field(..., description="Name of the service to register")
    url: str = Field(..., description="URL of the service to register")

websocket_clients = {}
service_registry = {}

def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        openapi_version=app.openapi_version,
        description=app.description,
        routes=app.routes,
    )
    openapi_schema["servers"] = [
        {"url": "https://katydid-glorious-slightly.ngrok-free.app"}
    ]
    app.openapi_schema = openapi_schema
    return app.openapi_schema
FILE: ./legacy/query_logs.py
from elasticsearch import Elasticsearch

# Configure Elasticsearch client
es = Elasticsearch(['http://localhost:9200'])

# Query the logs
response = es.search(
    index='sample-logs',
    body={
        'query': {
            'match_all': {}
        }
    }
)

# Print the results
for hit in response['hits']['hits']:
    print(hit['_source'])
FILE: ./legacy/sample_logging.py
import logging
import time
from logging_config import configure_logging

# Configure logging
logger = configure_logging('sample_logger', ['http://localhost:9200'], 'sample-logs')

# Sample logging
for i in range(10):
    logger.info(f'Logging info message {i}')
    logger.warning(f'Logging warning message {i}')
    logger.error(f'Logging error message {i}')
    time.sleep(1)
FILE: ./microservices/command_service/config/config.json
{
  "proxy_url": "http://localhost:8010/register",
  "host": "0.0.0.0",
  "port": 8014,
  "service_name": "command-service",
  "logging": {
    "level": "INFO",
    "format": "{asctime} {name} {levelname} {message}",
    "sinks": ["console", "file", "elastic"],
    "elastic_url": "http://localhost:9200"
  }
}
FILE: ./microservices/command_service/config/config.py
import logging
import json
from concurrent.futures import ThreadPoolExecutor
import requests
import os
from pydantic import BaseSettings

class Settings(BaseSettings):
    proxy_url: str
    host: str
    port: int
    service_name: str
    logging_level: str
    logging_format: str
    logging_sinks: list
    elastic_url: str

def load_config():
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    with open(config_path) as config_file:
        config_data = json.load(config_file)
        return Settings(
            proxy_url=config_data['proxy_url'],
            host=config_data['host'],
            port=config_data['port'],
            service_name=config_data['service_name'],
            logging_level=config_data['logging']['level'],
            logging_format=config_data['logging']['format'],
            logging_sinks=config_data['logging']['sinks'],
            elastic_url=config_data['logging']['elastic_url']
        )



settings = load_config()
FILE: ./microservices/command_service/config/__init__.py
FILE: ./microservices/command_service/controllers/command_controller.py
from fastapi import APIRouter, HTTPException, Depends
from command_service.models.command_message import CommandMessage
from command_service.services.command_service import run_command
from command_service.services.logger import CustomLogger, log_decorator
from command_service.services.logger import get_logger
from command_service.config.config import Settings, load_config
from command_service.services.logger import CustomLogger
from pydantic import BaseModel
import logging
import requests
import traceback

router = APIRouter()

@router.post('/execute-bash')
async def command_service(message: CommandMessage):
    settings = load_config()
    logger = CustomLogger(settings)

    logger.info(f'Handling command: {message.command} in path: {message.path}')

    try:
        stdout, stderr = await run_command(message.command, message.path, settings, logger)

        if stderr:
            logger.error(f'Command execution failed: {stderr}')
            return {'stdout': stdout, 'stderr': stderr}

        logger.info(f'Command succeeded: stdout: {stdout}, stderr: {stderr}')
        return {'stdout': stdout, 'stderr': stderr}

    except Exception as e:
        logger.error(f'Failed to execute command: {str(e)}')
        return {'stdout': '', 'stderr': str(e)}

class ElasticQueryMessage(BaseModel):
    connection_string: str
    index: str
    query: dict

class ElasticLogMessage(BaseModel):
    connection_string: str
    index: str
    log: dict

@router.post('/elastic-query')
async def handle_elastic(message: ElasticQueryMessage):
    settings = load_config()
    logger = CustomLogger(settings)

FILE: ./microservices/command_service/controllers/__init__.py
FILE: ./microservices/command_service/main.py
from fastapi import FastAPI
from contextlib import asynccontextmanager
from command_service.services.registration_service import RegistrationService
from command_service.config.config import settings
from command_service.controllers import command_controller
from command_service.services.logger import CustomLogger
import logging
import asyncio

# Initialize the logger using CustomLogger
custom_logger = CustomLogger(settings)
logger = custom_logger

@asynccontextmanager
async def lifespan(app: FastAPI):
    openapi_schema = app.openapi()

    # Hardcoding the servers field
    openapi_schema['servers'] = [{"url": f"http://{settings.host}:{settings.port}"}]
    app.openapi_schema = openapi_schema

    registration_service = RegistrationService(settings, logger)
    # Start the service registration process as a background task
    asyncio.create_task(registration_service.register_service())
    yield
    # Any cleanup logic here if needed

app = FastAPI(lifespan=lifespan)
app.include_router(command_controller.router)

if __name__ == "__main__":
    logger.info("Starting the application")
    import uvicorn
    uvicorn.run(app, host=settings.host, port=settings.port)
FILE: ./microservices/command_service/models/command_message.py
from pydantic import BaseModel

class CommandMessage(BaseModel):
    command: str
    path: str = ""
FILE: ./microservices/command_service/models/register_request.py
from typing import Optional, Dict, Any
from pydantic import BaseModel

class RegisterRequest(BaseModel):
    service_name: str
    openapi_url: Optional[str] = None  # Make this field optional
    openapi_json: Optional[Dict[str, Any]] = None  # Make this field optional and ensure it's a dictionary
FILE: ./microservices/command_service/models/__init__.py
FILE: ./microservices/command_service/services/command_service.py
import asyncio
import logging
import os
from command_service.config.config import Settings

async def run_command(command: str, path: str, settings: Settings, logger: logging.Logger):
    logger.info(f"Running command: {command} in path: {path}")

    full_path = os.path.abspath(path) if path else os.getcwd()

    process = await asyncio.create_subprocess_shell(
        command,
        cwd=full_path,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )

    stdout, stderr = await process.communicate()

    return stdout.decode(), stderr.decode()
FILE: ./microservices/command_service/services/logger.py
import logging
from datetime import datetime
import json
from concurrent.futures import ThreadPoolExecutor
import requests

class ElasticsearchHandler(logging.Handler):
    def __init__(self, elastic_url):
        super().__init__()
        self.elastic_url = elastic_url
        self.executor = ThreadPoolExecutor(max_workers=1)

    def emit(self, record):
        log_entry = self.format(record)
        self.executor.submit(self.send_to_elasticsearch, log_entry, record)

    def send_to_elasticsearch(self, log_entry, record):
        try:
            log_message = {
                "@timestamp": datetime.utcnow().isoformat(),
                "message": log_entry,
                "level": record.levelname,
                "logger_name": record.name
            }
            print(f"Sending log to Elasticsearch: {json.dumps(log_message, indent=2)}")  # Debug print
            response = requests.post(
                f"{self.elastic_url}/logs/_doc",  # Corrected URL
                headers={"Content-Type": "application/json"},
                json=log_message
            )
            response.raise_for_status()
        except requests.HTTPError as e:
            print(f"Failed to send log to Elasticsearch: {e.response.status_code} {e.response.reason}")
            print(f"Response content: {e.response.content}")
        except json.JSONDecodeError as e:
            print(f"JSON decoding error: {e}")
        except Exception as e:
            print(f"Unexpected error: {e}")

class CustomLogger:
    def __init__(self, settings):
        self.logger = logging.getLogger('custom_logger')
        if not self.logger.hasHandlers():
            self.logger.setLevel(settings.logging_level)
            formatter = logging.Formatter(settings.logging_format, style='{')

            if 'console' in settings.logging_sinks:
                console_handler = logging.StreamHandler()
                console_handler.setFormatter(formatter)
                self.logger.addHandler(console_handler)
FILE: ./microservices/command_service/services/registration_service.py
import httpx
from fastapi import HTTPException
from command_service.services.logger import CustomLogger, log_decorator
from command_service.config.config import Settings
import logging
from command_service.models.register_request import RegisterRequest

class RegistrationService:
    def __init__(self, settings: Settings, logger: CustomLogger):
        self.settings = settings
        self.logger = logger

    @log_decorator()
    async def register_service(self):
        registration_data = RegisterRequest(
            service_name=self.settings.service_name,
            openapi_url=f'http://{self.settings.host}:{self.settings.port}/openapi.json'
        )

        timeout = httpx.Timeout(10.0, connect=10.0)  # Define timeout

        try:
            self.logger.log(logging.INFO, f'Registering service with the proxy...{registration_data.dict()}')
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(self.settings.proxy_url, json=registration_data.dict())
                response.raise_for_status()
            self.logger.log(logging.INFO, 'Service registered successfully with the proxy.')
        except httpx.RequestError as e:
            self.logger.log(logging.ERROR, f'Failed to register service with proxy: {e}')
            raise HTTPException(status_code=500, detail='Failed to register service with proxy')
FILE: ./microservices/command_service/services/__init__.py
FILE: ./microservices/command_service/__init__.py
FILE: ./microservices/tests/test_command_service.py
import unittest
from unittest.mock import patch, AsyncMock
from command_service.services.command_service import run_command
from command_service.config.config import Settings
import logging
import asyncio

class TestCommandService(unittest.TestCase):
    def setUp(self):
        config_data = {
            "proxy_url": "http://localhost:8010/register",
            "host": "0.0.0.0",
            "port": 8003,
            "service_name": "execute-bash",
            "logging_level": "INFO",
            "logging_format": "{asctime} {correlation_id} {codefile} {methodname} {parameters} {message}",
            "logging_sinks": ["console"],
            "elastic_url": "http://localhost:9200/logs"
        }
        self.settings = Settings(**config_data)
        self.logger = logging.getLogger("custom_logger")

    @patch("asyncio.create_subprocess_shell")
    def test_run_command_success(self, mock_subprocess):
        mock_process = AsyncMock()
        mock_process.communicate.return_value = (b"output", b"")
        mock_subprocess.return_value = mock_process

        command = "echo test"
        path = ""
        stdout, stderr = asyncio.run(run_command(command, path, self.settings, self.logger))

        self.assertEqual(stdout, "output")
        self.assertEqual(stderr, "")

    @patch("asyncio.create_subprocess_shell")
    def test_run_command_failure(self, mock_subprocess):
        mock_process = AsyncMock()
        mock_process.communicate.return_value = (b"", b"error")
        mock_subprocess.return_value = mock_process

        command = "wrongcommand"
        path = ""
        stdout, stderr = asyncio.run(run_command(command, path, self.settings, self.logger))

        self.assertEqual(stdout, "")
        self.assertEqual(stderr, "error")

if __name__ == "__main__":
    unittest.main()
FILE: ./microservices/tests/test_config.py
import unittest
import command_service
from unittest.mock import patch, mock_open

class TestConfig(unittest.TestCase):
    @patch("builtins.open", new_callable=mock_open, read_data="{\"proxy_url\": \"http://localhost:8010/register\", \"host\": \"0.0.0.0\", \"port\": 8003, \"service_name\": \"execute-bash\", \"logging\": {\"level\": \"INFO\", \"format\": \"{asctime} {correlation_id} {codefile} {methodname} {parameters} {message}\", \"sinks\": [\"console\"], \"elastic_url\": \"http://localhost:9200/logs\"}}")
    def test_load_config(self, mock_file):
        settings = load_config()
        self.assertEqual(settings.proxy_url, "http://localhost:8010/register")
        self.assertEqual(settings.host, "0.0.0.0")
        self.assertEqual(settings.port, 8003)
        self.assertEqual(settings.service_name, "execute-bash")
        self.assertEqual(settings.logging_level, "INFO")
        self.assertEqual(settings.logging_format, "{asctime} {correlation_id} {codefile} {methodname} {parameters} {message}")
        self.assertEqual(settings.logging_sinks, ["console"])
        self.assertEqual(settings.elastic_url, "http://localhost:9200/logs")

if __name__ == "__main__":
    unittest.main()
FILE: ./microservices/tests/test_logger.py
import unittest
from unittest.mock import patch
from command_service.config.config import Settings
from command_service.services.logger import CustomLogger
import logging

class TestCustomLogger(unittest.TestCase):
    def setUp(self):
        self.config_data = {
            "proxy_url": "http://localhost:8010/register",
            "host": "0.0.0.0",
            "port": 8003,
            "service_name": "execute-bash",
            "logging_level": "INFO",
            "logging_format": "{asctime} {message}",
            "logging_sinks": ["console"],
            "elastic_url": "http://localhost:9200/logs"
        }
        self.settings = Settings(**self.config_data)

    @patch("logging.Logger.log")
    def test_logger_initialization(self, mock_log):
        custom_logger = CustomLogger(self.settings)
        self.assertIsInstance(custom_logger.logger, logging.Logger)
        self.assertEqual(custom_logger.logger.level, logging.INFO)

    @patch("logging.Logger.log")
    def test_log_method(self, mock_log):
        custom_logger = CustomLogger(self.settings)
        custom_logger.log(logging.INFO, "Test message", correlation_id="123")

        mock_log.assert_called_once()
        call_args = mock_log.call_args[0]
        self.assertEqual(call_args[0], logging.INFO)
        self.assertIn("Test message", call_args[1]["message"])

if __name__ == "__main__":
    unittest.main()

FILE: ./microservices/tests/test_registration_service.py
import unittest
from unittest.mock import patch, AsyncMock
from command_service.services.registration_service import RegistrationService
from command_service.config.config import Settings
from command_service.services.logger import CustomLogger
import logging
import asyncio
import httpx
from fastapi import HTTPException

class TestRegistrationService(unittest.TestCase):
    def setUp(self):
        config_data = {
            "proxy_url": "http://localhost:8010/register",
            "host": "0.0.0.0",
            "port": 8003,
            "service_name": "execute-bash",
            "logging_level": "INFO",
            "logging_format": "{asctime} {message}",
            "logging_sinks": ["console"],
            "elastic_url": "http://localhost:9200/logs"
        }
        self.settings = Settings(**config_data)
        self.logger = CustomLogger(self.settings)

    @patch("httpx.AsyncClient.post", new_callable=AsyncMock)
    @patch.object(CustomLogger, "log")
    def test_register_service_success(self, mock_log, mock_post):
        mock_post.return_value.status_code = 200

        registration_service = RegistrationService(self.settings, self.logger)
        result = asyncio.run(registration_service.register_service())

        self.assertIsNone(result)
        mock_post.assert_called_once_with(self.settings.proxy_url, json={
            "service_name": self.settings.service_name,
            "url": f"http://{self.settings.host}:{self.settings.port}"
        })

    @patch("httpx.AsyncClient.post", new_callable=AsyncMock)
    @patch.object(CustomLogger, "log")
    def test_register_service_failure(self, mock_log, mock_post):
        mock_post.side_effect = httpx.RequestError("Failed to register service with proxy", request=object())

        registration_service = RegistrationService(self.settings, self.logger)

        with self.assertRaises(HTTPException):
            asyncio.run(registration_service.register_service())

        mock_post.assert_called_once_with(self.settings.proxy_url, json={
FILE: ./microservices/__init__.py
FILE: ./proxy_service/proxy.py
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Body
from pydantic import BaseModel, Field
from typing import Any, Optional
import requests
import asyncio
import yaml
from fastapi.openapi.utils import get_openapi
import logging
from contextlib import asynccontextmanager

logging.basicConfig(level=logging.INFO)

app = FastAPI(
    title="Proxy Service API",
    description="API for the Proxy Service to forward requests to registered services",
    version="1.0.0",
)

class Envelope(BaseModel):
    endpoint_service_name: str = Field(..., description="Name of the service to forward the request to")
    endpoint_path: str = Field(..., description="Path of the service endpoint")
    endpoint_request_type: str = Field(..., description="HTTP method of the request (GET, POST, etc.)")
    endpoint_headers: Any = Field(default={}, description="Headers to include in the forwarded request")
    endpoint_params: Any = Field(default={}, description="Query parameters to include in the forwarded request")
    endpoint_body: Any = Field(default={}, description="Body of the forwarded request")
    connection_id: Optional[str] = Field(None, description="Connection ID for WebSocket listener")
    endpoint_url: str = Field(..., description="URL of the service to register")

class RegisterRequest(BaseModel):
    service_name: str = Field(..., description="Name of the service to register")
    url: str = Field(..., description="URL of the service to register")

websocket_clients = {}
service_registry = {}

def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        openapi_version=app.openapi_version,
        description=app.description,
        routes=app.routes,
    )
    openapi_schema["servers"] = [
        {"url": "https://katydid-glorious-slightly.ngrok-free.app"}
    ]
    app.openapi_schema = openapi_schema
    return app.openapi_schema
FILE: ./scripts/register_services.py
import requests

# Replace with the actual IPs of your deployed services
proxy_service_ip = "PROXY_SERVICE_IP"
command_service_ip = "COMMAND_SERVICE_IP"
websocket_listener_service_ip = "WEBSOCKET_LISTENER_SERVICE_IP"

# URLs for registration
register_url = f"http://{proxy_service_ip}:8000/register"

# Service data
services = [
    {
        "service_name": "command-service",
        "openapi_url": f"http://{command_service_ip}:8001/openapi.json"
    },
    {
        "service_name": "websocket-listener-service",
        "openapi_url": f"http://{websocket_listener_service_ip}:8002/openapi.json"
    }
]

# Register each service
for service_data in services:
    response = requests.post(register_url, json=service_data)
    print(f"Registering {service_data[service_name]}: {response.json()}")
FILE: ./venv/common.py
import logging
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from pydantic import BaseModel, Field
from typing import Dict, Any
from fastapi.openapi.utils import get_openapi
import yaml

# Setup logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

class Envelope(BaseModel):
    service_name: str = Field(..., description="Name of the service to forward the request to")
    request_type: str = Field(..., description="HTTP method of the request (GET, POST, etc.)")
    headers: Dict[str, str] = Field(default={}, description="Headers to include in the forwarded request")
    params: Dict[str, Any] = Field(default={}, description="Query parameters to include in the forwarded request")
    body: Dict[str, Any] = Field(default={}, description="Body of the forwarded request")

class RegisterRequest(BaseModel):
    service_name: str = Field(..., description="Name of the service to register")
    url: str = Field(..., description="URL of the service to register")

class DeregisterRequest(BaseModel):
    service_name: str = Field(..., description="Name of the service to deregister")

def custom_openapi(app: FastAPI):
    if app.openapi_schema:
        return app.openapi_schema
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        openapi_version=app.openapi_version,
        description=app.description,
        routes=app.routes,
    )
    openapi_schema["servers"] = [
        {"url": "https://katydid-glorious-slightly.ngrok-free.app"}
    ]
    app.openapi_schema = openapi_schema
    return app.openapi_schema

def suppress_ping_pong_logs():
    class PingPongFilter(logging.Filter):
        def filter(self, record):
            if "ping" in record.getMessage() or "pong" in record.getMessage():
                return False
            return True

    logging.getLogger('websockets.protocol').addFilter(PingPongFilter())
FILE: ./venv/Lib/site-packages/pip/_internal/build_env.py
"""Build Environment used for isolation during sdist building
"""

import contextlib
import logging
import os
import pathlib
import sys
import textwrap
import zipfile
from collections import OrderedDict
from sysconfig import get_paths
from types import TracebackType
from typing import TYPE_CHECKING, Iterable, Iterator, List, Optional, Set, Tuple, Type

from pip._vendor.certifi import where
from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.version import Version

from pip import __file__ as pip_location
from pip._internal.cli.spinners import open_spinner
from pip._internal.locations import get_platlib, get_prefixed_libs, get_purelib
from pip._internal.metadata import get_environment
from pip._internal.utils.subprocess import call_subprocess
from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds

if TYPE_CHECKING:
    from pip._internal.index.package_finder import PackageFinder

logger = logging.getLogger(__name__)


class _Prefix:
    def __init__(self, path: str) -> None:
        self.path = path
        self.setup = False
        self.bin_dir = get_paths(
            "nt" if os.name == "nt" else "posix_prefix",
            vars={"base": path, "platbase": path},
        )["scripts"]
        self.lib_dirs = get_prefixed_libs(path)


@contextlib.contextmanager
def _create_standalone_pip() -> Iterator[str]:
    """Create a "standalone pip" zip file.

    The zip file's content is identical to the currently-running pip.
    It will be used to install requirements into the build environment.
    """
FILE: ./venv/Lib/site-packages/pip/_internal/cache.py
"""Cache Management
"""

import hashlib
import json
import logging
import os
from typing import Any, Dict, List, Optional, Set

from pip._vendor.packaging.tags import Tag, interpreter_name, interpreter_version
from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.exceptions import InvalidWheelFilename
from pip._internal.models.format_control import FormatControl
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
from pip._internal.utils.urls import path_to_url

logger = logging.getLogger(__name__)


def _hash_dict(d: Dict[str, str]) -> str:
    """Return a stable sha224 of a dictionary."""
    s = json.dumps(d, sort_keys=True, separators=(",", ":"), ensure_ascii=True)
    return hashlib.sha224(s.encode("ascii")).hexdigest()


class Cache:
    """An abstract class - provides cache directories for data from links


    :param cache_dir: The root of the cache.
    :param format_control: An object of FormatControl class to limit
        binaries being read from the cache.
    :param allowed_formats: which formats of files the cache should store.
        ('binary' and 'source' are the only allowed values)
    """

    def __init__(
        self, cache_dir: str, format_control: FormatControl, allowed_formats: Set[str]
    ) -> None:
        super().__init__()
        assert not cache_dir or os.path.isabs(cache_dir)
        self.cache_dir = cache_dir or None
        self.format_control = format_control
        self.allowed_formats = allowed_formats

        _valid_formats = {"source", "binary"}
        assert self.allowed_formats.union(_valid_formats) == _valid_formats
FILE: ./venv/Lib/site-packages/pip/_internal/cli/autocompletion.py
"""Logic that powers autocompletion installed by ``pip completion``.
"""

import optparse
import os
import sys
from itertools import chain
from typing import Any, Iterable, List, Optional

from pip._internal.cli.main_parser import create_main_parser
from pip._internal.commands import commands_dict, create_command
from pip._internal.metadata import get_default_environment


def autocomplete() -> None:
    """Entry Point for completion of main and subcommand options."""
    # Don't complete if user hasn't sourced bash_completion file.
    if "PIP_AUTO_COMPLETE" not in os.environ:
        return
    cwords = os.environ["COMP_WORDS"].split()[1:]
    cword = int(os.environ["COMP_CWORD"])
    try:
        current = cwords[cword - 1]
    except IndexError:
        current = ""

    parser = create_main_parser()
    subcommands = list(commands_dict)
    options = []

    # subcommand
    subcommand_name: Optional[str] = None
    for word in cwords:
        if word in subcommands:
            subcommand_name = word
            break
    # subcommand options
    if subcommand_name is not None:
        # special case: 'help' subcommand has no options
        if subcommand_name == "help":
            sys.exit(1)
        # special case: list locally installed dists for show and uninstall
        should_list_installed = not current.startswith("-") and subcommand_name in [
            "show",
            "uninstall",
        ]
        if should_list_installed:
            env = get_default_environment()
            lc = current.lower()
            installed = [
FILE: ./venv/Lib/site-packages/pip/_internal/cli/base_command.py
"""Base Command class, and related routines"""

import functools
import logging
import logging.config
import optparse
import os
import sys
import traceback
from optparse import Values
from typing import Any, Callable, List, Optional, Tuple

from pip._internal.cli import cmdoptions
from pip._internal.cli.command_context import CommandContextMixIn
from pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter
from pip._internal.cli.status_codes import (
    ERROR,
    PREVIOUS_BUILD_DIR_ERROR,
    UNKNOWN_ERROR,
    VIRTUALENV_NOT_FOUND,
)
from pip._internal.exceptions import (
    BadCommand,
    CommandError,
    InstallationError,
    NetworkConnectionError,
    PreviousBuildDirError,
    UninstallationError,
)
from pip._internal.utils.filesystem import check_path_owner
from pip._internal.utils.logging import BrokenStdoutLoggingError, setup_logging
from pip._internal.utils.misc import get_prog, normalize_path
from pip._internal.utils.temp_dir import TempDirectoryTypeRegistry as TempDirRegistry
from pip._internal.utils.temp_dir import global_tempdir_manager, tempdir_registry
from pip._internal.utils.virtualenv import running_under_virtualenv

__all__ = ["Command"]

logger = logging.getLogger(__name__)


class Command(CommandContextMixIn):
    usage: str = ""
    ignore_require_venv: bool = False

    def __init__(self, name: str, summary: str, isolated: bool = False) -> None:
        super().__init__()

        self.name = name
        self.summary = summary
FILE: ./venv/Lib/site-packages/pip/_internal/cli/cmdoptions.py
"""
shared options and groups

The principle here is to define options once, but *not* instantiate them
globally. One reason being that options with action='append' can carry state
between parses. pip parses general options twice internally, and shouldn't
pass on state. To be consistent, all options will follow this design.
"""

# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import os
import textwrap
import warnings
from functools import partial
from optparse import SUPPRESS_HELP, Option, OptionGroup, OptionParser, Values
from textwrap import dedent
from typing import Any, Callable, Dict, Optional, Tuple

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.cli.parser import ConfigOptionParser
from pip._internal.cli.progress_bars import BAR_TYPES
from pip._internal.exceptions import CommandError
from pip._internal.locations import USER_CACHE_DIR, get_src_prefix
from pip._internal.models.format_control import FormatControl
from pip._internal.models.index import PyPI
from pip._internal.models.target_python import TargetPython
from pip._internal.utils.hashes import STRONG_HASHES
from pip._internal.utils.misc import strtobool


def raise_option_error(parser: OptionParser, option: Option, msg: str) -> None:
    """
    Raise an option parsing error using parser.error().

    Args:
      parser: an OptionParser instance.
      option: an Option instance.
      msg: the error text.
    """
    msg = f"{option} error: {msg}"
    msg = textwrap.fill(" ".join(msg.split()))
    parser.error(msg)


def make_option_group(group: Dict[str, Any], parser: ConfigOptionParser) -> OptionGroup:
    """
    Return an OptionGroup object
FILE: ./venv/Lib/site-packages/pip/_internal/cli/command_context.py
from contextlib import ExitStack, contextmanager
from typing import ContextManager, Iterator, TypeVar

_T = TypeVar("_T", covariant=True)


class CommandContextMixIn:
    def __init__(self) -> None:
        super().__init__()
        self._in_main_context = False
        self._main_context = ExitStack()

    @contextmanager
    def main_context(self) -> Iterator[None]:
        assert not self._in_main_context

        self._in_main_context = True
        try:
            with self._main_context:
                yield
        finally:
            self._in_main_context = False

    def enter_context(self, context_provider: ContextManager[_T]) -> _T:
        assert self._in_main_context

        return self._main_context.enter_context(context_provider)
FILE: ./venv/Lib/site-packages/pip/_internal/cli/main.py
"""Primary application entrypoint.
"""
import locale
import logging
import os
import sys
from typing import List, Optional

from pip._internal.cli.autocompletion import autocomplete
from pip._internal.cli.main_parser import parse_command
from pip._internal.commands import create_command
from pip._internal.exceptions import PipError
from pip._internal.utils import deprecation

logger = logging.getLogger(__name__)


# Do not import and use main() directly! Using it directly is actively
# discouraged by pip's maintainers. The name, location and behavior of
# this function is subject to change, so calling it directly is not
# portable across different pip versions.

# In addition, running pip in-process is unsupported and unsafe. This is
# elaborated in detail at
# https://pip.pypa.io/en/stable/user_guide/#using-pip-from-your-program.
# That document also provides suggestions that should work for nearly
# all users that are considering importing and using main() directly.

# However, we know that certain users will still want to invoke pip
# in-process. If you understand and accept the implications of using pip
# in an unsupported manner, the best approach is to use runpy to avoid
# depending on the exact location of this entry point.

# The following example shows how to use runpy to invoke pip in that
# case:
#
#     sys.argv = ["pip", your, args, here]
#     runpy.run_module("pip", run_name="__main__")
#
# Note that this will exit the process after running, unlike a direct
# call to main. As it is not safe to do any processing after calling
# main, this should not be an issue in practice.


def main(args: Optional[List[str]] = None) -> int:
    if args is None:
        args = sys.argv[1:]

    # Configure our deprecation warnings to be sent through loggers
    deprecation.install_warning_logger()
FILE: ./venv/Lib/site-packages/pip/_internal/cli/main_parser.py
"""A single place for constructing and exposing the main parser
"""

import os
import sys
from typing import List, Tuple

from pip._internal.cli import cmdoptions
from pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter
from pip._internal.commands import commands_dict, get_similar_commands
from pip._internal.exceptions import CommandError
from pip._internal.utils.misc import get_pip_version, get_prog

__all__ = ["create_main_parser", "parse_command"]


def create_main_parser() -> ConfigOptionParser:
    """Creates and returns the main parser for pip's CLI"""

    parser = ConfigOptionParser(
        usage="\n%prog <command> [options]",
        add_help_option=False,
        formatter=UpdatingDefaultsHelpFormatter(),
        name="global",
        prog=get_prog(),
    )
    parser.disable_interspersed_args()

    parser.version = get_pip_version()

    # add the general options
    gen_opts = cmdoptions.make_option_group(cmdoptions.general_group, parser)
    parser.add_option_group(gen_opts)

    # so the help formatter knows
    parser.main = True  # type: ignore

    # create command listing for description
    description = [""] + [
        f"{name:27} {command_info.summary}"
        for name, command_info in commands_dict.items()
    ]
    parser.description = "\n".join(description)

    return parser


def parse_command(args: List[str]) -> Tuple[str, List[str]]:
    parser = create_main_parser()

FILE: ./venv/Lib/site-packages/pip/_internal/cli/parser.py
"""Base option parser setup"""

import logging
import optparse
import shutil
import sys
import textwrap
from contextlib import suppress
from typing import Any, Dict, Iterator, List, Tuple

from pip._internal.cli.status_codes import UNKNOWN_ERROR
from pip._internal.configuration import Configuration, ConfigurationError
from pip._internal.utils.misc import redact_auth_from_url, strtobool

logger = logging.getLogger(__name__)


class PrettyHelpFormatter(optparse.IndentedHelpFormatter):
    """A prettier/less verbose help formatter for optparse."""

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        # help position must be aligned with __init__.parseopts.description
        kwargs["max_help_position"] = 30
        kwargs["indent_increment"] = 1
        kwargs["width"] = shutil.get_terminal_size()[0] - 2
        super().__init__(*args, **kwargs)

    def format_option_strings(self, option: optparse.Option) -> str:
        return self._format_option_strings(option)

    def _format_option_strings(
        self, option: optparse.Option, mvarfmt: str = " <{}>", optsep: str = ", "
    ) -> str:
        """
        Return a comma-separated list of option strings and metavars.

        :param option:  tuple of (short opt, long opt), e.g: ('-f', '--format')
        :param mvarfmt: metavar format string
        :param optsep:  separator
        """
        opts = []

        if option._short_opts:
            opts.append(option._short_opts[0])
        if option._long_opts:
            opts.append(option._long_opts[0])
        if len(opts) > 1:
            opts.insert(1, optsep)

        if option.takes_value():
FILE: ./venv/Lib/site-packages/pip/_internal/cli/progress_bars.py
import itertools
import sys
from signal import SIGINT, default_int_handler, signal
from typing import Any

from pip._vendor.progress.bar import Bar, FillingCirclesBar, IncrementalBar
from pip._vendor.progress.spinner import Spinner

from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.logging import get_indentation
from pip._internal.utils.misc import format_size

try:
    from pip._vendor import colorama
# Lots of different errors can come from this, including SystemError and
# ImportError.
except Exception:
    colorama = None


def _select_progress_class(preferred: Bar, fallback: Bar) -> Bar:
    encoding = getattr(preferred.file, "encoding", None)

    # If we don't know what encoding this file is in, then we'll just assume
    # that it doesn't support unicode and use the ASCII bar.
    if not encoding:
        return fallback

    # Collect all of the possible characters we want to use with the preferred
    # bar.
    characters = [
        getattr(preferred, "empty_fill", ""),
        getattr(preferred, "fill", ""),
    ]
    characters += list(getattr(preferred, "phases", []))

    # Try to decode the characters we're using for the bar using the encoding
    # of the given file, if this works then we'll assume that we can use the
    # fancier bar and if not we'll fall back to the plaintext bar.
    try:
        "".join(characters).encode(encoding)
    except UnicodeEncodeError:
        return fallback
    else:
        return preferred


_BaseBar: Any = _select_progress_class(IncrementalBar, Bar)


FILE: ./venv/Lib/site-packages/pip/_internal/cli/req_command.py
"""Contains the Command base classes that depend on PipSession.

The classes in this module are in a separate module so the commands not
needing download / PackageFinder capability don't unnecessarily import the
PackageFinder machinery and all its vendored dependencies, etc.
"""

import logging
import os
import sys
from functools import partial
from optparse import Values
from typing import Any, List, Optional, Tuple

from pip._internal.cache import WheelCache
from pip._internal.cli import cmdoptions
from pip._internal.cli.base_command import Command
from pip._internal.cli.command_context import CommandContextMixIn
from pip._internal.exceptions import CommandError, PreviousBuildDirError
from pip._internal.index.collector import LinkCollector
from pip._internal.index.package_finder import PackageFinder
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.models.target_python import TargetPython
from pip._internal.network.session import PipSession
from pip._internal.operations.prepare import RequirementPreparer
from pip._internal.req.constructors import (
    install_req_from_editable,
    install_req_from_line,
    install_req_from_parsed_requirement,
    install_req_from_req_string,
)
from pip._internal.req.req_file import parse_requirements
from pip._internal.req.req_install import InstallRequirement
from pip._internal.req.req_tracker import RequirementTracker
from pip._internal.resolution.base import BaseResolver
from pip._internal.self_outdated_check import pip_self_version_check
from pip._internal.utils.deprecation import deprecated
from pip._internal.utils.temp_dir import (
    TempDirectory,
    TempDirectoryTypeRegistry,
    tempdir_kinds,
)
from pip._internal.utils.virtualenv import running_under_virtualenv

logger = logging.getLogger(__name__)


class SessionCommandMixin(CommandContextMixIn):

    """
FILE: ./venv/Lib/site-packages/pip/_internal/cli/spinners.py
import contextlib
import itertools
import logging
import sys
import time
from typing import IO, Iterator

from pip._vendor.progress import HIDE_CURSOR, SHOW_CURSOR

from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.logging import get_indentation

logger = logging.getLogger(__name__)


class SpinnerInterface:
    def spin(self) -> None:
        raise NotImplementedError()

    def finish(self, final_status: str) -> None:
        raise NotImplementedError()


class InteractiveSpinner(SpinnerInterface):
    def __init__(
        self,
        message: str,
        file: IO[str] = None,
        spin_chars: str = "-\\|/",
        # Empirically, 8 updates/second looks nice
        min_update_interval_seconds: float = 0.125,
    ):
        self._message = message
        if file is None:
            file = sys.stdout
        self._file = file
        self._rate_limiter = RateLimiter(min_update_interval_seconds)
        self._finished = False

        self._spin_cycle = itertools.cycle(spin_chars)

        self._file.write(" " * get_indentation() + self._message + " ... ")
        self._width = 0

    def _write(self, status: str) -> None:
        assert not self._finished
        # Erase what we wrote before by backspacing to the beginning, writing
        # spaces to overwrite the old text, and then backspacing again
        backup = "\b" * self._width
        self._file.write(backup + " " * self._width + backup)
FILE: ./venv/Lib/site-packages/pip/_internal/cli/status_codes.py
SUCCESS = 0
ERROR = 1
UNKNOWN_ERROR = 2
VIRTUALENV_NOT_FOUND = 3
PREVIOUS_BUILD_DIR_ERROR = 4
NO_MATCHES_FOUND = 23
FILE: ./venv/Lib/site-packages/pip/_internal/cli/__init__.py
"""Subpackage containing all of pip's command line interface related code
"""

# This file intentionally does not import submodules
FILE: ./venv/Lib/site-packages/pip/_internal/commands/cache.py
import os
import textwrap
from optparse import Values
from typing import Any, List

import pip._internal.utils.filesystem as filesystem
from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.exceptions import CommandError, PipError
from pip._internal.utils.logging import getLogger

logger = getLogger(__name__)


class CacheCommand(Command):
    """
    Inspect and manage pip's wheel cache.

    Subcommands:

    - dir: Show the cache directory.
    - info: Show information about the cache.
    - list: List filenames of packages stored in the cache.
    - remove: Remove one or more package from the cache.
    - purge: Remove all items from the cache.

    ``<pattern>`` can be a glob expression or a package name.
    """

    ignore_require_venv = True
    usage = """
        %prog dir
        %prog info
        %prog list [<pattern>] [--format=[human, abspath]]
        %prog remove <pattern>
        %prog purge
    """

    def add_options(self) -> None:

        self.cmd_opts.add_option(
            "--format",
            action="store",
            dest="list_format",
            default="human",
            choices=("human", "abspath"),
            help="Select the output format among: human (default) or abspath",
        )

        self.parser.insert_option_group(0, self.cmd_opts)
FILE: ./venv/Lib/site-packages/pip/_internal/commands/check.py
import logging
from optparse import Values
from typing import List

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.operations.check import (
    check_package_set,
    create_package_set_from_installed,
)
from pip._internal.utils.misc import write_output

logger = logging.getLogger(__name__)


class CheckCommand(Command):
    """Verify installed packages have compatible dependencies."""

    usage = """
      %prog [options]"""

    def run(self, options: Values, args: List[str]) -> int:

        package_set, parsing_probs = create_package_set_from_installed()
        missing, conflicting = check_package_set(package_set)

        for project_name in missing:
            version = package_set[project_name].version
            for dependency in missing[project_name]:
                write_output(
                    "%s %s requires %s, which is not installed.",
                    project_name,
                    version,
                    dependency[0],
                )

        for project_name in conflicting:
            version = package_set[project_name].version
            for dep_name, dep_version, req in conflicting[project_name]:
                write_output(
                    "%s %s has requirement %s, but you have %s %s.",
                    project_name,
                    version,
                    req,
                    dep_name,
                    dep_version,
                )

        if missing or conflicting or parsing_probs:
            return ERROR
FILE: ./venv/Lib/site-packages/pip/_internal/commands/completion.py
import sys
import textwrap
from optparse import Values
from typing import List

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.utils.misc import get_prog

BASE_COMPLETION = """
# pip {shell} completion start{script}# pip {shell} completion end
"""

COMPLETION_SCRIPTS = {
    "bash": """
        _pip_completion()
        {{
            COMPREPLY=( $( COMP_WORDS="${{COMP_WORDS[*]}}" \\
                           COMP_CWORD=$COMP_CWORD \\
                           PIP_AUTO_COMPLETE=1 $1 2>/dev/null ) )
        }}
        complete -o default -F _pip_completion {prog}
    """,
    "zsh": """
        function _pip_completion {{
          local words cword
          read -Ac words
          read -cn cword
          reply=( $( COMP_WORDS="$words[*]" \\
                     COMP_CWORD=$(( cword-1 )) \\
                     PIP_AUTO_COMPLETE=1 $words[1] 2>/dev/null ))
        }}
        compctl -K _pip_completion {prog}
    """,
    "fish": """
        function __fish_complete_pip
            set -lx COMP_WORDS (commandline -o) ""
            set -lx COMP_CWORD ( \\
                math (contains -i -- (commandline -t) $COMP_WORDS)-1 \\
            )
            set -lx PIP_AUTO_COMPLETE 1
            string split \\  -- (eval $COMP_WORDS[1])
        end
        complete -fa "(__fish_complete_pip)" -c {prog}
    """,
}


class CompletionCommand(Command):
    """A helper command to be used for command completion."""
FILE: ./venv/Lib/site-packages/pip/_internal/commands/configuration.py
import logging
import os
import subprocess
from optparse import Values
from typing import Any, List, Optional

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.configuration import (
    Configuration,
    Kind,
    get_configuration_files,
    kinds,
)
from pip._internal.exceptions import PipError
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import get_prog, write_output

logger = logging.getLogger(__name__)


class ConfigurationCommand(Command):
    """
    Manage local and global configuration.

    Subcommands:

    - list: List the active configuration (or from the file specified)
    - edit: Edit the configuration file in an editor
    - get: Get the value associated with name
    - set: Set the name=value
    - unset: Unset the value associated with name
    - debug: List the configuration files and values defined under them

    If none of --user, --global and --site are passed, a virtual
    environment configuration file is used if one is active and the file
    exists. Otherwise, all modifications happen to the user file by
    default.
    """

    ignore_require_venv = True
    usage = """
        %prog [<file-option>] list
        %prog [<file-option>] [--editor <editor-path>] edit

        %prog [<file-option>] get name
        %prog [<file-option>] set name value
        %prog [<file-option>] unset name
        %prog [<file-option>] debug
    """
FILE: ./venv/Lib/site-packages/pip/_internal/commands/debug.py
import locale
import logging
import os
import sys
from optparse import Values
from types import ModuleType
from typing import Any, Dict, List, Optional

import pip._vendor
from pip._vendor.certifi import where
from pip._vendor.packaging.version import parse as parse_version

from pip import __file__ as pip_location
from pip._internal.cli import cmdoptions
from pip._internal.cli.base_command import Command
from pip._internal.cli.cmdoptions import make_target_python
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.configuration import Configuration
from pip._internal.metadata import get_environment
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import get_pip_version

logger = logging.getLogger(__name__)


def show_value(name: str, value: Any) -> None:
    logger.info("%s: %s", name, value)


def show_sys_implementation() -> None:
    logger.info("sys.implementation:")
    implementation_name = sys.implementation.name
    with indent_log():
        show_value("name", implementation_name)


def create_vendor_txt_map() -> Dict[str, str]:
    vendor_txt_path = os.path.join(
        os.path.dirname(pip_location), "_vendor", "vendor.txt"
    )

    with open(vendor_txt_path) as f:
        # Purge non version specifying lines.
        # Also, remove any space prefix or suffixes (including comments).
        lines = [
            line.strip().split(" ", 1)[0] for line in f.readlines() if "==" in line
        ]

    # Transform into "module" -> version dict.
    return dict(line.split("==", 1) for line in lines)  # type: ignore
FILE: ./venv/Lib/site-packages/pip/_internal/commands/download.py
import logging
import os
from optparse import Values
from typing import List

from pip._internal.cli import cmdoptions
from pip._internal.cli.cmdoptions import make_target_python
from pip._internal.cli.req_command import RequirementCommand, with_cleanup
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.req.req_tracker import get_requirement_tracker
from pip._internal.utils.misc import ensure_dir, normalize_path, write_output
from pip._internal.utils.temp_dir import TempDirectory

logger = logging.getLogger(__name__)


class DownloadCommand(RequirementCommand):
    """
    Download packages from:

    - PyPI (and other indexes) using requirement specifiers.
    - VCS project urls.
    - Local project directories.
    - Local or remote source archives.

    pip also supports downloading from "requirements files", which provide
    an easy way to specify a whole environment to be downloaded.
    """

    usage = """
      %prog [options] <requirement specifier> [package-index-options] ...
      %prog [options] -r <requirements file> [package-index-options] ...
      %prog [options] <vcs project url> ...
      %prog [options] <local project path> ...
      %prog [options] <archive url/path> ..."""

    def add_options(self) -> None:
        self.cmd_opts.add_option(cmdoptions.constraints())
        self.cmd_opts.add_option(cmdoptions.requirements())
        self.cmd_opts.add_option(cmdoptions.no_deps())
        self.cmd_opts.add_option(cmdoptions.global_options())
        self.cmd_opts.add_option(cmdoptions.no_binary())
        self.cmd_opts.add_option(cmdoptions.only_binary())
        self.cmd_opts.add_option(cmdoptions.prefer_binary())
        self.cmd_opts.add_option(cmdoptions.src())
        self.cmd_opts.add_option(cmdoptions.pre())
        self.cmd_opts.add_option(cmdoptions.require_hashes())
        self.cmd_opts.add_option(cmdoptions.progress_bar())
        self.cmd_opts.add_option(cmdoptions.no_build_isolation())
        self.cmd_opts.add_option(cmdoptions.use_pep517())
FILE: ./venv/Lib/site-packages/pip/_internal/commands/freeze.py
import sys
from optparse import Values
from typing import List

from pip._internal.cli import cmdoptions
from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.operations.freeze import freeze
from pip._internal.utils.compat import stdlib_pkgs

DEV_PKGS = {"pip", "setuptools", "distribute", "wheel"}


class FreezeCommand(Command):
    """
    Output installed packages in requirements format.

    packages are listed in a case-insensitive sorted order.
    """

    usage = """
      %prog [options]"""
    log_streams = ("ext://sys.stderr", "ext://sys.stderr")

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            "-r",
            "--requirement",
            dest="requirements",
            action="append",
            default=[],
            metavar="file",
            help=(
                "Use the order in the given requirements file and its "
                "comments when generating output. This option can be "
                "used multiple times."
            ),
        )
        self.cmd_opts.add_option(
            "-l",
            "--local",
            dest="local",
            action="store_true",
            default=False,
            help=(
                "If in a virtualenv that has global access, do not output "
                "globally-installed packages."
            ),
        )
        self.cmd_opts.add_option(
FILE: ./venv/Lib/site-packages/pip/_internal/commands/hash.py
import hashlib
import logging
import sys
from optparse import Values
from typing import List

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.utils.hashes import FAVORITE_HASH, STRONG_HASHES
from pip._internal.utils.misc import read_chunks, write_output

logger = logging.getLogger(__name__)


class HashCommand(Command):
    """
    Compute a hash of a local package archive.

    These can be used with --hash in a requirements file to do repeatable
    installs.
    """

    usage = "%prog [options] <file> ..."
    ignore_require_venv = True

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            "-a",
            "--algorithm",
            dest="algorithm",
            choices=STRONG_HASHES,
            action="store",
            default=FAVORITE_HASH,
            help="The hash algorithm to use: one of {}".format(
                ", ".join(STRONG_HASHES)
            ),
        )
        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: List[str]) -> int:
        if not args:
            self.parser.print_usage(sys.stderr)
            return ERROR

        algorithm = options.algorithm
        for path in args:
            write_output(
                "%s:\n--hash=%s:%s", path, algorithm, _hash_of_file(path, algorithm)
            )
        return SUCCESS
FILE: ./venv/Lib/site-packages/pip/_internal/commands/help.py
from optparse import Values
from typing import List

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.exceptions import CommandError


class HelpCommand(Command):
    """Show help for commands"""

    usage = """
      %prog <command>"""
    ignore_require_venv = True

    def run(self, options: Values, args: List[str]) -> int:
        from pip._internal.commands import (
            commands_dict,
            create_command,
            get_similar_commands,
        )

        try:
            # 'pip help' with no args is handled by pip.__init__.parseopt()
            cmd_name = args[0]  # the command we need help for
        except IndexError:
            return SUCCESS

        if cmd_name not in commands_dict:
            guess = get_similar_commands(cmd_name)

            msg = [f'unknown command "{cmd_name}"']
            if guess:
                msg.append(f'maybe you meant "{guess}"')

            raise CommandError(" - ".join(msg))

        command = create_command(cmd_name)
        command.parser.print_help()

        return SUCCESS
FILE: ./venv/Lib/site-packages/pip/_internal/commands/index.py
import logging
from optparse import Values
from typing import Any, Iterable, List, Optional, Union

from pip._vendor.packaging.version import LegacyVersion, Version

from pip._internal.cli import cmdoptions
from pip._internal.cli.req_command import IndexGroupCommand
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.commands.search import print_dist_installation_info
from pip._internal.exceptions import CommandError, DistributionNotFound, PipError
from pip._internal.index.collector import LinkCollector
from pip._internal.index.package_finder import PackageFinder
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.models.target_python import TargetPython
from pip._internal.network.session import PipSession
from pip._internal.utils.misc import write_output

logger = logging.getLogger(__name__)


class IndexCommand(IndexGroupCommand):
    """
    Inspect information available from package indexes.
    """

    usage = """
        %prog versions <package>
    """

    def add_options(self) -> None:
        cmdoptions.add_target_python_options(self.cmd_opts)

        self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
        self.cmd_opts.add_option(cmdoptions.pre())
        self.cmd_opts.add_option(cmdoptions.no_binary())
        self.cmd_opts.add_option(cmdoptions.only_binary())

        index_opts = cmdoptions.make_option_group(
            cmdoptions.index_group,
            self.parser,
        )

        self.parser.insert_option_group(0, index_opts)
        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: List[str]) -> int:
        handlers = {
            "versions": self.get_available_package_versions,
        }
FILE: ./venv/Lib/site-packages/pip/_internal/commands/install.py
import errno
import operator
import os
import shutil
import site
from optparse import SUPPRESS_HELP, Values
from typing import Iterable, List, Optional

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.cache import WheelCache
from pip._internal.cli import cmdoptions
from pip._internal.cli.cmdoptions import make_target_python
from pip._internal.cli.req_command import (
    RequirementCommand,
    warn_if_run_as_root,
    with_cleanup,
)
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.exceptions import CommandError, InstallationError
from pip._internal.locations import get_scheme
from pip._internal.metadata import get_environment
from pip._internal.models.format_control import FormatControl
from pip._internal.operations.check import ConflictDetails, check_install_conflicts
from pip._internal.req import install_given_reqs
from pip._internal.req.req_install import InstallRequirement
from pip._internal.req.req_tracker import get_requirement_tracker
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.distutils_args import parse_distutils_args
from pip._internal.utils.filesystem import test_writable_dir
from pip._internal.utils.logging import getLogger
from pip._internal.utils.misc import (
    ensure_dir,
    get_pip_version,
    protect_pip_from_modification_on_windows,
    write_output,
)
from pip._internal.utils.temp_dir import TempDirectory
from pip._internal.utils.virtualenv import (
    running_under_virtualenv,
    virtualenv_no_global,
)
from pip._internal.wheel_builder import (
    BinaryAllowedPredicate,
    build,
    should_build_for_install_command,
)

logger = getLogger(__name__)

FILE: ./venv/Lib/site-packages/pip/_internal/commands/list.py
import json
import logging
from optparse import Values
from typing import TYPE_CHECKING, Iterator, List, Optional, Sequence, Tuple, cast

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.cli import cmdoptions
from pip._internal.cli.req_command import IndexGroupCommand
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.exceptions import CommandError
from pip._internal.index.collector import LinkCollector
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution, get_environment
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.network.session import PipSession
from pip._internal.utils.compat import stdlib_pkgs
from pip._internal.utils.misc import tabulate, write_output
from pip._internal.utils.parallel import map_multithread

if TYPE_CHECKING:
    from pip._internal.metadata.base import DistributionVersion

    class _DistWithLatestInfo(BaseDistribution):
        """Give the distribution object a couple of extra fields.

        These will be populated during ``get_outdated()``. This is dirty but
        makes the rest of the code much cleaner.
        """

        latest_version: DistributionVersion
        latest_filetype: str

    _ProcessedDists = Sequence[_DistWithLatestInfo]


logger = logging.getLogger(__name__)


class ListCommand(IndexGroupCommand):
    """
    List installed packages, including editables.

    Packages are listed in a case-insensitive sorted order.
    """

    ignore_require_venv = True
    usage = """
      %prog [options]"""

FILE: ./venv/Lib/site-packages/pip/_internal/commands/search.py
import logging
import shutil
import sys
import textwrap
import xmlrpc.client
from collections import OrderedDict
from optparse import Values
from typing import TYPE_CHECKING, Dict, List, Optional

from pip._vendor.packaging.version import parse as parse_version

from pip._internal.cli.base_command import Command
from pip._internal.cli.req_command import SessionCommandMixin
from pip._internal.cli.status_codes import NO_MATCHES_FOUND, SUCCESS
from pip._internal.exceptions import CommandError
from pip._internal.metadata import get_default_environment
from pip._internal.models.index import PyPI
from pip._internal.network.xmlrpc import PipXmlrpcTransport
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import write_output

if TYPE_CHECKING:
    from typing import TypedDict

    class TransformedHit(TypedDict):
        name: str
        summary: str
        versions: List[str]


logger = logging.getLogger(__name__)


class SearchCommand(Command, SessionCommandMixin):
    """Search for PyPI packages whose name or summary contains <query>."""

    usage = """
      %prog [options] <query>"""
    ignore_require_venv = True

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            "-i",
            "--index",
            dest="index",
            metavar="URL",
            default=PyPI.pypi_url,
            help="Base URL of Python Package Index (default %default)",
        )

FILE: ./venv/Lib/site-packages/pip/_internal/commands/show.py
import csv
import logging
import pathlib
from optparse import Values
from typing import Iterator, List, NamedTuple, Optional, Tuple

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.cli.base_command import Command
from pip._internal.cli.status_codes import ERROR, SUCCESS
from pip._internal.metadata import BaseDistribution, get_default_environment
from pip._internal.utils.misc import write_output

logger = logging.getLogger(__name__)


class ShowCommand(Command):
    """
    Show information about one or more installed packages.

    The output is in RFC-compliant mail header format.
    """

    usage = """
      %prog [options] <package> ..."""
    ignore_require_venv = True

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            "-f",
            "--files",
            dest="files",
            action="store_true",
            default=False,
            help="Show the full list of installed files for each package.",
        )

        self.parser.insert_option_group(0, self.cmd_opts)

    def run(self, options: Values, args: List[str]) -> int:
        if not args:
            logger.warning("ERROR: Please provide a package name or names.")
            return ERROR
        query = args

        results = search_packages_info(query)
        if not print_results(
            results, list_files=options.files, verbose=options.verbose
        ):
            return ERROR
FILE: ./venv/Lib/site-packages/pip/_internal/commands/uninstall.py
import logging
from optparse import Values
from typing import List

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.cli.base_command import Command
from pip._internal.cli.req_command import SessionCommandMixin, warn_if_run_as_root
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.exceptions import InstallationError
from pip._internal.req import parse_requirements
from pip._internal.req.constructors import (
    install_req_from_line,
    install_req_from_parsed_requirement,
)
from pip._internal.utils.misc import protect_pip_from_modification_on_windows

logger = logging.getLogger(__name__)


class UninstallCommand(Command, SessionCommandMixin):
    """
    Uninstall packages.

    pip is able to uninstall most installed packages. Known exceptions are:

    - Pure distutils packages installed with ``python setup.py install``, which
      leave behind no metadata to determine what files were installed.
    - Script wrappers installed by ``python setup.py develop``.
    """

    usage = """
      %prog [options] <package> ...
      %prog [options] -r <requirements file> ..."""

    def add_options(self) -> None:
        self.cmd_opts.add_option(
            "-r",
            "--requirement",
            dest="requirements",
            action="append",
            default=[],
            metavar="file",
            help=(
                "Uninstall all the packages listed in the given requirements "
                "file.  This option can be used multiple times."
            ),
        )
        self.cmd_opts.add_option(
            "-y",
FILE: ./venv/Lib/site-packages/pip/_internal/commands/wheel.py
import logging
import os
import shutil
from optparse import Values
from typing import List

from pip._internal.cache import WheelCache
from pip._internal.cli import cmdoptions
from pip._internal.cli.req_command import RequirementCommand, with_cleanup
from pip._internal.cli.status_codes import SUCCESS
from pip._internal.exceptions import CommandError
from pip._internal.req.req_install import InstallRequirement
from pip._internal.req.req_tracker import get_requirement_tracker
from pip._internal.utils.misc import ensure_dir, normalize_path
from pip._internal.utils.temp_dir import TempDirectory
from pip._internal.wheel_builder import build, should_build_for_wheel_command

logger = logging.getLogger(__name__)


class WheelCommand(RequirementCommand):
    """
    Build Wheel archives for your requirements and dependencies.

    Wheel is a built-package format, and offers the advantage of not
    recompiling your software during every install. For more details, see the
    wheel docs: https://wheel.readthedocs.io/en/latest/

    Requirements: setuptools>=0.8, and wheel.

    'pip wheel' uses the bdist_wheel setuptools extension from the wheel
    package to build individual wheels.

    """

    usage = """
      %prog [options] <requirement specifier> ...
      %prog [options] -r <requirements file> ...
      %prog [options] [-e] <vcs project url> ...
      %prog [options] [-e] <local project path> ...
      %prog [options] <archive url/path> ..."""

    def add_options(self) -> None:

        self.cmd_opts.add_option(
            "-w",
            "--wheel-dir",
            dest="wheel_dir",
            metavar="dir",
            default=os.curdir,
FILE: ./venv/Lib/site-packages/pip/_internal/commands/__init__.py
"""
Package containing all pip commands
"""

import importlib
from collections import namedtuple
from typing import Any, Dict, Optional

from pip._internal.cli.base_command import Command

CommandInfo = namedtuple("CommandInfo", "module_path, class_name, summary")

# This dictionary does a bunch of heavy lifting for help output:
# - Enables avoiding additional (costly) imports for presenting `--help`.
# - The ordering matters for help display.
#
# Even though the module path starts with the same "pip._internal.commands"
# prefix, the full path makes testing easier (specifically when modifying
# `commands_dict` in test setup / teardown).
commands_dict: Dict[str, CommandInfo] = {
    "install": CommandInfo(
        "pip._internal.commands.install",
        "InstallCommand",
        "Install packages.",
    ),
    "download": CommandInfo(
        "pip._internal.commands.download",
        "DownloadCommand",
        "Download packages.",
    ),
    "uninstall": CommandInfo(
        "pip._internal.commands.uninstall",
        "UninstallCommand",
        "Uninstall packages.",
    ),
    "freeze": CommandInfo(
        "pip._internal.commands.freeze",
        "FreezeCommand",
        "Output installed packages in requirements format.",
    ),
    "list": CommandInfo(
        "pip._internal.commands.list",
        "ListCommand",
        "List installed packages.",
    ),
    "show": CommandInfo(
        "pip._internal.commands.show",
        "ShowCommand",
        "Show information about installed packages.",
    ),
FILE: ./venv/Lib/site-packages/pip/_internal/configuration.py
"""Configuration management setup

Some terminology:
- name
  As written in config files.
- value
  Value associated with a name
- key
  Name combined with it's section (section.name)
- variant
  A single word describing where the configuration key-value pair came from
"""

import configparser
import locale
import os
import sys
from typing import Any, Dict, Iterable, List, NewType, Optional, Tuple

from pip._internal.exceptions import (
    ConfigurationError,
    ConfigurationFileCouldNotBeLoaded,
)
from pip._internal.utils import appdirs
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.logging import getLogger
from pip._internal.utils.misc import ensure_dir, enum

RawConfigParser = configparser.RawConfigParser  # Shorthand
Kind = NewType("Kind", str)

CONFIG_BASENAME = "pip.ini" if WINDOWS else "pip.conf"
ENV_NAMES_IGNORED = "version", "help"

# The kinds of configurations there are.
kinds = enum(
    USER="user",  # User Specific
    GLOBAL="global",  # System Wide
    SITE="site",  # [Virtual] Environment Specific
    ENV="env",  # from PIP_CONFIG_FILE
    ENV_VAR="env-var",  # from Environment Variables
)
OVERRIDE_ORDER = kinds.GLOBAL, kinds.USER, kinds.SITE, kinds.ENV, kinds.ENV_VAR
VALID_LOAD_ONLY = kinds.USER, kinds.GLOBAL, kinds.SITE

logger = getLogger(__name__)


# NOTE: Maybe use the optionx attribute to normalize keynames.
def _normalize_name(name: str) -> str:
FILE: ./venv/Lib/site-packages/pip/_internal/distributions/base.py
import abc

from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata.base import BaseDistribution
from pip._internal.req import InstallRequirement


class AbstractDistribution(metaclass=abc.ABCMeta):
    """A base class for handling installable artifacts.

    The requirements for anything installable are as follows:

     - we must be able to determine the requirement name
       (or we can't correctly handle the non-upgrade case).

     - for packages with setup requirements, we must also be able
       to determine their requirements without installing additional
       packages (for the same reason as run-time dependencies)

     - we must be able to create a Distribution object exposing the
       above metadata.
    """

    def __init__(self, req: InstallRequirement) -> None:
        super().__init__()
        self.req = req

    @abc.abstractmethod
    def get_metadata_distribution(self) -> BaseDistribution:
        raise NotImplementedError()

    @abc.abstractmethod
    def prepare_distribution_metadata(
        self, finder: PackageFinder, build_isolation: bool
    ) -> None:
        raise NotImplementedError()
FILE: ./venv/Lib/site-packages/pip/_internal/distributions/installed.py
from pip._internal.distributions.base import AbstractDistribution
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution


class InstalledDistribution(AbstractDistribution):
    """Represents an installed package.

    This does not need any preparation as the required information has already
    been computed.
    """

    def get_metadata_distribution(self) -> BaseDistribution:
        from pip._internal.metadata.pkg_resources import Distribution as _Dist

        assert self.req.satisfied_by is not None, "not actually installed"
        return _Dist(self.req.satisfied_by)

    def prepare_distribution_metadata(
        self, finder: PackageFinder, build_isolation: bool
    ) -> None:
        pass
FILE: ./venv/Lib/site-packages/pip/_internal/distributions/sdist.py
import logging
from typing import Iterable, Set, Tuple

from pip._internal.build_env import BuildEnvironment
from pip._internal.distributions.base import AbstractDistribution
from pip._internal.exceptions import InstallationError
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution
from pip._internal.utils.subprocess import runner_with_spinner_message

logger = logging.getLogger(__name__)


class SourceDistribution(AbstractDistribution):
    """Represents a source distribution.

    The preparation step for these needs metadata for the packages to be
    generated, either using PEP 517 or using the legacy `setup.py egg_info`.
    """

    def get_metadata_distribution(self) -> BaseDistribution:
        from pip._internal.metadata.pkg_resources import Distribution as _Dist

        return _Dist(self.req.get_dist())

    def prepare_distribution_metadata(
        self, finder: PackageFinder, build_isolation: bool
    ) -> None:
        # Load pyproject.toml, to determine whether PEP 517 is to be used
        self.req.load_pyproject_toml()

        # Set up the build isolation, if this requirement should be isolated
        should_isolate = self.req.use_pep517 and build_isolation
        if should_isolate:
            # Setup an isolated environment and install the build backend static
            # requirements in it.
            self._prepare_build_backend(finder)
            # Check that if the requirement is editable, it either supports PEP 660 or
            # has a setup.py or a setup.cfg. This cannot be done earlier because we need
            # to setup the build backend to verify it supports build_editable, nor can
            # it be done later, because we want to avoid installing build requirements
            # needlessly. Doing it here also works around setuptools generating
            # UNKNOWN.egg-info when running get_requires_for_build_wheel on a directory
            # without setup.py nor setup.cfg.
            self.req.isolated_editable_sanity_check()
            # Install the dynamic build requirements.
            self._install_build_reqs(finder)

        self.req.prepare_metadata()

FILE: ./venv/Lib/site-packages/pip/_internal/distributions/wheel.py
from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.distributions.base import AbstractDistribution
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import (
    BaseDistribution,
    FilesystemWheel,
    get_wheel_distribution,
)


class WheelDistribution(AbstractDistribution):
    """Represents a wheel distribution.

    This does not need any preparation as wheels can be directly unpacked.
    """

    def get_metadata_distribution(self) -> BaseDistribution:
        """Loads the metadata from the wheel file into memory and returns a
        Distribution that uses it, not relying on the wheel file or
        requirement.
        """
        assert self.req.local_file_path, "Set as part of preparation during download"
        assert self.req.name, "Wheels are never unnamed"
        wheel = FilesystemWheel(self.req.local_file_path)
        return get_wheel_distribution(wheel, canonicalize_name(self.req.name))

    def prepare_distribution_metadata(
        self, finder: PackageFinder, build_isolation: bool
    ) -> None:
        pass
FILE: ./venv/Lib/site-packages/pip/_internal/distributions/__init__.py
from pip._internal.distributions.base import AbstractDistribution
from pip._internal.distributions.sdist import SourceDistribution
from pip._internal.distributions.wheel import WheelDistribution
from pip._internal.req.req_install import InstallRequirement


def make_distribution_for_install_requirement(
    install_req: InstallRequirement,
) -> AbstractDistribution:
    """Returns a Distribution for the given InstallRequirement"""
    # Editable requirements will always be source distributions. They use the
    # legacy logic until we create a modern standard for them.
    if install_req.editable:
        return SourceDistribution(install_req)

    # If it's a wheel, it's a WheelDistribution
    if install_req.is_wheel:
        return WheelDistribution(install_req)

    # Otherwise, a SourceDistribution
    return SourceDistribution(install_req)
FILE: ./venv/Lib/site-packages/pip/_internal/exceptions.py
"""Exceptions used throughout package"""

import configparser
from itertools import chain, groupby, repeat
from typing import TYPE_CHECKING, Dict, List, Optional, Union

from pip._vendor.pkg_resources import Distribution
from pip._vendor.requests.models import Request, Response

if TYPE_CHECKING:
    from hashlib import _Hash

    from pip._internal.metadata import BaseDistribution
    from pip._internal.req.req_install import InstallRequirement


class PipError(Exception):
    """Base pip exception"""


class ConfigurationError(PipError):
    """General exception in configuration"""


class InstallationError(PipError):
    """General exception during installation"""


class UninstallationError(PipError):
    """General exception during uninstallation"""


class NoneMetadataError(PipError):
    """
    Raised when accessing "METADATA" or "PKG-INFO" metadata for a
    pip._vendor.pkg_resources.Distribution object and
    `dist.has_metadata('METADATA')` returns True but
    `dist.get_metadata('METADATA')` returns None (and similarly for
    "PKG-INFO").
    """

    def __init__(
        self,
        dist: Union[Distribution, "BaseDistribution"],
        metadata_name: str,
    ) -> None:
        """
        :param dist: A Distribution object.
        :param metadata_name: The name of the metadata being accessed
            (can be "METADATA" or "PKG-INFO").
FILE: ./venv/Lib/site-packages/pip/_internal/index/collector.py
"""
The main purpose of this module is to expose LinkCollector.collect_sources().
"""

import cgi
import collections
import functools
import itertools
import logging
import os
import re
import urllib.parse
import urllib.request
import xml.etree.ElementTree
from optparse import Values
from typing import (
    Callable,
    Iterable,
    List,
    MutableMapping,
    NamedTuple,
    Optional,
    Sequence,
    Union,
)

from pip._vendor import html5lib, requests
from pip._vendor.requests import Response
from pip._vendor.requests.exceptions import RetryError, SSLError

from pip._internal.exceptions import NetworkConnectionError
from pip._internal.models.link import Link
from pip._internal.models.search_scope import SearchScope
from pip._internal.network.session import PipSession
from pip._internal.network.utils import raise_for_status
from pip._internal.utils.filetypes import is_archive_file
from pip._internal.utils.misc import pairwise, redact_auth_from_url
from pip._internal.vcs import vcs

from .sources import CandidatesFromPage, LinkSource, build_source

logger = logging.getLogger(__name__)

HTMLElement = xml.etree.ElementTree.Element
ResponseHeaders = MutableMapping[str, str]


def _match_vcs_scheme(url: str) -> Optional[str]:
    """Look for VCS schemes in the URL.

FILE: ./venv/Lib/site-packages/pip/_internal/index/package_finder.py
"""Routines related to PyPI, indexes"""

# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import functools
import itertools
import logging
import re
from typing import FrozenSet, Iterable, List, Optional, Set, Tuple, Union

from pip._vendor.packaging import specifiers
from pip._vendor.packaging.tags import Tag
from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.packaging.version import _BaseVersion
from pip._vendor.packaging.version import parse as parse_version

from pip._internal.exceptions import (
    BestVersionAlreadyInstalled,
    DistributionNotFound,
    InvalidWheelFilename,
    UnsupportedWheel,
)
from pip._internal.index.collector import LinkCollector, parse_links
from pip._internal.models.candidate import InstallationCandidate
from pip._internal.models.format_control import FormatControl
from pip._internal.models.link import Link
from pip._internal.models.search_scope import SearchScope
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.models.target_python import TargetPython
from pip._internal.models.wheel import Wheel
from pip._internal.req import InstallRequirement
from pip._internal.utils._log import getLogger
from pip._internal.utils.filetypes import WHEEL_EXTENSION
from pip._internal.utils.hashes import Hashes
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import build_netloc
from pip._internal.utils.packaging import check_requires_python
from pip._internal.utils.unpacking import SUPPORTED_EXTENSIONS
from pip._internal.utils.urls import url_to_path

__all__ = ["FormatControl", "BestCandidateResult", "PackageFinder"]


logger = getLogger(__name__)

BuildTag = Union[Tuple[()], Tuple[int, str]]
CandidateSortingKey = Tuple[int, int, int, _BaseVersion, Optional[int], BuildTag]


FILE: ./venv/Lib/site-packages/pip/_internal/index/sources.py
import logging
import mimetypes
import os
import pathlib
from typing import Callable, Iterable, Optional, Tuple

from pip._internal.models.candidate import InstallationCandidate
from pip._internal.models.link import Link
from pip._internal.utils.urls import path_to_url, url_to_path
from pip._internal.vcs import is_url

logger = logging.getLogger(__name__)

FoundCandidates = Iterable[InstallationCandidate]
FoundLinks = Iterable[Link]
CandidatesFromPage = Callable[[Link], Iterable[InstallationCandidate]]
PageValidator = Callable[[Link], bool]


class LinkSource:
    @property
    def link(self) -> Optional[Link]:
        """Returns the underlying link, if there's one."""
        raise NotImplementedError()

    def page_candidates(self) -> FoundCandidates:
        """Candidates found by parsing an archive listing HTML file."""
        raise NotImplementedError()

    def file_links(self) -> FoundLinks:
        """Links found by specifying archives directly."""
        raise NotImplementedError()


def _is_html_file(file_url: str) -> bool:
    return mimetypes.guess_type(file_url, strict=False)[0] == "text/html"


class _FlatDirectorySource(LinkSource):
    """Link source specified by ``--find-links=<path-to-dir>``.

    This looks the content of the directory, and returns:

    * ``page_candidates``: Links listed on each HTML file in the directory.
    * ``file_candidates``: Archives in the directory.
    """

    def __init__(
        self,
        candidates_from_page: CandidatesFromPage,
FILE: ./venv/Lib/site-packages/pip/_internal/index/__init__.py
"""Index interaction code
"""
FILE: ./venv/Lib/site-packages/pip/_internal/locations/base.py
import functools
import os
import site
import sys
import sysconfig
import typing

from pip._internal.utils import appdirs
from pip._internal.utils.virtualenv import running_under_virtualenv

# Application Directories
USER_CACHE_DIR = appdirs.user_cache_dir("pip")

# FIXME doesn't account for venv linked to global site-packages
site_packages: typing.Optional[str] = sysconfig.get_path("purelib")


def get_major_minor_version() -> str:
    """
    Return the major-minor version of the current Python as a string, e.g.
    "3.7" or "3.10".
    """
    return "{}.{}".format(*sys.version_info)


def get_src_prefix() -> str:
    if running_under_virtualenv():
        src_prefix = os.path.join(sys.prefix, "src")
    else:
        # FIXME: keep src in cwd for now (it is not a temporary folder)
        try:
            src_prefix = os.path.join(os.getcwd(), "src")
        except OSError:
            # In case the current working directory has been renamed or deleted
            sys.exit("The folder you are executing pip from can no longer be found.")

    # under macOS + virtualenv sys.prefix is not properly resolved
    # it is something like /path/to/python/bin/..
    return os.path.abspath(src_prefix)


try:
    # Use getusersitepackages if this is present, as it ensures that the
    # value is initialised properly.
    user_site: typing.Optional[str] = site.getusersitepackages()
except AttributeError:
    user_site = site.USER_SITE


@functools.lru_cache(maxsize=None)
FILE: ./venv/Lib/site-packages/pip/_internal/locations/_distutils.py
"""Locations where we look for configs, install stuff, etc"""

# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import logging
import os
import sys
from distutils.cmd import Command as DistutilsCommand
from distutils.command.install import SCHEME_KEYS
from distutils.command.install import install as distutils_install_command
from distutils.sysconfig import get_python_lib
from typing import Dict, List, Optional, Tuple, Union, cast

from pip._internal.models.scheme import Scheme
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.virtualenv import running_under_virtualenv

from .base import get_major_minor_version

logger = logging.getLogger(__name__)


def distutils_scheme(
    dist_name: str,
    user: bool = False,
    home: str = None,
    root: str = None,
    isolated: bool = False,
    prefix: str = None,
    *,
    ignore_config_files: bool = False,
) -> Dict[str, str]:
    """
    Return a distutils install scheme
    """
    from distutils.dist import Distribution

    dist_args: Dict[str, Union[str, List[str]]] = {"name": dist_name}
    if isolated:
        dist_args["script_args"] = ["--no-user-cfg"]

    d = Distribution(dist_args)
    if not ignore_config_files:
        try:
            d.parse_config_files()
        except UnicodeDecodeError:
            # Typeshed does not include find_config_files() for some reason.
            paths = d.find_config_files()  # type: ignore
            logger.warning(
FILE: ./venv/Lib/site-packages/pip/_internal/locations/_sysconfig.py
import distutils.util  # FIXME: For change_root.
import logging
import os
import sys
import sysconfig
import typing

from pip._internal.exceptions import InvalidSchemeCombination, UserInstallationInvalid
from pip._internal.models.scheme import SCHEME_KEYS, Scheme
from pip._internal.utils.virtualenv import running_under_virtualenv

from .base import get_major_minor_version, is_osx_framework

logger = logging.getLogger(__name__)


# Notes on _infer_* functions.
# Unfortunately ``get_default_scheme()`` didn't exist before 3.10, so there's no
# way to ask things like "what is the '_prefix' scheme on this platform". These
# functions try to answer that with some heuristics while accounting for ad-hoc
# platforms not covered by CPython's default sysconfig implementation. If the
# ad-hoc implementation does not fully implement sysconfig, we'll fall back to
# a POSIX scheme.

_AVAILABLE_SCHEMES = set(sysconfig.get_scheme_names())

_PREFERRED_SCHEME_API = getattr(sysconfig, "get_preferred_scheme", None)


def _should_use_osx_framework_prefix() -> bool:
    """Check for Apple's ``osx_framework_library`` scheme.

    Python distributed by Apple's Command Line Tools has this special scheme
    that's used when:

    * This is a framework build.
    * We are installing into the system prefix.

    This does not account for ``pip install --prefix`` (also means we're not
    installing to the system prefix), which should use ``posix_prefix``, but
    logic here means ``_infer_prefix()`` outputs ``osx_framework_library``. But
    since ``prefix`` is not available for ``sysconfig.get_default_scheme()``,
    which is the stdlib replacement for ``_infer_prefix()``, presumably Apple
    wouldn't be able to magically switch between ``osx_framework_library`` and
    ``posix_prefix``. ``_infer_prefix()`` returning ``osx_framework_library``
    means its behavior is consistent whether we use the stdlib implementation
    or our own, and we deal with this special case in ``get_scheme()`` instead.
    """
    return (
        "osx_framework_library" in _AVAILABLE_SCHEMES
FILE: ./venv/Lib/site-packages/pip/_internal/locations/__init__.py
import functools
import logging
import os
import pathlib
import sys
import sysconfig
from typing import Any, Dict, Iterator, List, Optional, Tuple

from pip._internal.models.scheme import SCHEME_KEYS, Scheme
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.deprecation import deprecated
from pip._internal.utils.virtualenv import running_under_virtualenv

from . import _distutils, _sysconfig
from .base import (
    USER_CACHE_DIR,
    get_major_minor_version,
    get_src_prefix,
    is_osx_framework,
    site_packages,
    user_site,
)

__all__ = [
    "USER_CACHE_DIR",
    "get_bin_prefix",
    "get_bin_user",
    "get_major_minor_version",
    "get_platlib",
    "get_prefixed_libs",
    "get_purelib",
    "get_scheme",
    "get_src_prefix",
    "site_packages",
    "user_site",
]


logger = logging.getLogger(__name__)

if os.environ.get("_PIP_LOCATIONS_NO_WARN_ON_MISMATCH"):
    _MISMATCH_LEVEL = logging.DEBUG
else:
    _MISMATCH_LEVEL = logging.WARNING

_PLATLIBDIR: str = getattr(sys, "platlibdir", "lib")

_USE_SYSCONFIG = sys.version_info >= (3, 10)


FILE: ./venv/Lib/site-packages/pip/_internal/main.py
from typing import List, Optional


def main(args: Optional[List[str]] = None) -> int:
    """This is preserved for old console scripts that may still be referencing
    it.

    For additional details, see https://github.com/pypa/pip/issues/7498.
    """
    from pip._internal.utils.entrypoints import _wrapper

    return _wrapper(args)
FILE: ./venv/Lib/site-packages/pip/_internal/metadata/base.py
import email.message
import json
import logging
import re
import zipfile
from typing import (
    IO,
    TYPE_CHECKING,
    Collection,
    Container,
    Iterable,
    Iterator,
    List,
    Optional,
    Union,
)

from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.specifiers import InvalidSpecifier, SpecifierSet
from pip._vendor.packaging.utils import NormalizedName
from pip._vendor.packaging.version import LegacyVersion, Version

from pip._internal.models.direct_url import (
    DIRECT_URL_METADATA_NAME,
    DirectUrl,
    DirectUrlValidationError,
)
from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
from pip._internal.utils.egg_link import egg_link_path_from_sys_path
from pip._internal.utils.urls import url_to_path

if TYPE_CHECKING:
    from typing import Protocol
else:
    Protocol = object

DistributionVersion = Union[LegacyVersion, Version]

logger = logging.getLogger(__name__)


class BaseEntryPoint(Protocol):
    @property
    def name(self) -> str:
        raise NotImplementedError()

    @property
    def value(self) -> str:
        raise NotImplementedError()

FILE: ./venv/Lib/site-packages/pip/_internal/metadata/pkg_resources.py
import email.message
import logging
from typing import Collection, Iterable, Iterator, List, NamedTuple, Optional

from pip._vendor import pkg_resources
from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import parse as parse_version

from pip._internal.utils import misc  # TODO: Move definition here.
from pip._internal.utils.packaging import get_installer, get_metadata
from pip._internal.utils.wheel import pkg_resources_distribution_for_wheel

from .base import (
    BaseDistribution,
    BaseEntryPoint,
    BaseEnvironment,
    DistributionVersion,
    Wheel,
)

logger = logging.getLogger(__name__)


class EntryPoint(NamedTuple):
    name: str
    value: str
    group: str


class Distribution(BaseDistribution):
    def __init__(self, dist: pkg_resources.Distribution) -> None:
        self._dist = dist

    @classmethod
    def from_wheel(cls, wheel: Wheel, name: str) -> "Distribution":
        with wheel.as_zipfile() as zf:
            dist = pkg_resources_distribution_for_wheel(zf, name, wheel.location)
        return cls(dist)

    @property
    def location(self) -> Optional[str]:
        return self._dist.location

    @property
    def info_directory(self) -> Optional[str]:
        return self._dist.egg_info

    @property
    def canonical_name(self) -> NormalizedName:
FILE: ./venv/Lib/site-packages/pip/_internal/metadata/__init__.py
from typing import List, Optional

from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel

__all__ = [
    "BaseDistribution",
    "BaseEnvironment",
    "FilesystemWheel",
    "MemoryWheel",
    "Wheel",
    "get_default_environment",
    "get_environment",
    "get_wheel_distribution",
]


def get_default_environment() -> BaseEnvironment:
    """Get the default representation for the current environment.

    This returns an Environment instance from the chosen backend. The default
    Environment instance should be built from ``sys.path`` and may use caching
    to share instance state accorss calls.
    """
    from .pkg_resources import Environment

    return Environment.default()


def get_environment(paths: Optional[List[str]]) -> BaseEnvironment:
    """Get a representation of the environment specified by ``paths``.

    This returns an Environment instance from the chosen backend based on the
    given import paths. The backend must build a fresh instance representing
    the state of installed distributions when this function is called.
    """
    from .pkg_resources import Environment

    return Environment.from_paths(paths)


def get_wheel_distribution(wheel: Wheel, canonical_name: str) -> BaseDistribution:
    """Get the representation of the specified wheel's distribution metadata.

    This returns a Distribution instance from the chosen backend based on
    the given wheel's ``.dist-info`` directory.

    :param canonical_name: Normalized project name of the given wheel.
    """
    from .pkg_resources import Distribution

FILE: ./venv/Lib/site-packages/pip/_internal/models/candidate.py
from pip._vendor.packaging.version import parse as parse_version

from pip._internal.models.link import Link
from pip._internal.utils.models import KeyBasedCompareMixin


class InstallationCandidate(KeyBasedCompareMixin):
    """Represents a potential "candidate" for installation."""

    __slots__ = ["name", "version", "link"]

    def __init__(self, name: str, version: str, link: Link) -> None:
        self.name = name
        self.version = parse_version(version)
        self.link = link

        super().__init__(
            key=(self.name, self.version, self.link),
            defining_class=InstallationCandidate,
        )

    def __repr__(self) -> str:
        return "<InstallationCandidate({!r}, {!r}, {!r})>".format(
            self.name,
            self.version,
            self.link,
        )

    def __str__(self) -> str:
        return "{!r} candidate (version {} at {})".format(
            self.name,
            self.version,
            self.link,
        )
FILE: ./venv/Lib/site-packages/pip/_internal/models/direct_url.py
""" PEP 610 """
import json
import re
import urllib.parse
from typing import Any, Dict, Iterable, Optional, Type, TypeVar, Union

__all__ = [
    "DirectUrl",
    "DirectUrlValidationError",
    "DirInfo",
    "ArchiveInfo",
    "VcsInfo",
]

T = TypeVar("T")

DIRECT_URL_METADATA_NAME = "direct_url.json"
ENV_VAR_RE = re.compile(r"^\$\{[A-Za-z0-9-_]+\}(:\$\{[A-Za-z0-9-_]+\})?$")


class DirectUrlValidationError(Exception):
    pass


def _get(
    d: Dict[str, Any], expected_type: Type[T], key: str, default: Optional[T] = None
) -> Optional[T]:
    """Get value from dictionary and verify expected type."""
    if key not in d:
        return default
    value = d[key]
    if not isinstance(value, expected_type):
        raise DirectUrlValidationError(
            "{!r} has unexpected type for {} (expected {})".format(
                value, key, expected_type
            )
        )
    return value


def _get_required(
    d: Dict[str, Any], expected_type: Type[T], key: str, default: Optional[T] = None
) -> T:
    value = _get(d, expected_type, key, default)
    if value is None:
        raise DirectUrlValidationError(f"{key} must have a value")
    return value


def _exactly_one_of(infos: Iterable[Optional["InfoType"]]) -> "InfoType":
FILE: ./venv/Lib/site-packages/pip/_internal/models/format_control.py
from typing import FrozenSet, Optional, Set

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.exceptions import CommandError


class FormatControl:
    """Helper for managing formats from which a package can be installed."""

    __slots__ = ["no_binary", "only_binary"]

    def __init__(
        self,
        no_binary: Optional[Set[str]] = None,
        only_binary: Optional[Set[str]] = None,
    ) -> None:
        if no_binary is None:
            no_binary = set()
        if only_binary is None:
            only_binary = set()

        self.no_binary = no_binary
        self.only_binary = only_binary

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, self.__class__):
            return NotImplemented

        if self.__slots__ != other.__slots__:
            return False

        return all(getattr(self, k) == getattr(other, k) for k in self.__slots__)

    def __repr__(self) -> str:
        return "{}({}, {})".format(
            self.__class__.__name__, self.no_binary, self.only_binary
        )

    @staticmethod
    def handle_mutual_excludes(value: str, target: Set[str], other: Set[str]) -> None:
        if value.startswith("-"):
            raise CommandError(
                "--no-binary / --only-binary option requires 1 argument."
            )
        new = value.split(",")
        while ":all:" in new:
            other.clear()
            target.clear()
            target.add(":all:")
FILE: ./venv/Lib/site-packages/pip/_internal/models/index.py
import urllib.parse


class PackageIndex:
    """Represents a Package Index and provides easier access to endpoints"""

    __slots__ = ["url", "netloc", "simple_url", "pypi_url", "file_storage_domain"]

    def __init__(self, url: str, file_storage_domain: str) -> None:
        super().__init__()
        self.url = url
        self.netloc = urllib.parse.urlsplit(url).netloc
        self.simple_url = self._url_for_path("simple")
        self.pypi_url = self._url_for_path("pypi")

        # This is part of a temporary hack used to block installs of PyPI
        # packages which depend on external urls only necessary until PyPI can
        # block such packages themselves
        self.file_storage_domain = file_storage_domain

    def _url_for_path(self, path: str) -> str:
        return urllib.parse.urljoin(self.url, path)


PyPI = PackageIndex("https://pypi.org/", file_storage_domain="files.pythonhosted.org")
TestPyPI = PackageIndex(
    "https://test.pypi.org/", file_storage_domain="test-files.pythonhosted.org"
)
FILE: ./venv/Lib/site-packages/pip/_internal/models/link.py
import functools
import logging
import os
import posixpath
import re
import urllib.parse
from typing import TYPE_CHECKING, Dict, List, NamedTuple, Optional, Tuple, Union

from pip._internal.utils.filetypes import WHEEL_EXTENSION
from pip._internal.utils.hashes import Hashes
from pip._internal.utils.misc import (
    redact_auth_from_url,
    split_auth_from_netloc,
    splitext,
)
from pip._internal.utils.models import KeyBasedCompareMixin
from pip._internal.utils.urls import path_to_url, url_to_path

if TYPE_CHECKING:
    from pip._internal.index.collector import HTMLPage

logger = logging.getLogger(__name__)


_SUPPORTED_HASHES = ("sha1", "sha224", "sha384", "sha256", "sha512", "md5")


class Link(KeyBasedCompareMixin):
    """Represents a parsed link from a Package Index's simple URL"""

    __slots__ = [
        "_parsed_url",
        "_url",
        "comes_from",
        "requires_python",
        "yanked_reason",
        "cache_link_parsing",
    ]

    def __init__(
        self,
        url: str,
        comes_from: Optional[Union[str, "HTMLPage"]] = None,
        requires_python: Optional[str] = None,
        yanked_reason: Optional[str] = None,
        cache_link_parsing: bool = True,
    ) -> None:
        """
        :param url: url of the resource pointed to (href of the link)
        :param comes_from: instance of HTMLPage where the link was found,
FILE: ./venv/Lib/site-packages/pip/_internal/models/scheme.py
"""
For types associated with installation schemes.

For a general overview of available schemes and their context, see
https://docs.python.org/3/install/index.html#alternate-installation.
"""


SCHEME_KEYS = ["platlib", "purelib", "headers", "scripts", "data"]


class Scheme:
    """A Scheme holds paths which are used as the base directories for
    artifacts associated with a Python package.
    """

    __slots__ = SCHEME_KEYS

    def __init__(
        self,
        platlib: str,
        purelib: str,
        headers: str,
        scripts: str,
        data: str,
    ) -> None:
        self.platlib = platlib
        self.purelib = purelib
        self.headers = headers
        self.scripts = scripts
        self.data = data
FILE: ./venv/Lib/site-packages/pip/_internal/models/search_scope.py
import itertools
import logging
import os
import posixpath
import urllib.parse
from typing import List

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.models.index import PyPI
from pip._internal.utils.compat import has_tls
from pip._internal.utils.misc import normalize_path, redact_auth_from_url

logger = logging.getLogger(__name__)


class SearchScope:

    """
    Encapsulates the locations that pip is configured to search.
    """

    __slots__ = ["find_links", "index_urls"]

    @classmethod
    def create(
        cls,
        find_links: List[str],
        index_urls: List[str],
    ) -> "SearchScope":
        """
        Create a SearchScope object after normalizing the `find_links`.
        """
        # Build find_links. If an argument starts with ~, it may be
        # a local file relative to a home directory. So try normalizing
        # it and if it exists, use the normalized version.
        # This is deliberately conservative - it might be fine just to
        # blindly normalize anything starting with a ~...
        built_find_links: List[str] = []
        for link in find_links:
            if link.startswith("~"):
                new_link = normalize_path(link)
                if os.path.exists(new_link):
                    link = new_link
            built_find_links.append(link)

        # If we don't have TLS enabled, then WARN if anyplace we're looking
        # relies on TLS.
        if not has_tls():
            for link in itertools.chain(index_urls, built_find_links):
FILE: ./venv/Lib/site-packages/pip/_internal/models/selection_prefs.py
from typing import Optional

from pip._internal.models.format_control import FormatControl


class SelectionPreferences:
    """
    Encapsulates the candidate selection preferences for downloading
    and installing files.
    """

    __slots__ = [
        "allow_yanked",
        "allow_all_prereleases",
        "format_control",
        "prefer_binary",
        "ignore_requires_python",
    ]

    # Don't include an allow_yanked default value to make sure each call
    # site considers whether yanked releases are allowed. This also causes
    # that decision to be made explicit in the calling code, which helps
    # people when reading the code.
    def __init__(
        self,
        allow_yanked: bool,
        allow_all_prereleases: bool = False,
        format_control: Optional[FormatControl] = None,
        prefer_binary: bool = False,
        ignore_requires_python: Optional[bool] = None,
    ) -> None:
        """Create a SelectionPreferences object.

        :param allow_yanked: Whether files marked as yanked (in the sense
            of PEP 592) are permitted to be candidates for install.
        :param format_control: A FormatControl object or None. Used to control
            the selection of source packages / binary packages when consulting
            the index and links.
        :param prefer_binary: Whether to prefer an old, but valid, binary
            dist over a new source dist.
        :param ignore_requires_python: Whether to ignore incompatible
            "Requires-Python" values in links. Defaults to False.
        """
        if ignore_requires_python is None:
            ignore_requires_python = False

        self.allow_yanked = allow_yanked
        self.allow_all_prereleases = allow_all_prereleases
        self.format_control = format_control
        self.prefer_binary = prefer_binary
FILE: ./venv/Lib/site-packages/pip/_internal/models/target_python.py
import sys
from typing import List, Optional, Tuple

from pip._vendor.packaging.tags import Tag

from pip._internal.utils.compatibility_tags import get_supported, version_info_to_nodot
from pip._internal.utils.misc import normalize_version_info


class TargetPython:

    """
    Encapsulates the properties of a Python interpreter one is targeting
    for a package install, download, etc.
    """

    __slots__ = [
        "_given_py_version_info",
        "abis",
        "implementation",
        "platforms",
        "py_version",
        "py_version_info",
        "_valid_tags",
    ]

    def __init__(
        self,
        platforms: Optional[List[str]] = None,
        py_version_info: Optional[Tuple[int, ...]] = None,
        abis: Optional[List[str]] = None,
        implementation: Optional[str] = None,
    ) -> None:
        """
        :param platforms: A list of strings or None. If None, searches for
            packages that are supported by the current system. Otherwise, will
            find packages that can be built on the platforms passed in. These
            packages will only be downloaded for distribution: they will
            not be built locally.
        :param py_version_info: An optional tuple of ints representing the
            Python version information to use (e.g. `sys.version_info[:3]`).
            This can have length 1, 2, or 3 when provided.
        :param abis: A list of strings or None. This is passed to
            compatibility_tags.py's get_supported() function as is.
        :param implementation: A string or None. This is passed to
            compatibility_tags.py's get_supported() function as is.
        """
        # Store the given py_version_info for when we call get_supported().
        self._given_py_version_info = py_version_info

FILE: ./venv/Lib/site-packages/pip/_internal/models/wheel.py
"""Represents a wheel file and provides access to the various parts of the
name that have meaning.
"""
import re
from typing import Dict, Iterable, List

from pip._vendor.packaging.tags import Tag

from pip._internal.exceptions import InvalidWheelFilename


class Wheel:
    """A wheel file"""

    wheel_file_re = re.compile(
        r"""^(?P<namever>(?P<name>.+?)-(?P<ver>.*?))
        ((-(?P<build>\d[^-]*?))?-(?P<pyver>.+?)-(?P<abi>.+?)-(?P<plat>.+?)
        \.whl|\.dist-info)$""",
        re.VERBOSE,
    )

    def __init__(self, filename: str) -> None:
        """
        :raises InvalidWheelFilename: when the filename is invalid for a wheel
        """
        wheel_info = self.wheel_file_re.match(filename)
        if not wheel_info:
            raise InvalidWheelFilename(f"{filename} is not a valid wheel filename.")
        self.filename = filename
        self.name = wheel_info.group("name").replace("_", "-")
        # we'll assume "_" means "-" due to wheel naming scheme
        # (https://github.com/pypa/pip/issues/1150)
        self.version = wheel_info.group("ver").replace("_", "-")
        self.build_tag = wheel_info.group("build")
        self.pyversions = wheel_info.group("pyver").split(".")
        self.abis = wheel_info.group("abi").split(".")
        self.plats = wheel_info.group("plat").split(".")

        # All the tag combinations from this file
        self.file_tags = {
            Tag(x, y, z) for x in self.pyversions for y in self.abis for z in self.plats
        }

    def get_formatted_file_tags(self) -> List[str]:
        """Return the wheel's tags as a sorted list of strings."""
        return sorted(str(tag) for tag in self.file_tags)

    def support_index_min(self, tags: List[Tag]) -> int:
        """Return the lowest index that one of the wheel's file_tag combinations
        achieves in the given list of supported tags.
FILE: ./venv/Lib/site-packages/pip/_internal/models/__init__.py
"""A package that contains models that represent entities.
"""
FILE: ./venv/Lib/site-packages/pip/_internal/network/auth.py
"""Network Authentication Helpers

Contains interface (MultiDomainBasicAuth) and associated glue code for
providing credentials in the context of network requests.
"""

import urllib.parse
from typing import Any, Dict, List, Optional, Tuple

from pip._vendor.requests.auth import AuthBase, HTTPBasicAuth
from pip._vendor.requests.models import Request, Response
from pip._vendor.requests.utils import get_netrc_auth

from pip._internal.utils.logging import getLogger
from pip._internal.utils.misc import (
    ask,
    ask_input,
    ask_password,
    remove_auth_from_url,
    split_auth_netloc_from_url,
)
from pip._internal.vcs.versioncontrol import AuthInfo

logger = getLogger(__name__)

Credentials = Tuple[str, str, str]

try:
    import keyring
except ImportError:
    keyring = None  # type: ignore[assignment]
except Exception as exc:
    logger.warning(
        "Keyring is skipped due to an exception: %s",
        str(exc),
    )
    keyring = None  # type: ignore[assignment]


def get_keyring_auth(url: Optional[str], username: Optional[str]) -> Optional[AuthInfo]:
    """Return the tuple auth for a given url from keyring."""
    global keyring
    if not url or not keyring:
        return None

    try:
        try:
            get_credential = keyring.get_credential
        except AttributeError:
            pass
FILE: ./venv/Lib/site-packages/pip/_internal/network/cache.py
"""HTTP cache implementation.
"""

import os
from contextlib import contextmanager
from typing import Iterator, Optional

from pip._vendor.cachecontrol.cache import BaseCache
from pip._vendor.cachecontrol.caches import FileCache
from pip._vendor.requests.models import Response

from pip._internal.utils.filesystem import adjacent_tmp_file, replace
from pip._internal.utils.misc import ensure_dir


def is_from_cache(response: Response) -> bool:
    return getattr(response, "from_cache", False)


@contextmanager
def suppressed_cache_errors() -> Iterator[None]:
    """If we can't access the cache then we can just skip caching and process
    requests as if caching wasn't enabled.
    """
    try:
        yield
    except OSError:
        pass


class SafeFileCache(BaseCache):
    """
    A file based cache which is safe to use even when the target directory may
    not be accessible or writable.
    """

    def __init__(self, directory: str) -> None:
        assert directory is not None, "Cache directory must not be None."
        super().__init__()
        self.directory = directory

    def _get_cache_path(self, name: str) -> str:
        # From cachecontrol.caches.file_cache.FileCache._fn, brought into our
        # class for backwards-compatibility and to avoid using a non-public
        # method.
        hashed = FileCache.encode(name)
        parts = list(hashed[:5]) + [hashed]
        return os.path.join(self.directory, *parts)

    def get(self, key: str) -> Optional[bytes]:
FILE: ./venv/Lib/site-packages/pip/_internal/network/download.py
"""Download files with progress indicators.
"""
import cgi
import logging
import mimetypes
import os
from typing import Iterable, Optional, Tuple

from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response

from pip._internal.cli.progress_bars import DownloadProgressProvider
from pip._internal.exceptions import NetworkConnectionError
from pip._internal.models.index import PyPI
from pip._internal.models.link import Link
from pip._internal.network.cache import is_from_cache
from pip._internal.network.session import PipSession
from pip._internal.network.utils import HEADERS, raise_for_status, response_chunks
from pip._internal.utils.misc import format_size, redact_auth_from_url, splitext

logger = logging.getLogger(__name__)


def _get_http_response_size(resp: Response) -> Optional[int]:
    try:
        return int(resp.headers["content-length"])
    except (ValueError, KeyError, TypeError):
        return None


def _prepare_download(
    resp: Response,
    link: Link,
    progress_bar: str,
) -> Iterable[bytes]:
    total_length = _get_http_response_size(resp)

    if link.netloc == PyPI.file_storage_domain:
        url = link.show_url
    else:
        url = link.url_without_fragment

    logged_url = redact_auth_from_url(url)

    if total_length:
        logged_url = "{} ({})".format(logged_url, format_size(total_length))

    if is_from_cache(resp):
        logger.info("Using cached %s", logged_url)
    else:
        logger.info("Downloading %s", logged_url)
FILE: ./venv/Lib/site-packages/pip/_internal/network/lazy_wheel.py
"""Lazy ZIP over HTTP"""

__all__ = ["HTTPRangeRequestUnsupported", "dist_from_wheel_url"]

from bisect import bisect_left, bisect_right
from contextlib import contextmanager
from tempfile import NamedTemporaryFile
from typing import Any, Dict, Iterator, List, Optional, Tuple
from zipfile import BadZipfile, ZipFile

from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response

from pip._internal.metadata import BaseDistribution, MemoryWheel, get_wheel_distribution
from pip._internal.network.session import PipSession
from pip._internal.network.utils import HEADERS, raise_for_status, response_chunks


class HTTPRangeRequestUnsupported(Exception):
    pass


def dist_from_wheel_url(name: str, url: str, session: PipSession) -> BaseDistribution:
    """Return a distribution object from the given wheel URL.

    This uses HTTP range requests to only fetch the potion of the wheel
    containing metadata, just enough for the object to be constructed.
    If such requests are not supported, HTTPRangeRequestUnsupported
    is raised.
    """
    with LazyZipOverHTTP(url, session) as zf:
        # For read-only ZIP files, ZipFile only needs methods read,
        # seek, seekable and tell, not the whole IO protocol.
        wheel = MemoryWheel(zf.name, zf)  # type: ignore
        # After context manager exit, wheel.name
        # is an invalid file by intention.
        return get_wheel_distribution(wheel, canonicalize_name(name))


class LazyZipOverHTTP:
    """File-like object mapped to a ZIP file over HTTP.

    This uses HTTP range requests to lazily fetch the file's content,
    which is supposed to be fed to ZipFile.  If such requests are not
    supported by the server, raise HTTPRangeRequestUnsupported
    during initialization.
    """

    def __init__(
        self, url: str, session: PipSession, chunk_size: int = CONTENT_CHUNK_SIZE
FILE: ./venv/Lib/site-packages/pip/_internal/network/session.py
"""PipSession and supporting code, containing all pip-specific
network request configuration and behavior.
"""

import email.utils
import io
import ipaddress
import json
import logging
import mimetypes
import os
import platform
import shutil
import subprocess
import sys
import urllib.parse
import warnings
from typing import Any, Dict, Iterator, List, Mapping, Optional, Sequence, Tuple, Union

from pip._vendor import requests, urllib3
from pip._vendor.cachecontrol import CacheControlAdapter
from pip._vendor.requests.adapters import BaseAdapter, HTTPAdapter
from pip._vendor.requests.models import PreparedRequest, Response
from pip._vendor.requests.structures import CaseInsensitiveDict
from pip._vendor.urllib3.connectionpool import ConnectionPool
from pip._vendor.urllib3.exceptions import InsecureRequestWarning

from pip import __version__
from pip._internal.metadata import get_default_environment
from pip._internal.models.link import Link
from pip._internal.network.auth import MultiDomainBasicAuth
from pip._internal.network.cache import SafeFileCache

# Import ssl from compat so the initial import occurs in only one place.
from pip._internal.utils.compat import has_tls
from pip._internal.utils.glibc import libc_ver
from pip._internal.utils.misc import build_url_from_netloc, parse_netloc
from pip._internal.utils.urls import url_to_path

logger = logging.getLogger(__name__)

SecureOrigin = Tuple[str, str, Optional[Union[int, str]]]


# Ignore warning raised when using --trusted-host.
warnings.filterwarnings("ignore", category=InsecureRequestWarning)


SECURE_ORIGINS: List[SecureOrigin] = [
    # protocol, hostname, port
FILE: ./venv/Lib/site-packages/pip/_internal/network/utils.py
from typing import Dict, Iterator

from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response

from pip._internal.exceptions import NetworkConnectionError

# The following comments and HTTP headers were originally added by
# Donald Stufft in git commit 22c562429a61bb77172039e480873fb239dd8c03.
#
# We use Accept-Encoding: identity here because requests defaults to
# accepting compressed responses. This breaks in a variety of ways
# depending on how the server is configured.
# - Some servers will notice that the file isn't a compressible file
#   and will leave the file alone and with an empty Content-Encoding
# - Some servers will notice that the file is already compressed and
#   will leave the file alone, adding a Content-Encoding: gzip header
# - Some servers won't notice anything at all and will take a file
#   that's already been compressed and compress it again, and set
#   the Content-Encoding: gzip header
# By setting this to request only the identity encoding we're hoping
# to eliminate the third case.  Hopefully there does not exist a server
# which when given a file will notice it is already compressed and that
# you're not asking for a compressed file and will then decompress it
# before sending because if that's the case I don't think it'll ever be
# possible to make this work.
HEADERS: Dict[str, str] = {"Accept-Encoding": "identity"}


def raise_for_status(resp: Response) -> None:
    http_error_msg = ""
    if isinstance(resp.reason, bytes):
        # We attempt to decode utf-8 first because some servers
        # choose to localize their reason strings. If the string
        # isn't utf-8, we fall back to iso-8859-1 for all other
        # encodings.
        try:
            reason = resp.reason.decode("utf-8")
        except UnicodeDecodeError:
            reason = resp.reason.decode("iso-8859-1")
    else:
        reason = resp.reason

    if 400 <= resp.status_code < 500:
        http_error_msg = (
            f"{resp.status_code} Client Error: {reason} for url: {resp.url}"
        )

    elif 500 <= resp.status_code < 600:
        http_error_msg = (
            f"{resp.status_code} Server Error: {reason} for url: {resp.url}"
FILE: ./venv/Lib/site-packages/pip/_internal/network/xmlrpc.py
"""xmlrpclib.Transport implementation
"""

import logging
import urllib.parse
import xmlrpc.client
from typing import TYPE_CHECKING, Tuple

from pip._internal.exceptions import NetworkConnectionError
from pip._internal.network.session import PipSession
from pip._internal.network.utils import raise_for_status

if TYPE_CHECKING:
    from xmlrpc.client import _HostType, _Marshallable

logger = logging.getLogger(__name__)


class PipXmlrpcTransport(xmlrpc.client.Transport):
    """Provide a `xmlrpclib.Transport` implementation via a `PipSession`
    object.
    """

    def __init__(
        self, index_url: str, session: PipSession, use_datetime: bool = False
    ) -> None:
        super().__init__(use_datetime)
        index_parts = urllib.parse.urlparse(index_url)
        self._scheme = index_parts.scheme
        self._session = session

    def request(
        self,
        host: "_HostType",
        handler: str,
        request_body: bytes,
        verbose: bool = False,
    ) -> Tuple["_Marshallable", ...]:
        assert isinstance(host, str)
        parts = (self._scheme, host, handler, None, None, None)
        url = urllib.parse.urlunparse(parts)
        try:
            headers = {"Content-Type": "text/xml"}
            response = self._session.post(
                url,
                data=request_body,
                headers=headers,
                stream=True,
            )
            raise_for_status(response)
FILE: ./venv/Lib/site-packages/pip/_internal/network/__init__.py
"""Contains purely network-related utilities.
"""
FILE: ./venv/Lib/site-packages/pip/_internal/operations/build/metadata.py
"""Metadata generation logic for source distributions.
"""

import os

from pip._vendor.pep517.wrappers import Pep517HookCaller

from pip._internal.build_env import BuildEnvironment
from pip._internal.utils.subprocess import runner_with_spinner_message
from pip._internal.utils.temp_dir import TempDirectory


def generate_metadata(build_env: BuildEnvironment, backend: Pep517HookCaller) -> str:
    """Generate metadata using mechanisms described in PEP 517.

    Returns the generated metadata directory.
    """
    metadata_tmpdir = TempDirectory(kind="modern-metadata", globally_managed=True)

    metadata_dir = metadata_tmpdir.path

    with build_env:
        # Note that Pep517HookCaller implements a fallback for
        # prepare_metadata_for_build_wheel, so we don't have to
        # consider the possibility that this hook doesn't exist.
        runner = runner_with_spinner_message("Preparing metadata (pyproject.toml)")
        with backend.subprocess_runner(runner):
            distinfo_dir = backend.prepare_metadata_for_build_wheel(metadata_dir)

    return os.path.join(metadata_dir, distinfo_dir)
FILE: ./venv/Lib/site-packages/pip/_internal/operations/build/metadata_editable.py
"""Metadata generation logic for source distributions.
"""

import os

from pip._vendor.pep517.wrappers import Pep517HookCaller

from pip._internal.build_env import BuildEnvironment
from pip._internal.utils.subprocess import runner_with_spinner_message
from pip._internal.utils.temp_dir import TempDirectory


def generate_editable_metadata(
    build_env: BuildEnvironment, backend: Pep517HookCaller
) -> str:
    """Generate metadata using mechanisms described in PEP 660.

    Returns the generated metadata directory.
    """
    metadata_tmpdir = TempDirectory(kind="modern-metadata", globally_managed=True)

    metadata_dir = metadata_tmpdir.path

    with build_env:
        # Note that Pep517HookCaller implements a fallback for
        # prepare_metadata_for_build_wheel/editable, so we don't have to
        # consider the possibility that this hook doesn't exist.
        runner = runner_with_spinner_message(
            "Preparing editable metadata (pyproject.toml)"
        )
        with backend.subprocess_runner(runner):
            distinfo_dir = backend.prepare_metadata_for_build_editable(metadata_dir)

    return os.path.join(metadata_dir, distinfo_dir)
FILE: ./venv/Lib/site-packages/pip/_internal/operations/build/metadata_legacy.py
"""Metadata generation logic for legacy source distributions.
"""

import logging
import os

from pip._internal.build_env import BuildEnvironment
from pip._internal.cli.spinners import open_spinner
from pip._internal.exceptions import InstallationError
from pip._internal.utils.setuptools_build import make_setuptools_egg_info_args
from pip._internal.utils.subprocess import call_subprocess
from pip._internal.utils.temp_dir import TempDirectory

logger = logging.getLogger(__name__)


def _find_egg_info(directory: str) -> str:
    """Find an .egg-info subdirectory in `directory`."""
    filenames = [f for f in os.listdir(directory) if f.endswith(".egg-info")]

    if not filenames:
        raise InstallationError(f"No .egg-info directory found in {directory}")

    if len(filenames) > 1:
        raise InstallationError(
            "More than one .egg-info directory found in {}".format(directory)
        )

    return os.path.join(directory, filenames[0])


def generate_metadata(
    build_env: BuildEnvironment,
    setup_py_path: str,
    source_dir: str,
    isolated: bool,
    details: str,
) -> str:
    """Generate metadata using setup.py-based defacto mechanisms.

    Returns the generated metadata directory.
    """
    logger.debug(
        "Running setup.py (path:%s) egg_info for package %s",
        setup_py_path,
        details,
    )

    egg_info_dir = TempDirectory(kind="pip-egg-info", globally_managed=True).path

FILE: ./venv/Lib/site-packages/pip/_internal/operations/build/wheel.py
import logging
import os
from typing import Optional

from pip._vendor.pep517.wrappers import Pep517HookCaller

from pip._internal.utils.subprocess import runner_with_spinner_message

logger = logging.getLogger(__name__)


def build_wheel_pep517(
    name: str,
    backend: Pep517HookCaller,
    metadata_directory: str,
    tempd: str,
) -> Optional[str]:
    """Build one InstallRequirement using the PEP 517 build process.

    Returns path to wheel if successfully built. Otherwise, returns None.
    """
    assert metadata_directory is not None
    try:
        logger.debug("Destination directory: %s", tempd)

        runner = runner_with_spinner_message(
            f"Building wheel for {name} (pyproject.toml)"
        )
        with backend.subprocess_runner(runner):
            wheel_name = backend.build_wheel(
                tempd,
                metadata_directory=metadata_directory,
            )
    except Exception:
        logger.error("Failed building wheel for %s", name)
        return None
    return os.path.join(tempd, wheel_name)
FILE: ./venv/Lib/site-packages/pip/_internal/operations/build/wheel_editable.py
import logging
import os
from typing import Optional

from pip._vendor.pep517.wrappers import HookMissing, Pep517HookCaller

from pip._internal.utils.subprocess import runner_with_spinner_message

logger = logging.getLogger(__name__)


def build_wheel_editable(
    name: str,
    backend: Pep517HookCaller,
    metadata_directory: str,
    tempd: str,
) -> Optional[str]:
    """Build one InstallRequirement using the PEP 660 build process.

    Returns path to wheel if successfully built. Otherwise, returns None.
    """
    assert metadata_directory is not None
    try:
        logger.debug("Destination directory: %s", tempd)

        runner = runner_with_spinner_message(
            f"Building editable for {name} (pyproject.toml)"
        )
        with backend.subprocess_runner(runner):
            try:
                wheel_name = backend.build_editable(
                    tempd,
                    metadata_directory=metadata_directory,
                )
            except HookMissing as e:
                logger.error(
                    "Cannot build editable %s because the build "
                    "backend does not have the %s hook",
                    name,
                    e,
                )
                return None
    except Exception:
        logger.error("Failed building editable for %s", name)
        return None
    return os.path.join(tempd, wheel_name)
FILE: ./venv/Lib/site-packages/pip/_internal/operations/build/wheel_legacy.py
import logging
import os.path
from typing import List, Optional

from pip._internal.cli.spinners import open_spinner
from pip._internal.utils.setuptools_build import make_setuptools_bdist_wheel_args
from pip._internal.utils.subprocess import (
    LOG_DIVIDER,
    call_subprocess,
    format_command_args,
)

logger = logging.getLogger(__name__)


def format_command_result(
    command_args: List[str],
    command_output: str,
) -> str:
    """Format command information for logging."""
    command_desc = format_command_args(command_args)
    text = f"Command arguments: {command_desc}\n"

    if not command_output:
        text += "Command output: None"
    elif logger.getEffectiveLevel() > logging.DEBUG:
        text += "Command output: [use --verbose to show]"
    else:
        if not command_output.endswith("\n"):
            command_output += "\n"
        text += f"Command output:\n{command_output}{LOG_DIVIDER}"

    return text


def get_legacy_build_wheel_path(
    names: List[str],
    temp_dir: str,
    name: str,
    command_args: List[str],
    command_output: str,
) -> Optional[str]:
    """Return the path to the wheel in the temporary build directory."""
    # Sort for determinism.
    names = sorted(names)
    if not names:
        msg = ("Legacy build of wheel for {!r} created no files.\n").format(name)
        msg += format_command_result(command_args, command_output)
        logger.warning(msg)
        return None
FILE: ./venv/Lib/site-packages/pip/_internal/operations/build/__init__.py
FILE: ./venv/Lib/site-packages/pip/_internal/operations/check.py
"""Validation of dependencies of packages
"""

import logging
from typing import Callable, Dict, List, NamedTuple, Optional, Set, Tuple

from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name

from pip._internal.distributions import make_distribution_for_install_requirement
from pip._internal.metadata import get_default_environment
from pip._internal.metadata.base import DistributionVersion
from pip._internal.req.req_install import InstallRequirement

logger = logging.getLogger(__name__)


class PackageDetails(NamedTuple):
    version: DistributionVersion
    dependencies: List[Requirement]


# Shorthands
PackageSet = Dict[NormalizedName, PackageDetails]
Missing = Tuple[NormalizedName, Requirement]
Conflicting = Tuple[NormalizedName, DistributionVersion, Requirement]

MissingDict = Dict[NormalizedName, List[Missing]]
ConflictingDict = Dict[NormalizedName, List[Conflicting]]
CheckResult = Tuple[MissingDict, ConflictingDict]
ConflictDetails = Tuple[PackageSet, CheckResult]


def create_package_set_from_installed() -> Tuple[PackageSet, bool]:
    """Converts a list of distributions into a PackageSet."""
    package_set = {}
    problems = False
    env = get_default_environment()
    for dist in env.iter_installed_distributions(local_only=False, skip=()):
        name = dist.canonical_name
        try:
            dependencies = list(dist.iter_dependencies())
            package_set[name] = PackageDetails(dist.version, dependencies)
        except (OSError, ValueError) as e:
            # Don't crash on unreadable or broken metadata.
            logger.warning("Error parsing requirements for %s: %s", name, e)
            problems = True
    return package_set, problems


FILE: ./venv/Lib/site-packages/pip/_internal/operations/freeze.py
import collections
import logging
import os
from typing import Container, Dict, Iterable, Iterator, List, NamedTuple, Optional, Set

from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.packaging.version import Version

from pip._internal.exceptions import BadCommand, InstallationError
from pip._internal.metadata import BaseDistribution, get_environment
from pip._internal.req.constructors import (
    install_req_from_editable,
    install_req_from_line,
)
from pip._internal.req.req_file import COMMENT_RE
from pip._internal.utils.direct_url_helpers import direct_url_as_pep440_direct_reference

logger = logging.getLogger(__name__)


class _EditableInfo(NamedTuple):
    requirement: str
    comments: List[str]


def freeze(
    requirement: Optional[List[str]] = None,
    local_only: bool = False,
    user_only: bool = False,
    paths: Optional[List[str]] = None,
    isolated: bool = False,
    exclude_editable: bool = False,
    skip: Container[str] = (),
) -> Iterator[str]:
    installations: Dict[str, FrozenRequirement] = {}

    dists = get_environment(paths).iter_installed_distributions(
        local_only=local_only,
        skip=(),
        user_only=user_only,
    )
    for dist in dists:
        req = FrozenRequirement.from_dist(dist)
        if exclude_editable and req.editable:
            continue
        installations[req.canonical_name] = req

    if requirement:
        # the options that don't get turned into an InstallRequirement
        # should only be emitted once, even if the same option is in multiple
FILE: ./venv/Lib/site-packages/pip/_internal/operations/install/editable_legacy.py
"""Legacy editable installation process, i.e. `setup.py develop`.
"""
import logging
from typing import List, Optional, Sequence

from pip._internal.build_env import BuildEnvironment
from pip._internal.utils.logging import indent_log
from pip._internal.utils.setuptools_build import make_setuptools_develop_args
from pip._internal.utils.subprocess import call_subprocess

logger = logging.getLogger(__name__)


def install_editable(
    install_options: List[str],
    global_options: Sequence[str],
    prefix: Optional[str],
    home: Optional[str],
    use_user_site: bool,
    name: str,
    setup_py_path: str,
    isolated: bool,
    build_env: BuildEnvironment,
    unpacked_source_directory: str,
) -> None:
    """Install a package in editable mode. Most arguments are pass-through
    to setuptools.
    """
    logger.info("Running setup.py develop for %s", name)

    args = make_setuptools_develop_args(
        setup_py_path,
        global_options=global_options,
        install_options=install_options,
        no_user_config=isolated,
        prefix=prefix,
        home=home,
        use_user_site=use_user_site,
    )

    with indent_log():
        with build_env:
            call_subprocess(
                args,
                cwd=unpacked_source_directory,
            )
FILE: ./venv/Lib/site-packages/pip/_internal/operations/install/legacy.py
"""Legacy installation process, i.e. `setup.py install`.
"""

import logging
import os
from distutils.util import change_root
from typing import List, Optional, Sequence

from pip._internal.build_env import BuildEnvironment
from pip._internal.exceptions import InstallationError
from pip._internal.models.scheme import Scheme
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import ensure_dir
from pip._internal.utils.setuptools_build import make_setuptools_install_args
from pip._internal.utils.subprocess import runner_with_spinner_message
from pip._internal.utils.temp_dir import TempDirectory

logger = logging.getLogger(__name__)


class LegacyInstallFailure(Exception):
    pass


def write_installed_files_from_setuptools_record(
    record_lines: List[str],
    root: Optional[str],
    req_description: str,
) -> None:
    def prepend_root(path: str) -> str:
        if root is None or not os.path.isabs(path):
            return path
        else:
            return change_root(root, path)

    for line in record_lines:
        directory = os.path.dirname(line)
        if directory.endswith(".egg-info"):
            egg_info_dir = prepend_root(directory)
            break
    else:
        message = (
            "{} did not indicate that it installed an "
            ".egg-info directory. Only setup.py projects "
            "generating .egg-info directories are supported."
        ).format(req_description)
        raise InstallationError(message)

    new_lines = []
    for line in record_lines:
FILE: ./venv/Lib/site-packages/pip/_internal/operations/install/wheel.py
"""Support for installing and building the "wheel" binary package format.
"""

import collections
import compileall
import contextlib
import csv
import importlib
import logging
import os.path
import re
import shutil
import sys
import warnings
from base64 import urlsafe_b64encode
from email.message import Message
from itertools import chain, filterfalse, starmap
from typing import (
    IO,
    TYPE_CHECKING,
    Any,
    BinaryIO,
    Callable,
    Dict,
    Iterable,
    Iterator,
    List,
    NewType,
    Optional,
    Sequence,
    Set,
    Tuple,
    Union,
    cast,
)
from zipfile import ZipFile, ZipInfo

from pip._vendor.distlib.scripts import ScriptMaker
from pip._vendor.distlib.util import get_export_entry
from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.exceptions import InstallationError
from pip._internal.locations import get_major_minor_version
from pip._internal.metadata import (
    BaseDistribution,
    FilesystemWheel,
    get_wheel_distribution,
)
from pip._internal.models.direct_url import DIRECT_URL_METADATA_NAME, DirectUrl
from pip._internal.models.scheme import SCHEME_KEYS, Scheme
FILE: ./venv/Lib/site-packages/pip/_internal/operations/install/__init__.py
"""For modules related to installing packages.
"""
FILE: ./venv/Lib/site-packages/pip/_internal/operations/prepare.py
"""Prepares a distribution for installation
"""

# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import logging
import mimetypes
import os
import shutil
from typing import Dict, Iterable, List, Optional

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.distributions import make_distribution_for_install_requirement
from pip._internal.distributions.installed import InstalledDistribution
from pip._internal.exceptions import (
    DirectoryUrlHashUnsupported,
    HashMismatch,
    HashUnpinned,
    InstallationError,
    NetworkConnectionError,
    PreviousBuildDirError,
    VcsHashUnsupported,
)
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.network.download import BatchDownloader, Downloader
from pip._internal.network.lazy_wheel import (
    HTTPRangeRequestUnsupported,
    dist_from_wheel_url,
)
from pip._internal.network.session import PipSession
from pip._internal.req.req_install import InstallRequirement
from pip._internal.req.req_tracker import RequirementTracker
from pip._internal.utils.filesystem import copy2_fixed
from pip._internal.utils.hashes import Hashes, MissingHashes
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import display_path, hide_url, is_installable_dir, rmtree
from pip._internal.utils.temp_dir import TempDirectory
from pip._internal.utils.unpacking import unpack_file
from pip._internal.vcs import vcs

logger = logging.getLogger(__name__)


def _get_prepared_distribution(
    req: InstallRequirement,
FILE: ./venv/Lib/site-packages/pip/_internal/operations/__init__.py
FILE: ./venv/Lib/site-packages/pip/_internal/pyproject.py
import os
from collections import namedtuple
from typing import Any, List, Optional

from pip._vendor import tomli
from pip._vendor.packaging.requirements import InvalidRequirement, Requirement

from pip._internal.exceptions import InstallationError


def _is_list_of_str(obj: Any) -> bool:
    return isinstance(obj, list) and all(isinstance(item, str) for item in obj)


def make_pyproject_path(unpacked_source_directory: str) -> str:
    return os.path.join(unpacked_source_directory, "pyproject.toml")


BuildSystemDetails = namedtuple(
    "BuildSystemDetails", ["requires", "backend", "check", "backend_path"]
)


def load_pyproject_toml(
    use_pep517: Optional[bool], pyproject_toml: str, setup_py: str, req_name: str
) -> Optional[BuildSystemDetails]:
    """Load the pyproject.toml file.

    Parameters:
        use_pep517 - Has the user requested PEP 517 processing? None
                     means the user hasn't explicitly specified.
        pyproject_toml - Location of the project's pyproject.toml file
        setup_py - Location of the project's setup.py file
        req_name - The name of the requirement we're processing (for
                   error reporting)

    Returns:
        None if we should use the legacy code path, otherwise a tuple
        (
            requirements from pyproject.toml,
            name of PEP 517 backend,
            requirements we should check are installed after setting
                up the build environment
            directory paths to import the backend from (backend-path),
                relative to the project root.
        )
    """
    has_pyproject = os.path.isfile(pyproject_toml)
    has_setup = os.path.isfile(setup_py)

FILE: ./venv/Lib/site-packages/pip/_internal/req/constructors.py
"""Backing implementation for InstallRequirement's various constructors

The idea here is that these formed a major chunk of InstallRequirement's size
so, moving them and support code dedicated to them outside of that class
helps creates for better understandability for the rest of the code.

These are meant to be used elsewhere within pip to create instances of
InstallRequirement.
"""

import logging
import os
import re
from typing import Any, Dict, Optional, Set, Tuple, Union

from pip._vendor.packaging.markers import Marker
from pip._vendor.packaging.requirements import InvalidRequirement, Requirement
from pip._vendor.packaging.specifiers import Specifier
from pip._vendor.pkg_resources import RequirementParseError, parse_requirements

from pip._internal.exceptions import InstallationError
from pip._internal.models.index import PyPI, TestPyPI
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.req.req_file import ParsedRequirement
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.filetypes import is_archive_file
from pip._internal.utils.misc import is_installable_dir
from pip._internal.utils.packaging import get_requirement
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs import is_url, vcs

__all__ = [
    "install_req_from_editable",
    "install_req_from_line",
    "parse_editable",
]

logger = logging.getLogger(__name__)
operators = Specifier._operators.keys()


def _strip_extras(path: str) -> Tuple[str, Optional[str]]:
    m = re.match(r"^(.+)(\[[^\]]+\])$", path)
    extras = None
    if m:
        path_no_extras = m.group(1)
        extras = m.group(2)
    else:
        path_no_extras = path
FILE: ./venv/Lib/site-packages/pip/_internal/req/req_file.py
"""
Requirements file parsing
"""

import optparse
import os
import re
import shlex
import urllib.parse
from optparse import Values
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    Dict,
    Iterable,
    Iterator,
    List,
    Optional,
    Tuple,
)

from pip._internal.cli import cmdoptions
from pip._internal.exceptions import InstallationError, RequirementsFileParseError
from pip._internal.models.search_scope import SearchScope
from pip._internal.network.session import PipSession
from pip._internal.network.utils import raise_for_status
from pip._internal.utils.encoding import auto_decode
from pip._internal.utils.urls import get_url_scheme

if TYPE_CHECKING:
    # NoReturn introduced in 3.6.2; imported only for type checking to maintain
    # pip compatibility with older patch versions of Python 3.6
    from typing import NoReturn

    from pip._internal.index.package_finder import PackageFinder

__all__ = ["parse_requirements"]

ReqFileLines = Iterable[Tuple[int, str]]

LineParser = Callable[[str], Tuple[str, Values]]

SCHEME_RE = re.compile(r"^(http|https|file):", re.I)
COMMENT_RE = re.compile(r"(^|\s+)#.*$")

# Matches environment variable-style values in '${MY_VARIABLE_1}' with the
# variable name consisting of only uppercase letters, digits or the '_'
# (underscore). This follows the POSIX standard defined in IEEE Std 1003.1,
# 2013 Edition.
FILE: ./venv/Lib/site-packages/pip/_internal/req/req_install.py
# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import functools
import logging
import os
import shutil
import sys
import uuid
import zipfile
from typing import Any, Collection, Dict, Iterable, List, Optional, Sequence, Union

from pip._vendor import pkg_resources
from pip._vendor.packaging.markers import Marker
from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.specifiers import SpecifierSet
from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.packaging.version import Version
from pip._vendor.packaging.version import parse as parse_version
from pip._vendor.pep517.wrappers import Pep517HookCaller
from pip._vendor.pkg_resources import Distribution

from pip._internal.build_env import BuildEnvironment, NoOpBuildEnvironment
from pip._internal.exceptions import InstallationError
from pip._internal.locations import get_scheme
from pip._internal.models.link import Link
from pip._internal.operations.build.metadata import generate_metadata
from pip._internal.operations.build.metadata_editable import generate_editable_metadata
from pip._internal.operations.build.metadata_legacy import (
    generate_metadata as generate_metadata_legacy,
)
from pip._internal.operations.install.editable_legacy import (
    install_editable as install_editable_legacy,
)
from pip._internal.operations.install.legacy import LegacyInstallFailure
from pip._internal.operations.install.legacy import install as install_legacy
from pip._internal.operations.install.wheel import install_wheel
from pip._internal.pyproject import load_pyproject_toml, make_pyproject_path
from pip._internal.req.req_uninstall import UninstallPathSet
from pip._internal.utils.deprecation import deprecated
from pip._internal.utils.direct_url_helpers import (
    direct_url_for_editable,
    direct_url_from_link,
)
from pip._internal.utils.hashes import Hashes
from pip._internal.utils.misc import (
    ask_path_exists,
    backup_dir,
    display_path,
    dist_in_site_packages,
FILE: ./venv/Lib/site-packages/pip/_internal/req/req_set.py
import logging
from collections import OrderedDict
from typing import Dict, Iterable, List, Optional, Tuple

from pip._vendor.packaging.utils import canonicalize_name

from pip._internal.exceptions import InstallationError
from pip._internal.models.wheel import Wheel
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils import compatibility_tags

logger = logging.getLogger(__name__)


class RequirementSet:
    def __init__(self, check_supported_wheels: bool = True) -> None:
        """Create a RequirementSet."""

        self.requirements: Dict[str, InstallRequirement] = OrderedDict()
        self.check_supported_wheels = check_supported_wheels

        self.unnamed_requirements: List[InstallRequirement] = []

    def __str__(self) -> str:
        requirements = sorted(
            (req for req in self.requirements.values() if not req.comes_from),
            key=lambda req: canonicalize_name(req.name or ""),
        )
        return " ".join(str(req.req) for req in requirements)

    def __repr__(self) -> str:
        requirements = sorted(
            self.requirements.values(),
            key=lambda req: canonicalize_name(req.name or ""),
        )

        format_string = "<{classname} object; {count} requirement(s): {reqs}>"
        return format_string.format(
            classname=self.__class__.__name__,
            count=len(requirements),
            reqs=", ".join(str(req.req) for req in requirements),
        )

    def add_unnamed_requirement(self, install_req: InstallRequirement) -> None:
        assert not install_req.name
        self.unnamed_requirements.append(install_req)

    def add_named_requirement(self, install_req: InstallRequirement) -> None:
        assert install_req.name

FILE: ./venv/Lib/site-packages/pip/_internal/req/req_tracker.py
import contextlib
import hashlib
import logging
import os
from types import TracebackType
from typing import Dict, Iterator, Optional, Set, Type, Union

from pip._internal.models.link import Link
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.temp_dir import TempDirectory

logger = logging.getLogger(__name__)


@contextlib.contextmanager
def update_env_context_manager(**changes: str) -> Iterator[None]:
    target = os.environ

    # Save values from the target and change them.
    non_existent_marker = object()
    saved_values: Dict[str, Union[object, str]] = {}
    for name, new_value in changes.items():
        try:
            saved_values[name] = target[name]
        except KeyError:
            saved_values[name] = non_existent_marker
        target[name] = new_value

    try:
        yield
    finally:
        # Restore original values in the target.
        for name, original_value in saved_values.items():
            if original_value is non_existent_marker:
                del target[name]
            else:
                assert isinstance(original_value, str)  # for mypy
                target[name] = original_value


@contextlib.contextmanager
def get_requirement_tracker() -> Iterator["RequirementTracker"]:
    root = os.environ.get("PIP_REQ_TRACKER")
    with contextlib.ExitStack() as ctx:
        if root is None:
            root = ctx.enter_context(TempDirectory(kind="req-tracker")).path
            ctx.enter_context(update_env_context_manager(PIP_REQ_TRACKER=root))
            logger.debug("Initialized build tracking at %s", root)

        with RequirementTracker(root) as tracker:
FILE: ./venv/Lib/site-packages/pip/_internal/req/req_uninstall.py
import csv
import functools
import os
import sys
import sysconfig
from importlib.util import cache_from_source
from typing import Any, Callable, Dict, Iterable, Iterator, List, Optional, Set, Tuple

from pip._vendor import pkg_resources
from pip._vendor.pkg_resources import Distribution

from pip._internal.exceptions import UninstallationError
from pip._internal.locations import get_bin_prefix, get_bin_user
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.egg_link import egg_link_path_from_location
from pip._internal.utils.logging import getLogger, indent_log
from pip._internal.utils.misc import (
    ask,
    dist_in_usersite,
    dist_is_local,
    is_local,
    normalize_path,
    renames,
    rmtree,
)
from pip._internal.utils.temp_dir import AdjacentTempDirectory, TempDirectory

logger = getLogger(__name__)


def _script_names(dist: Distribution, script_name: str, is_gui: bool) -> List[str]:
    """Create the fully qualified name of the files created by
    {console,gui}_scripts for the given ``dist``.
    Returns the list of file names
    """
    if dist_in_usersite(dist):
        bin_dir = get_bin_user()
    else:
        bin_dir = get_bin_prefix()
    exe_name = os.path.join(bin_dir, script_name)
    paths_to_remove = [exe_name]
    if WINDOWS:
        paths_to_remove.append(exe_name + ".exe")
        paths_to_remove.append(exe_name + ".exe.manifest")
        if is_gui:
            paths_to_remove.append(exe_name + "-script.pyw")
        else:
            paths_to_remove.append(exe_name + "-script.py")
    return paths_to_remove

FILE: ./venv/Lib/site-packages/pip/_internal/req/__init__.py
import collections
import logging
from typing import Iterator, List, Optional, Sequence, Tuple

from pip._internal.utils.logging import indent_log

from .req_file import parse_requirements
from .req_install import InstallRequirement
from .req_set import RequirementSet

__all__ = [
    "RequirementSet",
    "InstallRequirement",
    "parse_requirements",
    "install_given_reqs",
]

logger = logging.getLogger(__name__)


class InstallationResult:
    def __init__(self, name: str) -> None:
        self.name = name

    def __repr__(self) -> str:
        return f"InstallationResult(name={self.name!r})"


def _validate_requirements(
    requirements: List[InstallRequirement],
) -> Iterator[Tuple[str, InstallRequirement]]:
    for req in requirements:
        assert req.name, f"invalid to-be-installed requirement: {req}"
        yield req.name, req


def install_given_reqs(
    requirements: List[InstallRequirement],
    install_options: List[str],
    global_options: Sequence[str],
    root: Optional[str],
    home: Optional[str],
    prefix: Optional[str],
    warn_script_location: bool,
    use_user_site: bool,
    pycompile: bool,
) -> List[InstallationResult]:
    """
    Install everything in the given list.

FILE: ./venv/Lib/site-packages/pip/_internal/resolution/base.py
from typing import Callable, List, Optional

from pip._internal.req.req_install import InstallRequirement
from pip._internal.req.req_set import RequirementSet

InstallRequirementProvider = Callable[
    [str, Optional[InstallRequirement]], InstallRequirement
]


class BaseResolver:
    def resolve(
        self, root_reqs: List[InstallRequirement], check_supported_wheels: bool
    ) -> RequirementSet:
        raise NotImplementedError()

    def get_installation_order(
        self, req_set: RequirementSet
    ) -> List[InstallRequirement]:
        raise NotImplementedError()
FILE: ./venv/Lib/site-packages/pip/_internal/resolution/legacy/resolver.py
"""Dependency Resolution

The dependency resolution in pip is performed as follows:

for top-level requirements:
    a. only one spec allowed per project, regardless of conflicts or not.
       otherwise a "double requirement" exception is raised
    b. they override sub-dependency requirements.
for sub-dependencies
    a. "first found, wins" (where the order is breadth first)
"""

# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import logging
import sys
from collections import defaultdict
from itertools import chain
from typing import DefaultDict, Iterable, List, Optional, Set, Tuple

from pip._vendor.packaging import specifiers
from pip._vendor.packaging.requirements import Requirement

from pip._internal.cache import WheelCache
from pip._internal.exceptions import (
    BestVersionAlreadyInstalled,
    DistributionNotFound,
    HashError,
    HashErrors,
    NoneMetadataError,
    UnsupportedPythonVersion,
)
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution
from pip._internal.models.link import Link
from pip._internal.operations.prepare import RequirementPreparer
from pip._internal.req.req_install import (
    InstallRequirement,
    check_invalid_constraint_type,
)
from pip._internal.req.req_set import RequirementSet
from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
from pip._internal.utils.compatibility_tags import get_supported
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import dist_in_usersite, normalize_version_info
from pip._internal.utils.packaging import check_requires_python

logger = logging.getLogger(__name__)

FILE: ./venv/Lib/site-packages/pip/_internal/resolution/legacy/__init__.py
FILE: ./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/base.py
from typing import FrozenSet, Iterable, Optional, Tuple, Union

from pip._vendor.packaging.specifiers import SpecifierSet
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import LegacyVersion, Version

from pip._internal.models.link import Link, links_equivalent
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.hashes import Hashes

CandidateLookup = Tuple[Optional["Candidate"], Optional[InstallRequirement]]
CandidateVersion = Union[LegacyVersion, Version]


def format_name(project: str, extras: FrozenSet[str]) -> str:
    if not extras:
        return project
    canonical_extras = sorted(canonicalize_name(e) for e in extras)
    return "{}[{}]".format(project, ",".join(canonical_extras))


class Constraint:
    def __init__(
        self, specifier: SpecifierSet, hashes: Hashes, links: FrozenSet[Link]
    ) -> None:
        self.specifier = specifier
        self.hashes = hashes
        self.links = links

    @classmethod
    def empty(cls) -> "Constraint":
        return Constraint(SpecifierSet(), Hashes(), frozenset())

    @classmethod
    def from_ireq(cls, ireq: InstallRequirement) -> "Constraint":
        links = frozenset([ireq.link]) if ireq.link else frozenset()
        return Constraint(ireq.specifier, ireq.hashes(trust_internet=False), links)

    def __bool__(self) -> bool:
        return bool(self.specifier) or bool(self.hashes) or bool(self.links)

    def __and__(self, other: InstallRequirement) -> "Constraint":
        if not isinstance(other, InstallRequirement):
            return NotImplemented
        specifier = self.specifier & other.specifier
        hashes = self.hashes & other.hashes(trust_internet=False)
        links = self.links
        if other.link:
            links = links.union([other.link])
        return Constraint(specifier, hashes, links)
FILE: ./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/candidates.py
import logging
import sys
from typing import TYPE_CHECKING, Any, FrozenSet, Iterable, Optional, Tuple, Union, cast

from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.packaging.version import Version

from pip._internal.exceptions import HashError, MetadataInconsistent
from pip._internal.metadata import BaseDistribution
from pip._internal.models.link import Link, links_equivalent
from pip._internal.models.wheel import Wheel
from pip._internal.req.constructors import (
    install_req_from_editable,
    install_req_from_line,
)
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.misc import normalize_version_info

from .base import Candidate, CandidateVersion, Requirement, format_name

if TYPE_CHECKING:
    from .factory import Factory

logger = logging.getLogger(__name__)

BaseCandidate = Union[
    "AlreadyInstalledCandidate",
    "EditableCandidate",
    "LinkCandidate",
]

# Avoid conflicting with the PyPI package "Python".
REQUIRES_PYTHON_IDENTIFIER = cast(NormalizedName, "<Python from Requires-Python>")


def as_base_candidate(candidate: Candidate) -> Optional[BaseCandidate]:
    """The runtime version of BaseCandidate."""
    base_candidate_classes = (
        AlreadyInstalledCandidate,
        EditableCandidate,
        LinkCandidate,
    )
    if isinstance(candidate, base_candidate_classes):
        return candidate
    return None


def make_install_req_from_link(
    link: Link, template: InstallRequirement
) -> InstallRequirement:
FILE: ./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/factory.py
import contextlib
import functools
import logging
from typing import (
    TYPE_CHECKING,
    Dict,
    FrozenSet,
    Iterable,
    Iterator,
    List,
    Mapping,
    NamedTuple,
    Optional,
    Sequence,
    Set,
    Tuple,
    TypeVar,
    cast,
)

from pip._vendor.packaging.requirements import InvalidRequirement
from pip._vendor.packaging.specifiers import SpecifierSet
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
from pip._vendor.resolvelib import ResolutionImpossible

from pip._internal.cache import CacheEntry, WheelCache
from pip._internal.exceptions import (
    DistributionNotFound,
    InstallationError,
    InstallationSubprocessError,
    MetadataInconsistent,
    UnsupportedPythonVersion,
    UnsupportedWheel,
)
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution, get_default_environment
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.operations.prepare import RequirementPreparer
from pip._internal.req.constructors import install_req_from_link_and_ireq
from pip._internal.req.req_install import (
    InstallRequirement,
    check_invalid_constraint_type,
)
from pip._internal.resolution.base import InstallRequirementProvider
from pip._internal.utils.compatibility_tags import get_supported
from pip._internal.utils.hashes import Hashes
from pip._internal.utils.packaging import get_requirement
from pip._internal.utils.virtualenv import running_under_virtualenv

FILE: ./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py
"""Utilities to lazily create and visit candidates found.

Creating and visiting a candidate is a *very* costly operation. It involves
fetching, extracting, potentially building modules from source, and verifying
distribution metadata. It is therefore crucial for performance to keep
everything here lazy all the way down, so we only touch candidates that we
absolutely need, and not "download the world" when we only need one version of
something.
"""

import functools
from collections.abc import Sequence
from typing import TYPE_CHECKING, Any, Callable, Iterator, Optional, Set, Tuple

from pip._vendor.packaging.version import _BaseVersion

from .base import Candidate

IndexCandidateInfo = Tuple[_BaseVersion, Callable[[], Optional[Candidate]]]

if TYPE_CHECKING:
    SequenceCandidate = Sequence[Candidate]
else:
    # For compatibility: Python before 3.9 does not support using [] on the
    # Sequence class.
    #
    # >>> from collections.abc import Sequence
    # >>> Sequence[str]
    # Traceback (most recent call last):
    #   File "<stdin>", line 1, in <module>
    # TypeError: 'ABCMeta' object is not subscriptable
    #
    # TODO: Remove this block after dropping Python 3.8 support.
    SequenceCandidate = Sequence


def _iter_built(infos: Iterator[IndexCandidateInfo]) -> Iterator[Candidate]:
    """Iterator for ``FoundCandidates``.

    This iterator is used when the package is not already installed. Candidates
    from index come later in their normal ordering.
    """
    versions_found: Set[_BaseVersion] = set()
    for version, func in infos:
        if version in versions_found:
            continue
        candidate = func()
        if candidate is None:
            continue
        yield candidate
FILE: ./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/provider.py
import collections
import math
from typing import TYPE_CHECKING, Dict, Iterable, Iterator, Mapping, Sequence, Union

from pip._vendor.resolvelib.providers import AbstractProvider

from .base import Candidate, Constraint, Requirement
from .candidates import REQUIRES_PYTHON_IDENTIFIER
from .factory import Factory

if TYPE_CHECKING:
    from pip._vendor.resolvelib.providers import Preference
    from pip._vendor.resolvelib.resolvers import RequirementInformation

    PreferenceInformation = RequirementInformation[Requirement, Candidate]

    _ProviderBase = AbstractProvider[Requirement, Candidate, str]
else:
    _ProviderBase = AbstractProvider

# Notes on the relationship between the provider, the factory, and the
# candidate and requirement classes.
#
# The provider is a direct implementation of the resolvelib class. Its role
# is to deliver the API that resolvelib expects.
#
# Rather than work with completely abstract "requirement" and "candidate"
# concepts as resolvelib does, pip has concrete classes implementing these two
# ideas. The API of Requirement and Candidate objects are defined in the base
# classes, but essentially map fairly directly to the equivalent provider
# methods. In particular, `find_matches` and `is_satisfied_by` are
# requirement methods, and `get_dependencies` is a candidate method.
#
# The factory is the interface to pip's internal mechanisms. It is stateless,
# and is created by the resolver and held as a property of the provider. It is
# responsible for creating Requirement and Candidate objects, and provides
# services to those objects (access to pip's finder and preparer).


class PipProvider(_ProviderBase):
    """Pip's provider implementation for resolvelib.

    :params constraints: A mapping of constraints specified by the user. Keys
        are canonicalized project names.
    :params ignore_dependencies: Whether the user specified ``--no-deps``.
    :params upgrade_strategy: The user-specified upgrade strategy.
    :params user_requested: A set of canonicalized package names that the user
        supplied for pip to install/upgrade.
    """

FILE: ./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/reporter.py
from collections import defaultdict
from logging import getLogger
from typing import Any, DefaultDict

from pip._vendor.resolvelib.reporters import BaseReporter

from .base import Candidate, Requirement

logger = getLogger(__name__)


class PipReporter(BaseReporter):
    def __init__(self) -> None:
        self.backtracks_by_package: DefaultDict[str, int] = defaultdict(int)

        self._messages_at_backtrack = {
            1: (
                "pip is looking at multiple versions of {package_name} to "
                "determine which version is compatible with other "
                "requirements. This could take a while."
            ),
            8: (
                "pip is looking at multiple versions of {package_name} to "
                "determine which version is compatible with other "
                "requirements. This could take a while."
            ),
            13: (
                "This is taking longer than usual. You might need to provide "
                "the dependency resolver with stricter constraints to reduce "
                "runtime. See https://pip.pypa.io/warnings/backtracking for "
                "guidance. If you want to abort this run, press Ctrl + C."
            ),
        }

    def backtracking(self, candidate: Candidate) -> None:
        self.backtracks_by_package[candidate.name] += 1

        count = self.backtracks_by_package[candidate.name]
        if count not in self._messages_at_backtrack:
            return

        message = self._messages_at_backtrack[count]
        logger.info("INFO: %s", message.format(package_name=candidate.name))


class PipDebuggingReporter(BaseReporter):
    """A reporter that does an info log for every event it sees."""

    def starting(self) -> None:
        logger.info("Reporter.starting()")
FILE: ./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/requirements.py
from pip._vendor.packaging.specifiers import SpecifierSet
from pip._vendor.packaging.utils import NormalizedName, canonicalize_name

from pip._internal.req.req_install import InstallRequirement

from .base import Candidate, CandidateLookup, Requirement, format_name


class ExplicitRequirement(Requirement):
    def __init__(self, candidate: Candidate) -> None:
        self.candidate = candidate

    def __str__(self) -> str:
        return str(self.candidate)

    def __repr__(self) -> str:
        return "{class_name}({candidate!r})".format(
            class_name=self.__class__.__name__,
            candidate=self.candidate,
        )

    @property
    def project_name(self) -> NormalizedName:
        # No need to canonicalise - the candidate did this
        return self.candidate.project_name

    @property
    def name(self) -> str:
        # No need to canonicalise - the candidate did this
        return self.candidate.name

    def format_for_error(self) -> str:
        return self.candidate.format_for_error()

    def get_candidate_lookup(self) -> CandidateLookup:
        return self.candidate, None

    def is_satisfied_by(self, candidate: Candidate) -> bool:
        return candidate == self.candidate


class SpecifierRequirement(Requirement):
    def __init__(self, ireq: InstallRequirement) -> None:
        assert ireq.link is None, "This is a link, not a specifier"
        self._ireq = ireq
        self._extras = frozenset(ireq.extras)

    def __str__(self) -> str:
        return str(self._ireq.req)

FILE: ./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/resolver.py
import functools
import logging
import os
from typing import TYPE_CHECKING, Dict, List, Optional, Set, Tuple, cast

from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.resolvelib import BaseReporter, ResolutionImpossible
from pip._vendor.resolvelib import Resolver as RLResolver
from pip._vendor.resolvelib.structs import DirectedGraph

from pip._internal.cache import WheelCache
from pip._internal.index.package_finder import PackageFinder
from pip._internal.operations.prepare import RequirementPreparer
from pip._internal.req.req_install import InstallRequirement
from pip._internal.req.req_set import RequirementSet
from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
from pip._internal.resolution.resolvelib.provider import PipProvider
from pip._internal.resolution.resolvelib.reporter import (
    PipDebuggingReporter,
    PipReporter,
)

from .base import Candidate, Requirement
from .factory import Factory

if TYPE_CHECKING:
    from pip._vendor.resolvelib.resolvers import Result as RLResult

    Result = RLResult[Requirement, Candidate, str]


logger = logging.getLogger(__name__)


class Resolver(BaseResolver):
    _allowed_strategies = {"eager", "only-if-needed", "to-satisfy-only"}

    def __init__(
        self,
        preparer: RequirementPreparer,
        finder: PackageFinder,
        wheel_cache: Optional[WheelCache],
        make_install_req: InstallRequirementProvider,
        use_user_site: bool,
        ignore_dependencies: bool,
        ignore_installed: bool,
        ignore_requires_python: bool,
        force_reinstall: bool,
        upgrade_strategy: str,
        py_version_info: Optional[Tuple[int, ...]] = None,
FILE: ./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/__init__.py
FILE: ./venv/Lib/site-packages/pip/_internal/resolution/__init__.py
FILE: ./venv/Lib/site-packages/pip/_internal/self_outdated_check.py
import datetime
import hashlib
import json
import logging
import optparse
import os.path
import sys
from typing import Any, Dict

from pip._vendor.packaging.version import parse as parse_version

from pip._internal.index.collector import LinkCollector
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import get_default_environment
from pip._internal.models.selection_prefs import SelectionPreferences
from pip._internal.network.session import PipSession
from pip._internal.utils.filesystem import adjacent_tmp_file, check_path_owner, replace
from pip._internal.utils.misc import ensure_dir

SELFCHECK_DATE_FMT = "%Y-%m-%dT%H:%M:%SZ"


logger = logging.getLogger(__name__)


def _get_statefile_name(key: str) -> str:
    key_bytes = key.encode()
    name = hashlib.sha224(key_bytes).hexdigest()
    return name


class SelfCheckState:
    def __init__(self, cache_dir: str) -> None:
        self.state: Dict[str, Any] = {}
        self.statefile_path = None

        # Try to load the existing state
        if cache_dir:
            self.statefile_path = os.path.join(
                cache_dir, "selfcheck", _get_statefile_name(self.key)
            )
            try:
                with open(self.statefile_path, encoding="utf-8") as statefile:
                    self.state = json.load(statefile)
            except (OSError, ValueError, KeyError):
                # Explicitly suppressing exceptions, since we don't want to
                # error out if the cache file is invalid.
                pass

    @property
FILE: ./venv/Lib/site-packages/pip/_internal/utils/appdirs.py
"""
This code wraps the vendored appdirs module to so the return values are
compatible for the current pip code base.

The intention is to rewrite current usages gradually, keeping the tests pass,
and eventually drop this after all usages are changed.
"""

import os
import sys
from typing import List

from pip._vendor import platformdirs as _appdirs


def user_cache_dir(appname: str) -> str:
    return _appdirs.user_cache_dir(appname, appauthor=False)


def _macos_user_config_dir(appname: str, roaming: bool = True) -> str:
    # Use ~/Application Support/pip, if the directory exists.
    path = _appdirs.user_data_dir(appname, appauthor=False, roaming=roaming)
    if os.path.isdir(path):
        return path

    # Use a Linux-like ~/.config/pip, by default.
    linux_like_path = "~/.config/"
    if appname:
        linux_like_path = os.path.join(linux_like_path, appname)

    return os.path.expanduser(linux_like_path)


def user_config_dir(appname: str, roaming: bool = True) -> str:
    if sys.platform == "darwin":
        return _macos_user_config_dir(appname, roaming)

    return _appdirs.user_config_dir(appname, appauthor=False, roaming=roaming)


# for the discussion regarding site_config_dir locations
# see <https://github.com/pypa/pip/issues/1733>
def site_config_dirs(appname: str) -> List[str]:
    if sys.platform == "darwin":
        return [_appdirs.site_data_dir(appname, appauthor=False, multipath=True)]

    dirval = _appdirs.site_config_dir(appname, appauthor=False, multipath=True)
    if sys.platform == "win32":
        return [dirval]

FILE: ./venv/Lib/site-packages/pip/_internal/utils/compat.py
"""Stuff that differs in different Python versions and platform
distributions."""

import logging
import os
import sys

__all__ = ["get_path_uid", "stdlib_pkgs", "WINDOWS"]


logger = logging.getLogger(__name__)


def has_tls() -> bool:
    try:
        import _ssl  # noqa: F401  # ignore unused

        return True
    except ImportError:
        pass

    from pip._vendor.urllib3.util import IS_PYOPENSSL

    return IS_PYOPENSSL


def get_path_uid(path: str) -> int:
    """
    Return path's uid.

    Does not follow symlinks:
        https://github.com/pypa/pip/pull/935#discussion_r5307003

    Placed this function in compat due to differences on AIX and
    Jython, that should eventually go away.

    :raises OSError: When path is a symlink or can't be read.
    """
    if hasattr(os, "O_NOFOLLOW"):
        fd = os.open(path, os.O_RDONLY | os.O_NOFOLLOW)
        file_uid = os.fstat(fd).st_uid
        os.close(fd)
    else:  # AIX and Jython
        # WARNING: time of check vulnerability, but best we can do w/o NOFOLLOW
        if not os.path.islink(path):
            # older versions of Jython don't have `os.fstat`
            file_uid = os.stat(path).st_uid
        else:
            # raise OSError for parity with os.O_NOFOLLOW above
            raise OSError(f"{path} is a symlink; Will not return uid for symlinks")
FILE: ./venv/Lib/site-packages/pip/_internal/utils/compatibility_tags.py
"""Generate and work with PEP 425 Compatibility Tags.
"""

import re
from typing import List, Optional, Tuple

from pip._vendor.packaging.tags import (
    PythonVersion,
    Tag,
    compatible_tags,
    cpython_tags,
    generic_tags,
    interpreter_name,
    interpreter_version,
    mac_platforms,
)

_osx_arch_pat = re.compile(r"(.+)_(\d+)_(\d+)_(.+)")


def version_info_to_nodot(version_info: Tuple[int, ...]) -> str:
    # Only use up to the first two numbers.
    return "".join(map(str, version_info[:2]))


def _mac_platforms(arch: str) -> List[str]:
    match = _osx_arch_pat.match(arch)
    if match:
        name, major, minor, actual_arch = match.groups()
        mac_version = (int(major), int(minor))
        arches = [
            # Since we have always only checked that the platform starts
            # with "macosx", for backwards-compatibility we extract the
            # actual prefix provided by the user in case they provided
            # something like "macosxcustom_". It may be good to remove
            # this as undocumented or deprecate it in the future.
            "{}_{}".format(name, arch[len("macosx_") :])
            for arch in mac_platforms(mac_version, actual_arch)
        ]
    else:
        # arch pattern didn't match (?!)
        arches = [arch]
    return arches


def _custom_manylinux_platforms(arch: str) -> List[str]:
    arches = [arch]
    arch_prefix, arch_sep, arch_suffix = arch.partition("_")
    if arch_prefix == "manylinux2014":
        # manylinux1/manylinux2010 wheels run on most manylinux2014 systems
FILE: ./venv/Lib/site-packages/pip/_internal/utils/datetime.py
"""For when pip wants to check the date or time.
"""

import datetime


def today_is_later_than(year: int, month: int, day: int) -> bool:
    today = datetime.date.today()
    given = datetime.date(year, month, day)

    return today > given
FILE: ./venv/Lib/site-packages/pip/_internal/utils/deprecation.py
"""
A module that implements tooling to enable easy warnings about deprecations.
"""

import logging
import warnings
from typing import Any, Optional, TextIO, Type, Union

from pip._vendor.packaging.version import parse

from pip import __version__ as current_version  # NOTE: tests patch this name.

DEPRECATION_MSG_PREFIX = "DEPRECATION: "


class PipDeprecationWarning(Warning):
    pass


_original_showwarning: Any = None


# Warnings <-> Logging Integration
def _showwarning(
    message: Union[Warning, str],
    category: Type[Warning],
    filename: str,
    lineno: int,
    file: Optional[TextIO] = None,
    line: Optional[str] = None,
) -> None:
    if file is not None:
        if _original_showwarning is not None:
            _original_showwarning(message, category, filename, lineno, file, line)
    elif issubclass(category, PipDeprecationWarning):
        # We use a specially named logger which will handle all of the
        # deprecation messages for pip.
        logger = logging.getLogger("pip._internal.deprecations")
        logger.warning(message)
    else:
        _original_showwarning(message, category, filename, lineno, file, line)


def install_warning_logger() -> None:
    # Enable our Deprecation Warnings
    warnings.simplefilter("default", PipDeprecationWarning, append=True)

    global _original_showwarning

    if _original_showwarning is None:
FILE: ./venv/Lib/site-packages/pip/_internal/utils/direct_url_helpers.py
from typing import Optional

from pip._internal.models.direct_url import ArchiveInfo, DirectUrl, DirInfo, VcsInfo
from pip._internal.models.link import Link
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs import vcs


def direct_url_as_pep440_direct_reference(direct_url: DirectUrl, name: str) -> str:
    """Convert a DirectUrl to a pip requirement string."""
    direct_url.validate()  # if invalid, this is a pip bug
    requirement = name + " @ "
    fragments = []
    if isinstance(direct_url.info, VcsInfo):
        requirement += "{}+{}@{}".format(
            direct_url.info.vcs, direct_url.url, direct_url.info.commit_id
        )
    elif isinstance(direct_url.info, ArchiveInfo):
        requirement += direct_url.url
        if direct_url.info.hash:
            fragments.append(direct_url.info.hash)
    else:
        assert isinstance(direct_url.info, DirInfo)
        requirement += direct_url.url
    if direct_url.subdirectory:
        fragments.append("subdirectory=" + direct_url.subdirectory)
    if fragments:
        requirement += "#" + "&".join(fragments)
    return requirement


def direct_url_for_editable(source_dir: str) -> DirectUrl:
    return DirectUrl(
        url=path_to_url(source_dir),
        info=DirInfo(editable=True),
    )


def direct_url_from_link(
    link: Link, source_dir: Optional[str] = None, link_is_in_wheel_cache: bool = False
) -> DirectUrl:
    if link.is_vcs:
        vcs_backend = vcs.get_backend_for_scheme(link.scheme)
        assert vcs_backend
        url, requested_revision, _ = vcs_backend.get_url_rev_and_auth(
            link.url_without_fragment
        )
        # For VCS links, we need to find out and add commit_id.
        if link_is_in_wheel_cache:
            # If the requested VCS link corresponds to a cached
FILE: ./venv/Lib/site-packages/pip/_internal/utils/distutils_args.py
from distutils.errors import DistutilsArgError
from distutils.fancy_getopt import FancyGetopt
from typing import Dict, List

_options = [
    ("exec-prefix=", None, ""),
    ("home=", None, ""),
    ("install-base=", None, ""),
    ("install-data=", None, ""),
    ("install-headers=", None, ""),
    ("install-lib=", None, ""),
    ("install-platlib=", None, ""),
    ("install-purelib=", None, ""),
    ("install-scripts=", None, ""),
    ("prefix=", None, ""),
    ("root=", None, ""),
    ("user", None, ""),
]


# typeshed doesn't permit Tuple[str, None, str], see python/typeshed#3469.
_distutils_getopt = FancyGetopt(_options)  # type: ignore


def parse_distutils_args(args: List[str]) -> Dict[str, str]:
    """Parse provided arguments, returning an object that has the
    matched arguments.

    Any unknown arguments are ignored.
    """
    result = {}
    for arg in args:
        try:
            _, match = _distutils_getopt.getopt(args=[arg])
        except DistutilsArgError:
            # We don't care about any other options, which here may be
            # considered unrecognized since our option list is not
            # exhaustive.
            pass
        else:
            result.update(match.__dict__)
    return result
FILE: ./venv/Lib/site-packages/pip/_internal/utils/egg_link.py
# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import os
import re
import sys
from typing import Optional

from pip._internal.locations import site_packages, user_site
from pip._internal.utils.virtualenv import (
    running_under_virtualenv,
    virtualenv_no_global,
)

__all__ = [
    "egg_link_path_from_sys_path",
    "egg_link_path_from_location",
]


def _egg_link_name(raw_name: str) -> str:
    """
    Convert a Name metadata value to a .egg-link name, by applying
    the same substitution as pkg_resources's safe_name function.
    Note: we cannot use canonicalize_name because it has a different logic.
    """
    return re.sub("[^A-Za-z0-9.]+", "-", raw_name) + ".egg-link"


def egg_link_path_from_sys_path(raw_name: str) -> Optional[str]:
    """
    Look for a .egg-link file for project name, by walking sys.path.
    """
    egg_link_name = _egg_link_name(raw_name)
    for path_item in sys.path:
        egg_link = os.path.join(path_item, egg_link_name)
        if os.path.isfile(egg_link):
            return egg_link
    return None


def egg_link_path_from_location(raw_name: str) -> Optional[str]:
    """
    Return the path for the .egg-link file if it exists, otherwise, None.

    There's 3 scenarios:
    1) not in a virtualenv
       try to find in site.USER_SITE, then site_packages
    2) in a no-global virtualenv
       try to find in site_packages
FILE: ./venv/Lib/site-packages/pip/_internal/utils/encoding.py
import codecs
import locale
import re
import sys
from typing import List, Tuple

BOMS: List[Tuple[bytes, str]] = [
    (codecs.BOM_UTF8, "utf-8"),
    (codecs.BOM_UTF16, "utf-16"),
    (codecs.BOM_UTF16_BE, "utf-16-be"),
    (codecs.BOM_UTF16_LE, "utf-16-le"),
    (codecs.BOM_UTF32, "utf-32"),
    (codecs.BOM_UTF32_BE, "utf-32-be"),
    (codecs.BOM_UTF32_LE, "utf-32-le"),
]

ENCODING_RE = re.compile(br"coding[:=]\s*([-\w.]+)")


def auto_decode(data: bytes) -> str:
    """Check a bytes string for a BOM to correctly detect the encoding

    Fallback to locale.getpreferredencoding(False) like open() on Python3"""
    for bom, encoding in BOMS:
        if data.startswith(bom):
            return data[len(bom) :].decode(encoding)
    # Lets check the first two lines as in PEP263
    for line in data.split(b"\n")[:2]:
        if line[0:1] == b"#" and ENCODING_RE.search(line):
            result = ENCODING_RE.search(line)
            assert result is not None
            encoding = result.groups()[0].decode("ascii")
            return data.decode(encoding)
    return data.decode(
        locale.getpreferredencoding(False) or sys.getdefaultencoding(),
    )
FILE: ./venv/Lib/site-packages/pip/_internal/utils/entrypoints.py
import sys
from typing import List, Optional

from pip._internal.cli.main import main


def _wrapper(args: Optional[List[str]] = None) -> int:
    """Central wrapper for all old entrypoints.

    Historically pip has had several entrypoints defined. Because of issues
    arising from PATH, sys.path, multiple Pythons, their interactions, and most
    of them having a pip installed, users suffer every time an entrypoint gets
    moved.

    To alleviate this pain, and provide a mechanism for warning users and
    directing them to an appropriate place for help, we now define all of
    our old entrypoints as wrappers for the current one.
    """
    sys.stderr.write(
        "WARNING: pip is being invoked by an old script wrapper. This will "
        "fail in a future version of pip.\n"
        "Please see https://github.com/pypa/pip/issues/5599 for advice on "
        "fixing the underlying issue.\n"
        "To avoid this problem you can invoke Python with '-m pip' instead of "
        "running pip directly.\n"
    )
    return main(args)
FILE: ./venv/Lib/site-packages/pip/_internal/utils/filesystem.py
import fnmatch
import os
import os.path
import random
import shutil
import stat
import sys
from contextlib import contextmanager
from tempfile import NamedTemporaryFile
from typing import Any, BinaryIO, Iterator, List, Union, cast

from pip._vendor.tenacity import retry, stop_after_delay, wait_fixed

from pip._internal.utils.compat import get_path_uid
from pip._internal.utils.misc import format_size


def check_path_owner(path: str) -> bool:
    # If we don't have a way to check the effective uid of this process, then
    # we'll just assume that we own the directory.
    if sys.platform == "win32" or not hasattr(os, "geteuid"):
        return True

    assert os.path.isabs(path)

    previous = None
    while path != previous:
        if os.path.lexists(path):
            # Check if path is writable by current user.
            if os.geteuid() == 0:
                # Special handling for root user in order to handle properly
                # cases where users use sudo without -H flag.
                try:
                    path_uid = get_path_uid(path)
                except OSError:
                    return False
                return path_uid == 0
            else:
                return os.access(path, os.W_OK)
        else:
            previous, path = path, os.path.dirname(path)
    return False  # assume we don't own the path


def copy2_fixed(src: str, dest: str) -> None:
    """Wrap shutil.copy2() but map errors copying socket files to
    SpecialFileError as expected.

    See also https://bugs.python.org/issue37700.
    """
FILE: ./venv/Lib/site-packages/pip/_internal/utils/filetypes.py
"""Filetype information.
"""

from typing import Tuple

from pip._internal.utils.misc import splitext

WHEEL_EXTENSION = ".whl"
BZ2_EXTENSIONS: Tuple[str, ...] = (".tar.bz2", ".tbz")
XZ_EXTENSIONS: Tuple[str, ...] = (
    ".tar.xz",
    ".txz",
    ".tlz",
    ".tar.lz",
    ".tar.lzma",
)
ZIP_EXTENSIONS: Tuple[str, ...] = (".zip", WHEEL_EXTENSION)
TAR_EXTENSIONS: Tuple[str, ...] = (".tar.gz", ".tgz", ".tar")
ARCHIVE_EXTENSIONS = ZIP_EXTENSIONS + BZ2_EXTENSIONS + TAR_EXTENSIONS + XZ_EXTENSIONS


def is_archive_file(name: str) -> bool:
    """Return True if `name` is a considered as an archive file."""
    ext = splitext(name)[1].lower()
    if ext in ARCHIVE_EXTENSIONS:
        return True
    return False
FILE: ./venv/Lib/site-packages/pip/_internal/utils/glibc.py
# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import os
import sys
from typing import Optional, Tuple


def glibc_version_string() -> Optional[str]:
    "Returns glibc version string, or None if not using glibc."
    return glibc_version_string_confstr() or glibc_version_string_ctypes()


def glibc_version_string_confstr() -> Optional[str]:
    "Primary implementation of glibc_version_string using os.confstr."
    # os.confstr is quite a bit faster than ctypes.DLL. It's also less likely
    # to be broken or missing. This strategy is used in the standard library
    # platform module:
    # https://github.com/python/cpython/blob/fcf1d003bf4f0100c9d0921ff3d70e1127ca1b71/Lib/platform.py#L175-L183
    if sys.platform == "win32":
        return None
    try:
        # os.confstr("CS_GNU_LIBC_VERSION") returns a string like "glibc 2.17":
        _, version = os.confstr("CS_GNU_LIBC_VERSION").split()
    except (AttributeError, OSError, ValueError):
        # os.confstr() or CS_GNU_LIBC_VERSION not available (or a bad value)...
        return None
    return version


def glibc_version_string_ctypes() -> Optional[str]:
    "Fallback implementation of glibc_version_string using ctypes."

    try:
        import ctypes
    except ImportError:
        return None

    # ctypes.CDLL(None) internally calls dlopen(NULL), and as the dlopen
    # manpage says, "If filename is NULL, then the returned handle is for the
    # main program". This way we can let the linker do the work to figure out
    # which libc our process is actually using.
    process_namespace = ctypes.CDLL(None)
    try:
        gnu_get_libc_version = process_namespace.gnu_get_libc_version
    except AttributeError:
        # Symbol doesn't exist -> therefore, we are not linked to
        # glibc.
        return None

FILE: ./venv/Lib/site-packages/pip/_internal/utils/hashes.py
import hashlib
from typing import TYPE_CHECKING, BinaryIO, Dict, Iterator, List

from pip._internal.exceptions import HashMismatch, HashMissing, InstallationError
from pip._internal.utils.misc import read_chunks

if TYPE_CHECKING:
    from hashlib import _Hash

    # NoReturn introduced in 3.6.2; imported only for type checking to maintain
    # pip compatibility with older patch versions of Python 3.6
    from typing import NoReturn


# The recommended hash algo of the moment. Change this whenever the state of
# the art changes; it won't hurt backward compatibility.
FAVORITE_HASH = "sha256"


# Names of hashlib algorithms allowed by the --hash option and ``pip hash``
# Currently, those are the ones at least as collision-resistant as sha256.
STRONG_HASHES = ["sha256", "sha384", "sha512"]


class Hashes:
    """A wrapper that builds multiple hashes at once and checks them against
    known-good values

    """

    def __init__(self, hashes: Dict[str, List[str]] = None) -> None:
        """
        :param hashes: A dict of algorithm names pointing to lists of allowed
            hex digests
        """
        allowed = {}
        if hashes is not None:
            for alg, keys in hashes.items():
                # Make sure values are always sorted (to ease equality checks)
                allowed[alg] = sorted(keys)
        self._allowed = allowed

    def __and__(self, other: "Hashes") -> "Hashes":
        if not isinstance(other, Hashes):
            return NotImplemented

        # If either of the Hashes object is entirely empty (i.e. no hash
        # specified at all), all hashes from the other object are allowed.
        if not other:
            return self
FILE: ./venv/Lib/site-packages/pip/_internal/utils/inject_securetransport.py
"""A helper module that injects SecureTransport, on import.

The import should be done as early as possible, to ensure all requests and
sessions (or whatever) are created after injecting SecureTransport.

Note that we only do the injection on macOS, when the linked OpenSSL is too
old to handle TLSv1.2.
"""

import sys


def inject_securetransport() -> None:
    # Only relevant on macOS
    if sys.platform != "darwin":
        return

    try:
        import ssl
    except ImportError:
        return

    # Checks for OpenSSL 1.0.1
    if ssl.OPENSSL_VERSION_NUMBER >= 0x1000100F:
        return

    try:
        from pip._vendor.urllib3.contrib import securetransport
    except (ImportError, OSError):
        return

    securetransport.inject_into_urllib3()


inject_securetransport()
FILE: ./venv/Lib/site-packages/pip/_internal/utils/logging.py
import contextlib
import errno
import logging
import logging.handlers
import os
import sys
from logging import Filter
from typing import IO, Any, Callable, Iterator, Optional, TextIO, Type, cast

from pip._internal.utils._log import VERBOSE, getLogger
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.deprecation import DEPRECATION_MSG_PREFIX
from pip._internal.utils.misc import ensure_dir

try:
    import threading
except ImportError:
    import dummy_threading as threading  # type: ignore


try:
    from pip._vendor import colorama
# Lots of different errors can come from this, including SystemError and
# ImportError.
except Exception:
    colorama = None


_log_state = threading.local()
subprocess_logger = getLogger("pip.subprocessor")


class BrokenStdoutLoggingError(Exception):
    """
    Raised if BrokenPipeError occurs for the stdout stream while logging.
    """


def _is_broken_pipe_error(exc_class: Type[BaseException], exc: BaseException) -> bool:
    if exc_class is BrokenPipeError:
        return True

    # On Windows, a broken pipe can show up as EINVAL rather than EPIPE:
    # https://bugs.python.org/issue19612
    # https://bugs.python.org/issue30418
    if not WINDOWS:
        return False

    return isinstance(exc, OSError) and exc.errno in (errno.EINVAL, errno.EPIPE)

FILE: ./venv/Lib/site-packages/pip/_internal/utils/misc.py
# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import contextlib
import errno
import getpass
import hashlib
import io
import logging
import os
import posixpath
import shutil
import stat
import sys
import urllib.parse
from io import StringIO
from itertools import filterfalse, tee, zip_longest
from types import TracebackType
from typing import (
    Any,
    BinaryIO,
    Callable,
    ContextManager,
    Iterable,
    Iterator,
    List,
    Optional,
    TextIO,
    Tuple,
    Type,
    TypeVar,
    cast,
)

from pip._vendor.pkg_resources import Distribution
from pip._vendor.tenacity import retry, stop_after_delay, wait_fixed

from pip import __version__
from pip._internal.exceptions import CommandError
from pip._internal.locations import get_major_minor_version, site_packages, user_site
from pip._internal.utils.compat import WINDOWS
from pip._internal.utils.egg_link import egg_link_path_from_location
from pip._internal.utils.virtualenv import running_under_virtualenv

__all__ = [
    "rmtree",
    "display_path",
    "backup_dir",
    "ask",
    "splitext",
FILE: ./venv/Lib/site-packages/pip/_internal/utils/models.py
"""Utilities for defining models
"""

import operator
from typing import Any, Callable, Type


class KeyBasedCompareMixin:
    """Provides comparison capabilities that is based on a key"""

    __slots__ = ["_compare_key", "_defining_class"]

    def __init__(self, key: Any, defining_class: Type["KeyBasedCompareMixin"]) -> None:
        self._compare_key = key
        self._defining_class = defining_class

    def __hash__(self) -> int:
        return hash(self._compare_key)

    def __lt__(self, other: Any) -> bool:
        return self._compare(other, operator.__lt__)

    def __le__(self, other: Any) -> bool:
        return self._compare(other, operator.__le__)

    def __gt__(self, other: Any) -> bool:
        return self._compare(other, operator.__gt__)

    def __ge__(self, other: Any) -> bool:
        return self._compare(other, operator.__ge__)

    def __eq__(self, other: Any) -> bool:
        return self._compare(other, operator.__eq__)

    def _compare(self, other: Any, method: Callable[[Any, Any], bool]) -> bool:
        if not isinstance(other, self._defining_class):
            return NotImplemented

        return method(self._compare_key, other._compare_key)
FILE: ./venv/Lib/site-packages/pip/_internal/utils/packaging.py
import functools
import logging
from email.message import Message
from email.parser import FeedParser
from typing import Optional, Tuple

from pip._vendor import pkg_resources
from pip._vendor.packaging import specifiers, version
from pip._vendor.packaging.requirements import Requirement
from pip._vendor.pkg_resources import Distribution

from pip._internal.exceptions import NoneMetadataError
from pip._internal.utils.misc import display_path

logger = logging.getLogger(__name__)


def check_requires_python(
    requires_python: Optional[str], version_info: Tuple[int, ...]
) -> bool:
    """
    Check if the given Python version matches a "Requires-Python" specifier.

    :param version_info: A 3-tuple of ints representing a Python
        major-minor-micro version to check (e.g. `sys.version_info[:3]`).

    :return: `True` if the given Python version satisfies the requirement.
        Otherwise, return `False`.

    :raises InvalidSpecifier: If `requires_python` has an invalid format.
    """
    if requires_python is None:
        # The package provides no information
        return True
    requires_python_specifier = specifiers.SpecifierSet(requires_python)

    python_version = version.parse(".".join(map(str, version_info)))
    return python_version in requires_python_specifier


def get_metadata(dist: Distribution) -> Message:
    """
    :raises NoneMetadataError: if the distribution reports `has_metadata()`
        True but `get_metadata()` returns None.
    """
    metadata_name = "METADATA"
    if isinstance(dist, pkg_resources.DistInfoDistribution) and dist.has_metadata(
        metadata_name
    ):
        metadata = dist.get_metadata(metadata_name)
FILE: ./venv/Lib/site-packages/pip/_internal/utils/parallel.py
"""Convenient parallelization of higher order functions.

This module provides two helper functions, with appropriate fallbacks on
Python 2 and on systems lacking support for synchronization mechanisms:

- map_multiprocess
- map_multithread

These helpers work like Python 3's map, with two differences:

- They don't guarantee the order of processing of
  the elements of the iterable.
- The underlying process/thread pools chop the iterable into
  a number of chunks, so that for very long iterables using
  a large value for chunksize can make the job complete much faster
  than using the default value of 1.
"""

__all__ = ["map_multiprocess", "map_multithread"]

from contextlib import contextmanager
from multiprocessing import Pool as ProcessPool
from multiprocessing import pool
from multiprocessing.dummy import Pool as ThreadPool
from typing import Callable, Iterable, Iterator, TypeVar, Union

from pip._vendor.requests.adapters import DEFAULT_POOLSIZE

Pool = Union[pool.Pool, pool.ThreadPool]
S = TypeVar("S")
T = TypeVar("T")

# On platforms without sem_open, multiprocessing[.dummy] Pool
# cannot be created.
try:
    import multiprocessing.synchronize  # noqa
except ImportError:
    LACK_SEM_OPEN = True
else:
    LACK_SEM_OPEN = False

# Incredibly large timeout to work around bpo-8296 on Python 2.
TIMEOUT = 2000000


@contextmanager
def closing(pool: Pool) -> Iterator[Pool]:
    """Return a context manager making sure the pool closes properly."""
    try:
        yield pool
FILE: ./venv/Lib/site-packages/pip/_internal/utils/pkg_resources.py
from typing import Dict, Iterable, List

from pip._vendor.pkg_resources import yield_lines


class DictMetadata:
    """IMetadataProvider that reads metadata files from a dictionary."""

    def __init__(self, metadata: Dict[str, bytes]) -> None:
        self._metadata = metadata

    def has_metadata(self, name: str) -> bool:
        return name in self._metadata

    def get_metadata(self, name: str) -> str:
        try:
            return self._metadata[name].decode()
        except UnicodeDecodeError as e:
            # Mirrors handling done in pkg_resources.NullProvider.
            e.reason += f" in {name} file"
            raise

    def get_metadata_lines(self, name: str) -> Iterable[str]:
        return yield_lines(self.get_metadata(name))

    def metadata_isdir(self, name: str) -> bool:
        return False

    def metadata_listdir(self, name: str) -> List[str]:
        return []

    def run_script(self, script_name: str, namespace: str) -> None:
        pass
FILE: ./venv/Lib/site-packages/pip/_internal/utils/setuptools_build.py
import sys
from typing import List, Optional, Sequence

# Shim to wrap setup.py invocation with setuptools
#
# We set sys.argv[0] to the path to the underlying setup.py file so
# setuptools / distutils don't take the path to the setup.py to be "-c" when
# invoking via the shim.  This avoids e.g. the following manifest_maker
# warning: "warning: manifest_maker: standard file '-c' not found".
_SETUPTOOLS_SHIM = (
    "import io, os, sys, setuptools, tokenize; sys.argv[0] = {0!r}; __file__={0!r};"
    "f = getattr(tokenize, 'open', open)(__file__) "
    "if os.path.exists(__file__) "
    "else io.StringIO('from setuptools import setup; setup()');"
    "code = f.read().replace('\\r\\n', '\\n');"
    "f.close();"
    "exec(compile(code, __file__, 'exec'))"
)


def make_setuptools_shim_args(
    setup_py_path: str,
    global_options: Sequence[str] = None,
    no_user_config: bool = False,
    unbuffered_output: bool = False,
) -> List[str]:
    """
    Get setuptools command arguments with shim wrapped setup file invocation.

    :param setup_py_path: The path to setup.py to be wrapped.
    :param global_options: Additional global options.
    :param no_user_config: If True, disables personal user configuration.
    :param unbuffered_output: If True, adds the unbuffered switch to the
     argument list.
    """
    args = [sys.executable]
    if unbuffered_output:
        args += ["-u"]
    args += ["-c", _SETUPTOOLS_SHIM.format(setup_py_path)]
    if global_options:
        args += global_options
    if no_user_config:
        args += ["--no-user-cfg"]
    return args


def make_setuptools_bdist_wheel_args(
    setup_py_path: str,
    global_options: Sequence[str],
    build_options: Sequence[str],
FILE: ./venv/Lib/site-packages/pip/_internal/utils/subprocess.py
import logging
import os
import shlex
import subprocess
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    Iterable,
    List,
    Mapping,
    Optional,
    Union,
)

from pip._internal.cli.spinners import SpinnerInterface, open_spinner
from pip._internal.exceptions import InstallationSubprocessError
from pip._internal.utils.logging import VERBOSE, subprocess_logger
from pip._internal.utils.misc import HiddenText

if TYPE_CHECKING:
    # Literal was introduced in Python 3.8.
    #
    # TODO: Remove `if TYPE_CHECKING` when dropping support for Python 3.7.
    from typing import Literal

CommandArgs = List[Union[str, HiddenText]]


LOG_DIVIDER = "----------------------------------------"


def make_command(*args: Union[str, HiddenText, CommandArgs]) -> CommandArgs:
    """
    Create a CommandArgs object.
    """
    command_args: CommandArgs = []
    for arg in args:
        # Check for list instead of CommandArgs since CommandArgs is
        # only known during type-checking.
        if isinstance(arg, list):
            command_args.extend(arg)
        else:
            # Otherwise, arg is str or HiddenText.
            command_args.append(arg)

    return command_args


def format_command_args(args: Union[List[str], CommandArgs]) -> str:
FILE: ./venv/Lib/site-packages/pip/_internal/utils/temp_dir.py
import errno
import itertools
import logging
import os.path
import tempfile
from contextlib import ExitStack, contextmanager
from typing import Any, Dict, Iterator, Optional, TypeVar, Union

from pip._internal.utils.misc import enum, rmtree

logger = logging.getLogger(__name__)

_T = TypeVar("_T", bound="TempDirectory")


# Kinds of temporary directories. Only needed for ones that are
# globally-managed.
tempdir_kinds = enum(
    BUILD_ENV="build-env",
    EPHEM_WHEEL_CACHE="ephem-wheel-cache",
    REQ_BUILD="req-build",
)


_tempdir_manager: Optional[ExitStack] = None


@contextmanager
def global_tempdir_manager() -> Iterator[None]:
    global _tempdir_manager
    with ExitStack() as stack:
        old_tempdir_manager, _tempdir_manager = _tempdir_manager, stack
        try:
            yield
        finally:
            _tempdir_manager = old_tempdir_manager


class TempDirectoryTypeRegistry:
    """Manages temp directory behavior"""

    def __init__(self) -> None:
        self._should_delete: Dict[str, bool] = {}

    def set_delete(self, kind: str, value: bool) -> None:
        """Indicate whether a TempDirectory of the given kind should be
        auto-deleted.
        """
        self._should_delete[kind] = value

FILE: ./venv/Lib/site-packages/pip/_internal/utils/unpacking.py
"""Utilities related archives.
"""

import logging
import os
import shutil
import stat
import tarfile
import zipfile
from typing import Iterable, List, Optional
from zipfile import ZipInfo

from pip._internal.exceptions import InstallationError
from pip._internal.utils.filetypes import (
    BZ2_EXTENSIONS,
    TAR_EXTENSIONS,
    XZ_EXTENSIONS,
    ZIP_EXTENSIONS,
)
from pip._internal.utils.misc import ensure_dir

logger = logging.getLogger(__name__)


SUPPORTED_EXTENSIONS = ZIP_EXTENSIONS + TAR_EXTENSIONS

try:
    import bz2  # noqa

    SUPPORTED_EXTENSIONS += BZ2_EXTENSIONS
except ImportError:
    logger.debug("bz2 module is not available")

try:
    # Only for Python 3.3+
    import lzma  # noqa

    SUPPORTED_EXTENSIONS += XZ_EXTENSIONS
except ImportError:
    logger.debug("lzma module is not available")


def current_umask() -> int:
    """Get the current umask which involves having to set it temporarily."""
    mask = os.umask(0)
    os.umask(mask)
    return mask


def split_leading_dir(path: str) -> List[str]:
FILE: ./venv/Lib/site-packages/pip/_internal/utils/urls.py
import os
import string
import urllib.parse
import urllib.request
from typing import Optional

from .compat import WINDOWS


def get_url_scheme(url: str) -> Optional[str]:
    if ":" not in url:
        return None
    return url.split(":", 1)[0].lower()


def path_to_url(path: str) -> str:
    """
    Convert a path to a file: URL.  The path will be made absolute and have
    quoted path parts.
    """
    path = os.path.normpath(os.path.abspath(path))
    url = urllib.parse.urljoin("file:", urllib.request.pathname2url(path))
    return url


def url_to_path(url: str) -> str:
    """
    Convert a file: URL to a path.
    """
    assert url.startswith(
        "file:"
    ), f"You can only turn file: urls into filenames (not {url!r})"

    _, netloc, path, _, _ = urllib.parse.urlsplit(url)

    if not netloc or netloc == "localhost":
        # According to RFC 8089, same as empty authority.
        netloc = ""
    elif WINDOWS:
        # If we have a UNC path, prepend UNC share notation.
        netloc = "\\\\" + netloc
    else:
        raise ValueError(
            f"non-local file URIs are not supported on this platform: {url!r}"
        )

    path = urllib.request.url2pathname(netloc + path)

    # On Windows, urlsplit parses the path as something like "/C:/Users/foo".
    # This creates issues for path-related functions like io.open(), so we try
FILE: ./venv/Lib/site-packages/pip/_internal/utils/virtualenv.py
import logging
import os
import re
import site
import sys
from typing import List, Optional

logger = logging.getLogger(__name__)
_INCLUDE_SYSTEM_SITE_PACKAGES_REGEX = re.compile(
    r"include-system-site-packages\s*=\s*(?P<value>true|false)"
)


def _running_under_venv() -> bool:
    """Checks if sys.base_prefix and sys.prefix match.

    This handles PEP 405 compliant virtual environments.
    """
    return sys.prefix != getattr(sys, "base_prefix", sys.prefix)


def _running_under_regular_virtualenv() -> bool:
    """Checks if sys.real_prefix is set.

    This handles virtual environments created with pypa's virtualenv.
    """
    # pypa/virtualenv case
    return hasattr(sys, "real_prefix")


def running_under_virtualenv() -> bool:
    """Return True if we're running inside a virtualenv, False otherwise."""
    return _running_under_venv() or _running_under_regular_virtualenv()


def _get_pyvenv_cfg_lines() -> Optional[List[str]]:
    """Reads {sys.prefix}/pyvenv.cfg and returns its contents as list of lines

    Returns None, if it could not read/access the file.
    """
    pyvenv_cfg_file = os.path.join(sys.prefix, "pyvenv.cfg")
    try:
        # Although PEP 405 does not specify, the built-in venv module always
        # writes with UTF-8. (pypa/pip#8717)
        with open(pyvenv_cfg_file, encoding="utf-8") as f:
            return f.read().splitlines()  # avoids trailing newlines
    except OSError:
        return None


FILE: ./venv/Lib/site-packages/pip/_internal/utils/wheel.py
"""Support functions for working with wheel files.
"""

import logging
from email.message import Message
from email.parser import Parser
from typing import Dict, Tuple
from zipfile import BadZipFile, ZipFile

from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.pkg_resources import DistInfoDistribution, Distribution

from pip._internal.exceptions import UnsupportedWheel
from pip._internal.utils.pkg_resources import DictMetadata

VERSION_COMPATIBLE = (1, 0)


logger = logging.getLogger(__name__)


class WheelMetadata(DictMetadata):
    """Metadata provider that maps metadata decoding exceptions to our
    internal exception type.
    """

    def __init__(self, metadata: Dict[str, bytes], wheel_name: str) -> None:
        super().__init__(metadata)
        self._wheel_name = wheel_name

    def get_metadata(self, name: str) -> str:
        try:
            return super().get_metadata(name)
        except UnicodeDecodeError as e:
            # Augment the default error with the origin of the file.
            raise UnsupportedWheel(
                f"Error decoding metadata for {self._wheel_name}: {e}"
            )


def pkg_resources_distribution_for_wheel(
    wheel_zip: ZipFile, name: str, location: str
) -> Distribution:
    """Get a pkg_resources distribution given a wheel.

    :raises UnsupportedWheel: on any errors
    """
    info_dir, _ = parse_wheel(wheel_zip, name)

    metadata_files = [p for p in wheel_zip.namelist() if p.startswith(f"{info_dir}/")]
FILE: ./venv/Lib/site-packages/pip/_internal/utils/_log.py
"""Customize logging

Defines custom logger class for the `logger.verbose(...)` method.

init_logging() must be called before any other modules that call logging.getLogger.
"""

import logging
from typing import Any, cast

# custom log level for `--verbose` output
# between DEBUG and INFO
VERBOSE = 15


class VerboseLogger(logging.Logger):
    """Custom Logger, defining a verbose log-level

    VERBOSE is between INFO and DEBUG.
    """

    def verbose(self, msg: str, *args: Any, **kwargs: Any) -> None:
        return self.log(VERBOSE, msg, *args, **kwargs)


def getLogger(name: str) -> VerboseLogger:
    """logging.getLogger, but ensures our VerboseLogger class is returned"""
    return cast(VerboseLogger, logging.getLogger(name))


def init_logging() -> None:
    """Register our VerboseLogger and VERBOSE log level.

    Should be called before any calls to getLogger(),
    i.e. in pip._internal.__init__
    """
    logging.setLoggerClass(VerboseLogger)
    logging.addLevelName(VERBOSE, "VERBOSE")
FILE: ./venv/Lib/site-packages/pip/_internal/utils/__init__.py
FILE: ./venv/Lib/site-packages/pip/_internal/vcs/bazaar.py
import logging
from typing import List, Optional, Tuple

from pip._internal.utils.misc import HiddenText, display_path
from pip._internal.utils.subprocess import make_command
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs.versioncontrol import (
    AuthInfo,
    RemoteNotFoundError,
    RevOptions,
    VersionControl,
    vcs,
)

logger = logging.getLogger(__name__)


class Bazaar(VersionControl):
    name = "bzr"
    dirname = ".bzr"
    repo_name = "branch"
    schemes = (
        "bzr+http",
        "bzr+https",
        "bzr+ssh",
        "bzr+sftp",
        "bzr+ftp",
        "bzr+lp",
        "bzr+file",
    )

    @staticmethod
    def get_base_rev_args(rev: str) -> List[str]:
        return ["-r", rev]

    def fetch_new(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
        rev_display = rev_options.to_display()
        logger.info(
            "Checking out %s%s to %s",
            url,
            rev_display,
            display_path(dest),
        )
        cmd_args = make_command("branch", "-q", rev_options.to_args(), url, dest)
        self.run_command(cmd_args)

    def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
        self.run_command(make_command("switch", url), cwd=dest)

    def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
FILE: ./venv/Lib/site-packages/pip/_internal/vcs/git.py
import logging
import os.path
import pathlib
import re
import urllib.parse
import urllib.request
from typing import List, Optional, Tuple

from pip._internal.exceptions import BadCommand, InstallationError
from pip._internal.utils.misc import HiddenText, display_path, hide_url
from pip._internal.utils.subprocess import make_command
from pip._internal.vcs.versioncontrol import (
    AuthInfo,
    RemoteNotFoundError,
    RemoteNotValidError,
    RevOptions,
    VersionControl,
    find_path_to_project_root_from_repo_root,
    vcs,
)

urlsplit = urllib.parse.urlsplit
urlunsplit = urllib.parse.urlunsplit


logger = logging.getLogger(__name__)


GIT_VERSION_REGEX = re.compile(
    r"^git version "  # Prefix.
    r"(\d+)"  # Major.
    r"\.(\d+)"  # Dot, minor.
    r"(?:\.(\d+))?"  # Optional dot, patch.
    r".*$"  # Suffix, including any pre- and post-release segments we don't care about.
)

HASH_REGEX = re.compile("^[a-fA-F0-9]{40}$")

# SCP (Secure copy protocol) shorthand. e.g. 'git@example.com:foo/bar.git'
SCP_REGEX = re.compile(
    r"""^
    # Optional user, e.g. 'git@'
    (\w+@)?
    # Server, e.g. 'github.com'.
    ([^/:]+):
    # The server-side path. e.g. 'user/project.git'. Must start with an
    # alphanumeric character so as not to be confusable with a Windows paths
    # like 'C:/foo/bar' or 'C:\foo\bar'.
    (\w[^:]*)
    $""",
FILE: ./venv/Lib/site-packages/pip/_internal/vcs/mercurial.py
import configparser
import logging
import os
from typing import List, Optional

from pip._internal.exceptions import BadCommand, InstallationError
from pip._internal.utils.misc import HiddenText, display_path
from pip._internal.utils.subprocess import make_command
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs.versioncontrol import (
    RevOptions,
    VersionControl,
    find_path_to_project_root_from_repo_root,
    vcs,
)

logger = logging.getLogger(__name__)


class Mercurial(VersionControl):
    name = "hg"
    dirname = ".hg"
    repo_name = "clone"
    schemes = (
        "hg+file",
        "hg+http",
        "hg+https",
        "hg+ssh",
        "hg+static-http",
    )

    @staticmethod
    def get_base_rev_args(rev: str) -> List[str]:
        return [rev]

    def fetch_new(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
        rev_display = rev_options.to_display()
        logger.info(
            "Cloning hg %s%s to %s",
            url,
            rev_display,
            display_path(dest),
        )
        self.run_command(make_command("clone", "--noupdate", "-q", url, dest))
        self.run_command(
            make_command("update", "-q", rev_options.to_args()),
            cwd=dest,
        )

    def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
FILE: ./venv/Lib/site-packages/pip/_internal/vcs/subversion.py
import logging
import os
import re
from typing import List, Optional, Tuple

from pip._internal.utils.misc import (
    HiddenText,
    display_path,
    is_console_interactive,
    is_installable_dir,
    split_auth_from_netloc,
)
from pip._internal.utils.subprocess import CommandArgs, make_command
from pip._internal.vcs.versioncontrol import (
    AuthInfo,
    RemoteNotFoundError,
    RevOptions,
    VersionControl,
    vcs,
)

logger = logging.getLogger(__name__)

_svn_xml_url_re = re.compile('url="([^"]+)"')
_svn_rev_re = re.compile(r'committed-rev="(\d+)"')
_svn_info_xml_rev_re = re.compile(r'\s*revision="(\d+)"')
_svn_info_xml_url_re = re.compile(r"<url>(.*)</url>")


class Subversion(VersionControl):
    name = "svn"
    dirname = ".svn"
    repo_name = "checkout"
    schemes = ("svn+ssh", "svn+http", "svn+https", "svn+svn", "svn+file")

    @classmethod
    def should_add_vcs_url_prefix(cls, remote_url: str) -> bool:
        return True

    @staticmethod
    def get_base_rev_args(rev: str) -> List[str]:
        return ["-r", rev]

    @classmethod
    def get_revision(cls, location: str) -> str:
        """
        Return the maximum revision for all files under a given location
        """
        # Note: taken from setuptools.command.egg_info
        revision = 0
FILE: ./venv/Lib/site-packages/pip/_internal/vcs/versioncontrol.py
"""Handles all VCS (version control) support"""

import logging
import os
import shutil
import sys
import urllib.parse
from typing import (
    TYPE_CHECKING,
    Any,
    Dict,
    Iterable,
    Iterator,
    List,
    Mapping,
    Optional,
    Tuple,
    Type,
    Union,
)

from pip._internal.cli.spinners import SpinnerInterface
from pip._internal.exceptions import BadCommand, InstallationError
from pip._internal.utils.misc import (
    HiddenText,
    ask_path_exists,
    backup_dir,
    display_path,
    hide_url,
    hide_value,
    is_installable_dir,
    rmtree,
)
from pip._internal.utils.subprocess import CommandArgs, call_subprocess, make_command
from pip._internal.utils.urls import get_url_scheme

if TYPE_CHECKING:
    # Literal was introduced in Python 3.8.
    #
    # TODO: Remove `if TYPE_CHECKING` when dropping support for Python 3.7.
    from typing import Literal


__all__ = ["vcs"]


logger = logging.getLogger(__name__)

AuthInfo = Tuple[Optional[str], Optional[str]]

FILE: ./venv/Lib/site-packages/pip/_internal/vcs/__init__.py
# Expose a limited set of classes and functions so callers outside of
# the vcs package don't need to import deeper than `pip._internal.vcs`.
# (The test directory may still need to import from a vcs sub-package.)
# Import all vcs modules to register each VCS in the VcsSupport object.
import pip._internal.vcs.bazaar
import pip._internal.vcs.git
import pip._internal.vcs.mercurial
import pip._internal.vcs.subversion  # noqa: F401
from pip._internal.vcs.versioncontrol import (  # noqa: F401
    RemoteNotFoundError,
    RemoteNotValidError,
    is_url,
    make_vcs_requirement_url,
    vcs,
)
FILE: ./venv/Lib/site-packages/pip/_internal/wheel_builder.py
"""Orchestrator for building wheels from InstallRequirements.
"""

import logging
import os.path
import re
import shutil
from typing import Any, Callable, Iterable, List, Optional, Tuple

from pip._vendor.packaging.utils import canonicalize_name, canonicalize_version
from pip._vendor.packaging.version import InvalidVersion, Version

from pip._internal.cache import WheelCache
from pip._internal.exceptions import InvalidWheelFilename, UnsupportedWheel
from pip._internal.metadata import FilesystemWheel, get_wheel_distribution
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.operations.build.wheel import build_wheel_pep517
from pip._internal.operations.build.wheel_editable import build_wheel_editable
from pip._internal.operations.build.wheel_legacy import build_wheel_legacy
from pip._internal.req.req_install import InstallRequirement
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import ensure_dir, hash_file, is_wheel_installed
from pip._internal.utils.setuptools_build import make_setuptools_clean_args
from pip._internal.utils.subprocess import call_subprocess
from pip._internal.utils.temp_dir import TempDirectory
from pip._internal.utils.urls import path_to_url
from pip._internal.vcs import vcs

logger = logging.getLogger(__name__)

_egg_info_re = re.compile(r"([a-z0-9_.]+)-([a-z0-9_.!+-]+)", re.IGNORECASE)

BinaryAllowedPredicate = Callable[[InstallRequirement], bool]
BuildResult = Tuple[List[InstallRequirement], List[InstallRequirement]]


def _contains_egg_info(s: str) -> bool:
    """Determine whether the string looks like an egg_info.

    :param s: The string to parse. E.g. foo-2.1
    """
    return bool(_egg_info_re.search(s))


def _should_build(
    req: InstallRequirement,
    need_wheel: bool,
    check_binary_allowed: BinaryAllowedPredicate,
) -> bool:
FILE: ./venv/Lib/site-packages/pip/_internal/__init__.py
from typing import List, Optional

import pip._internal.utils.inject_securetransport  # noqa
from pip._internal.utils import _log

# init_logging() must be called before any call to logging.getLogger()
# which happens at import of most modules.
_log.init_logging()


def main(args: (Optional[List[str]]) = None) -> int:
    """This is preserved for old console scripts that may still be referencing
    it.

    For additional details, see https://github.com/pypa/pip/issues/7498.
    """
    from pip._internal.utils.entrypoints import _wrapper

    return _wrapper(args)
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/adapter.py
import types
import functools
import zlib

from pip._vendor.requests.adapters import HTTPAdapter

from .controller import CacheController
from .cache import DictCache
from .filewrapper import CallbackFileWrapper


class CacheControlAdapter(HTTPAdapter):
    invalidating_methods = {"PUT", "DELETE"}

    def __init__(
        self,
        cache=None,
        cache_etags=True,
        controller_class=None,
        serializer=None,
        heuristic=None,
        cacheable_methods=None,
        *args,
        **kw
    ):
        super(CacheControlAdapter, self).__init__(*args, **kw)
        self.cache = DictCache() if cache is None else cache
        self.heuristic = heuristic
        self.cacheable_methods = cacheable_methods or ("GET",)

        controller_factory = controller_class or CacheController
        self.controller = controller_factory(
            self.cache, cache_etags=cache_etags, serializer=serializer
        )

    def send(self, request, cacheable_methods=None, **kw):
        """
        Send a request. Use the request information to see if it
        exists in the cache and cache the response if we need to and can.
        """
        cacheable = cacheable_methods or self.cacheable_methods
        if request.method in cacheable:
            try:
                cached_response = self.controller.cached_request(request)
            except zlib.error:
                cached_response = None
            if cached_response:
                return self.build_response(request, cached_response, from_cache=True)

            # check for etags and add headers if appropriate
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/cache.py
"""
The cache object API for implementing caches. The default is a thread
safe in-memory dictionary.
"""
from threading import Lock


class BaseCache(object):

    def get(self, key):
        raise NotImplementedError()

    def set(self, key, value):
        raise NotImplementedError()

    def delete(self, key):
        raise NotImplementedError()

    def close(self):
        pass


class DictCache(BaseCache):

    def __init__(self, init_dict=None):
        self.lock = Lock()
        self.data = init_dict or {}

    def get(self, key):
        return self.data.get(key, None)

    def set(self, key, value):
        with self.lock:
            self.data.update({key: value})

    def delete(self, key):
        with self.lock:
            if key in self.data:
                self.data.pop(key)
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py
import hashlib
import os
from textwrap import dedent

from ..cache import BaseCache
from ..controller import CacheController

try:
    FileNotFoundError
except NameError:
    # py2.X
    FileNotFoundError = (IOError, OSError)


def _secure_open_write(filename, fmode):
    # We only want to write to this file, so open it in write only mode
    flags = os.O_WRONLY

    # os.O_CREAT | os.O_EXCL will fail if the file already exists, so we only
    #  will open *new* files.
    # We specify this because we want to ensure that the mode we pass is the
    # mode of the file.
    flags |= os.O_CREAT | os.O_EXCL

    # Do not follow symlinks to prevent someone from making a symlink that
    # we follow and insecurely open a cache file.
    if hasattr(os, "O_NOFOLLOW"):
        flags |= os.O_NOFOLLOW

    # On Windows we'll mark this file as binary
    if hasattr(os, "O_BINARY"):
        flags |= os.O_BINARY

    # Before we open our file, we want to delete any existing file that is
    # there
    try:
        os.remove(filename)
    except (IOError, OSError):
        # The file must not exist already, so we can just skip ahead to opening
        pass

    # Open our file, the use of os.O_CREAT | os.O_EXCL will ensure that if a
    # race condition happens between the os.remove and this line, that an
    # error will be raised. Because we utilize a lockfile this should only
    # happen if someone is attempting to attack us.
    fd = os.open(filename, flags, fmode)
    try:
        return os.fdopen(fd, "wb")

    except:
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/caches/redis_cache.py
from __future__ import division

from datetime import datetime
from pip._vendor.cachecontrol.cache import BaseCache


class RedisCache(BaseCache):

    def __init__(self, conn):
        self.conn = conn

    def get(self, key):
        return self.conn.get(key)

    def set(self, key, value, expires=None):
        if not expires:
            self.conn.set(key, value)
        else:
            expires = expires - datetime.utcnow()
            self.conn.setex(key, int(expires.total_seconds()), value)

    def delete(self, key):
        self.conn.delete(key)

    def clear(self):
        """Helper for clearing all the keys in a database. Use with
        caution!"""
        for key in self.conn.keys():
            self.conn.delete(key)

    def close(self):
        """Redis uses connection pooling, no need to close the connection."""
        pass
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/caches/__init__.py
from .file_cache import FileCache  # noqa
from .redis_cache import RedisCache  # noqa
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/compat.py
try:
    from urllib.parse import urljoin
except ImportError:
    from urlparse import urljoin


try:
    import cPickle as pickle
except ImportError:
    import pickle


# Handle the case where the requests module has been patched to not have
# urllib3 bundled as part of its source.
try:
    from pip._vendor.requests.packages.urllib3.response import HTTPResponse
except ImportError:
    from pip._vendor.urllib3.response import HTTPResponse

try:
    from pip._vendor.requests.packages.urllib3.util import is_fp_closed
except ImportError:
    from pip._vendor.urllib3.util import is_fp_closed

# Replicate some six behaviour
try:
    text_type = unicode
except NameError:
    text_type = str
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/controller.py
"""
The httplib2 algorithms ported for use with requests.
"""
import logging
import re
import calendar
import time
from email.utils import parsedate_tz

from pip._vendor.requests.structures import CaseInsensitiveDict

from .cache import DictCache
from .serialize import Serializer


logger = logging.getLogger(__name__)

URI = re.compile(r"^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?")


def parse_uri(uri):
    """Parses a URI using the regex given in Appendix B of RFC 3986.

        (scheme, authority, path, query, fragment) = parse_uri(uri)
    """
    groups = URI.match(uri).groups()
    return (groups[1], groups[3], groups[4], groups[6], groups[8])


class CacheController(object):
    """An interface to see if request should cached or not.
    """

    def __init__(
        self, cache=None, cache_etags=True, serializer=None, status_codes=None
    ):
        self.cache = DictCache() if cache is None else cache
        self.cache_etags = cache_etags
        self.serializer = serializer or Serializer()
        self.cacheable_status_codes = status_codes or (200, 203, 300, 301)

    @classmethod
    def _urlnorm(cls, uri):
        """Normalize the URL to create a safe key for the cache"""
        (scheme, authority, path, query, fragment) = parse_uri(uri)
        if not scheme or not authority:
            raise Exception("Only absolute URIs are allowed. uri = %s" % uri)

        scheme = scheme.lower()
        authority = authority.lower()
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/filewrapper.py
from io import BytesIO


class CallbackFileWrapper(object):
    """
    Small wrapper around a fp object which will tee everything read into a
    buffer, and when that file is closed it will execute a callback with the
    contents of that buffer.

    All attributes are proxied to the underlying file object.

    This class uses members with a double underscore (__) leading prefix so as
    not to accidentally shadow an attribute.
    """

    def __init__(self, fp, callback):
        self.__buf = BytesIO()
        self.__fp = fp
        self.__callback = callback

    def __getattr__(self, name):
        # The vaguaries of garbage collection means that self.__fp is
        # not always set.  By using __getattribute__ and the private
        # name[0] allows looking up the attribute value and raising an
        # AttributeError when it doesn't exist. This stop thigns from
        # infinitely recursing calls to getattr in the case where
        # self.__fp hasn't been set.
        #
        # [0] https://docs.python.org/2/reference/expressions.html#atom-identifiers
        fp = self.__getattribute__("_CallbackFileWrapper__fp")
        return getattr(fp, name)

    def __is_fp_closed(self):
        try:
            return self.__fp.fp is None

        except AttributeError:
            pass

        try:
            return self.__fp.closed

        except AttributeError:
            pass

        # We just don't cache it then.
        # TODO: Add some logging here...
        return False

    def _close(self):
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/heuristics.py
import calendar
import time

from email.utils import formatdate, parsedate, parsedate_tz

from datetime import datetime, timedelta

TIME_FMT = "%a, %d %b %Y %H:%M:%S GMT"


def expire_after(delta, date=None):
    date = date or datetime.utcnow()
    return date + delta


def datetime_to_header(dt):
    return formatdate(calendar.timegm(dt.timetuple()))


class BaseHeuristic(object):

    def warning(self, response):
        """
        Return a valid 1xx warning header value describing the cache
        adjustments.

        The response is provided too allow warnings like 113
        http://tools.ietf.org/html/rfc7234#section-5.5.4 where we need
        to explicitly say response is over 24 hours old.
        """
        return '110 - "Response is Stale"'

    def update_headers(self, response):
        """Update the response headers with any new headers.

        NOTE: This SHOULD always include some Warning header to
              signify that the response was cached by the client, not
              by way of the provided headers.
        """
        return {}

    def apply(self, response):
        updated_headers = self.update_headers(response)

        if updated_headers:
            response.headers.update(updated_headers)
            warning_header_value = self.warning(response)
            if warning_header_value is not None:
                response.headers.update({"Warning": warning_header_value})

FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/serialize.py
import base64
import io
import json
import zlib

from pip._vendor import msgpack
from pip._vendor.requests.structures import CaseInsensitiveDict

from .compat import HTTPResponse, pickle, text_type


def _b64_decode_bytes(b):
    return base64.b64decode(b.encode("ascii"))


def _b64_decode_str(s):
    return _b64_decode_bytes(s).decode("utf8")


class Serializer(object):

    def dumps(self, request, response, body=None):
        response_headers = CaseInsensitiveDict(response.headers)

        if body is None:
            body = response.read(decode_content=False)

            # NOTE: 99% sure this is dead code. I'm only leaving it
            #       here b/c I don't have a test yet to prove
            #       it. Basically, before using
            #       `cachecontrol.filewrapper.CallbackFileWrapper`,
            #       this made an effort to reset the file handle. The
            #       `CallbackFileWrapper` short circuits this code by
            #       setting the body as the content is consumed, the
            #       result being a `body` argument is *always* passed
            #       into cache_response, and in turn,
            #       `Serializer.dump`.
            response._fp = io.BytesIO(body)

        # NOTE: This is all a bit weird, but it's really important that on
        #       Python 2.x these objects are unicode and not str, even when
        #       they contain only ascii. The problem here is that msgpack
        #       understands the difference between unicode and bytes and we
        #       have it set to differentiate between them, however Python 2
        #       doesn't know the difference. Forcing these to unicode will be
        #       enough to have msgpack know the difference.
        data = {
            u"response": {
                u"body": body,
                u"headers": dict(
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/wrapper.py
from .adapter import CacheControlAdapter
from .cache import DictCache


def CacheControl(
    sess,
    cache=None,
    cache_etags=True,
    serializer=None,
    heuristic=None,
    controller_class=None,
    adapter_class=None,
    cacheable_methods=None,
):

    cache = DictCache() if cache is None else cache
    adapter_class = adapter_class or CacheControlAdapter
    adapter = adapter_class(
        cache,
        cache_etags=cache_etags,
        serializer=serializer,
        heuristic=heuristic,
        controller_class=controller_class,
        cacheable_methods=cacheable_methods,
    )
    sess.mount("http://", adapter)
    sess.mount("https://", adapter)

    return sess
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/_cmd.py
import logging

from pip._vendor import requests

from pip._vendor.cachecontrol.adapter import CacheControlAdapter
from pip._vendor.cachecontrol.cache import DictCache
from pip._vendor.cachecontrol.controller import logger

from argparse import ArgumentParser


def setup_logging():
    logger.setLevel(logging.DEBUG)
    handler = logging.StreamHandler()
    logger.addHandler(handler)


def get_session():
    adapter = CacheControlAdapter(
        DictCache(), cache_etags=True, serializer=None, heuristic=None
    )
    sess = requests.Session()
    sess.mount("http://", adapter)
    sess.mount("https://", adapter)

    sess.cache_controller = adapter.controller
    return sess


def get_args():
    parser = ArgumentParser()
    parser.add_argument("url", help="The URL to try and cache")
    return parser.parse_args()


def main(args=None):
    args = get_args()
    sess = get_session()

    # Make a request to get a response
    resp = sess.get(args.url)

    # Turn on logging
    setup_logging()

    # try setting the cache
    sess.cache_controller.cache_response(resp.request, resp.raw)

    # Now try to get it
    if sess.cache_controller.cached_request(resp.request):
FILE: ./venv/Lib/site-packages/pip/_vendor/cachecontrol/__init__.py
"""CacheControl import Interface.

Make it easy to import from cachecontrol without long namespaces.
"""
__author__ = "Eric Larson"
__email__ = "eric@ionrock.org"
__version__ = "0.12.6"

from .wrapper import CacheControl
from .adapter import CacheControlAdapter
from .controller import CacheController
FILE: ./venv/Lib/site-packages/pip/_vendor/certifi/core.py
# -*- coding: utf-8 -*-

"""
certifi.py
~~~~~~~~~~

This module returns the installation location of cacert.pem or its contents.
"""
import os


class _PipPatchedCertificate(Exception):
    pass


try:
    # Return a certificate file on disk for a standalone pip zipapp running in
    # an isolated build environment to use. Passing --cert to the standalone
    # pip does not work since requests calls where() unconditionally on import.
    _PIP_STANDALONE_CERT = os.environ.get("_PIP_STANDALONE_CERT")
    if _PIP_STANDALONE_CERT:
        def where():
            return _PIP_STANDALONE_CERT
        raise _PipPatchedCertificate()

    from importlib.resources import path as get_path, read_text

    _CACERT_CTX = None
    _CACERT_PATH = None

    def where():
        # This is slightly terrible, but we want to delay extracting the file
        # in cases where we're inside of a zipimport situation until someone
        # actually calls where(), but we don't want to re-extract the file
        # on every call of where(), so we'll do it once then store it in a
        # global variable.
        global _CACERT_CTX
        global _CACERT_PATH
        if _CACERT_PATH is None:
            # This is slightly janky, the importlib.resources API wants you to
            # manage the cleanup of this file, so it doesn't actually return a
            # path, it returns a context manager that will give you the path
            # when you enter it and will do any cleanup when you leave it. In
            # the common case of not needing a temporary file, it will just
            # return the file system location and the __exit__() is a no-op.
            #
            # We also have to hold onto the actual context manager, because
            # it will do the cleanup whenever it gets garbage collected, so
            # we will also store that at the global level as well.
            _CACERT_CTX = get_path("pip._vendor.certifi", "cacert.pem")
FILE: ./venv/Lib/site-packages/pip/_vendor/certifi/__init__.py
from .core import contents, where

__version__ = "2021.05.30"
FILE: ./venv/Lib/site-packages/pip/_vendor/certifi/__main__.py
import argparse

from pip._vendor.certifi import contents, where

parser = argparse.ArgumentParser()
parser.add_argument("-c", "--contents", action="store_true")
args = parser.parse_args()

if args.contents:
    print(contents())
else:
    print(where())
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/big5freq.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# Big5 frequency table
# by Taiwan's Mandarin Promotion Council
# <http://www.edu.tw:81/mandr/>
#
# 128  --> 0.42261
# 256  --> 0.57851
# 512  --> 0.74851
# 1024 --> 0.89384
# 2048 --> 0.97583
#
# Ideal Distribution Ratio = 0.74851/(1-0.74851) =2.98
# Random Distribution Ration = 512/(5401-512)=0.105
#
# Typical Distribution Ratio about 25% of Ideal one, still much higher than RDR

BIG5_TYPICAL_DISTRIBUTION_RATIO = 0.75

#Char to FreqOrder table
BIG5_TABLE_SIZE = 5376

BIG5_CHAR_TO_FREQ_ORDER = (
   1,1801,1506, 255,1431, 198,   9,  82,   6,5008, 177, 202,3681,1256,2821, 110, #   16
3814,  33,3274, 261,  76,  44,2114,  16,2946,2187,1176, 659,3971,  26,3451,2653, #   32
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/big5prober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import Big5DistributionAnalysis
from .mbcssm import BIG5_SM_MODEL


class Big5Prober(MultiByteCharSetProber):
    def __init__(self):
        super(Big5Prober, self).__init__()
        self.coding_sm = CodingStateMachine(BIG5_SM_MODEL)
        self.distribution_analyzer = Big5DistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "Big5"

    @property
    def language(self):
        return "Chinese"
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/chardistribution.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .euctwfreq import (EUCTW_CHAR_TO_FREQ_ORDER, EUCTW_TABLE_SIZE,
                        EUCTW_TYPICAL_DISTRIBUTION_RATIO)
from .euckrfreq import (EUCKR_CHAR_TO_FREQ_ORDER, EUCKR_TABLE_SIZE,
                        EUCKR_TYPICAL_DISTRIBUTION_RATIO)
from .gb2312freq import (GB2312_CHAR_TO_FREQ_ORDER, GB2312_TABLE_SIZE,
                         GB2312_TYPICAL_DISTRIBUTION_RATIO)
from .big5freq import (BIG5_CHAR_TO_FREQ_ORDER, BIG5_TABLE_SIZE,
                       BIG5_TYPICAL_DISTRIBUTION_RATIO)
from .jisfreq import (JIS_CHAR_TO_FREQ_ORDER, JIS_TABLE_SIZE,
                      JIS_TYPICAL_DISTRIBUTION_RATIO)


class CharDistributionAnalysis(object):
    ENOUGH_DATA_THRESHOLD = 1024
    SURE_YES = 0.99
    SURE_NO = 0.01
    MINIMUM_DATA_THRESHOLD = 3

    def __init__(self):
        # Mapping table to get frequency order from char order (get from
        # GetOrder())
        self._char_to_freq_order = None
        self._table_size = None  # Size of above table
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/charsetgroupprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .enums import ProbingState
from .charsetprober import CharSetProber


class CharSetGroupProber(CharSetProber):
    def __init__(self, lang_filter=None):
        super(CharSetGroupProber, self).__init__(lang_filter=lang_filter)
        self._active_num = 0
        self.probers = []
        self._best_guess_prober = None

    def reset(self):
        super(CharSetGroupProber, self).reset()
        self._active_num = 0
        for prober in self.probers:
            if prober:
                prober.reset()
                prober.active = True
                self._active_num += 1
        self._best_guess_prober = None

    @property
    def charset_name(self):
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/charsetprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import logging
import re

from .enums import ProbingState


class CharSetProber(object):

    SHORTCUT_THRESHOLD = 0.95

    def __init__(self, lang_filter=None):
        self._state = None
        self.lang_filter = lang_filter
        self.logger = logging.getLogger(__name__)

    def reset(self):
        self._state = ProbingState.DETECTING

    @property
    def charset_name(self):
        return None

FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/cli/chardetect.py
"""
Script which takes one or more file paths and reports on their detected
encodings

Example::

    % chardetect somefile someotherfile
    somefile: windows-1252 with confidence 0.5
    someotherfile: ascii with confidence 1.0

If no paths are provided, it takes its input from stdin.

"""

from __future__ import absolute_import, print_function, unicode_literals

import argparse
import sys

from pip._vendor.chardet import __version__
from pip._vendor.chardet.compat import PY2
from pip._vendor.chardet.universaldetector import UniversalDetector


def description_of(lines, name='stdin'):
    """
    Return a string describing the probable encoding of a file or
    list of strings.

    :param lines: The lines to get the encoding of.
    :type lines: Iterable of bytes
    :param name: Name of file or collection of lines
    :type name: str
    """
    u = UniversalDetector()
    for line in lines:
        line = bytearray(line)
        u.feed(line)
        # shortcut out of the loop to save reading further - particularly useful if we read a BOM.
        if u.done:
            break
    u.close()
    result = u.result
    if PY2:
        name = name.decode(sys.getfilesystemencoding(), 'ignore')
    if result['encoding']:
        return '{}: {} with confidence {}'.format(name, result['encoding'],
                                                     result['confidence'])
    else:
        return '{}: no result'.format(name)
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/cli/__init__.py

FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/codingstatemachine.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import logging

from .enums import MachineState


class CodingStateMachine(object):
    """
    A state machine to verify a byte sequence for a particular encoding. For
    each byte the detector receives, it will feed that byte to every active
    state machine available, one byte at a time. The state machine changes its
    state based on its previous state and the byte it receives. There are 3
    states in a state machine that are of interest to an auto-detector:

    START state: This is the state to start with, or a legal byte sequence
                 (i.e. a valid code point) for character has been identified.

    ME state:  This indicates that the state machine identified a byte sequence
               that is specific to the charset it is designed for and that
               there is no other possible encoding which can contain this byte
               sequence. This will to lead to an immediate positive answer for
               the detector.

    ERROR state: This indicates the state machine identified an illegal byte
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/compat.py
######################## BEGIN LICENSE BLOCK ########################
# Contributor(s):
#   Dan Blanchard
#   Ian Cordasco
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import sys


if sys.version_info < (3, 0):
    PY2 = True
    PY3 = False
    string_types = (str, unicode)
    text_type = unicode
    iteritems = dict.iteritems
else:
    PY2 = False
    PY3 = True
    string_types = (bytes, str)
    text_type = str
    iteritems = dict.items
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/cp949prober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .chardistribution import EUCKRDistributionAnalysis
from .codingstatemachine import CodingStateMachine
from .mbcharsetprober import MultiByteCharSetProber
from .mbcssm import CP949_SM_MODEL


class CP949Prober(MultiByteCharSetProber):
    def __init__(self):
        super(CP949Prober, self).__init__()
        self.coding_sm = CodingStateMachine(CP949_SM_MODEL)
        # NOTE: CP949 is a superset of EUC-KR, so the distribution should be
        #       not different.
        self.distribution_analyzer = EUCKRDistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "CP949"

    @property
    def language(self):
        return "Korean"
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/enums.py
"""
All of the Enums that are used throughout the chardet package.

:author: Dan Blanchard (dan.blanchard@gmail.com)
"""


class InputState(object):
    """
    This enum represents the different states a universal detector can be in.
    """
    PURE_ASCII = 0
    ESC_ASCII = 1
    HIGH_BYTE = 2


class LanguageFilter(object):
    """
    This enum represents the different language filters we can apply to a
    ``UniversalDetector``.
    """
    CHINESE_SIMPLIFIED = 0x01
    CHINESE_TRADITIONAL = 0x02
    JAPANESE = 0x04
    KOREAN = 0x08
    NON_CJK = 0x10
    ALL = 0x1F
    CHINESE = CHINESE_SIMPLIFIED | CHINESE_TRADITIONAL
    CJK = CHINESE | JAPANESE | KOREAN


class ProbingState(object):
    """
    This enum represents the different states a prober can be in.
    """
    DETECTING = 0
    FOUND_IT = 1
    NOT_ME = 2


class MachineState(object):
    """
    This enum represents the different states a state machine can be in.
    """
    START = 0
    ERROR = 1
    ITS_ME = 2


class SequenceLikelihood(object):
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/escprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .codingstatemachine import CodingStateMachine
from .enums import LanguageFilter, ProbingState, MachineState
from .escsm import (HZ_SM_MODEL, ISO2022CN_SM_MODEL, ISO2022JP_SM_MODEL,
                    ISO2022KR_SM_MODEL)


class EscCharSetProber(CharSetProber):
    """
    This CharSetProber uses a "code scheme" approach for detecting encodings,
    whereby easily recognizable escape or shift sequences are relied on to
    identify these encodings.
    """

    def __init__(self, lang_filter=None):
        super(EscCharSetProber, self).__init__(lang_filter=lang_filter)
        self.coding_sm = []
        if self.lang_filter & LanguageFilter.CHINESE_SIMPLIFIED:
            self.coding_sm.append(CodingStateMachine(HZ_SM_MODEL))
            self.coding_sm.append(CodingStateMachine(ISO2022CN_SM_MODEL))
        if self.lang_filter & LanguageFilter.JAPANESE:
            self.coding_sm.append(CodingStateMachine(ISO2022JP_SM_MODEL))
        if self.lang_filter & LanguageFilter.KOREAN:
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/escsm.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .enums import MachineState

HZ_CLS = (
1,0,0,0,0,0,0,0,  # 00 - 07
0,0,0,0,0,0,0,0,  # 08 - 0f
0,0,0,0,0,0,0,0,  # 10 - 17
0,0,0,1,0,0,0,0,  # 18 - 1f
0,0,0,0,0,0,0,0,  # 20 - 27
0,0,0,0,0,0,0,0,  # 28 - 2f
0,0,0,0,0,0,0,0,  # 30 - 37
0,0,0,0,0,0,0,0,  # 38 - 3f
0,0,0,0,0,0,0,0,  # 40 - 47
0,0,0,0,0,0,0,0,  # 48 - 4f
0,0,0,0,0,0,0,0,  # 50 - 57
0,0,0,0,0,0,0,0,  # 58 - 5f
0,0,0,0,0,0,0,0,  # 60 - 67
0,0,0,0,0,0,0,0,  # 68 - 6f
0,0,0,0,0,0,0,0,  # 70 - 77
0,0,0,4,0,5,2,0,  # 78 - 7f
1,1,1,1,1,1,1,1,  # 80 - 87
1,1,1,1,1,1,1,1,  # 88 - 8f
1,1,1,1,1,1,1,1,  # 90 - 97
1,1,1,1,1,1,1,1,  # 98 - 9f
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/eucjpprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .enums import ProbingState, MachineState
from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import EUCJPDistributionAnalysis
from .jpcntx import EUCJPContextAnalysis
from .mbcssm import EUCJP_SM_MODEL


class EUCJPProber(MultiByteCharSetProber):
    def __init__(self):
        super(EUCJPProber, self).__init__()
        self.coding_sm = CodingStateMachine(EUCJP_SM_MODEL)
        self.distribution_analyzer = EUCJPDistributionAnalysis()
        self.context_analyzer = EUCJPContextAnalysis()
        self.reset()

    def reset(self):
        super(EUCJPProber, self).reset()
        self.context_analyzer.reset()

    @property
    def charset_name(self):
        return "EUC-JP"
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/euckrfreq.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# Sampling from about 20M text materials include literature and computer technology

# 128  --> 0.79
# 256  --> 0.92
# 512  --> 0.986
# 1024 --> 0.99944
# 2048 --> 0.99999
#
# Idea Distribution Ratio = 0.98653 / (1-0.98653) = 73.24
# Random Distribution Ration = 512 / (2350-512) = 0.279.
#
# Typical Distribution Ratio

EUCKR_TYPICAL_DISTRIBUTION_RATIO = 6.0

EUCKR_TABLE_SIZE = 2352

# Char to FreqOrder table ,
EUCKR_CHAR_TO_FREQ_ORDER = (
  13, 130, 120,1396, 481,1719,1720, 328, 609, 212,1721, 707, 400, 299,1722,  87,
1397,1723, 104, 536,1117,1203,1724,1267, 685,1268, 508,1725,1726,1727,1728,1398,
1399,1729,1730,1731, 141, 621, 326,1057, 368,1732, 267, 488,  20,1733,1269,1734,
 945,1400,1735,  47, 904,1270,1736,1737, 773, 248,1738, 409, 313, 786, 429,1739,
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/euckrprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import EUCKRDistributionAnalysis
from .mbcssm import EUCKR_SM_MODEL


class EUCKRProber(MultiByteCharSetProber):
    def __init__(self):
        super(EUCKRProber, self).__init__()
        self.coding_sm = CodingStateMachine(EUCKR_SM_MODEL)
        self.distribution_analyzer = EUCKRDistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "EUC-KR"

    @property
    def language(self):
        return "Korean"
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/euctwfreq.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# EUCTW frequency table
# Converted from big5 work
# by Taiwan's Mandarin Promotion Council
# <http:#www.edu.tw:81/mandr/>

# 128  --> 0.42261
# 256  --> 0.57851
# 512  --> 0.74851
# 1024 --> 0.89384
# 2048 --> 0.97583
#
# Idea Distribution Ratio = 0.74851/(1-0.74851) =2.98
# Random Distribution Ration = 512/(5401-512)=0.105
#
# Typical Distribution Ratio about 25% of Ideal one, still much higher than RDR

EUCTW_TYPICAL_DISTRIBUTION_RATIO = 0.75

# Char to FreqOrder table ,
EUCTW_TABLE_SIZE = 5376

EUCTW_CHAR_TO_FREQ_ORDER = (
   1,1800,1506, 255,1431, 198,   9,  82,   6,7310, 177, 202,3615,1256,2808, 110,  # 2742
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/euctwprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import EUCTWDistributionAnalysis
from .mbcssm import EUCTW_SM_MODEL

class EUCTWProber(MultiByteCharSetProber):
    def __init__(self):
        super(EUCTWProber, self).__init__()
        self.coding_sm = CodingStateMachine(EUCTW_SM_MODEL)
        self.distribution_analyzer = EUCTWDistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "EUC-TW"

    @property
    def language(self):
        return "Taiwan"
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/gb2312freq.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# GB2312 most frequently used character table
#
# Char to FreqOrder table , from hz6763

# 512  --> 0.79  -- 0.79
# 1024 --> 0.92  -- 0.13
# 2048 --> 0.98  -- 0.06
# 6768 --> 1.00  -- 0.02
#
# Ideal Distribution Ratio = 0.79135/(1-0.79135) = 3.79
# Random Distribution Ration = 512 / (3755 - 512) = 0.157
#
# Typical Distribution Ratio about 25% of Ideal one, still much higher that RDR

GB2312_TYPICAL_DISTRIBUTION_RATIO = 0.9

GB2312_TABLE_SIZE = 3760

GB2312_CHAR_TO_FREQ_ORDER = (
1671, 749,1443,2364,3924,3807,2330,3921,1704,3463,2691,1511,1515, 572,3191,2205,
2361, 224,2558, 479,1711, 963,3162, 440,4060,1905,2966,2947,3580,2647,3961,3842,
2204, 869,4207, 970,2678,5626,2944,2956,1479,4048, 514,3595, 588,1346,2820,3409,
 249,4088,1746,1873,2047,1774, 581,1813, 358,1174,3590,1014,1561,4844,2245, 670,
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/gb2312prober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import GB2312DistributionAnalysis
from .mbcssm import GB2312_SM_MODEL

class GB2312Prober(MultiByteCharSetProber):
    def __init__(self):
        super(GB2312Prober, self).__init__()
        self.coding_sm = CodingStateMachine(GB2312_SM_MODEL)
        self.distribution_analyzer = GB2312DistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "GB2312"

    @property
    def language(self):
        return "Chinese"
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/hebrewprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
#          Shy Shalom
# Portions created by the Initial Developer are Copyright (C) 2005
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .enums import ProbingState

# This prober doesn't actually recognize a language or a charset.
# It is a helper prober for the use of the Hebrew model probers

### General ideas of the Hebrew charset recognition ###
#
# Four main charsets exist in Hebrew:
# "ISO-8859-8" - Visual Hebrew
# "windows-1255" - Logical Hebrew
# "ISO-8859-8-I" - Logical Hebrew
# "x-mac-hebrew" - ?? Logical Hebrew ??
#
# Both "ISO" charsets use a completely identical set of code points, whereas
# "windows-1255" and "x-mac-hebrew" are two different proper supersets of
# these code points. windows-1255 defines additional characters in the range
# 0x80-0x9F as some misc punctuation marks as well as some Hebrew-specific
# diacritics and additional 'Yiddish' ligature letters in the range 0xc0-0xd6.
# x-mac-hebrew defines similar additional code points but with a different
# mapping.
#
# As far as an average Hebrew text with no diacritics is concerned, all four
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/jisfreq.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# Sampling from about 20M text materials include literature and computer technology
#
# Japanese frequency table, applied to both S-JIS and EUC-JP
# They are sorted in order.

# 128  --> 0.77094
# 256  --> 0.85710
# 512  --> 0.92635
# 1024 --> 0.97130
# 2048 --> 0.99431
#
# Ideal Distribution Ratio = 0.92635 / (1-0.92635) = 12.58
# Random Distribution Ration = 512 / (2965+62+83+86-512) = 0.191
#
# Typical Distribution Ratio, 25% of IDR

JIS_TYPICAL_DISTRIBUTION_RATIO = 3.0

# Char to FreqOrder table ,
JIS_TABLE_SIZE = 4368

JIS_CHAR_TO_FREQ_ORDER = (
  40,   1,   6, 182, 152, 180, 295,2127, 285, 381,3295,4304,3068,4606,3165,3510, #   16
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/jpcntx.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################


# This is hiragana 2-char sequence table, the number in each cell represents its frequency category
jp2CharContext = (
(0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1),
(2,4,0,4,0,3,0,4,0,3,4,4,4,2,4,3,3,4,3,2,3,3,4,2,3,3,3,2,4,1,4,3,3,1,5,4,3,4,3,4,3,5,3,0,3,5,4,2,0,3,1,0,3,3,0,3,3,0,1,1,0,4,3,0,3,3,0,4,0,2,0,3,5,5,5,5,4,0,4,1,0,3,4),
(0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2),
(0,4,0,5,0,5,0,4,0,4,5,4,4,3,5,3,5,1,5,3,4,3,4,4,3,4,3,3,4,3,5,4,4,3,5,5,3,5,5,5,3,5,5,3,4,5,5,3,1,3,2,0,3,4,0,4,2,0,4,2,1,5,3,2,3,5,0,4,0,2,0,5,4,4,5,4,5,0,4,0,0,4,4),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,3,0,4,0,3,0,3,0,4,5,4,3,3,3,3,4,3,5,4,4,3,5,4,4,3,4,3,4,4,4,4,5,3,4,4,3,4,5,5,4,5,5,1,4,5,4,3,0,3,3,1,3,3,0,4,4,0,3,3,1,5,3,3,3,5,0,4,0,3,0,4,4,3,4,3,3,0,4,1,1,3,4),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,4,0,3,0,3,0,4,0,3,4,4,3,2,2,1,2,1,3,1,3,3,3,3,3,4,3,1,3,3,5,3,3,0,4,3,0,5,4,3,3,5,4,4,3,4,4,5,0,1,2,0,1,2,0,2,2,0,1,0,0,5,2,2,1,4,0,3,0,1,0,4,4,3,5,4,3,0,2,1,0,4,3),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,3,0,5,0,4,0,2,1,4,4,2,4,1,4,2,4,2,4,3,3,3,4,3,3,3,3,1,4,2,3,3,3,1,4,4,1,1,1,4,3,3,2,0,2,4,3,2,0,3,3,0,3,1,1,0,0,0,3,3,0,4,2,2,3,4,0,4,0,3,0,4,4,5,3,4,4,0,3,0,0,1,4),
(1,4,0,4,0,4,0,4,0,3,5,4,4,3,4,3,5,4,3,3,4,3,5,4,4,4,4,3,4,2,4,3,3,1,5,4,3,2,4,5,4,5,5,4,4,5,4,4,0,3,2,2,3,3,0,4,3,1,3,2,1,4,3,3,4,5,0,3,0,2,0,4,5,5,4,5,4,0,4,0,0,5,4),
(0,5,0,5,0,4,0,3,0,4,4,3,4,3,3,3,4,0,4,4,4,3,4,3,4,3,3,1,4,2,4,3,4,0,5,4,1,4,5,4,4,5,3,2,4,3,4,3,2,4,1,3,3,3,2,3,2,0,4,3,3,4,3,3,3,4,0,4,0,3,0,4,5,4,4,4,3,0,4,1,0,1,3),
(0,3,1,4,0,3,0,2,0,3,4,4,3,1,4,2,3,3,4,3,4,3,4,3,4,4,3,2,3,1,5,4,4,1,4,4,3,5,4,4,3,5,5,4,3,4,4,3,1,2,3,1,2,2,0,3,2,0,3,1,0,5,3,3,3,4,3,3,3,3,4,4,4,4,5,4,2,0,3,3,2,4,3),
(0,2,0,3,0,1,0,1,0,0,3,2,0,0,2,0,1,0,2,1,3,3,3,1,2,3,1,0,1,0,4,2,1,1,3,3,0,4,3,3,1,4,3,3,0,3,3,2,0,0,0,0,1,0,0,2,0,0,0,0,0,4,1,0,2,3,2,2,2,1,3,3,3,4,4,3,2,0,3,1,0,3,3),
(0,4,0,4,0,3,0,3,0,4,4,4,3,3,3,3,3,3,4,3,4,2,4,3,4,3,3,2,4,3,4,5,4,1,4,5,3,5,4,5,3,5,4,0,3,5,5,3,1,3,3,2,2,3,0,3,4,1,3,3,2,4,3,3,3,4,0,4,0,3,0,4,5,4,4,5,3,0,4,1,0,3,4),
(0,2,0,3,0,3,0,0,0,2,2,2,1,0,1,0,0,0,3,0,3,0,3,0,1,3,1,0,3,1,3,3,3,1,3,3,3,0,1,3,1,3,4,0,0,3,1,1,0,3,2,0,0,0,0,1,3,0,1,0,0,3,3,2,0,3,0,0,0,0,0,3,4,3,4,3,3,0,3,0,0,2,3),
(2,3,0,3,0,2,0,1,0,3,3,4,3,1,3,1,1,1,3,1,4,3,4,3,3,3,0,0,3,1,5,4,3,1,4,3,2,5,5,4,4,4,4,3,3,4,4,4,0,2,1,1,3,2,0,1,2,0,0,1,0,4,1,3,3,3,0,3,0,1,0,4,4,4,5,5,3,0,2,0,0,4,4),
(0,2,0,1,0,3,1,3,0,2,3,3,3,0,3,1,0,0,3,0,3,2,3,1,3,2,1,1,0,0,4,2,1,0,2,3,1,4,3,2,0,4,4,3,1,3,1,3,0,1,0,0,1,0,0,0,1,0,0,0,0,4,1,1,1,2,0,3,0,0,0,3,4,2,4,3,2,0,1,0,0,3,3),
(0,1,0,4,0,5,0,4,0,2,4,4,2,3,3,2,3,3,5,3,3,3,4,3,4,2,3,0,4,3,3,3,4,1,4,3,2,1,5,5,3,4,5,1,3,5,4,2,0,3,3,0,1,3,0,4,2,0,1,3,1,4,3,3,3,3,0,3,0,1,0,3,4,4,4,5,5,0,3,0,1,4,5),
(0,2,0,3,0,3,0,0,0,2,3,1,3,0,4,0,1,1,3,0,3,4,3,2,3,1,0,3,3,2,3,1,3,0,2,3,0,2,1,4,1,2,2,0,0,3,3,0,0,2,0,0,0,1,0,0,0,0,2,2,0,3,2,1,3,3,0,2,0,2,0,0,3,3,1,2,4,0,3,0,2,2,3),
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/langbulgarianmodel.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from pip._vendor.chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

BULGARIAN_LANG_MODEL = {
    63: {  # 'e'
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # 'А'
        32: 0,  # 'Б'
        35: 0,  # 'В'
        43: 0,  # 'Г'
        37: 0,  # 'Д'
        44: 0,  # 'Е'
        55: 0,  # 'Ж'
        47: 0,  # 'З'
        40: 0,  # 'И'
        59: 0,  # 'Й'
        33: 0,  # 'К'
        46: 0,  # 'Л'
        38: 0,  # 'М'
        36: 0,  # 'Н'
        41: 0,  # 'О'
        30: 0,  # 'П'
        39: 0,  # 'Р'
        28: 0,  # 'С'
        34: 0,  # 'Т'
        51: 0,  # 'У'
        48: 0,  # 'Ф'
        49: 0,  # 'Х'
        53: 0,  # 'Ц'
        50: 0,  # 'Ч'
        54: 0,  # 'Ш'
        57: 0,  # 'Щ'
        61: 0,  # 'Ъ'
        60: 0,  # 'Ю'
        56: 0,  # 'Я'
        1: 0,  # 'а'
        18: 1,  # 'б'
        9: 1,  # 'в'
        20: 1,  # 'г'
        11: 1,  # 'д'
        3: 1,  # 'е'
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/langgreekmodel.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from pip._vendor.chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

GREEK_LANG_MODEL = {
    60: {  # 'e'
        60: 2,  # 'e'
        55: 1,  # 'o'
        58: 2,  # 't'
        36: 1,  # '·'
        61: 0,  # 'Ά'
        46: 0,  # 'Έ'
        54: 0,  # 'Ό'
        31: 0,  # 'Α'
        51: 0,  # 'Β'
        43: 0,  # 'Γ'
        41: 0,  # 'Δ'
        34: 0,  # 'Ε'
        40: 0,  # 'Η'
        52: 0,  # 'Θ'
        47: 0,  # 'Ι'
        44: 0,  # 'Κ'
        53: 0,  # 'Λ'
        38: 0,  # 'Μ'
        49: 0,  # 'Ν'
        59: 0,  # 'Ξ'
        39: 0,  # 'Ο'
        35: 0,  # 'Π'
        48: 0,  # 'Ρ'
        37: 0,  # 'Σ'
        33: 0,  # 'Τ'
        45: 0,  # 'Υ'
        56: 0,  # 'Φ'
        50: 1,  # 'Χ'
        57: 0,  # 'Ω'
        17: 0,  # 'ά'
        18: 0,  # 'έ'
        22: 0,  # 'ή'
        15: 0,  # 'ί'
        1: 0,  # 'α'
        29: 0,  # 'β'
        20: 0,  # 'γ'
        21: 0,  # 'δ'
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/langhebrewmodel.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from pip._vendor.chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

HEBREW_LANG_MODEL = {
    50: {  # 'a'
        50: 0,  # 'a'
        60: 1,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 2,  # 'l'
        54: 2,  # 'n'
        49: 0,  # 'o'
        51: 2,  # 'r'
        43: 1,  # 's'
        44: 2,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # '´'
        48: 0,  # '¼'
        39: 0,  # '½'
        57: 0,  # '¾'
        30: 0,  # 'ְ'
        59: 0,  # 'ֱ'
        41: 0,  # 'ֲ'
        33: 0,  # 'ִ'
        37: 0,  # 'ֵ'
        36: 0,  # 'ֶ'
        31: 0,  # 'ַ'
        29: 0,  # 'ָ'
        35: 0,  # 'ֹ'
        62: 0,  # 'ֻ'
        28: 0,  # 'ּ'
        38: 0,  # 'ׁ'
        45: 0,  # 'ׂ'
        9: 0,  # 'א'
        8: 0,  # 'ב'
        20: 0,  # 'ג'
        16: 0,  # 'ד'
        3: 1,  # 'ה'
        2: 0,  # 'ו'
        24: 0,  # 'ז'
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/langhungarianmodel.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from pip._vendor.chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

HUNGARIAN_LANG_MODEL = {
    28: {  # 'A'
        28: 0,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 2,  # 'D'
        32: 1,  # 'E'
        50: 1,  # 'F'
        49: 2,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 2,  # 'K'
        41: 2,  # 'L'
        34: 1,  # 'M'
        35: 2,  # 'N'
        47: 1,  # 'O'
        46: 2,  # 'P'
        43: 2,  # 'R'
        33: 2,  # 'S'
        37: 2,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 2,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 2,  # 'd'
        1: 1,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 1,  # 'i'
        22: 1,  # 'j'
        7: 2,  # 'k'
        6: 2,  # 'l'
        13: 2,  # 'm'
        4: 2,  # 'n'
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/langrussianmodel.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from pip._vendor.chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

RUSSIAN_LANG_MODEL = {
    37: {  # 'А'
        37: 0,  # 'А'
        44: 1,  # 'Б'
        33: 1,  # 'В'
        46: 1,  # 'Г'
        41: 1,  # 'Д'
        48: 1,  # 'Е'
        56: 1,  # 'Ж'
        51: 1,  # 'З'
        42: 1,  # 'И'
        60: 1,  # 'Й'
        36: 1,  # 'К'
        49: 1,  # 'Л'
        38: 1,  # 'М'
        31: 2,  # 'Н'
        34: 1,  # 'О'
        35: 1,  # 'П'
        45: 1,  # 'Р'
        32: 1,  # 'С'
        40: 1,  # 'Т'
        52: 1,  # 'У'
        53: 1,  # 'Ф'
        55: 1,  # 'Х'
        58: 1,  # 'Ц'
        50: 1,  # 'Ч'
        57: 1,  # 'Ш'
        63: 1,  # 'Щ'
        62: 0,  # 'Ы'
        61: 0,  # 'Ь'
        47: 0,  # 'Э'
        59: 1,  # 'Ю'
        43: 1,  # 'Я'
        3: 1,  # 'а'
        21: 2,  # 'б'
        10: 2,  # 'в'
        19: 2,  # 'г'
        13: 2,  # 'д'
        2: 0,  # 'е'
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/langthaimodel.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from pip._vendor.chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

THAI_LANG_MODEL = {
    5: {  # 'ก'
        5: 2,  # 'ก'
        30: 2,  # 'ข'
        24: 2,  # 'ค'
        8: 2,  # 'ง'
        26: 2,  # 'จ'
        52: 0,  # 'ฉ'
        34: 1,  # 'ช'
        51: 1,  # 'ซ'
        47: 0,  # 'ญ'
        58: 3,  # 'ฎ'
        57: 2,  # 'ฏ'
        49: 0,  # 'ฐ'
        53: 0,  # 'ฑ'
        55: 0,  # 'ฒ'
        43: 2,  # 'ณ'
        20: 2,  # 'ด'
        19: 3,  # 'ต'
        44: 0,  # 'ถ'
        14: 2,  # 'ท'
        48: 0,  # 'ธ'
        3: 2,  # 'น'
        17: 1,  # 'บ'
        25: 2,  # 'ป'
        39: 1,  # 'ผ'
        62: 1,  # 'ฝ'
        31: 1,  # 'พ'
        54: 0,  # 'ฟ'
        45: 1,  # 'ภ'
        9: 2,  # 'ม'
        16: 1,  # 'ย'
        2: 3,  # 'ร'
        61: 2,  # 'ฤ'
        15: 3,  # 'ล'
        12: 3,  # 'ว'
        42: 2,  # 'ศ'
        46: 3,  # 'ษ'
        18: 2,  # 'ส'
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/langturkishmodel.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from pip._vendor.chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

TURKISH_LANG_MODEL = {
    23: {  # 'A'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 1,  # 'g'
        25: 1,  # 'h'
        3: 1,  # 'i'
        24: 0,  # 'j'
        10: 2,  # 'k'
        5: 1,  # 'l'
        13: 1,  # 'm'
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/latin1prober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .enums import ProbingState

FREQ_CAT_NUM = 4

UDF = 0  # undefined
OTH = 1  # other
ASC = 2  # ascii capital letter
ASS = 3  # ascii small letter
ACV = 4  # accent capital vowel
ACO = 5  # accent capital other
ASV = 6  # accent small vowel
ASO = 7  # accent small other
CLASS_NUM = 8  # total classes

Latin1_CharToClass = (
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 00 - 07
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 08 - 0F
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 10 - 17
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 18 - 1F
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 20 - 27
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 28 - 2F
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/mbcharsetprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#   Proofpoint, Inc.
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .enums import ProbingState, MachineState


class MultiByteCharSetProber(CharSetProber):
    """
    MultiByteCharSetProber
    """

    def __init__(self, lang_filter=None):
        super(MultiByteCharSetProber, self).__init__(lang_filter=lang_filter)
        self.distribution_analyzer = None
        self.coding_sm = None
        self._last_char = [0, 0]

    def reset(self):
        super(MultiByteCharSetProber, self).reset()
        if self.coding_sm:
            self.coding_sm.reset()
        if self.distribution_analyzer:
            self.distribution_analyzer.reset()
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/mbcsgroupprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#   Proofpoint, Inc.
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetgroupprober import CharSetGroupProber
from .utf8prober import UTF8Prober
from .sjisprober import SJISProber
from .eucjpprober import EUCJPProber
from .gb2312prober import GB2312Prober
from .euckrprober import EUCKRProber
from .cp949prober import CP949Prober
from .big5prober import Big5Prober
from .euctwprober import EUCTWProber


class MBCSGroupProber(CharSetGroupProber):
    def __init__(self, lang_filter=None):
        super(MBCSGroupProber, self).__init__(lang_filter=lang_filter)
        self.probers = [
            UTF8Prober(),
            SJISProber(),
            EUCJPProber(),
            GB2312Prober(),
            EUCKRProber(),
            CP949Prober(),
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/mbcssm.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .enums import MachineState

# BIG5

BIG5_CLS = (
    1,1,1,1,1,1,1,1,  # 00 - 07    #allow 0x00 as legal value
    1,1,1,1,1,1,0,0,  # 08 - 0f
    1,1,1,1,1,1,1,1,  # 10 - 17
    1,1,1,0,1,1,1,1,  # 18 - 1f
    1,1,1,1,1,1,1,1,  # 20 - 27
    1,1,1,1,1,1,1,1,  # 28 - 2f
    1,1,1,1,1,1,1,1,  # 30 - 37
    1,1,1,1,1,1,1,1,  # 38 - 3f
    2,2,2,2,2,2,2,2,  # 40 - 47
    2,2,2,2,2,2,2,2,  # 48 - 4f
    2,2,2,2,2,2,2,2,  # 50 - 57
    2,2,2,2,2,2,2,2,  # 58 - 5f
    2,2,2,2,2,2,2,2,  # 60 - 67
    2,2,2,2,2,2,2,2,  # 68 - 6f
    2,2,2,2,2,2,2,2,  # 70 - 77
    2,2,2,2,2,2,2,1,  # 78 - 7f
    4,4,4,4,4,4,4,4,  # 80 - 87
    4,4,4,4,4,4,4,4,  # 88 - 8f
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/metadata/languages.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Metadata about languages used by our model training code for our
SingleByteCharSetProbers.  Could be used for other things in the future.

This code is based on the language metadata from the uchardet project.
"""
from __future__ import absolute_import, print_function

from string import ascii_letters


# TODO: Add Ukranian (KOI8-U)

class Language(object):
    """Metadata about a language useful for training models

    :ivar name: The human name for the language, in English.
    :type name: str
    :ivar iso_code: 2-letter ISO 639-1 if possible, 3-letter ISO code otherwise,
                    or use another catalog as a last resort.
    :type iso_code: str
    :ivar use_ascii: Whether or not ASCII letters should be included in trained
                     models.
    :type use_ascii: bool
    :ivar charsets: The charsets we want to support and create data for.
    :type charsets: list of str
    :ivar alphabet: The characters in the language's alphabet. If `use_ascii` is
                    `True`, you only need to add those not in the ASCII set.
    :type alphabet: str
    :ivar wiki_start_pages: The Wikipedia pages to start from if we're crawling
                            Wikipedia for training data.
    :type wiki_start_pages: list of str
    """
    def __init__(self, name=None, iso_code=None, use_ascii=True, charsets=None,
                 alphabet=None, wiki_start_pages=None):
        super(Language, self).__init__()
        self.name = name
        self.iso_code = iso_code
        self.use_ascii = use_ascii
        self.charsets = charsets
        if self.use_ascii:
            if alphabet:
                alphabet += ascii_letters
            else:
                alphabet = ascii_letters
        elif not alphabet:
            raise ValueError('Must supply alphabet if use_ascii is False')
        self.alphabet = ''.join(sorted(set(alphabet))) if alphabet else None
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/metadata/__init__.py
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/sbcharsetprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from collections import namedtuple

from .charsetprober import CharSetProber
from .enums import CharacterCategory, ProbingState, SequenceLikelihood


SingleByteCharSetModel = namedtuple('SingleByteCharSetModel',
                                    ['charset_name',
                                     'language',
                                     'char_to_order_map',
                                     'language_model',
                                     'typical_positive_ratio',
                                     'keep_ascii_letters',
                                     'alphabet'])


class SingleByteCharSetProber(CharSetProber):
    SAMPLE_SIZE = 64
    SB_ENOUGH_REL_THRESHOLD = 1024  #  0.25 * SAMPLE_SIZE^2
    POSITIVE_SHORTCUT_THRESHOLD = 0.95
    NEGATIVE_SHORTCUT_THRESHOLD = 0.05

FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/sbcsgroupprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetgroupprober import CharSetGroupProber
from .hebrewprober import HebrewProber
from .langbulgarianmodel import (ISO_8859_5_BULGARIAN_MODEL,
                                 WINDOWS_1251_BULGARIAN_MODEL)
from .langgreekmodel import ISO_8859_7_GREEK_MODEL, WINDOWS_1253_GREEK_MODEL
from .langhebrewmodel import WINDOWS_1255_HEBREW_MODEL
# from .langhungarianmodel import (ISO_8859_2_HUNGARIAN_MODEL,
#                                  WINDOWS_1250_HUNGARIAN_MODEL)
from .langrussianmodel import (IBM855_RUSSIAN_MODEL, IBM866_RUSSIAN_MODEL,
                               ISO_8859_5_RUSSIAN_MODEL, KOI8_R_RUSSIAN_MODEL,
                               MACCYRILLIC_RUSSIAN_MODEL,
                               WINDOWS_1251_RUSSIAN_MODEL)
from .langthaimodel import TIS_620_THAI_MODEL
from .langturkishmodel import ISO_8859_9_TURKISH_MODEL
from .sbcharsetprober import SingleByteCharSetProber


class SBCSGroupProber(CharSetGroupProber):
    def __init__(self):
        super(SBCSGroupProber, self).__init__()
        hebrew_prober = HebrewProber()
        logical_hebrew_prober = SingleByteCharSetProber(WINDOWS_1255_HEBREW_MODEL,
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/sjisprober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import SJISDistributionAnalysis
from .jpcntx import SJISContextAnalysis
from .mbcssm import SJIS_SM_MODEL
from .enums import ProbingState, MachineState


class SJISProber(MultiByteCharSetProber):
    def __init__(self):
        super(SJISProber, self).__init__()
        self.coding_sm = CodingStateMachine(SJIS_SM_MODEL)
        self.distribution_analyzer = SJISDistributionAnalysis()
        self.context_analyzer = SJISContextAnalysis()
        self.reset()

    def reset(self):
        super(SJISProber, self).reset()
        self.context_analyzer.reset()

    @property
    def charset_name(self):
        return self.context_analyzer.charset_name
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/universaldetector.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################
"""
Module containing the UniversalDetector detector class, which is the primary
class a user of ``chardet`` should use.

:author: Mark Pilgrim (initial port to Python)
:author: Shy Shalom (original C code)
:author: Dan Blanchard (major refactoring for 3.0)
:author: Ian Cordasco
"""


import codecs
import logging
import re

from .charsetgroupprober import CharSetGroupProber
from .enums import InputState, LanguageFilter, ProbingState
from .escprober import EscCharSetProber
from .latin1prober import Latin1Prober
from .mbcsgroupprober import MBCSGroupProber
from .sbcsgroupprober import SBCSGroupProber


FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/utf8prober.py
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .enums import ProbingState, MachineState
from .codingstatemachine import CodingStateMachine
from .mbcssm import UTF8_SM_MODEL



class UTF8Prober(CharSetProber):
    ONE_CHAR_PROB = 0.5

    def __init__(self):
        super(UTF8Prober, self).__init__()
        self.coding_sm = CodingStateMachine(UTF8_SM_MODEL)
        self._num_mb_chars = None
        self.reset()

    def reset(self):
        super(UTF8Prober, self).reset()
        self.coding_sm.reset()
        self._num_mb_chars = 0

    @property
    def charset_name(self):
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/version.py
"""
This module exists only to simplify retrieving the version number of chardet
from within setup.py and from chardet subpackages.

:author: Dan Blanchard (dan.blanchard@gmail.com)
"""

__version__ = "4.0.0"
VERSION = __version__.split('.')
FILE: ./venv/Lib/site-packages/pip/_vendor/chardet/__init__.py
######################## BEGIN LICENSE BLOCK ########################
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################


from .universaldetector import UniversalDetector
from .enums import InputState
from .version import __version__, VERSION


__all__ = ['UniversalDetector', 'detect', 'detect_all', '__version__', 'VERSION']


def detect(byte_str):
    """
    Detect the encoding of the given byte string.

    :param byte_str:     The byte sequence to examine.
    :type byte_str:      ``bytes`` or ``bytearray``
    """
    if not isinstance(byte_str, bytearray):
        if not isinstance(byte_str, bytes):
            raise TypeError('Expected object of type bytes or bytearray, got: '
                            '{}'.format(type(byte_str)))
        else:
            byte_str = bytearray(byte_str)
    detector = UniversalDetector()
    detector.feed(byte_str)
    return detector.close()


def detect_all(byte_str):
    """
    Detect all the possible encodings of the given byte string.

    :param byte_str:     The byte sequence to examine.
    :type byte_str:      ``bytes`` or ``bytearray``
FILE: ./venv/Lib/site-packages/pip/_vendor/colorama/ansi.py
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
'''
This module generates ANSI character codes to printing colors to terminals.
See: http://en.wikipedia.org/wiki/ANSI_escape_code
'''

CSI = '\033['
OSC = '\033]'
BEL = '\a'


def code_to_chars(code):
    return CSI + str(code) + 'm'

def set_title(title):
    return OSC + '2;' + title + BEL

def clear_screen(mode=2):
    return CSI + str(mode) + 'J'

def clear_line(mode=2):
    return CSI + str(mode) + 'K'


class AnsiCodes(object):
    def __init__(self):
        # the subclasses declare class attributes which are numbers.
        # Upon instantiation we define instance attributes, which are the same
        # as the class attributes but wrapped with the ANSI escape sequence
        for name in dir(self):
            if not name.startswith('_'):
                value = getattr(self, name)
                setattr(self, name, code_to_chars(value))


class AnsiCursor(object):
    def UP(self, n=1):
        return CSI + str(n) + 'A'
    def DOWN(self, n=1):
        return CSI + str(n) + 'B'
    def FORWARD(self, n=1):
        return CSI + str(n) + 'C'
    def BACK(self, n=1):
        return CSI + str(n) + 'D'
    def POS(self, x=1, y=1):
        return CSI + str(y) + ';' + str(x) + 'H'


class AnsiFore(AnsiCodes):
    BLACK           = 30
FILE: ./venv/Lib/site-packages/pip/_vendor/colorama/ansitowin32.py
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
import re
import sys
import os

from .ansi import AnsiFore, AnsiBack, AnsiStyle, Style, BEL
from .winterm import WinTerm, WinColor, WinStyle
from .win32 import windll, winapi_test


winterm = None
if windll is not None:
    winterm = WinTerm()


class StreamWrapper(object):
    '''
    Wraps a stream (such as stdout), acting as a transparent proxy for all
    attribute access apart from method 'write()', which is delegated to our
    Converter instance.
    '''
    def __init__(self, wrapped, converter):
        # double-underscore everything to prevent clashes with names of
        # attributes on the wrapped stream object.
        self.__wrapped = wrapped
        self.__convertor = converter

    def __getattr__(self, name):
        return getattr(self.__wrapped, name)

    def __enter__(self, *args, **kwargs):
        # special method lookup bypasses __getattr__/__getattribute__, see
        # https://stackoverflow.com/questions/12632894/why-doesnt-getattr-work-with-exit
        # thus, contextlib magic methods are not proxied via __getattr__
        return self.__wrapped.__enter__(*args, **kwargs)

    def __exit__(self, *args, **kwargs):
        return self.__wrapped.__exit__(*args, **kwargs)

    def write(self, text):
        self.__convertor.write(text)

    def isatty(self):
        stream = self.__wrapped
        if 'PYCHARM_HOSTED' in os.environ:
            if stream is not None and (stream is sys.__stdout__ or stream is sys.__stderr__):
                return True
        try:
            stream_isatty = stream.isatty
        except AttributeError:
FILE: ./venv/Lib/site-packages/pip/_vendor/colorama/initialise.py
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
import atexit
import contextlib
import sys

from .ansitowin32 import AnsiToWin32


orig_stdout = None
orig_stderr = None

wrapped_stdout = None
wrapped_stderr = None

atexit_done = False


def reset_all():
    if AnsiToWin32 is not None:    # Issue #74: objects might become None at exit
        AnsiToWin32(orig_stdout).reset_all()


def init(autoreset=False, convert=None, strip=None, wrap=True):

    if not wrap and any([autoreset, convert, strip]):
        raise ValueError('wrap=False conflicts with any other arg=True')

    global wrapped_stdout, wrapped_stderr
    global orig_stdout, orig_stderr

    orig_stdout = sys.stdout
    orig_stderr = sys.stderr

    if sys.stdout is None:
        wrapped_stdout = None
    else:
        sys.stdout = wrapped_stdout = \
            wrap_stream(orig_stdout, convert, strip, autoreset, wrap)
    if sys.stderr is None:
        wrapped_stderr = None
    else:
        sys.stderr = wrapped_stderr = \
            wrap_stream(orig_stderr, convert, strip, autoreset, wrap)

    global atexit_done
    if not atexit_done:
        atexit.register(reset_all)
        atexit_done = True


FILE: ./venv/Lib/site-packages/pip/_vendor/colorama/win32.py
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.

# from winbase.h
STDOUT = -11
STDERR = -12

try:
    import ctypes
    from ctypes import LibraryLoader
    windll = LibraryLoader(ctypes.WinDLL)
    from ctypes import wintypes
except (AttributeError, ImportError):
    windll = None
    SetConsoleTextAttribute = lambda *_: None
    winapi_test = lambda *_: None
else:
    from ctypes import byref, Structure, c_char, POINTER

    COORD = wintypes._COORD

    class CONSOLE_SCREEN_BUFFER_INFO(Structure):
        """struct in wincon.h."""
        _fields_ = [
            ("dwSize", COORD),
            ("dwCursorPosition", COORD),
            ("wAttributes", wintypes.WORD),
            ("srWindow", wintypes.SMALL_RECT),
            ("dwMaximumWindowSize", COORD),
        ]
        def __str__(self):
            return '(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d)' % (
                self.dwSize.Y, self.dwSize.X
                , self.dwCursorPosition.Y, self.dwCursorPosition.X
                , self.wAttributes
                , self.srWindow.Top, self.srWindow.Left, self.srWindow.Bottom, self.srWindow.Right
                , self.dwMaximumWindowSize.Y, self.dwMaximumWindowSize.X
            )

    _GetStdHandle = windll.kernel32.GetStdHandle
    _GetStdHandle.argtypes = [
        wintypes.DWORD,
    ]
    _GetStdHandle.restype = wintypes.HANDLE

    _GetConsoleScreenBufferInfo = windll.kernel32.GetConsoleScreenBufferInfo
    _GetConsoleScreenBufferInfo.argtypes = [
        wintypes.HANDLE,
        POINTER(CONSOLE_SCREEN_BUFFER_INFO),
    ]
    _GetConsoleScreenBufferInfo.restype = wintypes.BOOL
FILE: ./venv/Lib/site-packages/pip/_vendor/colorama/winterm.py
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
from . import win32


# from wincon.h
class WinColor(object):
    BLACK   = 0
    BLUE    = 1
    GREEN   = 2
    CYAN    = 3
    RED     = 4
    MAGENTA = 5
    YELLOW  = 6
    GREY    = 7

# from wincon.h
class WinStyle(object):
    NORMAL              = 0x00 # dim text, dim background
    BRIGHT              = 0x08 # bright text, dim background
    BRIGHT_BACKGROUND   = 0x80 # dim text, bright background

class WinTerm(object):

    def __init__(self):
        self._default = win32.GetConsoleScreenBufferInfo(win32.STDOUT).wAttributes
        self.set_attrs(self._default)
        self._default_fore = self._fore
        self._default_back = self._back
        self._default_style = self._style
        # In order to emulate LIGHT_EX in windows, we borrow the BRIGHT style.
        # So that LIGHT_EX colors and BRIGHT style do not clobber each other,
        # we track them separately, since LIGHT_EX is overwritten by Fore/Back
        # and BRIGHT is overwritten by Style codes.
        self._light = 0

    def get_attrs(self):
        return self._fore + self._back * 16 + (self._style | self._light)

    def set_attrs(self, value):
        self._fore = value & 7
        self._back = (value >> 4) & 7
        self._style = value & (WinStyle.BRIGHT | WinStyle.BRIGHT_BACKGROUND)

    def reset_all(self, on_stderr=None):
        self.set_attrs(self._default)
        self.set_console(attrs=self._default)
        self._light = 0

    def fore(self, fore=None, light=False, on_stderr=False):
        if fore is None:
FILE: ./venv/Lib/site-packages/pip/_vendor/colorama/__init__.py
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.
from .initialise import init, deinit, reinit, colorama_text
from .ansi import Fore, Back, Style, Cursor
from .ansitowin32 import AnsiToWin32

__version__ = '0.4.4'
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/compat.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2013-2017 Vinay Sajip.
# Licensed to the Python Software Foundation under a contributor agreement.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
from __future__ import absolute_import

import os
import re
import sys

try:
    import ssl
except ImportError:  # pragma: no cover
    ssl = None

if sys.version_info[0] < 3:  # pragma: no cover
    from StringIO import StringIO
    string_types = basestring,
    text_type = unicode
    from types import FileType as file_type
    import __builtin__ as builtins
    import ConfigParser as configparser
    from ._backport import shutil
    from urlparse import urlparse, urlunparse, urljoin, urlsplit, urlunsplit
    from urllib import (urlretrieve, quote as _quote, unquote, url2pathname,
                        pathname2url, ContentTooShortError, splittype)

    def quote(s):
        if isinstance(s, unicode):
            s = s.encode('utf-8')
        return _quote(s)

    import urllib2
    from urllib2 import (Request, urlopen, URLError, HTTPError,
                         HTTPBasicAuthHandler, HTTPPasswordMgr,
                         HTTPHandler, HTTPRedirectHandler,
                         build_opener)
    if ssl:
        from urllib2 import HTTPSHandler
    import httplib
    import xmlrpclib
    import Queue as queue
    from HTMLParser import HTMLParser
    import htmlentitydefs
    raw_input = raw_input
    from itertools import ifilter as filter
    from itertools import ifilterfalse as filterfalse

FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/database.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012-2017 The Python Software Foundation.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
"""PEP 376 implementation."""

from __future__ import unicode_literals

import base64
import codecs
import contextlib
import hashlib
import logging
import os
import posixpath
import sys
import zipimport

from . import DistlibException, resources
from .compat import StringIO
from .version import get_scheme, UnsupportedVersionError
from .metadata import (Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME,
                       LEGACY_METADATA_FILENAME)
from .util import (parse_requirement, cached_property, parse_name_and_version,
                   read_exports, write_exports, CSVReader, CSVWriter)


__all__ = ['Distribution', 'BaseInstalledDistribution',
           'InstalledDistribution', 'EggInfoDistribution',
           'DistributionPath']


logger = logging.getLogger(__name__)

EXPORTS_FILENAME = 'pydist-exports.json'
COMMANDS_FILENAME = 'pydist-commands.json'

DIST_FILES = ('INSTALLER', METADATA_FILENAME, 'RECORD', 'REQUESTED',
              'RESOURCES', EXPORTS_FILENAME, 'SHARED')

DISTINFO_EXT = '.dist-info'


class _Cache(object):
    """
    A simple cache mapping names and .dist-info paths to distributions
    """
    def __init__(self):
        """
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/index.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2013 Vinay Sajip.
# Licensed to the Python Software Foundation under a contributor agreement.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
import hashlib
import logging
import os
import shutil
import subprocess
import tempfile
try:
    from threading import Thread
except ImportError:
    from dummy_threading import Thread

from . import DistlibException
from .compat import (HTTPBasicAuthHandler, Request, HTTPPasswordMgr,
                     urlparse, build_opener, string_types)
from .util import zip_dir, ServerProxy

logger = logging.getLogger(__name__)

DEFAULT_INDEX = 'https://pypi.org/pypi'
DEFAULT_REALM = 'pypi'

class PackageIndex(object):
    """
    This class represents a package index compatible with PyPI, the Python
    Package Index.
    """

    boundary = b'----------ThIs_Is_tHe_distlib_index_bouNdaRY_$'

    def __init__(self, url=None):
        """
        Initialise an instance.

        :param url: The URL of the index. If not specified, the URL for PyPI is
                    used.
        """
        self.url = url or DEFAULT_INDEX
        self.read_configuration()
        scheme, netloc, path, params, query, frag = urlparse(self.url)
        if params or query or frag or scheme not in ('http', 'https'):
            raise DistlibException('invalid repository: %s' % self.url)
        self.password_handler = None
        self.ssl_verifier = None
        self.gpg = None
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/locators.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012-2015 Vinay Sajip.
# Licensed to the Python Software Foundation under a contributor agreement.
# See LICENSE.txt and CONTRIBUTORS.txt.
#

import gzip
from io import BytesIO
import json
import logging
import os
import posixpath
import re
try:
    import threading
except ImportError:  # pragma: no cover
    import dummy_threading as threading
import zlib

from . import DistlibException
from .compat import (urljoin, urlparse, urlunparse, url2pathname, pathname2url,
                     queue, quote, unescape, build_opener,
                     HTTPRedirectHandler as BaseRedirectHandler, text_type,
                     Request, HTTPError, URLError)
from .database import Distribution, DistributionPath, make_dist
from .metadata import Metadata, MetadataInvalidError
from .util import (cached_property, ensure_slash, split_filename, get_project_data,
                   parse_requirement, parse_name_and_version, ServerProxy,
                   normalize_name)
from .version import get_scheme, UnsupportedVersionError
from .wheel import Wheel, is_compatible

logger = logging.getLogger(__name__)

HASHER_HASH = re.compile(r'^(\w+)=([a-f0-9]+)')
CHARSET = re.compile(r';\s*charset\s*=\s*(.*)\s*$', re.I)
HTML_CONTENT_TYPE = re.compile('text/html|application/x(ht)?ml')
DEFAULT_INDEX = 'https://pypi.org/pypi'

def get_all_distribution_names(url=None):
    """
    Return all distribution names known by an index.
    :param url: The URL of the index.
    :return: A list of all known distribution names.
    """
    if url is None:
        url = DEFAULT_INDEX
    client = ServerProxy(url, timeout=3.0)
    try:
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/manifest.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012-2013 Python Software Foundation.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
"""
Class representing the list of files in a distribution.

Equivalent to distutils.filelist, but fixes some problems.
"""
import fnmatch
import logging
import os
import re
import sys

from . import DistlibException
from .compat import fsdecode
from .util import convert_path


__all__ = ['Manifest']

logger = logging.getLogger(__name__)

# a \ followed by some spaces + EOL
_COLLAPSE_PATTERN = re.compile('\\\\w*\n', re.M)
_COMMENTED_LINE = re.compile('#.*?(?=\n)|\n(?=$)', re.M | re.S)

#
# Due to the different results returned by fnmatch.translate, we need
# to do slightly different processing for Python 2.7 and 3.2 ... this needed
# to be brought in for Python 3.6 onwards.
#
_PYTHON_VERSION = sys.version_info[:2]

class Manifest(object):
    """A list of files built by on exploring the filesystem and filtered by
    applying various patterns to what we find there.
    """

    def __init__(self, base=None):
        """
        Initialise an instance.

        :param base: The base directory to explore under.
        """
        self.base = os.path.abspath(os.path.normpath(base or os.getcwd()))
        self.prefix = self.base + os.sep
        self.allfiles = None
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/markers.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012-2017 Vinay Sajip.
# Licensed to the Python Software Foundation under a contributor agreement.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
"""
Parser for the environment markers micro-language defined in PEP 508.
"""

# Note: In PEP 345, the micro-language was Python compatible, so the ast
# module could be used to parse it. However, PEP 508 introduced operators such
# as ~= and === which aren't in Python, necessitating a different approach.

import os
import re
import sys
import platform

from .compat import string_types
from .util import in_venv, parse_marker
from .version import NormalizedVersion as NV

__all__ = ['interpret']

_VERSION_PATTERN = re.compile(r'((\d+(\.\d+)*\w*)|\'(\d+(\.\d+)*\w*)\'|\"(\d+(\.\d+)*\w*)\")')

def _is_literal(o):
    if not isinstance(o, string_types) or not o:
        return False
    return o[0] in '\'"'

def _get_versions(s):
    result = []
    for m in _VERSION_PATTERN.finditer(s):
        result.append(NV(m.groups()[0]))
    return set(result)

class Evaluator(object):
    """
    This class is used to evaluate marker expessions.
    """

    operations = {
        '==': lambda x, y: x == y,
        '===': lambda x, y: x == y,
        '~=': lambda x, y: x == y or x > y,
        '!=': lambda x, y: x != y,
        '<':  lambda x, y: x < y,
        '<=':  lambda x, y: x == y or x < y,
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/metadata.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 The Python Software Foundation.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
"""Implementation of the Metadata for Python packages PEPs.

Supports all metadata formats (1.0, 1.1, 1.2, 1.3/2.1 and withdrawn 2.0).
"""
from __future__ import unicode_literals

import codecs
from email import message_from_file
import json
import logging
import re


from . import DistlibException, __version__
from .compat import StringIO, string_types, text_type
from .markers import interpret
from .util import extract_by_key, get_extras
from .version import get_scheme, PEP440_VERSION_RE

logger = logging.getLogger(__name__)


class MetadataMissingError(DistlibException):
    """A required metadata is missing"""


class MetadataConflictError(DistlibException):
    """Attempt to read or write metadata fields that are conflictual."""


class MetadataUnrecognizedVersionError(DistlibException):
    """Unknown metadata version number."""


class MetadataInvalidError(DistlibException):
    """A metadata value is invalid"""

# public API of this module
__all__ = ['Metadata', 'PKG_INFO_ENCODING', 'PKG_INFO_PREFERRED_VERSION']

# Encoding used for the PKG-INFO files
PKG_INFO_ENCODING = 'utf-8'

# preferred version. Hopefully will be changed
# to 1.2 once PEP 345 is supported everywhere
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/resources.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2013-2017 Vinay Sajip.
# Licensed to the Python Software Foundation under a contributor agreement.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
from __future__ import unicode_literals

import bisect
import io
import logging
import os
import pkgutil
import sys
import types
import zipimport

from . import DistlibException
from .util import cached_property, get_cache_base, Cache

logger = logging.getLogger(__name__)


cache = None    # created when needed


class ResourceCache(Cache):
    def __init__(self, base=None):
        if base is None:
            # Use native string to avoid issues on 2.x: see Python #20140.
            base = os.path.join(get_cache_base(), str('resource-cache'))
        super(ResourceCache, self).__init__(base)

    def is_stale(self, resource, path):
        """
        Is the cache stale for the given resource?

        :param resource: The :class:`Resource` being cached.
        :param path: The path of the resource in the cache.
        :return: True if the cache is stale.
        """
        # Cache invalidation is a hard problem :-)
        return True

    def get(self, resource):
        """
        Get a resource into the cache,

        :param resource: A :class:`Resource` instance.
        :return: The pathname of the resource in the cache.
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/scripts.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2013-2015 Vinay Sajip.
# Licensed to the Python Software Foundation under a contributor agreement.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
from io import BytesIO
import logging
import os
import re
import struct
import sys

from .compat import sysconfig, detect_encoding, ZipFile
from .resources import finder
from .util import (FileOperator, get_export_entry, convert_path,
                   get_executable, get_platform, in_venv)

logger = logging.getLogger(__name__)

_DEFAULT_MANIFEST = '''
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0">
 <assemblyIdentity version="1.0.0.0"
 processorArchitecture="X86"
 name="%s"
 type="win32"/>

 <!-- Identify the application security requirements. -->
 <trustInfo xmlns="urn:schemas-microsoft-com:asm.v3">
 <security>
 <requestedPrivileges>
 <requestedExecutionLevel level="asInvoker" uiAccess="false"/>
 </requestedPrivileges>
 </security>
 </trustInfo>
</assembly>'''.strip()

# check if Python is called on the first line with this expression
FIRST_LINE_RE = re.compile(b'^#!.*pythonw?[0-9.]*([ \t].*)?$')
SCRIPT_TEMPLATE = r'''# -*- coding: utf-8 -*-
import re
import sys
from %(module)s import %(import_name)s
if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
    sys.exit(%(func)s())
'''


FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/util.py
#
# Copyright (C) 2012-2021 The Python Software Foundation.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
import codecs
from collections import deque
import contextlib
import csv
from glob import iglob as std_iglob
import io
import json
import logging
import os
import py_compile
import re
import socket
try:
    import ssl
except ImportError:  # pragma: no cover
    ssl = None
import subprocess
import sys
import tarfile
import tempfile
import textwrap

try:
    import threading
except ImportError:  # pragma: no cover
    import dummy_threading as threading
import time

from . import DistlibException
from .compat import (string_types, text_type, shutil, raw_input, StringIO,
                     cache_from_source, urlopen, urljoin, httplib, xmlrpclib,
                     splittype, HTTPHandler, BaseConfigurator, valid_ident,
                     Container, configparser, URLError, ZipFile, fsdecode,
                     unquote, urlparse)

logger = logging.getLogger(__name__)

#
# Requirement parsing code as per PEP 508
#

IDENTIFIER = re.compile(r'^([\w\.-]+)\s*')
VERSION_IDENTIFIER = re.compile(r'^([\w\.*+-]+)\s*')
COMPARE_OP = re.compile(r'^(<=?|>=?|={2,3}|[~!]=)\s*')
MARKER_OP = re.compile(r'^((<=?)|(>=?)|={2,3}|[~!]=|in|not\s+in)\s*')
OR = re.compile(r'^or\b\s*')
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/version.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012-2017 The Python Software Foundation.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
"""
Implementation of a flexible versioning scheme providing support for PEP-440,
setuptools-compatible and semantic versioning.
"""

import logging
import re

from .compat import string_types
from .util import parse_requirement

__all__ = ['NormalizedVersion', 'NormalizedMatcher',
           'LegacyVersion', 'LegacyMatcher',
           'SemanticVersion', 'SemanticMatcher',
           'UnsupportedVersionError', 'get_scheme']

logger = logging.getLogger(__name__)


class UnsupportedVersionError(ValueError):
    """This is an unsupported version."""
    pass


class Version(object):
    def __init__(self, s):
        self._string = s = s.strip()
        self._parts = parts = self.parse(s)
        assert isinstance(parts, tuple)
        assert len(parts) > 0

    def parse(self, s):
        raise NotImplementedError('please implement in a subclass')

    def _check_compatible(self, other):
        if type(self) != type(other):
            raise TypeError('cannot compare %r and %r' % (self, other))

    def __eq__(self, other):
        self._check_compatible(other)
        return self._parts == other._parts

    def __ne__(self, other):
        return not self.__eq__(other)

FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/wheel.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2013-2020 Vinay Sajip.
# Licensed to the Python Software Foundation under a contributor agreement.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
from __future__ import unicode_literals

import base64
import codecs
import datetime
from email import message_from_file
import hashlib
import imp
import json
import logging
import os
import posixpath
import re
import shutil
import sys
import tempfile
import zipfile

from . import __version__, DistlibException
from .compat import sysconfig, ZipFile, fsdecode, text_type, filter
from .database import InstalledDistribution
from .metadata import (Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME,
                       LEGACY_METADATA_FILENAME)
from .util import (FileOperator, convert_path, CSVReader, CSVWriter, Cache,
                   cached_property, get_cache_base, read_exports, tempdir,
                   get_platform)
from .version import NormalizedVersion, UnsupportedVersionError

logger = logging.getLogger(__name__)

cache = None    # created when needed

if hasattr(sys, 'pypy_version_info'):  # pragma: no cover
    IMP_PREFIX = 'pp'
elif sys.platform.startswith('java'):  # pragma: no cover
    IMP_PREFIX = 'jy'
elif sys.platform == 'cli':  # pragma: no cover
    IMP_PREFIX = 'ip'
else:
    IMP_PREFIX = 'cp'

VER_SUFFIX = sysconfig.get_config_var('py_version_nodot')
if not VER_SUFFIX:   # pragma: no cover
    VER_SUFFIX = '%s%s' % sys.version_info[:2]
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/_backport/misc.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 The Python Software Foundation.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
"""Backports for individual classes and functions."""

import os
import sys

__all__ = ['cache_from_source', 'callable', 'fsencode']


try:
    from imp import cache_from_source
except ImportError:
    def cache_from_source(py_file, debug=__debug__):
        ext = debug and 'c' or 'o'
        return py_file + ext


try:
    callable = callable
except NameError:
    from collections import Callable

    def callable(obj):
        return isinstance(obj, Callable)


try:
    fsencode = os.fsencode
except AttributeError:
    def fsencode(filename):
        if isinstance(filename, bytes):
            return filename
        elif isinstance(filename, str):
            return filename.encode(sys.getfilesystemencoding())
        else:
            raise TypeError("expect bytes or str, not %s" %
                            type(filename).__name__)
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/_backport/shutil.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 The Python Software Foundation.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
"""Utility functions for copying and archiving files and directory trees.

XXX The functions here don't copy the resource fork or other metadata on Mac.

"""

import os
import sys
import stat
from os.path import abspath
import fnmatch
try:
    from collections.abc import Callable
except ImportError:
    from collections import Callable
import errno
from . import tarfile

try:
    import bz2
    _BZ2_SUPPORTED = True
except ImportError:
    _BZ2_SUPPORTED = False

try:
    from pwd import getpwnam
except ImportError:
    getpwnam = None

try:
    from grp import getgrnam
except ImportError:
    getgrnam = None

__all__ = ["copyfileobj", "copyfile", "copymode", "copystat", "copy", "copy2",
           "copytree", "move", "rmtree", "Error", "SpecialFileError",
           "ExecError", "make_archive", "get_archive_formats",
           "register_archive_format", "unregister_archive_format",
           "get_unpack_formats", "register_unpack_format",
           "unregister_unpack_format", "unpack_archive", "ignore_patterns"]

class Error(EnvironmentError):
    pass

class SpecialFileError(EnvironmentError):
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/_backport/sysconfig.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 The Python Software Foundation.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
"""Access to Python's configuration information."""

import codecs
import os
import re
import sys
from os.path import pardir, realpath
try:
    import configparser
except ImportError:
    import ConfigParser as configparser


__all__ = [
    'get_config_h_filename',
    'get_config_var',
    'get_config_vars',
    'get_makefile_filename',
    'get_path',
    'get_path_names',
    'get_paths',
    'get_platform',
    'get_python_version',
    'get_scheme_names',
    'parse_config_h',
]


def _safe_realpath(path):
    try:
        return realpath(path)
    except OSError:
        return path


if sys.executable:
    _PROJECT_BASE = os.path.dirname(_safe_realpath(sys.executable))
else:
    # sys.executable can be empty if argv[0] has been changed and Python is
    # unable to retrieve the real program name
    _PROJECT_BASE = _safe_realpath(os.getcwd())

if os.name == "nt" and "pcbuild" in _PROJECT_BASE[-8:].lower():
    _PROJECT_BASE = _safe_realpath(os.path.join(_PROJECT_BASE, pardir))
# PC/VS7.1
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/_backport/tarfile.py
#-------------------------------------------------------------------
# tarfile.py
#-------------------------------------------------------------------
# Copyright (C) 2002 Lars Gustaebel <lars@gustaebel.de>
# All rights reserved.
#
# Permission  is  hereby granted,  free  of charge,  to  any person
# obtaining a  copy of  this software  and associated documentation
# files  (the  "Software"),  to   deal  in  the  Software   without
# restriction,  including  without limitation  the  rights to  use,
# copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies  of  the  Software,  and to  permit  persons  to  whom the
# Software  is  furnished  to  do  so,  subject  to  the  following
# conditions:
#
# The above copyright  notice and this  permission notice shall  be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS  IS", WITHOUT WARRANTY OF ANY  KIND,
# EXPRESS OR IMPLIED, INCLUDING  BUT NOT LIMITED TO  THE WARRANTIES
# OF  MERCHANTABILITY,  FITNESS   FOR  A  PARTICULAR   PURPOSE  AND
# NONINFRINGEMENT.  IN  NO  EVENT SHALL  THE  AUTHORS  OR COPYRIGHT
# HOLDERS  BE LIABLE  FOR ANY  CLAIM, DAMAGES  OR OTHER  LIABILITY,
# WHETHER  IN AN  ACTION OF  CONTRACT, TORT  OR OTHERWISE,  ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
# OTHER DEALINGS IN THE SOFTWARE.
#
from __future__ import print_function

"""Read from and write to tar format archives.
"""

__version__ = "$Revision$"

version     = "0.9.0"
__author__  = "Lars Gust\u00e4bel (lars@gustaebel.de)"
__date__    = "$Date: 2011-02-25 17:42:01 +0200 (Fri, 25 Feb 2011) $"
__cvsid__   = "$Id: tarfile.py 88586 2011-02-25 15:42:01Z marc-andre.lemburg $"
__credits__ = "Gustavo Niemeyer, Niels Gust\u00e4bel, Richard Townsend."

#---------
# Imports
#---------
import sys
import os
import stat
import errno
import time
import struct
import copy
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/_backport/__init__.py
"""Modules copied from Python 3 standard libraries, for internal use only.

Individual classes and functions are found in d2._backport.misc.  Intended
usage is to always import things missing from 3.1 from that module: the
built-in/stdlib objects will be used if found.
"""
FILE: ./venv/Lib/site-packages/pip/_vendor/distlib/__init__.py
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012-2019 Vinay Sajip.
# Licensed to the Python Software Foundation under a contributor agreement.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
import logging

__version__ = '0.3.3'

class DistlibException(Exception):
    pass

try:
    from logging import NullHandler
except ImportError: # pragma: no cover
    class NullHandler(logging.Handler):
        def handle(self, record): pass
        def emit(self, record): pass
        def createLock(self): self.lock = None

logger = logging.getLogger(__name__)
logger.addHandler(NullHandler())
FILE: ./venv/Lib/site-packages/pip/_vendor/distro.py
# Copyright 2015,2016,2017 Nir Cohen
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
The ``distro`` package (``distro`` stands for Linux Distribution) provides
information about the Linux distribution it runs on, such as a reliable
machine-readable distro ID, or version information.

It is the recommended replacement for Python's original
:py:func:`platform.linux_distribution` function, but it provides much more
functionality. An alternative implementation became necessary because Python
3.5 deprecated this function, and Python 3.8 removed it altogether. Its
predecessor function :py:func:`platform.dist` was already deprecated since
Python 2.6 and removed in Python 3.8. Still, there are many cases in which
access to OS distribution information is needed. See `Python issue 1322
<https://bugs.python.org/issue1322>`_ for more information.
"""

import argparse
import json
import logging
import os
import re
import shlex
import subprocess
import sys
import warnings

__version__ = "1.6.0"

# Use `if False` to avoid an ImportError on Python 2. After dropping Python 2
# support, can use typing.TYPE_CHECKING instead. See:
# https://docs.python.org/3/library/typing.html#typing.TYPE_CHECKING
if False:  # pragma: nocover
    from typing import (
        Any,
        Callable,
        Dict,
        Iterable,
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/constants.py
from __future__ import absolute_import, division, unicode_literals

import string

EOF = None

E = {
    "null-character":
        "Null character in input stream, replaced with U+FFFD.",
    "invalid-codepoint":
        "Invalid codepoint in stream.",
    "incorrectly-placed-solidus":
        "Solidus (/) incorrectly placed in tag.",
    "incorrect-cr-newline-entity":
        "Incorrect CR newline entity, replaced with LF.",
    "illegal-windows-1252-entity":
        "Entity used with illegal number (windows-1252 reference).",
    "cant-convert-numeric-entity":
        "Numeric entity couldn't be converted to character "
        "(codepoint U+%(charAsInt)08x).",
    "illegal-codepoint-for-numeric-entity":
        "Numeric entity represents an illegal codepoint: "
        "U+%(charAsInt)08x.",
    "numeric-entity-without-semicolon":
        "Numeric entity didn't end with ';'.",
    "expected-numeric-entity-but-got-eof":
        "Numeric entity expected. Got end of file instead.",
    "expected-numeric-entity":
        "Numeric entity expected but none found.",
    "named-entity-without-semicolon":
        "Named entity didn't end with ';'.",
    "expected-named-entity":
        "Named entity expected. Got none.",
    "attributes-in-end-tag":
        "End tag contains unexpected attributes.",
    'self-closing-flag-on-end-tag':
        "End tag contains unexpected self-closing flag.",
    "expected-tag-name-but-got-right-bracket":
        "Expected tag name. Got '>' instead.",
    "expected-tag-name-but-got-question-mark":
        "Expected tag name. Got '?' instead. (HTML doesn't "
        "support processing instructions.)",
    "expected-tag-name":
        "Expected tag name. Got something else instead",
    "expected-closing-tag-but-got-right-bracket":
        "Expected closing tag. Got '>' instead. Ignoring '</>'.",
    "expected-closing-tag-but-got-eof":
        "Expected closing tag. Unexpected end of file.",
    "expected-closing-tag-but-got-char":
        "Expected closing tag. Unexpected character '%(data)s' found.",
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/filters/alphabeticalattributes.py
from __future__ import absolute_import, division, unicode_literals

from . import base

from collections import OrderedDict


def _attr_key(attr):
    """Return an appropriate key for an attribute for sorting

    Attributes have a namespace that can be either ``None`` or a string. We
    can't compare the two because they're different types, so we convert
    ``None`` to an empty string first.

    """
    return (attr[0][0] or ''), attr[0][1]


class Filter(base.Filter):
    """Alphabetizes attributes for elements"""
    def __iter__(self):
        for token in base.Filter.__iter__(self):
            if token["type"] in ("StartTag", "EmptyTag"):
                attrs = OrderedDict()
                for name, value in sorted(token["data"].items(),
                                          key=_attr_key):
                    attrs[name] = value
                token["data"] = attrs
            yield token
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/filters/base.py
from __future__ import absolute_import, division, unicode_literals


class Filter(object):
    def __init__(self, source):
        self.source = source

    def __iter__(self):
        return iter(self.source)

    def __getattr__(self, name):
        return getattr(self.source, name)
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/filters/inject_meta_charset.py
from __future__ import absolute_import, division, unicode_literals

from . import base


class Filter(base.Filter):
    """Injects ``<meta charset=ENCODING>`` tag into head of document"""
    def __init__(self, source, encoding):
        """Creates a Filter

        :arg source: the source token stream

        :arg encoding: the encoding to set

        """
        base.Filter.__init__(self, source)
        self.encoding = encoding

    def __iter__(self):
        state = "pre_head"
        meta_found = (self.encoding is None)
        pending = []

        for token in base.Filter.__iter__(self):
            type = token["type"]
            if type == "StartTag":
                if token["name"].lower() == "head":
                    state = "in_head"

            elif type == "EmptyTag":
                if token["name"].lower() == "meta":
                    # replace charset with actual encoding
                    has_http_equiv_content_type = False
                    for (namespace, name), value in token["data"].items():
                        if namespace is not None:
                            continue
                        elif name.lower() == 'charset':
                            token["data"][(namespace, name)] = self.encoding
                            meta_found = True
                            break
                        elif name == 'http-equiv' and value.lower() == 'content-type':
                            has_http_equiv_content_type = True
                    else:
                        if has_http_equiv_content_type and (None, "content") in token["data"]:
                            token["data"][(None, "content")] = 'text/html; charset=%s' % self.encoding
                            meta_found = True

                elif token["name"].lower() == "head" and not meta_found:
                    # insert meta into empty head
                    yield {"type": "StartTag", "name": "head",
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/filters/lint.py
from __future__ import absolute_import, division, unicode_literals

from pip._vendor.six import text_type

from . import base
from ..constants import namespaces, voidElements

from ..constants import spaceCharacters
spaceCharacters = "".join(spaceCharacters)


class Filter(base.Filter):
    """Lints the token stream for errors

    If it finds any errors, it'll raise an ``AssertionError``.

    """
    def __init__(self, source, require_matching_tags=True):
        """Creates a Filter

        :arg source: the source token stream

        :arg require_matching_tags: whether or not to require matching tags

        """
        super(Filter, self).__init__(source)
        self.require_matching_tags = require_matching_tags

    def __iter__(self):
        open_elements = []
        for token in base.Filter.__iter__(self):
            type = token["type"]
            if type in ("StartTag", "EmptyTag"):
                namespace = token["namespace"]
                name = token["name"]
                assert namespace is None or isinstance(namespace, text_type)
                assert namespace != ""
                assert isinstance(name, text_type)
                assert name != ""
                assert isinstance(token["data"], dict)
                if (not namespace or namespace == namespaces["html"]) and name in voidElements:
                    assert type == "EmptyTag"
                else:
                    assert type == "StartTag"
                if type == "StartTag" and self.require_matching_tags:
                    open_elements.append((namespace, name))
                for (namespace, name), value in token["data"].items():
                    assert namespace is None or isinstance(namespace, text_type)
                    assert namespace != ""
                    assert isinstance(name, text_type)
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/filters/optionaltags.py
from __future__ import absolute_import, division, unicode_literals

from . import base


class Filter(base.Filter):
    """Removes optional tags from the token stream"""
    def slider(self):
        previous1 = previous2 = None
        for token in self.source:
            if previous1 is not None:
                yield previous2, previous1, token
            previous2 = previous1
            previous1 = token
        if previous1 is not None:
            yield previous2, previous1, None

    def __iter__(self):
        for previous, token, next in self.slider():
            type = token["type"]
            if type == "StartTag":
                if (token["data"] or
                        not self.is_optional_start(token["name"], previous, next)):
                    yield token
            elif type == "EndTag":
                if not self.is_optional_end(token["name"], next):
                    yield token
            else:
                yield token

    def is_optional_start(self, tagname, previous, next):
        type = next and next["type"] or None
        if tagname in 'html':
            # An html element's start tag may be omitted if the first thing
            # inside the html element is not a space character or a comment.
            return type not in ("Comment", "SpaceCharacters")
        elif tagname == 'head':
            # A head element's start tag may be omitted if the first thing
            # inside the head element is an element.
            # XXX: we also omit the start tag if the head element is empty
            if type in ("StartTag", "EmptyTag"):
                return True
            elif type == "EndTag":
                return next["name"] == "head"
        elif tagname == 'body':
            # A body element's start tag may be omitted if the first thing
            # inside the body element is not a space character or a comment,
            # except if the first thing inside the body element is a script
            # or style element and the node immediately preceding the body
            # element is a head element whose end tag has been omitted.
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/filters/sanitizer.py
"""Deprecated from html5lib 1.1.

See `here <https://github.com/html5lib/html5lib-python/issues/443>`_ for
information about its deprecation; `Bleach <https://github.com/mozilla/bleach>`_
is recommended as a replacement. Please let us know in the aforementioned issue
if Bleach is unsuitable for your needs.

"""
from __future__ import absolute_import, division, unicode_literals

import re
import warnings
from xml.sax.saxutils import escape, unescape

from pip._vendor.six.moves import urllib_parse as urlparse

from . import base
from ..constants import namespaces, prefixes

__all__ = ["Filter"]


_deprecation_msg = (
    "html5lib's sanitizer is deprecated; see " +
    "https://github.com/html5lib/html5lib-python/issues/443 and please let " +
    "us know if Bleach is unsuitable for your needs"
)

warnings.warn(_deprecation_msg, DeprecationWarning)

allowed_elements = frozenset((
    (namespaces['html'], 'a'),
    (namespaces['html'], 'abbr'),
    (namespaces['html'], 'acronym'),
    (namespaces['html'], 'address'),
    (namespaces['html'], 'area'),
    (namespaces['html'], 'article'),
    (namespaces['html'], 'aside'),
    (namespaces['html'], 'audio'),
    (namespaces['html'], 'b'),
    (namespaces['html'], 'big'),
    (namespaces['html'], 'blockquote'),
    (namespaces['html'], 'br'),
    (namespaces['html'], 'button'),
    (namespaces['html'], 'canvas'),
    (namespaces['html'], 'caption'),
    (namespaces['html'], 'center'),
    (namespaces['html'], 'cite'),
    (namespaces['html'], 'code'),
    (namespaces['html'], 'col'),
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/filters/whitespace.py
from __future__ import absolute_import, division, unicode_literals

import re

from . import base
from ..constants import rcdataElements, spaceCharacters
spaceCharacters = "".join(spaceCharacters)

SPACES_REGEX = re.compile("[%s]+" % spaceCharacters)


class Filter(base.Filter):
    """Collapses whitespace except in pre, textarea, and script elements"""
    spacePreserveElements = frozenset(["pre", "textarea"] + list(rcdataElements))

    def __iter__(self):
        preserve = 0
        for token in base.Filter.__iter__(self):
            type = token["type"]
            if type == "StartTag" \
                    and (preserve or token["name"] in self.spacePreserveElements):
                preserve += 1

            elif type == "EndTag" and preserve:
                preserve -= 1

            elif not preserve and type == "SpaceCharacters" and token["data"]:
                # Test on token["data"] above to not introduce spaces where there were not
                token["data"] = " "

            elif not preserve and type == "Characters":
                token["data"] = collapse_spaces(token["data"])

            yield token


def collapse_spaces(text):
    return SPACES_REGEX.sub(' ', text)
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/filters/__init__.py
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/html5parser.py
from __future__ import absolute_import, division, unicode_literals
from pip._vendor.six import with_metaclass, viewkeys

import types

from . import _inputstream
from . import _tokenizer

from . import treebuilders
from .treebuilders.base import Marker

from . import _utils
from .constants import (
    spaceCharacters, asciiUpper2Lower,
    specialElements, headingElements, cdataElements, rcdataElements,
    tokenTypes, tagTokenTypes,
    namespaces,
    htmlIntegrationPointElements, mathmlTextIntegrationPointElements,
    adjustForeignAttributes as adjustForeignAttributesMap,
    adjustMathMLAttributes, adjustSVGAttributes,
    E,
    _ReparseException
)


def parse(doc, treebuilder="etree", namespaceHTMLElements=True, **kwargs):
    """Parse an HTML document as a string or file-like object into a tree

    :arg doc: the document to parse as a string or file-like object

    :arg treebuilder: the treebuilder to use when parsing

    :arg namespaceHTMLElements: whether or not to namespace HTML elements

    :returns: parsed tree

    Example:

    >>> from html5lib.html5parser import parse
    >>> parse('<html><body><p>This is a doc</p></body></html>')
    <Element u'{http://www.w3.org/1999/xhtml}html' at 0x7feac4909db0>

    """
    tb = treebuilders.getTreeBuilder(treebuilder)
    p = HTMLParser(tb, namespaceHTMLElements=namespaceHTMLElements)
    return p.parse(doc, **kwargs)


def parseFragment(doc, container="div", treebuilder="etree", namespaceHTMLElements=True, **kwargs):
    """Parse an HTML fragment as a string or file-like object into a tree
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/serializer.py
from __future__ import absolute_import, division, unicode_literals
from pip._vendor.six import text_type

import re

from codecs import register_error, xmlcharrefreplace_errors

from .constants import voidElements, booleanAttributes, spaceCharacters
from .constants import rcdataElements, entities, xmlEntities
from . import treewalkers, _utils
from xml.sax.saxutils import escape

_quoteAttributeSpecChars = "".join(spaceCharacters) + "\"'=<>`"
_quoteAttributeSpec = re.compile("[" + _quoteAttributeSpecChars + "]")
_quoteAttributeLegacy = re.compile("[" + _quoteAttributeSpecChars +
                                   "\x00\x01\x02\x03\x04\x05\x06\x07\x08\t\n"
                                   "\x0b\x0c\r\x0e\x0f\x10\x11\x12\x13\x14\x15"
                                   "\x16\x17\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f"
                                   "\x20\x2f\x60\xa0\u1680\u180e\u180f\u2000"
                                   "\u2001\u2002\u2003\u2004\u2005\u2006\u2007"
                                   "\u2008\u2009\u200a\u2028\u2029\u202f\u205f"
                                   "\u3000]")


_encode_entity_map = {}
_is_ucs4 = len("\U0010FFFF") == 1
for k, v in list(entities.items()):
    # skip multi-character entities
    if ((_is_ucs4 and len(v) > 1) or
            (not _is_ucs4 and len(v) > 2)):
        continue
    if v != "&":
        if len(v) == 2:
            v = _utils.surrogatePairToCodepoint(v)
        else:
            v = ord(v)
        if v not in _encode_entity_map or k.islower():
            # prefer &lt; over &LT; and similarly for &amp;, &gt;, etc.
            _encode_entity_map[v] = k


def htmlentityreplace_errors(exc):
    if isinstance(exc, (UnicodeEncodeError, UnicodeTranslateError)):
        res = []
        codepoints = []
        skip = False
        for i, c in enumerate(exc.object[exc.start:exc.end]):
            if skip:
                skip = False
                continue
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treeadapters/genshi.py
from __future__ import absolute_import, division, unicode_literals

from genshi.core import QName, Attrs
from genshi.core import START, END, TEXT, COMMENT, DOCTYPE


def to_genshi(walker):
    """Convert a tree to a genshi tree

    :arg walker: the treewalker to use to walk the tree to convert it

    :returns: generator of genshi nodes

    """
    text = []
    for token in walker:
        type = token["type"]
        if type in ("Characters", "SpaceCharacters"):
            text.append(token["data"])
        elif text:
            yield TEXT, "".join(text), (None, -1, -1)
            text = []

        if type in ("StartTag", "EmptyTag"):
            if token["namespace"]:
                name = "{%s}%s" % (token["namespace"], token["name"])
            else:
                name = token["name"]
            attrs = Attrs([(QName("{%s}%s" % attr if attr[0] is not None else attr[1]), value)
                           for attr, value in token["data"].items()])
            yield (START, (QName(name), attrs), (None, -1, -1))
            if type == "EmptyTag":
                type = "EndTag"

        if type == "EndTag":
            if token["namespace"]:
                name = "{%s}%s" % (token["namespace"], token["name"])
            else:
                name = token["name"]

            yield END, QName(name), (None, -1, -1)

        elif type == "Comment":
            yield COMMENT, token["data"], (None, -1, -1)

        elif type == "Doctype":
            yield DOCTYPE, (token["name"], token["publicId"],
                            token["systemId"]), (None, -1, -1)

        else:
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treeadapters/sax.py
from __future__ import absolute_import, division, unicode_literals

from xml.sax.xmlreader import AttributesNSImpl

from ..constants import adjustForeignAttributes, unadjustForeignAttributes

prefix_mapping = {}
for prefix, localName, namespace in adjustForeignAttributes.values():
    if prefix is not None:
        prefix_mapping[prefix] = namespace


def to_sax(walker, handler):
    """Call SAX-like content handler based on treewalker walker

    :arg walker: the treewalker to use to walk the tree to convert it

    :arg handler: SAX handler to use

    """
    handler.startDocument()
    for prefix, namespace in prefix_mapping.items():
        handler.startPrefixMapping(prefix, namespace)

    for token in walker:
        type = token["type"]
        if type == "Doctype":
            continue
        elif type in ("StartTag", "EmptyTag"):
            attrs = AttributesNSImpl(token["data"],
                                     unadjustForeignAttributes)
            handler.startElementNS((token["namespace"], token["name"]),
                                   token["name"],
                                   attrs)
            if type == "EmptyTag":
                handler.endElementNS((token["namespace"], token["name"]),
                                     token["name"])
        elif type == "EndTag":
            handler.endElementNS((token["namespace"], token["name"]),
                                 token["name"])
        elif type in ("Characters", "SpaceCharacters"):
            handler.characters(token["data"])
        elif type == "Comment":
            pass
        else:
            assert False, "Unknown token type"

    for prefix, namespace in prefix_mapping.items():
        handler.endPrefixMapping(prefix)
    handler.endDocument()
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treeadapters/__init__.py
"""Tree adapters let you convert from one tree structure to another

Example:

.. code-block:: python

   from pip._vendor import html5lib
   from pip._vendor.html5lib.treeadapters import genshi

   doc = '<html><body>Hi!</body></html>'
   treebuilder = html5lib.getTreeBuilder('etree')
   parser = html5lib.HTMLParser(tree=treebuilder)
   tree = parser.parse(doc)
   TreeWalker = html5lib.getTreeWalker('etree')

   genshi_tree = genshi.to_genshi(TreeWalker(tree))

"""
from __future__ import absolute_import, division, unicode_literals

from . import sax

__all__ = ["sax"]

try:
    from . import genshi  # noqa
except ImportError:
    pass
else:
    __all__.append("genshi")
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/base.py
from __future__ import absolute_import, division, unicode_literals
from pip._vendor.six import text_type

from ..constants import scopingElements, tableInsertModeElements, namespaces

# The scope markers are inserted when entering object elements,
# marquees, table cells, and table captions, and are used to prevent formatting
# from "leaking" into tables, object elements, and marquees.
Marker = None

listElementsMap = {
    None: (frozenset(scopingElements), False),
    "button": (frozenset(scopingElements | {(namespaces["html"], "button")}), False),
    "list": (frozenset(scopingElements | {(namespaces["html"], "ol"),
                                          (namespaces["html"], "ul")}), False),
    "table": (frozenset([(namespaces["html"], "html"),
                         (namespaces["html"], "table")]), False),
    "select": (frozenset([(namespaces["html"], "optgroup"),
                          (namespaces["html"], "option")]), True)
}


class Node(object):
    """Represents an item in the tree"""
    def __init__(self, name):
        """Creates a Node

        :arg name: The tag name associated with the node

        """
        # The tag name associated with the node
        self.name = name
        # The parent of the current node (or None for the document node)
        self.parent = None
        # The value of the current node (applies to text nodes and comments)
        self.value = None
        # A dict holding name -> value pairs for attributes of the node
        self.attributes = {}
        # A list of child nodes of the current node. This must include all
        # elements but not necessarily other node types.
        self.childNodes = []
        # A list of miscellaneous flags that can be set on the node.
        self._flags = []

    def __str__(self):
        attributesStr = " ".join(["%s=\"%s\"" % (name, value)
                                  for name, value in
                                  self.attributes.items()])
        if attributesStr:
            return "<%s %s>" % (self.name, attributesStr)
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/dom.py
from __future__ import absolute_import, division, unicode_literals


try:
    from collections.abc import MutableMapping
except ImportError:  # Python 2.7
    from collections import MutableMapping
from xml.dom import minidom, Node
import weakref

from . import base
from .. import constants
from ..constants import namespaces
from .._utils import moduleFactoryFactory


def getDomBuilder(DomImplementation):
    Dom = DomImplementation

    class AttrList(MutableMapping):
        def __init__(self, element):
            self.element = element

        def __iter__(self):
            return iter(self.element.attributes.keys())

        def __setitem__(self, name, value):
            if isinstance(name, tuple):
                raise NotImplementedError
            else:
                attr = self.element.ownerDocument.createAttribute(name)
                attr.value = value
                self.element.attributes[name] = attr

        def __len__(self):
            return len(self.element.attributes)

        def items(self):
            return list(self.element.attributes.items())

        def values(self):
            return list(self.element.attributes.values())

        def __getitem__(self, name):
            if isinstance(name, tuple):
                raise NotImplementedError
            else:
                return self.element.attributes[name].value

        def __delitem__(self, name):
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/etree.py
from __future__ import absolute_import, division, unicode_literals
# pylint:disable=protected-access

from pip._vendor.six import text_type

import re

from copy import copy

from . import base
from .. import _ihatexml
from .. import constants
from ..constants import namespaces
from .._utils import moduleFactoryFactory

tag_regexp = re.compile("{([^}]*)}(.*)")


def getETreeBuilder(ElementTreeImplementation, fullTree=False):
    ElementTree = ElementTreeImplementation
    ElementTreeCommentType = ElementTree.Comment("asd").tag

    class Element(base.Node):
        def __init__(self, name, namespace=None):
            self._name = name
            self._namespace = namespace
            self._element = ElementTree.Element(self._getETreeTag(name,
                                                                  namespace))
            if namespace is None:
                self.nameTuple = namespaces["html"], self._name
            else:
                self.nameTuple = self._namespace, self._name
            self.parent = None
            self._childNodes = []
            self._flags = []

        def _getETreeTag(self, name, namespace):
            if namespace is None:
                etree_tag = name
            else:
                etree_tag = "{%s}%s" % (namespace, name)
            return etree_tag

        def _setName(self, name):
            self._name = name
            self._element.tag = self._getETreeTag(self._name, self._namespace)

        def _getName(self):
            return self._name

FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/etree_lxml.py
"""Module for supporting the lxml.etree library. The idea here is to use as much
of the native library as possible, without using fragile hacks like custom element
names that break between releases. The downside of this is that we cannot represent
all possible trees; specifically the following are known to cause problems:

Text or comments as siblings of the root element
Docypes with no name

When any of these things occur, we emit a DataLossWarning
"""

from __future__ import absolute_import, division, unicode_literals
# pylint:disable=protected-access

import warnings
import re
import sys

try:
    from collections.abc import MutableMapping
except ImportError:
    from collections import MutableMapping

from . import base
from ..constants import DataLossWarning
from .. import constants
from . import etree as etree_builders
from .. import _ihatexml

import lxml.etree as etree
from pip._vendor.six import PY3, binary_type


fullTree = True
tag_regexp = re.compile("{([^}]*)}(.*)")

comment_type = etree.Comment("asd").tag


class DocumentType(object):
    def __init__(self, name, publicId, systemId):
        self.name = name
        self.publicId = publicId
        self.systemId = systemId


class Document(object):
    def __init__(self):
        self._elementTree = None
        self._childNodes = []
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/__init__.py
"""A collection of modules for building different kinds of trees from HTML
documents.

To create a treebuilder for a new type of tree, you need to do
implement several things:

1. A set of classes for various types of elements: Document, Doctype, Comment,
   Element. These must implement the interface of ``base.treebuilders.Node``
   (although comment nodes have a different signature for their constructor,
   see ``treebuilders.etree.Comment``) Textual content may also be implemented
   as another node type, or not, as your tree implementation requires.

2. A treebuilder object (called ``TreeBuilder`` by convention) that inherits
   from ``treebuilders.base.TreeBuilder``. This has 4 required attributes:

   * ``documentClass`` - the class to use for the bottommost node of a document
   * ``elementClass`` - the class to use for HTML Elements
   * ``commentClass`` - the class to use for comments
   * ``doctypeClass`` - the class to use for doctypes

   It also has one required method:

   * ``getDocument`` - Returns the root node of the complete document tree

3. If you wish to run the unit tests, you must also create a ``testSerializer``
   method on your treebuilder which accepts a node and returns a string
   containing Node and its children serialized according to the format used in
   the unittests

"""

from __future__ import absolute_import, division, unicode_literals

from .._utils import default_etree

treeBuilderCache = {}


def getTreeBuilder(treeType, implementation=None, **kwargs):
    """Get a TreeBuilder class for various types of trees with built-in support

    :arg treeType: the name of the tree type required (case-insensitive). Supported
        values are:

        * "dom" - A generic builder for DOM implementations, defaulting to a
          xml.dom.minidom based implementation.
        * "etree" - A generic builder for tree implementations exposing an
          ElementTree-like interface, defaulting to xml.etree.cElementTree if
          available and xml.etree.ElementTree if not.
        * "lxml" - A etree-based builder for lxml.etree, handling limitations
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/base.py
from __future__ import absolute_import, division, unicode_literals

from xml.dom import Node
from ..constants import namespaces, voidElements, spaceCharacters

__all__ = ["DOCUMENT", "DOCTYPE", "TEXT", "ELEMENT", "COMMENT", "ENTITY", "UNKNOWN",
           "TreeWalker", "NonRecursiveTreeWalker"]

DOCUMENT = Node.DOCUMENT_NODE
DOCTYPE = Node.DOCUMENT_TYPE_NODE
TEXT = Node.TEXT_NODE
ELEMENT = Node.ELEMENT_NODE
COMMENT = Node.COMMENT_NODE
ENTITY = Node.ENTITY_NODE
UNKNOWN = "<#UNKNOWN#>"

spaceCharacters = "".join(spaceCharacters)


class TreeWalker(object):
    """Walks a tree yielding tokens

    Tokens are dicts that all have a ``type`` field specifying the type of the
    token.

    """
    def __init__(self, tree):
        """Creates a TreeWalker

        :arg tree: the tree to walk

        """
        self.tree = tree

    def __iter__(self):
        raise NotImplementedError

    def error(self, msg):
        """Generates an error token with the given message

        :arg msg: the error message

        :returns: SerializeError token

        """
        return {"type": "SerializeError", "data": msg}

    def emptyTag(self, namespace, name, attrs, hasChildren=False):
        """Generates an EmptyTag token

FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/dom.py
from __future__ import absolute_import, division, unicode_literals

from xml.dom import Node

from . import base


class TreeWalker(base.NonRecursiveTreeWalker):
    def getNodeDetails(self, node):
        if node.nodeType == Node.DOCUMENT_TYPE_NODE:
            return base.DOCTYPE, node.name, node.publicId, node.systemId

        elif node.nodeType in (Node.TEXT_NODE, Node.CDATA_SECTION_NODE):
            return base.TEXT, node.nodeValue

        elif node.nodeType == Node.ELEMENT_NODE:
            attrs = {}
            for attr in list(node.attributes.keys()):
                attr = node.getAttributeNode(attr)
                if attr.namespaceURI:
                    attrs[(attr.namespaceURI, attr.localName)] = attr.value
                else:
                    attrs[(None, attr.name)] = attr.value
            return (base.ELEMENT, node.namespaceURI, node.nodeName,
                    attrs, node.hasChildNodes())

        elif node.nodeType == Node.COMMENT_NODE:
            return base.COMMENT, node.nodeValue

        elif node.nodeType in (Node.DOCUMENT_NODE, Node.DOCUMENT_FRAGMENT_NODE):
            return (base.DOCUMENT,)

        else:
            return base.UNKNOWN, node.nodeType

    def getFirstChild(self, node):
        return node.firstChild

    def getNextSibling(self, node):
        return node.nextSibling

    def getParentNode(self, node):
        return node.parentNode
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/etree.py
from __future__ import absolute_import, division, unicode_literals

from collections import OrderedDict
import re

from pip._vendor.six import string_types

from . import base
from .._utils import moduleFactoryFactory

tag_regexp = re.compile("{([^}]*)}(.*)")


def getETreeBuilder(ElementTreeImplementation):
    ElementTree = ElementTreeImplementation
    ElementTreeCommentType = ElementTree.Comment("asd").tag

    class TreeWalker(base.NonRecursiveTreeWalker):  # pylint:disable=unused-variable
        """Given the particular ElementTree representation, this implementation,
        to avoid using recursion, returns "nodes" as tuples with the following
        content:

        1. The current element

        2. The index of the element relative to its parent

        3. A stack of ancestor elements

        4. A flag "text", "tail" or None to indicate if the current node is a
           text node; either the text or tail of the current element (1)
        """
        def getNodeDetails(self, node):
            if isinstance(node, tuple):  # It might be the root Element
                elt, _, _, flag = node
                if flag in ("text", "tail"):
                    return base.TEXT, getattr(elt, flag)
                else:
                    node = elt

            if not(hasattr(node, "tag")):
                node = node.getroot()

            if node.tag in ("DOCUMENT_ROOT", "DOCUMENT_FRAGMENT"):
                return (base.DOCUMENT,)

            elif node.tag == "<!DOCTYPE>":
                return (base.DOCTYPE, node.text,
                        node.get("publicId"), node.get("systemId"))

            elif node.tag == ElementTreeCommentType:
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/etree_lxml.py
from __future__ import absolute_import, division, unicode_literals
from pip._vendor.six import text_type

from collections import OrderedDict

from lxml import etree
from ..treebuilders.etree import tag_regexp

from . import base

from .. import _ihatexml


def ensure_str(s):
    if s is None:
        return None
    elif isinstance(s, text_type):
        return s
    else:
        return s.decode("ascii", "strict")


class Root(object):
    def __init__(self, et):
        self.elementtree = et
        self.children = []

        try:
            if et.docinfo.internalDTD:
                self.children.append(Doctype(self,
                                             ensure_str(et.docinfo.root_name),
                                             ensure_str(et.docinfo.public_id),
                                             ensure_str(et.docinfo.system_url)))
        except AttributeError:
            pass

        try:
            node = et.getroot()
        except AttributeError:
            node = et

        while node.getprevious() is not None:
            node = node.getprevious()
        while node is not None:
            self.children.append(node)
            node = node.getnext()

        self.text = None
        self.tail = None

FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/genshi.py
from __future__ import absolute_import, division, unicode_literals

from genshi.core import QName
from genshi.core import START, END, XML_NAMESPACE, DOCTYPE, TEXT
from genshi.core import START_NS, END_NS, START_CDATA, END_CDATA, PI, COMMENT

from . import base

from ..constants import voidElements, namespaces


class TreeWalker(base.TreeWalker):
    def __iter__(self):
        # Buffer the events so we can pass in the following one
        previous = None
        for event in self.tree:
            if previous is not None:
                for token in self.tokens(previous, event):
                    yield token
            previous = event

        # Don't forget the final event!
        if previous is not None:
            for token in self.tokens(previous, None):
                yield token

    def tokens(self, event, next):
        kind, data, _ = event
        if kind == START:
            tag, attribs = data
            name = tag.localname
            namespace = tag.namespace
            converted_attribs = {}
            for k, v in attribs:
                if isinstance(k, QName):
                    converted_attribs[(k.namespace, k.localname)] = v
                else:
                    converted_attribs[(None, k)] = v

            if namespace == namespaces["html"] and name in voidElements:
                for token in self.emptyTag(namespace, name, converted_attribs,
                                           not next or next[0] != END or
                                           next[1] != tag):
                    yield token
            else:
                yield self.startTag(namespace, name, converted_attribs)

        elif kind == END:
            name = data.localname
            namespace = data.namespace
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/__init__.py
"""A collection of modules for iterating through different kinds of
tree, generating tokens identical to those produced by the tokenizer
module.

To create a tree walker for a new type of tree, you need to
implement a tree walker object (called TreeWalker by convention) that
implements a 'serialize' method which takes a tree as sole argument and
returns an iterator which generates tokens.
"""

from __future__ import absolute_import, division, unicode_literals

from .. import constants
from .._utils import default_etree

__all__ = ["getTreeWalker", "pprint"]

treeWalkerCache = {}


def getTreeWalker(treeType, implementation=None, **kwargs):
    """Get a TreeWalker class for various types of tree with built-in support

    :arg str treeType: the name of the tree type required (case-insensitive).
        Supported values are:

        * "dom": The xml.dom.minidom DOM implementation
        * "etree": A generic walker for tree implementations exposing an
          elementtree-like interface (known to work with ElementTree,
          cElementTree and lxml.etree).
        * "lxml": Optimized walker for lxml.etree
        * "genshi": a Genshi stream

    :arg implementation: A module implementing the tree type e.g.
        xml.etree.ElementTree or cElementTree (Currently applies to the "etree"
        tree type only).

    :arg kwargs: keyword arguments passed to the etree walker--for other
        walkers, this has no effect

    :returns: a TreeWalker class

    """

    treeType = treeType.lower()
    if treeType not in treeWalkerCache:
        if treeType == "dom":
            from . import dom
            treeWalkerCache[treeType] = dom.TreeWalker
        elif treeType == "genshi":
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/_ihatexml.py
from __future__ import absolute_import, division, unicode_literals

import re
import warnings

from .constants import DataLossWarning

baseChar = """
[#x0041-#x005A] | [#x0061-#x007A] | [#x00C0-#x00D6] | [#x00D8-#x00F6] |
[#x00F8-#x00FF] | [#x0100-#x0131] | [#x0134-#x013E] | [#x0141-#x0148] |
[#x014A-#x017E] | [#x0180-#x01C3] | [#x01CD-#x01F0] | [#x01F4-#x01F5] |
[#x01FA-#x0217] | [#x0250-#x02A8] | [#x02BB-#x02C1] | #x0386 |
[#x0388-#x038A] | #x038C | [#x038E-#x03A1] | [#x03A3-#x03CE] |
[#x03D0-#x03D6] | #x03DA | #x03DC | #x03DE | #x03E0 | [#x03E2-#x03F3] |
[#x0401-#x040C] | [#x040E-#x044F] | [#x0451-#x045C] | [#x045E-#x0481] |
[#x0490-#x04C4] | [#x04C7-#x04C8] | [#x04CB-#x04CC] | [#x04D0-#x04EB] |
[#x04EE-#x04F5] | [#x04F8-#x04F9] | [#x0531-#x0556] | #x0559 |
[#x0561-#x0586] | [#x05D0-#x05EA] | [#x05F0-#x05F2] | [#x0621-#x063A] |
[#x0641-#x064A] | [#x0671-#x06B7] | [#x06BA-#x06BE] | [#x06C0-#x06CE] |
[#x06D0-#x06D3] | #x06D5 | [#x06E5-#x06E6] | [#x0905-#x0939] | #x093D |
[#x0958-#x0961] | [#x0985-#x098C] | [#x098F-#x0990] | [#x0993-#x09A8] |
[#x09AA-#x09B0] | #x09B2 | [#x09B6-#x09B9] | [#x09DC-#x09DD] |
[#x09DF-#x09E1] | [#x09F0-#x09F1] | [#x0A05-#x0A0A] | [#x0A0F-#x0A10] |
[#x0A13-#x0A28] | [#x0A2A-#x0A30] | [#x0A32-#x0A33] | [#x0A35-#x0A36] |
[#x0A38-#x0A39] | [#x0A59-#x0A5C] | #x0A5E | [#x0A72-#x0A74] |
[#x0A85-#x0A8B] | #x0A8D | [#x0A8F-#x0A91] | [#x0A93-#x0AA8] |
[#x0AAA-#x0AB0] | [#x0AB2-#x0AB3] | [#x0AB5-#x0AB9] | #x0ABD | #x0AE0 |
[#x0B05-#x0B0C] | [#x0B0F-#x0B10] | [#x0B13-#x0B28] | [#x0B2A-#x0B30] |
[#x0B32-#x0B33] | [#x0B36-#x0B39] | #x0B3D | [#x0B5C-#x0B5D] |
[#x0B5F-#x0B61] | [#x0B85-#x0B8A] | [#x0B8E-#x0B90] | [#x0B92-#x0B95] |
[#x0B99-#x0B9A] | #x0B9C | [#x0B9E-#x0B9F] | [#x0BA3-#x0BA4] |
[#x0BA8-#x0BAA] | [#x0BAE-#x0BB5] | [#x0BB7-#x0BB9] | [#x0C05-#x0C0C] |
[#x0C0E-#x0C10] | [#x0C12-#x0C28] | [#x0C2A-#x0C33] | [#x0C35-#x0C39] |
[#x0C60-#x0C61] | [#x0C85-#x0C8C] | [#x0C8E-#x0C90] | [#x0C92-#x0CA8] |
[#x0CAA-#x0CB3] | [#x0CB5-#x0CB9] | #x0CDE | [#x0CE0-#x0CE1] |
[#x0D05-#x0D0C] | [#x0D0E-#x0D10] | [#x0D12-#x0D28] | [#x0D2A-#x0D39] |
[#x0D60-#x0D61] | [#x0E01-#x0E2E] | #x0E30 | [#x0E32-#x0E33] |
[#x0E40-#x0E45] | [#x0E81-#x0E82] | #x0E84 | [#x0E87-#x0E88] | #x0E8A |
#x0E8D | [#x0E94-#x0E97] | [#x0E99-#x0E9F] | [#x0EA1-#x0EA3] | #x0EA5 |
#x0EA7 | [#x0EAA-#x0EAB] | [#x0EAD-#x0EAE] | #x0EB0 | [#x0EB2-#x0EB3] |
#x0EBD | [#x0EC0-#x0EC4] | [#x0F40-#x0F47] | [#x0F49-#x0F69] |
[#x10A0-#x10C5] | [#x10D0-#x10F6] | #x1100 | [#x1102-#x1103] |
[#x1105-#x1107] | #x1109 | [#x110B-#x110C] | [#x110E-#x1112] | #x113C |
#x113E | #x1140 | #x114C | #x114E | #x1150 | [#x1154-#x1155] | #x1159 |
[#x115F-#x1161] | #x1163 | #x1165 | #x1167 | #x1169 | [#x116D-#x116E] |
[#x1172-#x1173] | #x1175 | #x119E | #x11A8 | #x11AB | [#x11AE-#x11AF] |
[#x11B7-#x11B8] | #x11BA | [#x11BC-#x11C2] | #x11EB | #x11F0 | #x11F9 |
[#x1E00-#x1E9B] | [#x1EA0-#x1EF9] | [#x1F00-#x1F15] | [#x1F18-#x1F1D] |
[#x1F20-#x1F45] | [#x1F48-#x1F4D] | [#x1F50-#x1F57] | #x1F59 | #x1F5B |
#x1F5D | [#x1F5F-#x1F7D] | [#x1F80-#x1FB4] | [#x1FB6-#x1FBC] | #x1FBE |
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/_inputstream.py
from __future__ import absolute_import, division, unicode_literals

from pip._vendor.six import text_type
from pip._vendor.six.moves import http_client, urllib

import codecs
import re
from io import BytesIO, StringIO

from pip._vendor import webencodings

from .constants import EOF, spaceCharacters, asciiLetters, asciiUppercase
from .constants import _ReparseException
from . import _utils

# Non-unicode versions of constants for use in the pre-parser
spaceCharactersBytes = frozenset([item.encode("ascii") for item in spaceCharacters])
asciiLettersBytes = frozenset([item.encode("ascii") for item in asciiLetters])
asciiUppercaseBytes = frozenset([item.encode("ascii") for item in asciiUppercase])
spacesAngleBrackets = spaceCharactersBytes | frozenset([b">", b"<"])


invalid_unicode_no_surrogate = "[\u0001-\u0008\u000B\u000E-\u001F\u007F-\u009F\uFDD0-\uFDEF\uFFFE\uFFFF\U0001FFFE\U0001FFFF\U0002FFFE\U0002FFFF\U0003FFFE\U0003FFFF\U0004FFFE\U0004FFFF\U0005FFFE\U0005FFFF\U0006FFFE\U0006FFFF\U0007FFFE\U0007FFFF\U0008FFFE\U0008FFFF\U0009FFFE\U0009FFFF\U000AFFFE\U000AFFFF\U000BFFFE\U000BFFFF\U000CFFFE\U000CFFFF\U000DFFFE\U000DFFFF\U000EFFFE\U000EFFFF\U000FFFFE\U000FFFFF\U0010FFFE\U0010FFFF]"  # noqa

if _utils.supports_lone_surrogates:
    # Use one extra step of indirection and create surrogates with
    # eval. Not using this indirection would introduce an illegal
    # unicode literal on platforms not supporting such lone
    # surrogates.
    assert invalid_unicode_no_surrogate[-1] == "]" and invalid_unicode_no_surrogate.count("]") == 1
    invalid_unicode_re = re.compile(invalid_unicode_no_surrogate[:-1] +
                                    eval('"\\uD800-\\uDFFF"') +  # pylint:disable=eval-used
                                    "]")
else:
    invalid_unicode_re = re.compile(invalid_unicode_no_surrogate)

non_bmp_invalid_codepoints = {0x1FFFE, 0x1FFFF, 0x2FFFE, 0x2FFFF, 0x3FFFE,
                              0x3FFFF, 0x4FFFE, 0x4FFFF, 0x5FFFE, 0x5FFFF,
                              0x6FFFE, 0x6FFFF, 0x7FFFE, 0x7FFFF, 0x8FFFE,
                              0x8FFFF, 0x9FFFE, 0x9FFFF, 0xAFFFE, 0xAFFFF,
                              0xBFFFE, 0xBFFFF, 0xCFFFE, 0xCFFFF, 0xDFFFE,
                              0xDFFFF, 0xEFFFE, 0xEFFFF, 0xFFFFE, 0xFFFFF,
                              0x10FFFE, 0x10FFFF}

ascii_punctuation_re = re.compile("[\u0009-\u000D\u0020-\u002F\u003A-\u0040\u005C\u005B-\u0060\u007B-\u007E]")

# Cache for charsUntil()
charsUntilRegEx = {}


FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/_tokenizer.py
from __future__ import absolute_import, division, unicode_literals

from pip._vendor.six import unichr as chr

from collections import deque, OrderedDict
from sys import version_info

from .constants import spaceCharacters
from .constants import entities
from .constants import asciiLetters, asciiUpper2Lower
from .constants import digits, hexDigits, EOF
from .constants import tokenTypes, tagTokenTypes
from .constants import replacementCharacters

from ._inputstream import HTMLInputStream

from ._trie import Trie

entitiesTrie = Trie(entities)

if version_info >= (3, 7):
    attributeMap = dict
else:
    attributeMap = OrderedDict


class HTMLTokenizer(object):
    """ This class takes care of tokenizing HTML.

    * self.currentToken
      Holds the token that is currently being processed.

    * self.state
      Holds a reference to the method to be invoked... XXX

    * self.stream
      Points to HTMLInputStream object.
    """

    def __init__(self, stream, parser=None, **kwargs):

        self.stream = HTMLInputStream(stream, **kwargs)
        self.parser = parser

        # Setup the initial tokenizer state
        self.escapeFlag = False
        self.lastFourChars = []
        self.state = self.dataState
        self.escape = False

FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/_trie/py.py
from __future__ import absolute_import, division, unicode_literals
from pip._vendor.six import text_type

from bisect import bisect_left

from ._base import Trie as ABCTrie


class Trie(ABCTrie):
    def __init__(self, data):
        if not all(isinstance(x, text_type) for x in data.keys()):
            raise TypeError("All keys must be strings")

        self._data = data
        self._keys = sorted(data.keys())
        self._cachestr = ""
        self._cachepoints = (0, len(data))

    def __contains__(self, key):
        return key in self._data

    def __len__(self):
        return len(self._data)

    def __iter__(self):
        return iter(self._data)

    def __getitem__(self, key):
        return self._data[key]

    def keys(self, prefix=None):
        if prefix is None or prefix == "" or not self._keys:
            return set(self._keys)

        if prefix.startswith(self._cachestr):
            lo, hi = self._cachepoints
            start = i = bisect_left(self._keys, prefix, lo, hi)
        else:
            start = i = bisect_left(self._keys, prefix)

        keys = set()
        if start == len(self._keys):
            return keys

        while self._keys[i].startswith(prefix):
            keys.add(self._keys[i])
            i += 1

        self._cachestr = prefix
        self._cachepoints = (start, i)
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/_trie/_base.py
from __future__ import absolute_import, division, unicode_literals

try:
    from collections.abc import Mapping
except ImportError:  # Python 2.7
    from collections import Mapping


class Trie(Mapping):
    """Abstract base class for tries"""

    def keys(self, prefix=None):
        # pylint:disable=arguments-differ
        keys = super(Trie, self).keys()

        if prefix is None:
            return set(keys)

        return {x for x in keys if x.startswith(prefix)}

    def has_keys_with_prefix(self, prefix):
        for key in self.keys():
            if key.startswith(prefix):
                return True

        return False

    def longest_prefix(self, prefix):
        if prefix in self:
            return prefix

        for i in range(1, len(prefix) + 1):
            if prefix[:-i] in self:
                return prefix[:-i]

        raise KeyError(prefix)

    def longest_prefix_item(self, prefix):
        lprefix = self.longest_prefix(prefix)
        return (lprefix, self[lprefix])
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/_trie/__init__.py
from __future__ import absolute_import, division, unicode_literals

from .py import Trie

__all__ = ["Trie"]
FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/_utils.py
from __future__ import absolute_import, division, unicode_literals

from types import ModuleType

try:
    from collections.abc import Mapping
except ImportError:
    from collections import Mapping

from pip._vendor.six import text_type, PY3

if PY3:
    import xml.etree.ElementTree as default_etree
else:
    try:
        import xml.etree.cElementTree as default_etree
    except ImportError:
        import xml.etree.ElementTree as default_etree


__all__ = ["default_etree", "MethodDispatcher", "isSurrogatePair",
           "surrogatePairToCodepoint", "moduleFactoryFactory",
           "supports_lone_surrogates"]


# Platforms not supporting lone surrogates (\uD800-\uDFFF) should be
# caught by the below test. In general this would be any platform
# using UTF-16 as its encoding of unicode strings, such as
# Jython. This is because UTF-16 itself is based on the use of such
# surrogates, and there is no mechanism to further escape such
# escapes.
try:
    _x = eval('"\\uD800"')  # pylint:disable=eval-used
    if not isinstance(_x, text_type):
        # We need this with u"" because of http://bugs.jython.org/issue2039
        _x = eval('u"\\uD800"')  # pylint:disable=eval-used
        assert isinstance(_x, text_type)
except Exception:
    supports_lone_surrogates = False
else:
    supports_lone_surrogates = True


class MethodDispatcher(dict):
    """Dict with 2 special properties:

    On initiation, keys that are lists, sets or tuples are converted to
    multiple keys so accessing any one of the items in the original
    list-like object returns the matching value

FILE: ./venv/Lib/site-packages/pip/_vendor/html5lib/__init__.py
"""
HTML parsing library based on the `WHATWG HTML specification
<https://whatwg.org/html>`_. The parser is designed to be compatible with
existing HTML found in the wild and implements well-defined error recovery that
is largely compatible with modern desktop web browsers.

Example usage::

    from pip._vendor import html5lib
    with open("my_document.html", "rb") as f:
        tree = html5lib.parse(f)

For convenience, this module re-exports the following names:

* :func:`~.html5parser.parse`
* :func:`~.html5parser.parseFragment`
* :class:`~.html5parser.HTMLParser`
* :func:`~.treebuilders.getTreeBuilder`
* :func:`~.treewalkers.getTreeWalker`
* :func:`~.serializer.serialize`
"""

from __future__ import absolute_import, division, unicode_literals

from .html5parser import HTMLParser, parse, parseFragment
from .treebuilders import getTreeBuilder
from .treewalkers import getTreeWalker
from .serializer import serialize

__all__ = ["HTMLParser", "parse", "parseFragment", "getTreeBuilder",
           "getTreeWalker", "serialize"]

# this has to be at the top level, see how setup.py parses this
#: Distribution version number.
__version__ = "1.1"
FILE: ./venv/Lib/site-packages/pip/_vendor/idna/codec.py
from .core import encode, decode, alabel, ulabel, IDNAError
import codecs
import re
from typing import Tuple, Optional

_unicode_dots_re = re.compile('[\u002e\u3002\uff0e\uff61]')

class Codec(codecs.Codec):

    def encode(self, data, errors='strict'):
        # type: (str, str) -> Tuple[bytes, int]
        if errors != 'strict':
            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))

        if not data:
            return b"", 0

        return encode(data), len(data)

    def decode(self, data, errors='strict'):
        # type: (bytes, str) -> Tuple[str, int]
        if errors != 'strict':
            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))

        if not data:
            return '', 0

        return decode(data), len(data)

class IncrementalEncoder(codecs.BufferedIncrementalEncoder):
    def _buffer_encode(self, data, errors, final):  # type: ignore
        # type: (str, str, bool) -> Tuple[str, int]
        if errors != 'strict':
            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))

        if not data:
            return "", 0

        labels = _unicode_dots_re.split(data)
        trailing_dot = ''
        if labels:
            if not labels[-1]:
                trailing_dot = '.'
                del labels[-1]
            elif not final:
                # Keep potentially unfinished label until the next call
                del labels[-1]
                if labels:
                    trailing_dot = '.'

FILE: ./venv/Lib/site-packages/pip/_vendor/idna/compat.py
from .core import *
from .codec import *
from typing import Any, Union

def ToASCII(label):
    # type: (str) -> bytes
    return encode(label)

def ToUnicode(label):
    # type: (Union[bytes, bytearray]) -> str
    return decode(label)

def nameprep(s):
    # type: (Any) -> None
    raise NotImplementedError('IDNA 2008 does not utilise nameprep protocol')

FILE: ./venv/Lib/site-packages/pip/_vendor/idna/core.py
from . import idnadata
import bisect
import unicodedata
import re
from typing import Union, Optional
from .intranges import intranges_contain

_virama_combining_class = 9
_alabel_prefix = b'xn--'
_unicode_dots_re = re.compile('[\u002e\u3002\uff0e\uff61]')

class IDNAError(UnicodeError):
    """ Base exception for all IDNA-encoding related problems """
    pass


class IDNABidiError(IDNAError):
    """ Exception when bidirectional requirements are not satisfied """
    pass


class InvalidCodepoint(IDNAError):
    """ Exception when a disallowed or unallocated codepoint is used """
    pass


class InvalidCodepointContext(IDNAError):
    """ Exception when the codepoint is not valid in the context it is used """
    pass


def _combining_class(cp):
    # type: (int) -> int
    v = unicodedata.combining(chr(cp))
    if v == 0:
        if not unicodedata.name(chr(cp)):
            raise ValueError('Unknown character in unicodedata')
    return v

def _is_script(cp, script):
    # type: (str, str) -> bool
    return intranges_contain(ord(cp), idnadata.scripts[script])

def _punycode(s):
    # type: (str) -> bytes
    return s.encode('punycode')

def _unot(s):
    # type: (int) -> str
    return 'U+{:04X}'.format(s)
FILE: ./venv/Lib/site-packages/pip/_vendor/idna/idnadata.py
# This file is automatically generated by tools/idna-data

__version__ = '13.0.0'
scripts = {
    'Greek': (
        0x37000000374,
        0x37500000378,
        0x37a0000037e,
        0x37f00000380,
        0x38400000385,
        0x38600000387,
        0x3880000038b,
        0x38c0000038d,
        0x38e000003a2,
        0x3a3000003e2,
        0x3f000000400,
        0x1d2600001d2b,
        0x1d5d00001d62,
        0x1d6600001d6b,
        0x1dbf00001dc0,
        0x1f0000001f16,
        0x1f1800001f1e,
        0x1f2000001f46,
        0x1f4800001f4e,
        0x1f5000001f58,
        0x1f5900001f5a,
        0x1f5b00001f5c,
        0x1f5d00001f5e,
        0x1f5f00001f7e,
        0x1f8000001fb5,
        0x1fb600001fc5,
        0x1fc600001fd4,
        0x1fd600001fdc,
        0x1fdd00001ff0,
        0x1ff200001ff5,
        0x1ff600001fff,
        0x212600002127,
        0xab650000ab66,
        0x101400001018f,
        0x101a0000101a1,
        0x1d2000001d246,
    ),
    'Han': (
        0x2e8000002e9a,
        0x2e9b00002ef4,
        0x2f0000002fd6,
        0x300500003006,
        0x300700003008,
        0x30210000302a,
        0x30380000303c,
FILE: ./venv/Lib/site-packages/pip/_vendor/idna/intranges.py
"""
Given a list of integers, made up of (hopefully) a small number of long runs
of consecutive integers, compute a representation of the form
((start1, end1), (start2, end2) ...). Then answer the question "was x present
in the original list?" in time O(log(# runs)).
"""

import bisect
from typing import List, Tuple

def intranges_from_list(list_):
    # type: (List[int]) -> Tuple[int, ...]
    """Represent a list of integers as a sequence of ranges:
    ((start_0, end_0), (start_1, end_1), ...), such that the original
    integers are exactly those x such that start_i <= x < end_i for some i.

    Ranges are encoded as single integers (start << 32 | end), not as tuples.
    """

    sorted_list = sorted(list_)
    ranges = []
    last_write = -1
    for i in range(len(sorted_list)):
        if i+1 < len(sorted_list):
            if sorted_list[i] == sorted_list[i+1]-1:
                continue
        current_range = sorted_list[last_write+1:i+1]
        ranges.append(_encode_range(current_range[0], current_range[-1] + 1))
        last_write = i

    return tuple(ranges)

def _encode_range(start, end):
    # type: (int, int) -> int
    return (start << 32) | end

def _decode_range(r):
    # type: (int) -> Tuple[int, int]
    return (r >> 32), (r & ((1 << 32) - 1))


def intranges_contain(int_, ranges):
    # type: (int, Tuple[int, ...]) -> bool
    """Determine if `int_` falls into one of the ranges in `ranges`."""
    tuple_ = _encode_range(int_, 0)
    pos = bisect.bisect_left(ranges, tuple_)
    # we could be immediately ahead of a tuple (start, end)
    # with start < int_ <= end
    if pos > 0:
        left, right = _decode_range(ranges[pos-1])
FILE: ./venv/Lib/site-packages/pip/_vendor/idna/package_data.py
__version__ = '3.2'

FILE: ./venv/Lib/site-packages/pip/_vendor/idna/uts46data.py
# This file is automatically generated by tools/idna-data

from typing import List, Tuple, Union

"""IDNA Mapping Table from UTS46."""


__version__ = '13.0.0'
def _seg_0():
    # type: () -> List[Union[Tuple[int, str], Tuple[int, str, str]]]
    return [
    (0x0, '3'),
    (0x1, '3'),
    (0x2, '3'),
    (0x3, '3'),
    (0x4, '3'),
    (0x5, '3'),
    (0x6, '3'),
    (0x7, '3'),
    (0x8, '3'),
    (0x9, '3'),
    (0xA, '3'),
    (0xB, '3'),
    (0xC, '3'),
    (0xD, '3'),
    (0xE, '3'),
    (0xF, '3'),
    (0x10, '3'),
    (0x11, '3'),
    (0x12, '3'),
    (0x13, '3'),
    (0x14, '3'),
    (0x15, '3'),
    (0x16, '3'),
    (0x17, '3'),
    (0x18, '3'),
    (0x19, '3'),
    (0x1A, '3'),
    (0x1B, '3'),
    (0x1C, '3'),
    (0x1D, '3'),
    (0x1E, '3'),
    (0x1F, '3'),
    (0x20, '3'),
    (0x21, '3'),
    (0x22, '3'),
    (0x23, '3'),
    (0x24, '3'),
    (0x25, '3'),
    (0x26, '3'),
FILE: ./venv/Lib/site-packages/pip/_vendor/idna/__init__.py
from .package_data import __version__
from .core import (
    IDNABidiError,
    IDNAError,
    InvalidCodepoint,
    InvalidCodepointContext,
    alabel,
    check_bidi,
    check_hyphen_ok,
    check_initial_combiner,
    check_label,
    check_nfc,
    decode,
    encode,
    ulabel,
    uts46_remap,
    valid_contextj,
    valid_contexto,
    valid_label_length,
    valid_string_length,
)
from .intranges import intranges_contain

__all__ = [
    "IDNABidiError",
    "IDNAError",
    "InvalidCodepoint",
    "InvalidCodepointContext",
    "alabel",
    "check_bidi",
    "check_hyphen_ok",
    "check_initial_combiner",
    "check_label",
    "check_nfc",
    "decode",
    "encode",
    "intranges_contain",
    "ulabel",
    "uts46_remap",
    "valid_contextj",
    "valid_contexto",
    "valid_label_length",
    "valid_string_length",
]
FILE: ./venv/Lib/site-packages/pip/_vendor/msgpack/exceptions.py
class UnpackException(Exception):
    """Base class for some exceptions raised while unpacking.

    NOTE: unpack may raise exception other than subclass of
    UnpackException.  If you want to catch all error, catch
    Exception instead.
    """


class BufferFull(UnpackException):
    pass


class OutOfData(UnpackException):
    pass


class FormatError(ValueError, UnpackException):
    """Invalid msgpack format"""


class StackError(ValueError, UnpackException):
    """Too nested"""


# Deprecated.  Use ValueError instead
UnpackValueError = ValueError


class ExtraData(UnpackValueError):
    """ExtraData is raised when there is trailing data.

    This exception is raised while only one-shot (not streaming)
    unpack.
    """

    def __init__(self, unpacked, extra):
        self.unpacked = unpacked
        self.extra = extra

    def __str__(self):
        return "unpack(b) received extra data."


# Deprecated.  Use Exception instead to catch all exception during packing.
PackException = Exception
PackValueError = ValueError
PackOverflowError = OverflowError
FILE: ./venv/Lib/site-packages/pip/_vendor/msgpack/ext.py
# coding: utf-8
from collections import namedtuple
import datetime
import sys
import struct


PY2 = sys.version_info[0] == 2

if PY2:
    int_types = (int, long)
    _utc = None
else:
    int_types = int
    try:
        _utc = datetime.timezone.utc
    except AttributeError:
        _utc = datetime.timezone(datetime.timedelta(0))


class ExtType(namedtuple("ExtType", "code data")):
    """ExtType represents ext type in msgpack."""

    def __new__(cls, code, data):
        if not isinstance(code, int):
            raise TypeError("code must be int")
        if not isinstance(data, bytes):
            raise TypeError("data must be bytes")
        if not 0 <= code <= 127:
            raise ValueError("code must be 0~127")
        return super(ExtType, cls).__new__(cls, code, data)


class Timestamp(object):
    """Timestamp represents the Timestamp extension type in msgpack.

    When built with Cython, msgpack uses C methods to pack and unpack `Timestamp`. When using pure-Python
    msgpack, :func:`to_bytes` and :func:`from_bytes` are used to pack and unpack `Timestamp`.

    This class is immutable: Do not override seconds and nanoseconds.
    """

    __slots__ = ["seconds", "nanoseconds"]

    def __init__(self, seconds, nanoseconds=0):
        """Initialize a Timestamp object.

        :param int seconds:
            Number of seconds since the UNIX epoch (00:00:00 UTC Jan 1 1970, minus leap seconds).
            May be negative.
FILE: ./venv/Lib/site-packages/pip/_vendor/msgpack/fallback.py
"""Fallback pure Python implementation of msgpack"""

from datetime import datetime as _DateTime
import sys
import struct


PY2 = sys.version_info[0] == 2
if PY2:
    int_types = (int, long)

    def dict_iteritems(d):
        return d.iteritems()


else:
    int_types = int
    unicode = str
    xrange = range

    def dict_iteritems(d):
        return d.items()


if sys.version_info < (3, 5):
    # Ugly hack...
    RecursionError = RuntimeError

    def _is_recursionerror(e):
        return (
            len(e.args) == 1
            and isinstance(e.args[0], str)
            and e.args[0].startswith("maximum recursion depth exceeded")
        )


else:

    def _is_recursionerror(e):
        return True


if hasattr(sys, "pypy_version_info"):
    # StringIO is slow on PyPy, StringIO is faster.  However: PyPy's own
    # StringBuilder is fastest.
    from __pypy__ import newlist_hint

    try:
        from __pypy__.builders import BytesBuilder as StringBuilder
    except ImportError:
FILE: ./venv/Lib/site-packages/pip/_vendor/msgpack/_version.py
version = (1, 0, 2)
FILE: ./venv/Lib/site-packages/pip/_vendor/msgpack/__init__.py
# coding: utf-8
from ._version import version
from .exceptions import *
from .ext import ExtType, Timestamp

import os
import sys


if os.environ.get("MSGPACK_PUREPYTHON") or sys.version_info[0] == 2:
    from .fallback import Packer, unpackb, Unpacker
else:
    try:
        from ._cmsgpack import Packer, unpackb, Unpacker
    except ImportError:
        from .fallback import Packer, unpackb, Unpacker


def pack(o, stream, **kwargs):
    """
    Pack object `o` and write it to `stream`

    See :class:`Packer` for options.
    """
    packer = Packer(**kwargs)
    stream.write(packer.pack(o))


def packb(o, **kwargs):
    """
    Pack object `o` and return packed bytes

    See :class:`Packer` for options.
    """
    return Packer(**kwargs).pack(o)


def unpack(stream, **kwargs):
    """
    Unpack an object from `stream`.

    Raises `ExtraData` when `stream` contains extra bytes.
    See :class:`Unpacker` for options.
    """
    data = stream.read()
    return unpackb(data, **kwargs)


# alias for compatibility to simplejson/marshal/pickle.
load = unpack
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/markers.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import operator
import os
import platform
import sys
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

from pip._vendor.pyparsing import (  # noqa: N817
    Forward,
    Group,
    Literal as L,
    ParseException,
    ParseResults,
    QuotedString,
    ZeroOrMore,
    stringEnd,
    stringStart,
)

from .specifiers import InvalidSpecifier, Specifier

__all__ = [
    "InvalidMarker",
    "UndefinedComparison",
    "UndefinedEnvironmentName",
    "Marker",
    "default_environment",
]

Operator = Callable[[str, str], bool]


class InvalidMarker(ValueError):
    """
    An invalid marker was found, users should refer to PEP 508.
    """


class UndefinedComparison(ValueError):
    """
    An invalid operation was attempted on a value that doesn't support it.
    """


class UndefinedEnvironmentName(ValueError):
    """
    A name was attempted to be used that does not exist inside of the
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/requirements.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import re
import string
import urllib.parse
from typing import List, Optional as TOptional, Set

from pip._vendor.pyparsing import (  # noqa
    Combine,
    Literal as L,
    Optional,
    ParseException,
    Regex,
    Word,
    ZeroOrMore,
    originalTextFor,
    stringEnd,
    stringStart,
)

from .markers import MARKER_EXPR, Marker
from .specifiers import LegacySpecifier, Specifier, SpecifierSet


class InvalidRequirement(ValueError):
    """
    An invalid requirement was found, users should refer to PEP 508.
    """


ALPHANUM = Word(string.ascii_letters + string.digits)

LBRACKET = L("[").suppress()
RBRACKET = L("]").suppress()
LPAREN = L("(").suppress()
RPAREN = L(")").suppress()
COMMA = L(",").suppress()
SEMICOLON = L(";").suppress()
AT = L("@").suppress()

PUNCTUATION = Word("-_.")
IDENTIFIER_END = ALPHANUM | (ZeroOrMore(PUNCTUATION) + ALPHANUM)
IDENTIFIER = Combine(ALPHANUM + ZeroOrMore(IDENTIFIER_END))

NAME = IDENTIFIER("name")
EXTRA = IDENTIFIER

URI = Regex(r"[^ ]+")("url")
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/specifiers.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import abc
import functools
import itertools
import re
import warnings
from typing import (
    Callable,
    Dict,
    Iterable,
    Iterator,
    List,
    Optional,
    Pattern,
    Set,
    Tuple,
    TypeVar,
    Union,
)

from .utils import canonicalize_version
from .version import LegacyVersion, Version, parse

ParsedVersion = Union[Version, LegacyVersion]
UnparsedVersion = Union[Version, LegacyVersion, str]
VersionTypeVar = TypeVar("VersionTypeVar", bound=UnparsedVersion)
CallableOperator = Callable[[ParsedVersion, str], bool]


class InvalidSpecifier(ValueError):
    """
    An invalid specifier was found, users should refer to PEP 440.
    """


class BaseSpecifier(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def __str__(self) -> str:
        """
        Returns the str representation of this Specifier like object. This
        should be representative of the Specifier itself.
        """

    @abc.abstractmethod
    def __hash__(self) -> int:
        """
        Returns a hash value for this Specifier like object.
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/tags.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import logging
import platform
import sys
import sysconfig
from importlib.machinery import EXTENSION_SUFFIXES
from typing import (
    Dict,
    FrozenSet,
    Iterable,
    Iterator,
    List,
    Optional,
    Sequence,
    Tuple,
    Union,
    cast,
)

from . import _manylinux, _musllinux

logger = logging.getLogger(__name__)

PythonVersion = Sequence[int]
MacVersion = Tuple[int, int]

INTERPRETER_SHORT_NAMES: Dict[str, str] = {
    "python": "py",  # Generic.
    "cpython": "cp",
    "pypy": "pp",
    "ironpython": "ip",
    "jython": "jy",
}


_32_BIT_INTERPRETER = sys.maxsize <= 2 ** 32


class Tag:
    """
    A representation of the tag triple for a wheel.

    Instances are considered immutable and thus are hashable. Equality checking
    is also supported.
    """

    __slots__ = ["_interpreter", "_abi", "_platform", "_hash"]
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/utils.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import re
from typing import FrozenSet, NewType, Tuple, Union, cast

from .tags import Tag, parse_tag
from .version import InvalidVersion, Version

BuildTag = Union[Tuple[()], Tuple[int, str]]
NormalizedName = NewType("NormalizedName", str)


class InvalidWheelFilename(ValueError):
    """
    An invalid wheel filename was found, users should refer to PEP 427.
    """


class InvalidSdistFilename(ValueError):
    """
    An invalid sdist filename was found, users should refer to the packaging user guide.
    """


_canonicalize_regex = re.compile(r"[-_.]+")
# PEP 427: The build number must start with a digit.
_build_tag_regex = re.compile(r"(\d+)(.*)")


def canonicalize_name(name: str) -> NormalizedName:
    # This is taken from PEP 503.
    value = _canonicalize_regex.sub("-", name).lower()
    return cast(NormalizedName, value)


def canonicalize_version(version: Union[Version, str]) -> str:
    """
    This is very similar to Version.__str__, but has one subtle difference
    with the way it handles the release segment.
    """
    if isinstance(version, str):
        try:
            parsed = Version(version)
        except InvalidVersion:
            # Legacy versions cannot be normalized
            return version
    else:
        parsed = version
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/version.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import collections
import itertools
import re
import warnings
from typing import Callable, Iterator, List, Optional, SupportsInt, Tuple, Union

from ._structures import Infinity, InfinityType, NegativeInfinity, NegativeInfinityType

__all__ = ["parse", "Version", "LegacyVersion", "InvalidVersion", "VERSION_PATTERN"]

InfiniteTypes = Union[InfinityType, NegativeInfinityType]
PrePostDevType = Union[InfiniteTypes, Tuple[str, int]]
SubLocalType = Union[InfiniteTypes, int, str]
LocalType = Union[
    NegativeInfinityType,
    Tuple[
        Union[
            SubLocalType,
            Tuple[SubLocalType, str],
            Tuple[NegativeInfinityType, SubLocalType],
        ],
        ...,
    ],
]
CmpKey = Tuple[
    int, Tuple[int, ...], PrePostDevType, PrePostDevType, PrePostDevType, LocalType
]
LegacyCmpKey = Tuple[int, Tuple[str, ...]]
VersionComparisonMethod = Callable[
    [Union[CmpKey, LegacyCmpKey], Union[CmpKey, LegacyCmpKey]], bool
]

_Version = collections.namedtuple(
    "_Version", ["epoch", "release", "dev", "pre", "post", "local"]
)


def parse(version: str) -> Union["LegacyVersion", "Version"]:
    """
    Parse the given version string and return either a :class:`Version` object
    or a :class:`LegacyVersion` object depending on if the given version is
    a valid PEP 440 version or a legacy version.
    """
    try:
        return Version(version)
    except InvalidVersion:
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/_manylinux.py
import collections
import functools
import os
import re
import struct
import sys
import warnings
from typing import IO, Dict, Iterator, NamedTuple, Optional, Tuple


# Python does not provide platform information at sufficient granularity to
# identify the architecture of the running executable in some cases, so we
# determine it dynamically by reading the information from the running
# process. This only applies on Linux, which uses the ELF format.
class _ELFFileHeader:
    # https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#File_header
    class _InvalidELFFileHeader(ValueError):
        """
        An invalid ELF file header was found.
        """

    ELF_MAGIC_NUMBER = 0x7F454C46
    ELFCLASS32 = 1
    ELFCLASS64 = 2
    ELFDATA2LSB = 1
    ELFDATA2MSB = 2
    EM_386 = 3
    EM_S390 = 22
    EM_ARM = 40
    EM_X86_64 = 62
    EF_ARM_ABIMASK = 0xFF000000
    EF_ARM_ABI_VER5 = 0x05000000
    EF_ARM_ABI_FLOAT_HARD = 0x00000400

    def __init__(self, file: IO[bytes]) -> None:
        def unpack(fmt: str) -> int:
            try:
                data = file.read(struct.calcsize(fmt))
                result: Tuple[int, ...] = struct.unpack(fmt, data)
            except struct.error:
                raise _ELFFileHeader._InvalidELFFileHeader()
            return result[0]

        self.e_ident_magic = unpack(">I")
        if self.e_ident_magic != self.ELF_MAGIC_NUMBER:
            raise _ELFFileHeader._InvalidELFFileHeader()
        self.e_ident_class = unpack("B")
        if self.e_ident_class not in {self.ELFCLASS32, self.ELFCLASS64}:
            raise _ELFFileHeader._InvalidELFFileHeader()
        self.e_ident_data = unpack("B")
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/_musllinux.py
"""PEP 656 support.

This module implements logic to detect if the currently running Python is
linked against musl, and what musl version is used.
"""

import contextlib
import functools
import operator
import os
import re
import struct
import subprocess
import sys
from typing import IO, Iterator, NamedTuple, Optional, Tuple


def _read_unpacked(f: IO[bytes], fmt: str) -> Tuple[int, ...]:
    return struct.unpack(fmt, f.read(struct.calcsize(fmt)))


def _parse_ld_musl_from_elf(f: IO[bytes]) -> Optional[str]:
    """Detect musl libc location by parsing the Python executable.

    Based on: https://gist.github.com/lyssdod/f51579ae8d93c8657a5564aefc2ffbca
    ELF header: https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html
    """
    f.seek(0)
    try:
        ident = _read_unpacked(f, "16B")
    except struct.error:
        return None
    if ident[:4] != tuple(b"\x7fELF"):  # Invalid magic, not ELF.
        return None
    f.seek(struct.calcsize("HHI"), 1)  # Skip file type, machine, and version.

    try:
        # e_fmt: Format for program header.
        # p_fmt: Format for section header.
        # p_idx: Indexes to find p_type, p_offset, and p_filesz.
        e_fmt, p_fmt, p_idx = {
            1: ("IIIIHHH", "IIIIIIII", (0, 1, 4)),  # 32-bit.
            2: ("QQQIHHH", "IIQQQQQQ", (0, 2, 5)),  # 64-bit.
        }[ident[4]]
    except KeyError:
        return None
    else:
        p_get = operator.itemgetter(*p_idx)

    # Find the interpreter section and return its content.
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/_structures.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.


class InfinityType:
    def __repr__(self) -> str:
        return "Infinity"

    def __hash__(self) -> int:
        return hash(repr(self))

    def __lt__(self, other: object) -> bool:
        return False

    def __le__(self, other: object) -> bool:
        return False

    def __eq__(self, other: object) -> bool:
        return isinstance(other, self.__class__)

    def __ne__(self, other: object) -> bool:
        return not isinstance(other, self.__class__)

    def __gt__(self, other: object) -> bool:
        return True

    def __ge__(self, other: object) -> bool:
        return True

    def __neg__(self: object) -> "NegativeInfinityType":
        return NegativeInfinity


Infinity = InfinityType()


class NegativeInfinityType:
    def __repr__(self) -> str:
        return "-Infinity"

    def __hash__(self) -> int:
        return hash(repr(self))

    def __lt__(self, other: object) -> bool:
        return True

    def __le__(self, other: object) -> bool:
        return True

FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/__about__.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

__all__ = [
    "__title__",
    "__summary__",
    "__uri__",
    "__version__",
    "__author__",
    "__email__",
    "__license__",
    "__copyright__",
]

__title__ = "packaging"
__summary__ = "Core utilities for Python packages"
__uri__ = "https://github.com/pypa/packaging"

__version__ = "21.0"

__author__ = "Donald Stufft and individual contributors"
__email__ = "donald@stufft.io"

__license__ = "BSD-2-Clause or Apache-2.0"
__copyright__ = "2014-2019 %s" % __author__
FILE: ./venv/Lib/site-packages/pip/_vendor/packaging/__init__.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

from .__about__ import (
    __author__,
    __copyright__,
    __email__,
    __license__,
    __summary__,
    __title__,
    __uri__,
    __version__,
)

__all__ = [
    "__title__",
    "__summary__",
    "__uri__",
    "__version__",
    "__author__",
    "__email__",
    "__license__",
    "__copyright__",
]
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/build.py
"""Build a project using PEP 517 hooks.
"""
import argparse
import io
import logging
import os
import shutil

from .envbuild import BuildEnvironment
from .wrappers import Pep517HookCaller
from .dirtools import tempdir, mkdir_p
from .compat import FileNotFoundError, toml_load

log = logging.getLogger(__name__)


def validate_system(system):
    """
    Ensure build system has the requisite fields.
    """
    required = {'requires', 'build-backend'}
    if not (required <= set(system)):
        message = "Missing required fields: {missing}".format(
            missing=required-set(system),
        )
        raise ValueError(message)


def load_system(source_dir):
    """
    Load the build system from a source dir (pyproject.toml).
    """
    pyproject = os.path.join(source_dir, 'pyproject.toml')
    with io.open(pyproject, 'rb') as f:
        pyproject_data = toml_load(f)
    return pyproject_data['build-system']


def compat_system(source_dir):
    """
    Given a source dir, attempt to get a build system backend
    and requirements from pyproject.toml. Fallback to
    setuptools but only if the file was not found or a build
    system was not indicated.
    """
    try:
        system = load_system(source_dir)
    except (FileNotFoundError, KeyError):
        system = {}
    system.setdefault(
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/check.py
"""Check a project and backend by attempting to build using PEP 517 hooks.
"""
import argparse
import io
import logging
import os
from os.path import isfile, join as pjoin
import shutil
from subprocess import CalledProcessError
import sys
import tarfile
from tempfile import mkdtemp
import zipfile

from .colorlog import enable_colourful_output
from .compat import TOMLDecodeError, toml_load
from .envbuild import BuildEnvironment
from .wrappers import Pep517HookCaller

log = logging.getLogger(__name__)


def check_build_sdist(hooks, build_sys_requires):
    with BuildEnvironment() as env:
        try:
            env.pip_install(build_sys_requires)
            log.info('Installed static build dependencies')
        except CalledProcessError:
            log.error('Failed to install static build dependencies')
            return False

        try:
            reqs = hooks.get_requires_for_build_sdist({})
            log.info('Got build requires: %s', reqs)
        except Exception:
            log.error('Failure in get_requires_for_build_sdist', exc_info=True)
            return False

        try:
            env.pip_install(reqs)
            log.info('Installed dynamic build dependencies')
        except CalledProcessError:
            log.error('Failed to install dynamic build dependencies')
            return False

        td = mkdtemp()
        log.info('Trying to build sdist in %s', td)
        try:
            try:
                filename = hooks.build_sdist(td, {})
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/colorlog.py
"""Nicer log formatting with colours.

Code copied from Tornado, Apache licensed.
"""
# Copyright 2012 Facebook
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import logging
import sys

try:
    import curses
except ImportError:
    curses = None


def _stderr_supports_color():
    color = False
    if curses and hasattr(sys.stderr, 'isatty') and sys.stderr.isatty():
        try:
            curses.setupterm()
            if curses.tigetnum("colors") > 0:
                color = True
        except Exception:
            pass
    return color


class LogFormatter(logging.Formatter):
    """Log formatter with colour support
    """
    DEFAULT_COLORS = {
        logging.INFO: 2,  # Green
        logging.WARNING: 3,  # Yellow
        logging.ERROR: 1,  # Red
        logging.CRITICAL: 1,
    }

    def __init__(self, color=True, datefmt=None):
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/compat.py
"""Python 2/3 compatibility"""
import io
import json
import sys


# Handle reading and writing JSON in UTF-8, on Python 3 and 2.

if sys.version_info[0] >= 3:
    # Python 3
    def write_json(obj, path, **kwargs):
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(obj, f, **kwargs)

    def read_json(path):
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)

else:
    # Python 2
    def write_json(obj, path, **kwargs):
        with open(path, 'wb') as f:
            json.dump(obj, f, encoding='utf-8', **kwargs)

    def read_json(path):
        with open(path, 'rb') as f:
            return json.load(f)


# FileNotFoundError

try:
    FileNotFoundError = FileNotFoundError
except NameError:
    FileNotFoundError = IOError


if sys.version_info < (3, 6):
    from toml import load as _toml_load  # noqa: F401

    def toml_load(f):
        w = io.TextIOWrapper(f, encoding="utf8", newline="")
        try:
            return _toml_load(w)
        finally:
            w.detach()

    from toml import TomlDecodeError as TOMLDecodeError  # noqa: F401
else:
    from pip._vendor.tomli import load as toml_load  # noqa: F401
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/dirtools.py
import os
import io
import contextlib
import tempfile
import shutil
import errno
import zipfile


@contextlib.contextmanager
def tempdir():
    """Create a temporary directory in a context manager."""
    td = tempfile.mkdtemp()
    try:
        yield td
    finally:
        shutil.rmtree(td)


def mkdir_p(*args, **kwargs):
    """Like `mkdir`, but does not raise an exception if the
    directory already exists.
    """
    try:
        return os.mkdir(*args, **kwargs)
    except OSError as exc:
        if exc.errno != errno.EEXIST:
            raise


def dir_to_zipfile(root):
    """Construct an in-memory zip file for a directory."""
    buffer = io.BytesIO()
    zip_file = zipfile.ZipFile(buffer, 'w')
    for root, dirs, files in os.walk(root):
        for path in dirs:
            fs_path = os.path.join(root, path)
            rel_path = os.path.relpath(fs_path, root)
            zip_file.writestr(rel_path + '/', '')
        for path in files:
            fs_path = os.path.join(root, path)
            rel_path = os.path.relpath(fs_path, root)
            zip_file.write(fs_path, rel_path)
    return zip_file
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/envbuild.py
"""Build wheels/sdists by installing build deps to a temporary environment.
"""

import io
import os
import logging
import shutil
from subprocess import check_call
import sys
from sysconfig import get_paths
from tempfile import mkdtemp

from .compat import toml_load
from .wrappers import Pep517HookCaller, LoggerWrapper

log = logging.getLogger(__name__)


def _load_pyproject(source_dir):
    with io.open(
            os.path.join(source_dir, 'pyproject.toml'),
            'rb',
            ) as f:
        pyproject_data = toml_load(f)
    buildsys = pyproject_data['build-system']
    return (
        buildsys['requires'],
        buildsys['build-backend'],
        buildsys.get('backend-path'),
    )


class BuildEnvironment(object):
    """Context manager to install build deps in a simple temporary environment

    Based on code I wrote for pip, which is MIT licensed.
    """
    # Copyright (c) 2008-2016 The pip developers (see AUTHORS.txt file)
    #
    # Permission is hereby granted, free of charge, to any person obtaining
    # a copy of this software and associated documentation files (the
    # "Software"), to deal in the Software without restriction, including
    # without limitation the rights to use, copy, modify, merge, publish,
    # distribute, sublicense, and/or sell copies of the Software, and to
    # permit persons to whom the Software is furnished to do so, subject to
    # the following conditions:
    #
    # The above copyright notice and this permission notice shall be
    # included in all copies or substantial portions of the Software.
    #
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/in_process/_in_process.py
"""This is invoked in a subprocess to call the build backend hooks.

It expects:
- Command line args: hook_name, control_dir
- Environment variables:
      PEP517_BUILD_BACKEND=entry.point:spec
      PEP517_BACKEND_PATH=paths (separated with os.pathsep)
- control_dir/input.json:
  - {"kwargs": {...}}

Results:
- control_dir/output.json
  - {"return_val": ...}
"""
from glob import glob
from importlib import import_module
import json
import os
import os.path
from os.path import join as pjoin
import re
import shutil
import sys
import traceback

# This file is run as a script, and `import compat` is not zip-safe, so we
# include write_json() and read_json() from compat.py.
#
# Handle reading and writing JSON in UTF-8, on Python 3 and 2.

if sys.version_info[0] >= 3:
    # Python 3
    def write_json(obj, path, **kwargs):
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(obj, f, **kwargs)

    def read_json(path):
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)

else:
    # Python 2
    def write_json(obj, path, **kwargs):
        with open(path, 'wb') as f:
            json.dump(obj, f, encoding='utf-8', **kwargs)

    def read_json(path):
        with open(path, 'rb') as f:
            return json.load(f)

FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/in_process/__init__.py
"""This is a subpackage because the directory is on sys.path for _in_process.py

The subpackage should stay as empty as possible to avoid shadowing modules that
the backend might import.
"""
from os.path import dirname, abspath, join as pjoin
from contextlib import contextmanager

try:
    import importlib.resources as resources

    def _in_proc_script_path():
        return resources.path(__package__, '_in_process.py')
except ImportError:
    @contextmanager
    def _in_proc_script_path():
        yield pjoin(dirname(abspath(__file__)), '_in_process.py')
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/meta.py
"""Build metadata for a project using PEP 517 hooks.
"""
import argparse
import logging
import os
import shutil
import functools

try:
    import importlib.metadata as imp_meta
except ImportError:
    import importlib_metadata as imp_meta

try:
    from zipfile import Path
except ImportError:
    from zipp import Path

from .envbuild import BuildEnvironment
from .wrappers import Pep517HookCaller, quiet_subprocess_runner
from .dirtools import tempdir, mkdir_p, dir_to_zipfile
from .build import validate_system, load_system, compat_system

log = logging.getLogger(__name__)


def _prep_meta(hooks, env, dest):
    reqs = hooks.get_requires_for_build_wheel({})
    log.info('Got build requires: %s', reqs)

    env.pip_install(reqs)
    log.info('Installed dynamic build dependencies')

    with tempdir() as td:
        log.info('Trying to build metadata in %s', td)
        filename = hooks.prepare_metadata_for_build_wheel(td, {})
        source = os.path.join(td, filename)
        shutil.move(source, os.path.join(dest, os.path.basename(filename)))


def build(source_dir='.', dest=None, system=None):
    system = system or load_system(source_dir)
    dest = os.path.join(source_dir, dest or 'dist')
    mkdir_p(dest)
    validate_system(system)
    hooks = Pep517HookCaller(
        source_dir, system['build-backend'], system.get('backend-path')
    )

    with hooks.subprocess_runner(quiet_subprocess_runner):
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/wrappers.py
import threading
from contextlib import contextmanager
import os
from os.path import abspath, join as pjoin
import shutil
from subprocess import check_call, check_output, STDOUT
import sys
from tempfile import mkdtemp

from . import compat
from .in_process import _in_proc_script_path

__all__ = [
    'BackendUnavailable',
    'BackendInvalid',
    'HookMissing',
    'UnsupportedOperation',
    'default_subprocess_runner',
    'quiet_subprocess_runner',
    'Pep517HookCaller',
]


@contextmanager
def tempdir():
    td = mkdtemp()
    try:
        yield td
    finally:
        shutil.rmtree(td)


class BackendUnavailable(Exception):
    """Will be raised if the backend cannot be imported in the hook process."""
    def __init__(self, traceback):
        self.traceback = traceback


class BackendInvalid(Exception):
    """Will be raised if the backend is invalid."""
    def __init__(self, backend_name, backend_path, message):
        self.backend_name = backend_name
        self.backend_path = backend_path
        self.message = message


class HookMissing(Exception):
    """Will be raised on missing hooks."""
    def __init__(self, hook_name):
        super(HookMissing, self).__init__(hook_name)
FILE: ./venv/Lib/site-packages/pip/_vendor/pep517/__init__.py
"""Wrappers to build Python packages using PEP 517 hooks
"""

__version__ = '0.12.0'

from .wrappers import *  # noqa: F401, F403
FILE: ./venv/Lib/site-packages/pip/_vendor/pkg_resources/py31compat.py
import os
import errno
import sys

from pip._vendor import six


def _makedirs_31(path, exist_ok=False):
    try:
        os.makedirs(path)
    except OSError as exc:
        if not exist_ok or exc.errno != errno.EEXIST:
            raise


# rely on compatibility behavior until mode considerations
#  and exists_ok considerations are disentangled.
# See https://github.com/pypa/setuptools/pull/1083#issuecomment-315168663
needs_makedirs = (
    six.PY2 or
    (3, 4) <= sys.version_info < (3, 4, 1)
)
makedirs = _makedirs_31 if needs_makedirs else os.makedirs
FILE: ./venv/Lib/site-packages/pip/_vendor/pkg_resources/__init__.py
# coding: utf-8
"""
Package resource API
--------------------

A resource is a logical file contained within a package, or a logical
subdirectory thereof.  The package resource API expects resource names
to have their path parts separated with ``/``, *not* whatever the local
path separator is.  Do not use os.path operations to manipulate resource
names being passed into the API.

The package resource API is designed to work with normal filesystem packages,
.egg files, and unpacked .egg files.  It can also work in a limited way with
.zip files and with custom PEP 302 loaders that support the ``get_data()``
method.
"""

from __future__ import absolute_import

import sys
import os
import io
import time
import re
import types
import zipfile
import zipimport
import warnings
import stat
import functools
import pkgutil
import operator
import platform
import collections
import plistlib
import email.parser
import errno
import tempfile
import textwrap
import itertools
import inspect
import ntpath
import posixpath
from pkgutil import get_importer

try:
    import _imp
except ImportError:
    # Python 3.2 compatibility
    import imp as _imp
FILE: ./venv/Lib/site-packages/pip/_vendor/platformdirs/android.py
import os
import re
import sys
from functools import lru_cache

from .api import PlatformDirsABC


class Android(PlatformDirsABC):
    """
    Follows the guidance `from here <https://android.stackexchange.com/a/216132>`_. Makes use of the
    `appname <platformdirs.api.PlatformDirsABC.appname>` and
    `version <platformdirs.api.PlatformDirsABC.version>`.
    """

    @property
    def user_data_dir(self) -> str:
        """:return: data directory tied to the user, e.g. ``/data/user/<userid>/<packagename>/files/<AppName>``"""
        return self._append_app_name_and_version(_android_folder(), "files")

    @property
    def site_data_dir(self) -> str:
        """:return: data directory shared by users, same as `user_data_dir`"""
        return self.user_data_dir

    @property
    def user_config_dir(self) -> str:
        """
        :return: config directory tied to the user, e.g. ``/data/user/<userid>/<packagename>/shared_prefs/<AppName>``
        """
        return self._append_app_name_and_version(_android_folder(), "shared_prefs")

    @property
    def site_config_dir(self) -> str:
        """:return: config directory shared by the users, same as `user_config_dir`"""
        return self.user_config_dir

    @property
    def user_cache_dir(self) -> str:
        """:return: cache directory tied to the user, e.g. e.g. ``/data/user/<userid>/<packagename>/cache/<AppName>``"""
        return self._append_app_name_and_version(_android_folder(), "cache")

    @property
    def user_state_dir(self) -> str:
        """:return: state directory tied to the user, same as `user_data_dir`"""
        return self.user_data_dir

    @property
    def user_log_dir(self) -> str:
        """
FILE: ./venv/Lib/site-packages/pip/_vendor/platformdirs/api.py
import os
import sys
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Optional, Union

if sys.version_info >= (3, 8):  # pragma: no branch
    from typing import Literal  # pragma: no cover


class PlatformDirsABC(ABC):
    """
    Abstract base class for platform directories.
    """

    def __init__(
        self,
        appname: Optional[str] = None,
        appauthor: Union[str, None, "Literal[False]"] = None,
        version: Optional[str] = None,
        roaming: bool = False,
        multipath: bool = False,
        opinion: bool = True,
    ):
        """
        Create a new platform directory.

        :param appname: See `appname`.
        :param appauthor: See `appauthor`.
        :param version: See `version`.
        :param roaming: See `roaming`.
        :param multipath: See `multipath`.
        :param opinion: See `opinion`.
        """
        self.appname = appname  #: The name of application.
        self.appauthor = appauthor
        """
        The name of the app author or distributing body for this application. Typically, it is the owning company name.
        Defaults to `appname`. You may pass ``False`` to disable it.
        """
        self.version = version
        """
        An optional version path element to append to the path. You might want to use this if you want multiple versions
        of your app to be able to run independently. If used, this would typically be ``<major>.<minor>``.
        """
        self.roaming = roaming
        """
        Whether to use the roaming appdata directory on Windows. That means that for users on a Windows network setup
        for roaming profiles, this user data will be synced on login (see
        `here <http://technet.microsoft.com/en-us/library/cc766489(WS.10).aspx>`_).
FILE: ./venv/Lib/site-packages/pip/_vendor/platformdirs/macos.py
import os

from .api import PlatformDirsABC


class MacOS(PlatformDirsABC):
    """
    Platform directories for the macOS operating system. Follows the guidance from `Apple documentation
    <https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/MacOSXDirectories/MacOSXDirectories.html>`_.
    Makes use of the `appname <platformdirs.api.PlatformDirsABC.appname>` and
    `version <platformdirs.api.PlatformDirsABC.version>`.
    """

    @property
    def user_data_dir(self) -> str:
        """:return: data directory tied to the user, e.g. ``~/Library/Application Support/$appname/$version``"""
        return self._append_app_name_and_version(os.path.expanduser("~/Library/Application Support/"))

    @property
    def site_data_dir(self) -> str:
        """:return: data directory shared by users, e.g. ``/Library/Application Support/$appname/$version``"""
        return self._append_app_name_and_version("/Library/Application Support")

    @property
    def user_config_dir(self) -> str:
        """:return: config directory tied to the user, e.g. ``~/Library/Preferences/$appname/$version``"""
        return self._append_app_name_and_version(os.path.expanduser("~/Library/Preferences/"))

    @property
    def site_config_dir(self) -> str:
        """:return: config directory shared by the users, e.g. ``/Library/Preferences/$appname``"""
        return self._append_app_name_and_version("/Library/Preferences")

    @property
    def user_cache_dir(self) -> str:
        """:return: cache directory tied to the user, e.g. ``~/Library/Caches/$appname/$version``"""
        return self._append_app_name_and_version(os.path.expanduser("~/Library/Caches"))

    @property
    def user_state_dir(self) -> str:
        """:return: state directory tied to the user, same as `user_data_dir`"""
        return self.user_data_dir

    @property
    def user_log_dir(self) -> str:
        """:return: log directory tied to the user, e.g. ``~/Library/Logs/$appname/$version``"""
        return self._append_app_name_and_version(os.path.expanduser("~/Library/Logs"))

    @property
    def user_documents_dir(self) -> str:
FILE: ./venv/Lib/site-packages/pip/_vendor/platformdirs/unix.py
import os
import sys
from configparser import ConfigParser
from pathlib import Path
from typing import Optional

from .api import PlatformDirsABC

if sys.platform.startswith("linux"):  # pragma: no branch # no op check, only to please the type checker
    from os import getuid
else:

    def getuid() -> int:
        raise RuntimeError("should only be used on Linux")


class Unix(PlatformDirsABC):
    """
    On Unix/Linux, we follow the
    `XDG Basedir Spec <https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html>`_. The spec allows
    overriding directories with environment variables. The examples show are the default values, alongside the name of
    the environment variable that overrides them. Makes use of the
    `appname <platformdirs.api.PlatformDirsABC.appname>`,
    `version <platformdirs.api.PlatformDirsABC.version>`,
    `multipath <platformdirs.api.PlatformDirsABC.multipath>`,
    `opinion <platformdirs.api.PlatformDirsABC.opinion>`.
    """

    @property
    def user_data_dir(self) -> str:
        """
        :return: data directory tied to the user, e.g. ``~/.local/share/$appname/$version`` or
         ``$XDG_DATA_HOME/$appname/$version``
        """
        path = os.environ.get("XDG_DATA_HOME", "")
        if not path.strip():
            path = os.path.expanduser("~/.local/share")
        return self._append_app_name_and_version(path)

    @property
    def site_data_dir(self) -> str:
        """
        :return: data directories shared by users (if `multipath <platformdirs.api.PlatformDirsABC.multipath>` is
         enabled and ``XDG_DATA_DIR`` is set and a multi path the response is also a multi path separated by the OS
         path separator), e.g. ``/usr/local/share/$appname/$version`` or ``/usr/share/$appname/$version``
        """
        # XDG default for $XDG_DATA_DIRS; only first, if multipath is False
        path = os.environ.get("XDG_DATA_DIRS", "")
        if not path.strip():
            path = f"/usr/local/share{os.pathsep}/usr/share"
FILE: ./venv/Lib/site-packages/pip/_vendor/platformdirs/version.py
""" Version information """

__version__ = "2.4.0"
__version_info__ = (2, 4, 0)
FILE: ./venv/Lib/site-packages/pip/_vendor/platformdirs/windows.py
import ctypes
import os
from functools import lru_cache
from typing import Callable, Optional

from .api import PlatformDirsABC


class Windows(PlatformDirsABC):
    """`MSDN on where to store app data files
    <http://support.microsoft.com/default.aspx?scid=kb;en-us;310294#XSLTH3194121123120121120120>`_.
    Makes use of the
    `appname <platformdirs.api.PlatformDirsABC.appname>`,
    `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`,
    `version <platformdirs.api.PlatformDirsABC.version>`,
    `roaming <platformdirs.api.PlatformDirsABC.roaming>`,
    `opinion <platformdirs.api.PlatformDirsABC.opinion>`."""

    @property
    def user_data_dir(self) -> str:
        """
        :return: data directory tied to the user, e.g.
         ``%USERPROFILE%\\AppData\\Local\\$appauthor\\$appname`` (not roaming) or
         ``%USERPROFILE%\\AppData\\Roaming\\$appauthor\\$appname`` (roaming)
        """
        const = "CSIDL_APPDATA" if self.roaming else "CSIDL_LOCAL_APPDATA"
        path = os.path.normpath(get_win_folder(const))
        return self._append_parts(path)

    def _append_parts(self, path: str, *, opinion_value: Optional[str] = None) -> str:
        params = []
        if self.appname:
            if self.appauthor is not False:
                author = self.appauthor or self.appname
                params.append(author)
            params.append(self.appname)
            if opinion_value is not None and self.opinion:
                params.append(opinion_value)
            if self.version:
                params.append(self.version)
        return os.path.join(path, *params)

    @property
    def site_data_dir(self) -> str:
        """:return: data directory shared by users, e.g. ``C:\\ProgramData\\$appauthor\\$appname``"""
        path = os.path.normpath(get_win_folder("CSIDL_COMMON_APPDATA"))
        return self._append_parts(path)

    @property
    def user_config_dir(self) -> str:
FILE: ./venv/Lib/site-packages/pip/_vendor/platformdirs/__init__.py
"""
Utilities for determining application-specific dirs. See <https://github.com/platformdirs/platformdirs> for details and
usage.
"""
import importlib
import os
import sys
from pathlib import Path
from typing import TYPE_CHECKING, Optional, Type, Union

if TYPE_CHECKING:
    from typing_extensions import Literal  # pragma: no cover

from .api import PlatformDirsABC
from .version import __version__, __version_info__


def _set_platform_dir_class() -> Type[PlatformDirsABC]:
    if os.getenv("ANDROID_DATA") == "/data" and os.getenv("ANDROID_ROOT") == "/system":
        module, name = "pip._vendor.platformdirs.android", "Android"
    elif sys.platform == "win32":
        module, name = "pip._vendor.platformdirs.windows", "Windows"
    elif sys.platform == "darwin":
        module, name = "pip._vendor.platformdirs.macos", "MacOS"
    else:
        module, name = "pip._vendor.platformdirs.unix", "Unix"
    result: Type[PlatformDirsABC] = getattr(importlib.import_module(module), name)
    return result


PlatformDirs = _set_platform_dir_class()  #: Currently active platform
AppDirs = PlatformDirs  #: Backwards compatibility with appdirs


def user_data_dir(
    appname: Optional[str] = None,
    appauthor: Union[str, None, "Literal[False]"] = None,
    version: Optional[str] = None,
    roaming: bool = False,
) -> str:
    """
    :param appname: See `appname <platformdirs.api.PlatformDirsABC.appname>`.
    :param appauthor: See `appauthor <platformdirs.api.PlatformDirsABC.appauthor>`.
    :param version: See `version <platformdirs.api.PlatformDirsABC.version>`.
    :param roaming: See `roaming <platformdirs.api.PlatformDirsABC.version>`.
    :returns: data directory tied to the user
    """
    return PlatformDirs(appname=appname, appauthor=appauthor, version=version, roaming=roaming).user_data_dir


FILE: ./venv/Lib/site-packages/pip/_vendor/platformdirs/__main__.py
from pip._vendor.platformdirs import PlatformDirs, __version__

PROPS = (
    "user_data_dir",
    "user_config_dir",
    "user_cache_dir",
    "user_state_dir",
    "user_log_dir",
    "user_documents_dir",
    "user_runtime_dir",
    "site_data_dir",
    "site_config_dir",
)


def main() -> None:
    app_name = "MyApp"
    app_author = "MyCompany"

    print(f"-- platformdirs {__version__} --")

    print("-- app dirs (with optional 'version')")
    dirs = PlatformDirs(app_name, app_author, version="1.0")
    for prop in PROPS:
        print(f"{prop}: {getattr(dirs, prop)}")

    print("\n-- app dirs (without optional 'version')")
    dirs = PlatformDirs(app_name, app_author)
    for prop in PROPS:
        print(f"{prop}: {getattr(dirs, prop)}")

    print("\n-- app dirs (without optional 'appauthor')")
    dirs = PlatformDirs(app_name)
    for prop in PROPS:
        print(f"{prop}: {getattr(dirs, prop)}")

    print("\n-- app dirs (with disabled 'appauthor')")
    dirs = PlatformDirs(app_name, appauthor=False)
    for prop in PROPS:
        print(f"{prop}: {getattr(dirs, prop)}")


if __name__ == "__main__":
    main()
FILE: ./venv/Lib/site-packages/pip/_vendor/progress/bar.py
# -*- coding: utf-8 -*-

# Copyright (c) 2012 Georgios Verigakis <verigak@gmail.com>
#
# Permission to use, copy, modify, and distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

from __future__ import unicode_literals

import sys

from . import Progress
from .colors import color


class Bar(Progress):
    width = 32
    suffix = '%(index)d/%(max)d'
    bar_prefix = ' |'
    bar_suffix = '| '
    empty_fill = ' '
    fill = '#'
    color = None

    def update(self):
        filled_length = int(self.width * self.progress)
        empty_length = self.width - filled_length

        message = self.message % self
        bar = color(self.fill * filled_length, fg=self.color)
        empty = self.empty_fill * empty_length
        suffix = self.suffix % self
        line = ''.join([message, self.bar_prefix, bar, empty, self.bar_suffix,
                        suffix])
        self.writeln(line)


class ChargingBar(Bar):
    suffix = '%(percent)d%%'
    bar_prefix = ' '
    bar_suffix = ' '
FILE: ./venv/Lib/site-packages/pip/_vendor/progress/colors.py
# -*- coding: utf-8 -*-

# Copyright (c) 2020 Georgios Verigakis <verigak@gmail.com>
#
# Permission to use, copy, modify, and distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

from functools import partial


COLORS = ('black', 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan',
          'white')
STYLES = ('bold', 'faint', 'italic', 'underline', 'blink', 'blink2',
          'negative', 'concealed', 'crossed')


def color(s, fg=None, bg=None, style=None):
    sgr = []

    if fg:
        if fg in COLORS:
            sgr.append(str(30 + COLORS.index(fg)))
        elif isinstance(fg, int) and 0 <= fg <= 255:
            sgr.append('38;5;%d' % int(fg))
        else:
            raise Exception('Invalid color "%s"' % fg)

    if bg:
        if bg in COLORS:
            sgr.append(str(40 + COLORS.index(bg)))
        elif isinstance(bg, int) and 0 <= bg <= 255:
            sgr.append('48;5;%d' % bg)
        else:
            raise Exception('Invalid color "%s"' % bg)

    if style:
        for st in style.split('+'):
            if st in STYLES:
                sgr.append(str(1 + STYLES.index(st)))
            else:
                raise Exception('Invalid style "%s"' % st)
FILE: ./venv/Lib/site-packages/pip/_vendor/progress/counter.py
# -*- coding: utf-8 -*-

# Copyright (c) 2012 Georgios Verigakis <verigak@gmail.com>
#
# Permission to use, copy, modify, and distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

from __future__ import unicode_literals
from . import Infinite, Progress


class Counter(Infinite):
    def update(self):
        message = self.message % self
        line = ''.join([message, str(self.index)])
        self.writeln(line)


class Countdown(Progress):
    def update(self):
        message = self.message % self
        line = ''.join([message, str(self.remaining)])
        self.writeln(line)


class Stack(Progress):
    phases = (' ', '▁', '▂', '▃', '▄', '▅', '▆', '▇', '█')

    def update(self):
        nphases = len(self.phases)
        i = min(nphases - 1, int(self.progress * nphases))
        message = self.message % self
        line = ''.join([message, self.phases[i]])
        self.writeln(line)


class Pie(Stack):
    phases = ('○', '◔', '◑', '◕', '●')
FILE: ./venv/Lib/site-packages/pip/_vendor/progress/spinner.py
# -*- coding: utf-8 -*-

# Copyright (c) 2012 Georgios Verigakis <verigak@gmail.com>
#
# Permission to use, copy, modify, and distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

from __future__ import unicode_literals
from . import Infinite


class Spinner(Infinite):
    phases = ('-', '\\', '|', '/')
    hide_cursor = True

    def update(self):
        i = self.index % len(self.phases)
        message = self.message % self
        line = ''.join([message, self.phases[i]])
        self.writeln(line)


class PieSpinner(Spinner):
    phases = ['◷', '◶', '◵', '◴']


class MoonSpinner(Spinner):
    phases = ['◑', '◒', '◐', '◓']


class LineSpinner(Spinner):
    phases = ['⎺', '⎻', '⎼', '⎽', '⎼', '⎻']


class PixelSpinner(Spinner):
    phases = ['⣾', '⣷', '⣯', '⣟', '⡿', '⢿', '⣻', '⣽']
FILE: ./venv/Lib/site-packages/pip/_vendor/progress/__init__.py
# Copyright (c) 2012 Georgios Verigakis <verigak@gmail.com>
#
# Permission to use, copy, modify, and distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

from __future__ import division, print_function

from collections import deque
from datetime import timedelta
from math import ceil
from sys import stderr
try:
    from time import monotonic
except ImportError:
    from time import time as monotonic


__version__ = '1.6'

HIDE_CURSOR = '\x1b[?25l'
SHOW_CURSOR = '\x1b[?25h'


class Infinite(object):
    file = stderr
    sma_window = 10         # Simple Moving Average window
    check_tty = True
    hide_cursor = True

    def __init__(self, message='', **kwargs):
        self.index = 0
        self.start_ts = monotonic()
        self.avg = 0
        self._avg_update_ts = self.start_ts
        self._ts = self.start_ts
        self._xput = deque(maxlen=self.sma_window)
        for key, val in kwargs.items():
            setattr(self, key, val)

        self._max_width = 0
        self._hidden_cursor = False
FILE: ./venv/Lib/site-packages/pip/_vendor/pyparsing.py
# -*- coding: utf-8 -*-
# module pyparsing.py
#
# Copyright (c) 2003-2019  Paul T. McGuire
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#

__doc__ = \
"""
pyparsing module - Classes and methods to define and execute parsing grammars
=============================================================================

The pyparsing module is an alternative approach to creating and
executing simple grammars, vs. the traditional lex/yacc approach, or the
use of regular expressions.  With pyparsing, you don't need to learn
a new syntax for defining grammars or matching expressions - the parsing
module provides a library of classes that you use to construct the
grammar directly in Python.

Here is a program to parse "Hello, World!" (or any greeting of the form
``"<salutation>, <addressee>!"``), built up using :class:`Word`,
:class:`Literal`, and :class:`And` elements
(the :class:`'+'<ParserElement.__add__>` operators create :class:`And` expressions,
and the strings are auto-converted to :class:`Literal` expressions)::

    from pip._vendor.pyparsing import Word, alphas

    # define grammar of a greeting
    greet = Word(alphas) + "," + Word(alphas) + "!"

    hello = "Hello, World!"
    print (hello, "->", greet.parseString(hello))
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/adapters.py
# -*- coding: utf-8 -*-

"""
requests.adapters
~~~~~~~~~~~~~~~~~

This module contains the transport adapters that Requests uses to define
and maintain connections.
"""

import os.path
import socket

from pip._vendor.urllib3.poolmanager import PoolManager, proxy_from_url
from pip._vendor.urllib3.response import HTTPResponse
from pip._vendor.urllib3.util import parse_url
from pip._vendor.urllib3.util import Timeout as TimeoutSauce
from pip._vendor.urllib3.util.retry import Retry
from pip._vendor.urllib3.exceptions import ClosedPoolError
from pip._vendor.urllib3.exceptions import ConnectTimeoutError
from pip._vendor.urllib3.exceptions import HTTPError as _HTTPError
from pip._vendor.urllib3.exceptions import MaxRetryError
from pip._vendor.urllib3.exceptions import NewConnectionError
from pip._vendor.urllib3.exceptions import ProxyError as _ProxyError
from pip._vendor.urllib3.exceptions import ProtocolError
from pip._vendor.urllib3.exceptions import ReadTimeoutError
from pip._vendor.urllib3.exceptions import SSLError as _SSLError
from pip._vendor.urllib3.exceptions import ResponseError
from pip._vendor.urllib3.exceptions import LocationValueError

from .models import Response
from .compat import urlparse, basestring
from .utils import (DEFAULT_CA_BUNDLE_PATH, extract_zipped_paths,
                    get_encoding_from_headers, prepend_scheme_if_needed,
                    get_auth_from_url, urldefragauth, select_proxy)
from .structures import CaseInsensitiveDict
from .cookies import extract_cookies_to_jar
from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,
                         ProxyError, RetryError, InvalidSchema, InvalidProxyURL,
                         InvalidURL)
from .auth import _basic_auth_str

try:
    from pip._vendor.urllib3.contrib.socks import SOCKSProxyManager
except ImportError:
    def SOCKSProxyManager(*args, **kwargs):
        raise InvalidSchema("Missing dependencies for SOCKS support.")

DEFAULT_POOLBLOCK = False
DEFAULT_POOLSIZE = 10
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/api.py
# -*- coding: utf-8 -*-

"""
requests.api
~~~~~~~~~~~~

This module implements the Requests API.

:copyright: (c) 2012 by Kenneth Reitz.
:license: Apache2, see LICENSE for more details.
"""

from . import sessions


def request(method, url, **kwargs):
    """Constructs and sends a :class:`Request <Request>`.

    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
        to add for the file.
    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
    :param timeout: (optional) How many seconds to wait for the server to send data
        before giving up, as a float, or a :ref:`(connect timeout, read
        timeout) <timeouts>` tuple.
    :type timeout: float or tuple
    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
    :type allow_redirects: bool
    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
    :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
    :param stream: (optional) if ``False``, the response content will be immediately downloaded.
    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response

    Usage::

FILE: ./venv/Lib/site-packages/pip/_vendor/requests/auth.py
# -*- coding: utf-8 -*-

"""
requests.auth
~~~~~~~~~~~~~

This module contains the authentication handlers for Requests.
"""

import os
import re
import time
import hashlib
import threading
import warnings

from base64 import b64encode

from .compat import urlparse, str, basestring
from .cookies import extract_cookies_to_jar
from ._internal_utils import to_native_string
from .utils import parse_dict_header

CONTENT_TYPE_FORM_URLENCODED = 'application/x-www-form-urlencoded'
CONTENT_TYPE_MULTI_PART = 'multipart/form-data'


def _basic_auth_str(username, password):
    """Returns a Basic Auth string."""

    # "I want us to put a big-ol' comment on top of it that
    # says that this behaviour is dumb but we need to preserve
    # it because people are relying on it."
    #    - Lukasa
    #
    # These are here solely to maintain backwards compatibility
    # for things like ints. This will be removed in 3.0.0.
    if not isinstance(username, basestring):
        warnings.warn(
            "Non-string usernames will no longer be supported in Requests "
            "3.0.0. Please convert the object you've passed in ({!r}) to "
            "a string or bytes object in the near future to avoid "
            "problems.".format(username),
            category=DeprecationWarning,
        )
        username = str(username)

    if not isinstance(password, basestring):
        warnings.warn(
            "Non-string passwords will no longer be supported in Requests "
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/certs.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
requests.certs
~~~~~~~~~~~~~~

This module returns the preferred default CA certificate bundle. There is
only one — the one from the certifi package.

If you are packaging Requests, e.g., for a Linux distribution or a managed
environment, you can change the definition of where() to return a separately
packaged CA bundle.
"""
from pip._vendor.certifi import where

if __name__ == '__main__':
    print(where())
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/compat.py
# -*- coding: utf-8 -*-

"""
requests.compat
~~~~~~~~~~~~~~~

This module handles import compatibility issues between Python 2 and
Python 3.
"""

from pip._vendor import chardet

import sys

# -------
# Pythons
# -------

# Syntax sugar.
_ver = sys.version_info

#: Python 2.x?
is_py2 = (_ver[0] == 2)

#: Python 3.x?
is_py3 = (_ver[0] == 3)

# Note: We've patched out simplejson support in pip because it prevents
#       upgrading simplejson on Windows.
# try:
#     import simplejson as json
# except (ImportError, SyntaxError):
#     # simplejson does not support Python 3.2, it throws a SyntaxError
#     # because of u'...' Unicode literals.
import json

# ---------
# Specifics
# ---------

if is_py2:
    from urllib import (
        quote, unquote, quote_plus, unquote_plus, urlencode, getproxies,
        proxy_bypass, proxy_bypass_environment, getproxies_environment)
    from urlparse import urlparse, urlunparse, urljoin, urlsplit, urldefrag
    from urllib2 import parse_http_list
    import cookielib
    from Cookie import Morsel
    from StringIO import StringIO
    # Keep OrderedDict for backwards compatibility.
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/cookies.py
# -*- coding: utf-8 -*-

"""
requests.cookies
~~~~~~~~~~~~~~~~

Compatibility code to be able to use `cookielib.CookieJar` with requests.

requests.utils imports from here, so be careful with imports.
"""

import copy
import time
import calendar

from ._internal_utils import to_native_string
from .compat import cookielib, urlparse, urlunparse, Morsel, MutableMapping

try:
    import threading
except ImportError:
    import dummy_threading as threading


class MockRequest(object):
    """Wraps a `requests.Request` to mimic a `urllib2.Request`.

    The code in `cookielib.CookieJar` expects this interface in order to correctly
    manage cookie policies, i.e., determine whether a cookie can be set, given the
    domains of the request and the cookie.

    The original request object is read-only. The client is responsible for collecting
    the new headers via `get_new_headers()` and interpreting them appropriately. You
    probably want `get_cookie_header`, defined below.
    """

    def __init__(self, request):
        self._r = request
        self._new_headers = {}
        self.type = urlparse(self._r.url).scheme

    def get_type(self):
        return self.type

    def get_host(self):
        return urlparse(self._r.url).netloc

    def get_origin_req_host(self):
        return self.get_host()

FILE: ./venv/Lib/site-packages/pip/_vendor/requests/exceptions.py
# -*- coding: utf-8 -*-

"""
requests.exceptions
~~~~~~~~~~~~~~~~~~~

This module contains the set of Requests' exceptions.
"""
from pip._vendor.urllib3.exceptions import HTTPError as BaseHTTPError


class RequestException(IOError):
    """There was an ambiguous exception that occurred while handling your
    request.
    """

    def __init__(self, *args, **kwargs):
        """Initialize RequestException with `request` and `response` objects."""
        response = kwargs.pop('response', None)
        self.response = response
        self.request = kwargs.pop('request', None)
        if (response is not None and not self.request and
                hasattr(response, 'request')):
            self.request = self.response.request
        super(RequestException, self).__init__(*args, **kwargs)


class InvalidJSONError(RequestException):
    """A JSON error occurred."""


class HTTPError(RequestException):
    """An HTTP error occurred."""


class ConnectionError(RequestException):
    """A Connection error occurred."""


class ProxyError(ConnectionError):
    """A proxy error occurred."""


class SSLError(ConnectionError):
    """An SSL error occurred."""


class Timeout(RequestException):
    """The request timed out.

FILE: ./venv/Lib/site-packages/pip/_vendor/requests/help.py
"""Module containing bug report helper(s)."""
from __future__ import print_function

import json
import platform
import sys
import ssl

from pip._vendor import idna
from pip._vendor import urllib3

from . import __version__ as requests_version

charset_normalizer = None

try:
    from pip._vendor import chardet
except ImportError:
    chardet = None

try:
    from pip._vendor.urllib3.contrib import pyopenssl
except ImportError:
    pyopenssl = None
    OpenSSL = None
    cryptography = None
else:
    import OpenSSL
    import cryptography


def _implementation():
    """Return a dict with the Python implementation and version.

    Provide both the name and the version of the Python implementation
    currently running. For example, on CPython 2.7.5 it will return
    {'name': 'CPython', 'version': '2.7.5'}.

    This function works best on CPython and PyPy: in particular, it probably
    doesn't work for Jython or IronPython. Future investigation should be done
    to work out the correct shape of the code for those platforms.
    """
    implementation = platform.python_implementation()

    if implementation == 'CPython':
        implementation_version = platform.python_version()
    elif implementation == 'PyPy':
        implementation_version = '%s.%s.%s' % (sys.pypy_version_info.major,
                                               sys.pypy_version_info.minor,
                                               sys.pypy_version_info.micro)
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/hooks.py
# -*- coding: utf-8 -*-

"""
requests.hooks
~~~~~~~~~~~~~~

This module provides the capabilities for the Requests hooks system.

Available hooks:

``response``:
    The response generated from a Request.
"""
HOOKS = ['response']


def default_hooks():
    return {event: [] for event in HOOKS}

# TODO: response is the only one


def dispatch_hook(key, hooks, hook_data, **kwargs):
    """Dispatches a hook dictionary on a given piece of data."""
    hooks = hooks or {}
    hooks = hooks.get(key)
    if hooks:
        if hasattr(hooks, '__call__'):
            hooks = [hooks]
        for hook in hooks:
            _hook_data = hook(hook_data, **kwargs)
            if _hook_data is not None:
                hook_data = _hook_data
    return hook_data
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/models.py
# -*- coding: utf-8 -*-

"""
requests.models
~~~~~~~~~~~~~~~

This module contains the primary objects that power Requests.
"""

import datetime
import sys

# Import encoding now, to avoid implicit import later.
# Implicit import within threads may cause LookupError when standard library is in a ZIP,
# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.
import encodings.idna

from pip._vendor.urllib3.fields import RequestField
from pip._vendor.urllib3.filepost import encode_multipart_formdata
from pip._vendor.urllib3.util import parse_url
from pip._vendor.urllib3.exceptions import (
    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)

from io import UnsupportedOperation
from .hooks import default_hooks
from .structures import CaseInsensitiveDict

from .auth import HTTPBasicAuth
from .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar
from .exceptions import (
    HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,
    ContentDecodingError, ConnectionError, StreamConsumedError, InvalidJSONError)
from ._internal_utils import to_native_string, unicode_is_ascii
from .utils import (
    guess_filename, get_auth_from_url, requote_uri,
    stream_decode_response_unicode, to_key_val_list, parse_header_links,
    iter_slices, guess_json_utf, super_len, check_header_validity)
from .compat import (
    Callable, Mapping,
    cookielib, urlunparse, urlsplit, urlencode, str, bytes,
    is_py2, chardet, builtin_str, basestring)
from .compat import json as complexjson
from .status_codes import codes

#: The set of HTTP status codes that indicate an automatically
#: processable redirect.
REDIRECT_STATI = (
    codes.moved,               # 301
    codes.found,               # 302
    codes.other,               # 303
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/packages.py
import sys

# This code exists for backwards compatibility reasons.
# I don't like it either. Just look the other way. :)

for package in ('urllib3', 'idna', 'chardet'):
    vendored_package = "pip._vendor." + package
    locals()[package] = __import__(vendored_package)
    # This traversal is apparently necessary such that the identities are
    # preserved (requests.packages.urllib3.* is urllib3.*)
    for mod in list(sys.modules):
        if mod == vendored_package or mod.startswith(vendored_package + '.'):
            unprefixed_mod = mod[len("pip._vendor."):]
            sys.modules['pip._vendor.requests.packages.' + unprefixed_mod] = sys.modules[mod]

# Kinda cool, though, right?
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/sessions.py
# -*- coding: utf-8 -*-

"""
requests.sessions
~~~~~~~~~~~~~~~~~

This module provides a Session object to manage and persist settings across
requests (cookies, auth, proxies).
"""
import os
import sys
import time
from datetime import timedelta
from collections import OrderedDict

from .auth import _basic_auth_str
from .compat import cookielib, is_py3, urljoin, urlparse, Mapping
from .cookies import (
    cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)
from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT
from .hooks import default_hooks, dispatch_hook
from ._internal_utils import to_native_string
from .utils import to_key_val_list, default_headers, DEFAULT_PORTS
from .exceptions import (
    TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)

from .structures import CaseInsensitiveDict
from .adapters import HTTPAdapter

from .utils import (
    requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,
    get_auth_from_url, rewind_body
)

from .status_codes import codes

# formerly defined here, reexposed here for backward compatibility
from .models import REDIRECT_STATI

# Preferred clock, based on which one is more accurate on a given system.
if sys.platform == 'win32':
    try:  # Python 3.4+
        preferred_clock = time.perf_counter
    except AttributeError:  # Earlier than Python 3.
        preferred_clock = time.clock
else:
    preferred_clock = time.time


def merge_setting(request_setting, session_setting, dict_class=OrderedDict):
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/status_codes.py
# -*- coding: utf-8 -*-

r"""
The ``codes`` object defines a mapping from common names for HTTP statuses
to their numerical codes, accessible either as attributes or as dictionary
items.

Example::

    >>> import requests
    >>> requests.codes['temporary_redirect']
    307
    >>> requests.codes.teapot
    418
    >>> requests.codes['\o/']
    200

Some codes have multiple names, and both upper- and lower-case versions of
the names are allowed. For example, ``codes.ok``, ``codes.OK``, and
``codes.okay`` all correspond to the HTTP status code 200.
"""

from .structures import LookupDict

_codes = {

    # Informational.
    100: ('continue',),
    101: ('switching_protocols',),
    102: ('processing',),
    103: ('checkpoint',),
    122: ('uri_too_long', 'request_uri_too_long'),
    200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\o/', '✓'),
    201: ('created',),
    202: ('accepted',),
    203: ('non_authoritative_info', 'non_authoritative_information'),
    204: ('no_content',),
    205: ('reset_content', 'reset'),
    206: ('partial_content', 'partial'),
    207: ('multi_status', 'multiple_status', 'multi_stati', 'multiple_stati'),
    208: ('already_reported',),
    226: ('im_used',),

    # Redirection.
    300: ('multiple_choices',),
    301: ('moved_permanently', 'moved', '\\o-'),
    302: ('found',),
    303: ('see_other', 'other'),
    304: ('not_modified',),
    305: ('use_proxy',),
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/structures.py
# -*- coding: utf-8 -*-

"""
requests.structures
~~~~~~~~~~~~~~~~~~~

Data structures that power Requests.
"""

from collections import OrderedDict

from .compat import Mapping, MutableMapping


class CaseInsensitiveDict(MutableMapping):
    """A case-insensitive ``dict``-like object.

    Implements all methods and operations of
    ``MutableMapping`` as well as dict's ``copy``. Also
    provides ``lower_items``.

    All keys are expected to be strings. The structure remembers the
    case of the last key to be set, and ``iter(instance)``,
    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``
    will contain case-sensitive keys. However, querying and contains
    testing is case insensitive::

        cid = CaseInsensitiveDict()
        cid['Accept'] = 'application/json'
        cid['aCCEPT'] == 'application/json'  # True
        list(cid) == ['Accept']  # True

    For example, ``headers['content-encoding']`` will return the
    value of a ``'Content-Encoding'`` response header, regardless
    of how the header name was originally stored.

    If the constructor, ``.update``, or equality comparison
    operations are given keys that have equal ``.lower()``s, the
    behavior is undefined.
    """

    def __init__(self, data=None, **kwargs):
        self._store = OrderedDict()
        if data is None:
            data = {}
        self.update(data, **kwargs)

    def __setitem__(self, key, value):
        # Use the lowercased key for lookups, but store the actual
        # key alongside the value.
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/utils.py
# -*- coding: utf-8 -*-

"""
requests.utils
~~~~~~~~~~~~~~

This module provides utility functions that are used within Requests
that are also useful for external consumption.
"""

import codecs
import contextlib
import io
import os
import re
import socket
import struct
import sys
import tempfile
import warnings
import zipfile
from collections import OrderedDict
from pip._vendor.urllib3.util import make_headers

from .__version__ import __version__
from . import certs
# to_native_string is unused here, but imported here for backwards compatibility
from ._internal_utils import to_native_string
from .compat import parse_http_list as _parse_list_header
from .compat import (
    quote, urlparse, bytes, str, unquote, getproxies,
    proxy_bypass, urlunparse, basestring, integer_types, is_py3,
    proxy_bypass_environment, getproxies_environment, Mapping)
from .cookies import cookiejar_from_dict
from .structures import CaseInsensitiveDict
from .exceptions import (
    InvalidURL, InvalidHeader, FileModeWarning, UnrewindableBodyError)

NETRC_FILES = ('.netrc', '_netrc')

DEFAULT_CA_BUNDLE_PATH = certs.where()

DEFAULT_PORTS = {'http': 80, 'https': 443}

# Ensure that ', ' is used to preserve previous delimiter behavior.
DEFAULT_ACCEPT_ENCODING = ", ".join(
    re.split(r",\s*", make_headers(accept_encoding=True)["accept-encoding"])
)


FILE: ./venv/Lib/site-packages/pip/_vendor/requests/_internal_utils.py
# -*- coding: utf-8 -*-

"""
requests._internal_utils
~~~~~~~~~~~~~~

Provides utility functions that are consumed internally by Requests
which depend on extremely few external helpers (such as compat)
"""

from .compat import is_py2, builtin_str, str


def to_native_string(string, encoding='ascii'):
    """Given a string object, regardless of type, returns a representation of
    that string in the native string type, encoding and decoding where
    necessary. This assumes ASCII unless told otherwise.
    """
    if isinstance(string, builtin_str):
        out = string
    else:
        if is_py2:
            out = string.encode(encoding)
        else:
            out = string.decode(encoding)

    return out


def unicode_is_ascii(u_string):
    """Determine if unicode string only contains ASCII characters.

    :param str u_string: unicode string to check. Must be unicode
        and not Python 2 `str`.
    :rtype: bool
    """
    assert isinstance(u_string, str)
    try:
        u_string.encode('ascii')
        return True
    except UnicodeEncodeError:
        return False
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/__init__.py
# -*- coding: utf-8 -*-

#   __
#  /__)  _  _     _   _ _/   _
# / (   (- (/ (/ (- _)  /  _)
#          /

"""
Requests HTTP Library
~~~~~~~~~~~~~~~~~~~~~

Requests is an HTTP library, written in Python, for human beings.
Basic GET usage:

   >>> import requests
   >>> r = requests.get('https://www.python.org')
   >>> r.status_code
   200
   >>> b'Python is a programming language' in r.content
   True

... or POST:

   >>> payload = dict(key1='value1', key2='value2')
   >>> r = requests.post('https://httpbin.org/post', data=payload)
   >>> print(r.text)
   {
     ...
     "form": {
       "key1": "value1",
       "key2": "value2"
     },
     ...
   }

The other HTTP methods are supported - see `requests.api`. Full documentation
is at <https://requests.readthedocs.io>.

:copyright: (c) 2017 by Kenneth Reitz.
:license: Apache 2.0, see LICENSE for more details.
"""

from pip._vendor import urllib3
import warnings
from .exceptions import RequestsDependencyWarning

charset_normalizer_version = None

try:
    from pip._vendor.chardet import __version__ as chardet_version
FILE: ./venv/Lib/site-packages/pip/_vendor/requests/__version__.py
# .-. .-. .-. . . .-. .-. .-. .-.
# |(  |-  |.| | | |-  `-.  |  `-.
# ' ' `-' `-`.`-' `-' `-'  '  `-'

__title__ = 'requests'
__description__ = 'Python HTTP for Humans.'
__url__ = 'https://requests.readthedocs.io'
__version__ = '2.26.0'
__build__ = 0x022600
__author__ = 'Kenneth Reitz'
__author_email__ = 'me@kennethreitz.org'
__license__ = 'Apache 2.0'
__copyright__ = 'Copyright 2020 Kenneth Reitz'
__cake__ = u'\u2728 \U0001f370 \u2728'
FILE: ./venv/Lib/site-packages/pip/_vendor/resolvelib/compat/collections_abc.py
__all__ = ["Mapping", "Sequence"]

try:
    from collections.abc import Mapping, Sequence
except ImportError:
    from collections import Mapping, Sequence
FILE: ./venv/Lib/site-packages/pip/_vendor/resolvelib/compat/__init__.py
FILE: ./venv/Lib/site-packages/pip/_vendor/resolvelib/providers.py
class AbstractProvider(object):
    """Delegate class to provide requirement interface for the resolver."""

    def identify(self, requirement_or_candidate):
        """Given a requirement, return an identifier for it.

        This is used to identify a requirement, e.g. whether two requirements
        should have their specifier parts merged.
        """
        raise NotImplementedError

    def get_preference(
        self,
        identifier,
        resolutions,
        candidates,
        information,
        backtrack_causes,
    ):
        """Produce a sort key for given requirement based on preference.

        The preference is defined as "I think this requirement should be
        resolved first". The lower the return value is, the more preferred
        this group of arguments is.

        :param identifier: An identifier as returned by ``identify()``. This
            identifies the dependency matches of which should be returned.
        :param resolutions: Mapping of candidates currently pinned by the
            resolver. Each key is an identifier, and the value a candidate.
            The candidate may conflict with requirements from ``information``.
        :param candidates: Mapping of each dependency's possible candidates.
            Each value is an iterator of candidates.
        :param information: Mapping of requirement information of each package.
            Each value is an iterator of *requirement information*.
        :param backtrack_causes: Sequence of requirement information that were
            the requirements that caused the resolver to most recently backtrack.

        A *requirement information* instance is a named tuple with two members:

        * ``requirement`` specifies a requirement contributing to the current
          list of candidates.
        * ``parent`` specifies the candidate that provides (dependend on) the
          requirement, or ``None`` to indicate a root requirement.

        The preference could depend on a various of issues, including (not
        necessarily in this order):

        * Is this package pinned in the current resolution result?
        * How relaxed is the requirement? Stricter ones should probably be
          worked on first? (I don't know, actually.)
FILE: ./venv/Lib/site-packages/pip/_vendor/resolvelib/reporters.py
class BaseReporter(object):
    """Delegate class to provider progress reporting for the resolver."""

    def starting(self):
        """Called before the resolution actually starts."""

    def starting_round(self, index):
        """Called before each round of resolution starts.

        The index is zero-based.
        """

    def ending_round(self, index, state):
        """Called before each round of resolution ends.

        This is NOT called if the resolution ends at this round. Use `ending`
        if you want to report finalization. The index is zero-based.
        """

    def ending(self, state):
        """Called before the resolution ends successfully."""

    def adding_requirement(self, requirement, parent):
        """Called when adding a new requirement into the resolve criteria.

        :param requirement: The additional requirement to be applied to filter
            the available candidaites.
        :param parent: The candidate that requires ``requirement`` as a
            dependency, or None if ``requirement`` is one of the root
            requirements passed in from ``Resolver.resolve()``.
        """

    def backtracking(self, candidate):
        """Called when rejecting a candidate during backtracking."""

    def pinning(self, candidate):
        """Called when adding a candidate to the potential solution."""
FILE: ./venv/Lib/site-packages/pip/_vendor/resolvelib/resolvers.py
import collections
import operator

from .providers import AbstractResolver
from .structs import DirectedGraph, IteratorMapping, build_iter_view


RequirementInformation = collections.namedtuple(
    "RequirementInformation", ["requirement", "parent"]
)


class ResolverException(Exception):
    """A base class for all exceptions raised by this module.

    Exceptions derived by this class should all be handled in this module. Any
    bubbling pass the resolver should be treated as a bug.
    """


class RequirementsConflicted(ResolverException):
    def __init__(self, criterion):
        super(RequirementsConflicted, self).__init__(criterion)
        self.criterion = criterion

    def __str__(self):
        return "Requirements conflict: {}".format(
            ", ".join(repr(r) for r in self.criterion.iter_requirement()),
        )


class InconsistentCandidate(ResolverException):
    def __init__(self, candidate, criterion):
        super(InconsistentCandidate, self).__init__(candidate, criterion)
        self.candidate = candidate
        self.criterion = criterion

    def __str__(self):
        return "Provided candidate {!r} does not satisfy {}".format(
            self.candidate,
            ", ".join(repr(r) for r in self.criterion.iter_requirement()),
        )


class Criterion(object):
    """Representation of possible resolution results of a package.

    This holds three attributes:

    * `information` is a collection of `RequirementInformation` pairs.
FILE: ./venv/Lib/site-packages/pip/_vendor/resolvelib/structs.py
import itertools

from .compat import collections_abc


class DirectedGraph(object):
    """A graph structure with directed edges."""

    def __init__(self):
        self._vertices = set()
        self._forwards = {}  # <key> -> Set[<key>]
        self._backwards = {}  # <key> -> Set[<key>]

    def __iter__(self):
        return iter(self._vertices)

    def __len__(self):
        return len(self._vertices)

    def __contains__(self, key):
        return key in self._vertices

    def copy(self):
        """Return a shallow copy of this graph."""
        other = DirectedGraph()
        other._vertices = set(self._vertices)
        other._forwards = {k: set(v) for k, v in self._forwards.items()}
        other._backwards = {k: set(v) for k, v in self._backwards.items()}
        return other

    def add(self, key):
        """Add a new vertex to the graph."""
        if key in self._vertices:
            raise ValueError("vertex exists")
        self._vertices.add(key)
        self._forwards[key] = set()
        self._backwards[key] = set()

    def remove(self, key):
        """Remove a vertex from the graph, disconnecting all edges from/to it."""
        self._vertices.remove(key)
        for f in self._forwards.pop(key):
            self._backwards[f].remove(key)
        for t in self._backwards.pop(key):
            self._forwards[t].remove(key)

    def connected(self, f, t):
        return f in self._backwards[t] and t in self._forwards[f]

    def connect(self, f, t):
FILE: ./venv/Lib/site-packages/pip/_vendor/resolvelib/__init__.py
__all__ = [
    "__version__",
    "AbstractProvider",
    "AbstractResolver",
    "BaseReporter",
    "InconsistentCandidate",
    "Resolver",
    "RequirementsConflicted",
    "ResolutionError",
    "ResolutionImpossible",
    "ResolutionTooDeep",
]

__version__ = "0.8.0"


from .providers import AbstractProvider, AbstractResolver
from .reporters import BaseReporter
from .resolvers import (
    InconsistentCandidate,
    RequirementsConflicted,
    Resolver,
    ResolutionError,
    ResolutionImpossible,
    ResolutionTooDeep,
)
FILE: ./venv/Lib/site-packages/pip/_vendor/six.py
# Copyright (c) 2010-2020 Benjamin Peterson
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

"""Utilities for writing code that runs on Python 2 and 3"""

from __future__ import absolute_import

import functools
import itertools
import operator
import sys
import types

__author__ = "Benjamin Peterson <benjamin@python.org>"
__version__ = "1.16.0"


# Useful for very coarse version differentiation.
PY2 = sys.version_info[0] == 2
PY3 = sys.version_info[0] == 3
PY34 = sys.version_info[0:2] >= (3, 4)

if PY3:
    string_types = str,
    integer_types = int,
    class_types = type,
    text_type = str
    binary_type = bytes

    MAXSIZE = sys.maxsize
else:
    string_types = basestring,
    integer_types = (int, long)
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/after.py
# Copyright 2016 Julien Danjou
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import typing

from pip._vendor.tenacity import _utils

if typing.TYPE_CHECKING:
    import logging

    from pip._vendor.tenacity import RetryCallState


def after_nothing(retry_state: "RetryCallState") -> None:
    """After call strategy that does nothing."""


def after_log(
    logger: "logging.Logger",
    log_level: int,
    sec_format: str = "%0.3f",
) -> typing.Callable[["RetryCallState"], None]:
    """After call strategy that logs to some logger the finished attempt."""

    def log_it(retry_state: "RetryCallState") -> None:
        logger.log(
            log_level,
            f"Finished call to '{_utils.get_callback_name(retry_state.fn)}' "
            f"after {sec_format % retry_state.seconds_since_start}(s), "
            f"this was the {_utils.to_ordinal(retry_state.attempt_number)} time calling it.",
        )

    return log_it
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/before.py
# Copyright 2016 Julien Danjou
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import typing

from pip._vendor.tenacity import _utils

if typing.TYPE_CHECKING:
    import logging

    from pip._vendor.tenacity import RetryCallState


def before_nothing(retry_state: "RetryCallState") -> None:
    """Before call strategy that does nothing."""


def before_log(logger: "logging.Logger", log_level: int) -> typing.Callable[["RetryCallState"], None]:
    """Before call strategy that logs to some logger the attempt."""

    def log_it(retry_state: "RetryCallState") -> None:
        logger.log(
            log_level,
            f"Starting call to '{_utils.get_callback_name(retry_state.fn)}', "
            f"this is the {_utils.to_ordinal(retry_state.attempt_number)} time calling it.",
        )

    return log_it
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/before_sleep.py
# Copyright 2016 Julien Danjou
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import typing

from pip._vendor.tenacity import _utils

if typing.TYPE_CHECKING:
    import logging

    from pip._vendor.tenacity import RetryCallState


def before_sleep_nothing(retry_state: "RetryCallState") -> None:
    """Before call strategy that does nothing."""


def before_sleep_log(
    logger: "logging.Logger",
    log_level: int,
    exc_info: bool = False,
) -> typing.Callable[["RetryCallState"], None]:
    """Before call strategy that logs to some logger the attempt."""

    def log_it(retry_state: "RetryCallState") -> None:
        if retry_state.outcome.failed:
            ex = retry_state.outcome.exception()
            verb, value = "raised", f"{ex.__class__.__name__}: {ex}"

            if exc_info:
                local_exc_info = retry_state.outcome.exception()
            else:
                local_exc_info = False
        else:
            verb, value = "returned", retry_state.outcome.result()
            local_exc_info = False  # exc_info does not apply when no exception

FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/nap.py
# Copyright 2016 Étienne Bersac
# Copyright 2016 Julien Danjou
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
import typing

if typing.TYPE_CHECKING:
    import threading


def sleep(seconds: float) -> None:
    """
    Sleep strategy that delays execution for a given number of seconds.

    This is the default strategy, and may be mocked out for unit testing.
    """
    time.sleep(seconds)


class sleep_using_event:
    """Sleep strategy that waits on an event to be set."""

    def __init__(self, event: "threading.Event") -> None:
        self.event = event

    def __call__(self, timeout: typing.Optional[float]) -> None:
        # NOTE(harlowja): this may *not* actually wait for timeout
        # seconds if the event is set (ie this may eject out early).
        self.event.wait(timeout=timeout)
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/retry.py
# Copyright 2016–2021 Julien Danjou
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import abc
import re
import typing

if typing.TYPE_CHECKING:
    from pip._vendor.tenacity import RetryCallState


class retry_base(abc.ABC):
    """Abstract base class for retry strategies."""

    @abc.abstractmethod
    def __call__(self, retry_state: "RetryCallState") -> bool:
        pass

    def __and__(self, other: "retry_base") -> "retry_all":
        return retry_all(self, other)

    def __or__(self, other: "retry_base") -> "retry_any":
        return retry_any(self, other)


class _retry_never(retry_base):
    """Retry strategy that never rejects any result."""

    def __call__(self, retry_state: "RetryCallState") -> bool:
        return False


retry_never = _retry_never()


class _retry_always(retry_base):
    """Retry strategy that always rejects any result."""
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/stop.py
# Copyright 2016–2021 Julien Danjou
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import abc
import typing

if typing.TYPE_CHECKING:
    import threading

    from pip._vendor.tenacity import RetryCallState


class stop_base(abc.ABC):
    """Abstract base class for stop strategies."""

    @abc.abstractmethod
    def __call__(self, retry_state: "RetryCallState") -> bool:
        pass

    def __and__(self, other: "stop_base") -> "stop_all":
        return stop_all(self, other)

    def __or__(self, other: "stop_base") -> "stop_any":
        return stop_any(self, other)


class stop_any(stop_base):
    """Stop if any of the stop condition is valid."""

    def __init__(self, *stops: stop_base) -> None:
        self.stops = stops

    def __call__(self, retry_state: "RetryCallState") -> bool:
        return any(x(retry_state) for x in self.stops)


class stop_all(stop_base):
    """Stop if all the stop conditions are valid."""
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/tornadoweb.py
# Copyright 2017 Elisey Zanko
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
import typing

from pip._vendor.tenacity import BaseRetrying
from pip._vendor.tenacity import DoAttempt
from pip._vendor.tenacity import DoSleep
from pip._vendor.tenacity import RetryCallState

from tornado import gen

if typing.TYPE_CHECKING:
    from tornado.concurrent import Future

_RetValT = typing.TypeVar("_RetValT")


class TornadoRetrying(BaseRetrying):
    def __init__(self, sleep: "typing.Callable[[float], Future[None]]" = gen.sleep, **kwargs: typing.Any) -> None:
        super().__init__(**kwargs)
        self.sleep = sleep

    @gen.coroutine
    def __call__(  # type: ignore  # Change signature from supertype
        self,
        fn: "typing.Callable[..., typing.Union[typing.Generator[typing.Any, typing.Any, _RetValT], Future[_RetValT]]]",
        *args: typing.Any,
        **kwargs: typing.Any,
    ) -> "typing.Generator[typing.Any, typing.Any, _RetValT]":
        self.begin()

        retry_state = RetryCallState(retry_object=self, fn=fn, args=args, kwargs=kwargs)
        while True:
            do = self.iter(retry_state=retry_state)
            if isinstance(do, DoAttempt):
                try:
                    result = yield fn(*args, **kwargs)
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/wait.py
# Copyright 2016–2021 Julien Danjou
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import abc
import random
import typing

from pip._vendor.tenacity import _utils

if typing.TYPE_CHECKING:
    from pip._vendor.tenacity import RetryCallState


class wait_base(abc.ABC):
    """Abstract base class for wait strategies."""

    @abc.abstractmethod
    def __call__(self, retry_state: "RetryCallState") -> float:
        pass

    def __add__(self, other: "wait_base") -> "wait_combine":
        return wait_combine(self, other)

    def __radd__(self, other: "wait_base") -> typing.Union["wait_combine", "wait_base"]:
        # make it possible to use multiple waits with the built-in sum function
        if other == 0:
            return self
        return self.__add__(other)


class wait_fixed(wait_base):
    """Wait strategy that waits a fixed amount of time between each retry."""

    def __init__(self, wait: float) -> None:
        self.wait_fixed = wait

    def __call__(self, retry_state: "RetryCallState") -> float:
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/_asyncio.py
# Copyright 2016 Étienne Bersac
# Copyright 2016 Julien Danjou
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import functools
import sys
import typing
from asyncio import sleep

from pip._vendor.tenacity import AttemptManager
from pip._vendor.tenacity import BaseRetrying
from pip._vendor.tenacity import DoAttempt
from pip._vendor.tenacity import DoSleep
from pip._vendor.tenacity import RetryCallState

WrappedFn = typing.TypeVar("WrappedFn", bound=typing.Callable)
_RetValT = typing.TypeVar("_RetValT")


class AsyncRetrying(BaseRetrying):
    def __init__(self, sleep: typing.Callable[[float], typing.Awaitable] = sleep, **kwargs: typing.Any) -> None:
        super().__init__(**kwargs)
        self.sleep = sleep

    async def __call__(  # type: ignore  # Change signature from supertype
        self,
        fn: typing.Callable[..., typing.Awaitable[_RetValT]],
        *args: typing.Any,
        **kwargs: typing.Any,
    ) -> _RetValT:
        self.begin()

        retry_state = RetryCallState(retry_object=self, fn=fn, args=args, kwargs=kwargs)
        while True:
            do = self.iter(retry_state=retry_state)
            if isinstance(do, DoAttempt):
                try:
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/_utils.py
# Copyright 2016 Julien Danjou
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
import typing


# sys.maxsize:
# An integer giving the maximum value a variable of type Py_ssize_t can take.
MAX_WAIT = sys.maxsize / 2


def find_ordinal(pos_num: int) -> str:
    # See: https://en.wikipedia.org/wiki/English_numerals#Ordinal_numbers
    if pos_num == 0:
        return "th"
    elif pos_num == 1:
        return "st"
    elif pos_num == 2:
        return "nd"
    elif pos_num == 3:
        return "rd"
    elif 4 <= pos_num <= 20:
        return "th"
    else:
        return find_ordinal(pos_num % 10)


def to_ordinal(pos_num: int) -> str:
    return f"{pos_num}{find_ordinal(pos_num)}"


def get_callback_name(cb: typing.Callable[..., typing.Any]) -> str:
    """Get a callback fully-qualified name.

    If no name can be produced ``repr(cb)`` is called and returned.
    """
FILE: ./venv/Lib/site-packages/pip/_vendor/tenacity/__init__.py
# Copyright 2016-2018 Julien Danjou
# Copyright 2017 Elisey Zanko
# Copyright 2016 Étienne Bersac
# Copyright 2016 Joshua Harlow
# Copyright 2013-2014 Ray Holder
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import functools
import sys
import threading
import time
import typing as t
import warnings
from abc import ABC, abstractmethod
from concurrent import futures
from inspect import iscoroutinefunction

# Import all built-in retry strategies for easier usage.
from .retry import retry_base  # noqa
from .retry import retry_all  # noqa
from .retry import retry_always  # noqa
from .retry import retry_any  # noqa
from .retry import retry_if_exception  # noqa
from .retry import retry_if_exception_type  # noqa
from .retry import retry_if_not_exception_type  # noqa
from .retry import retry_if_not_result  # noqa
from .retry import retry_if_result  # noqa
from .retry import retry_never  # noqa
from .retry import retry_unless_exception_type  # noqa
from .retry import retry_if_exception_message  # noqa
from .retry import retry_if_not_exception_message  # noqa

# Import all nap strategies for easier usage.
from .nap import sleep  # noqa
from .nap import sleep_using_event  # noqa

# Import all built-in stop strategies for easier usage.
from .stop import stop_after_attempt  # noqa
from .stop import stop_after_delay  # noqa
FILE: ./venv/Lib/site-packages/pip/_vendor/tomli/_parser.py
import string
from types import MappingProxyType
from typing import (
    TYPE_CHECKING,
    Any,
    Callable,
    Dict,
    FrozenSet,
    Iterable,
    Optional,
    TextIO,
    Tuple,
)

from pip._vendor.tomli._re import (
    RE_BIN,
    RE_DATETIME,
    RE_HEX,
    RE_LOCALTIME,
    RE_NUMBER,
    RE_OCT,
    match_to_datetime,
    match_to_localtime,
    match_to_number,
)

if TYPE_CHECKING:
    from re import Pattern


ASCII_CTRL = frozenset(chr(i) for i in range(32)) | frozenset(chr(127))

# Neither of these sets include quotation mark or backslash. They are
# currently handled as separate cases in the parser functions.
ILLEGAL_BASIC_STR_CHARS = ASCII_CTRL - frozenset("\t")
ILLEGAL_MULTILINE_BASIC_STR_CHARS = ASCII_CTRL - frozenset("\t\n\r")

ILLEGAL_LITERAL_STR_CHARS = ILLEGAL_BASIC_STR_CHARS
ILLEGAL_MULTILINE_LITERAL_STR_CHARS = ASCII_CTRL - frozenset("\t\n")

ILLEGAL_COMMENT_CHARS = ILLEGAL_BASIC_STR_CHARS

TOML_WS = frozenset(" \t")
TOML_WS_AND_NEWLINE = TOML_WS | frozenset("\n")
BARE_KEY_CHARS = frozenset(string.ascii_letters + string.digits + "-_")
KEY_INITIAL_CHARS = BARE_KEY_CHARS | frozenset("\"'")

BASIC_STR_ESCAPE_REPLACEMENTS = MappingProxyType(
    {
        "\\b": "\u0008",  # backspace
FILE: ./venv/Lib/site-packages/pip/_vendor/tomli/_re.py
from datetime import date, datetime, time, timedelta, timezone, tzinfo
import re
from typing import TYPE_CHECKING, Any, Optional, Union

if TYPE_CHECKING:
    from re import Match

    from pip._vendor.tomli._parser import ParseFloat

# E.g.
# - 00:32:00.999999
# - 00:32:00
_TIME_RE_STR = r"([01][0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])(\.[0-9]+)?"

RE_HEX = re.compile(r"[0-9A-Fa-f](?:_?[0-9A-Fa-f])*")
RE_BIN = re.compile(r"[01](?:_?[01])*")
RE_OCT = re.compile(r"[0-7](?:_?[0-7])*")
RE_NUMBER = re.compile(
    r"[+-]?(?:0|[1-9](?:_?[0-9])*)"  # integer
    + r"(?:\.[0-9](?:_?[0-9])*)?"  # optional fractional part
    + r"(?:[eE][+-]?[0-9](?:_?[0-9])*)?"  # optional exponent part
)
RE_LOCALTIME = re.compile(_TIME_RE_STR)
RE_DATETIME = re.compile(
    r"([0-9]{4})-(0[1-9]|1[0-2])-(0[1-9]|1[0-9]|2[0-9]|3[01])"  # date, e.g. 1988-10-27
    + r"(?:"
    + r"[T ]"
    + _TIME_RE_STR
    + r"(?:(Z)|([+-])([01][0-9]|2[0-3]):([0-5][0-9]))?"  # time offset
    + r")?"
)


def match_to_datetime(match: "Match") -> Union[datetime, date]:
    """Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.

    Raises ValueError if the match does not correspond to a valid date
    or datetime.
    """
    (
        year_str,
        month_str,
        day_str,
        hour_str,
        minute_str,
        sec_str,
        micros_str,
        zulu_time,
        offset_dir_str,
        offset_hour_str,
FILE: ./venv/Lib/site-packages/pip/_vendor/tomli/__init__.py
"""A lil' TOML parser."""

__all__ = ("loads", "load", "TOMLDecodeError")
__version__ = "1.0.3"  # DO NOT EDIT THIS LINE MANUALLY. LET bump2version UTILITY DO IT

from pip._vendor.tomli._parser import TOMLDecodeError, load, loads
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/connection.py
from __future__ import absolute_import

import datetime
import logging
import os
import re
import socket
import warnings
from socket import error as SocketError
from socket import timeout as SocketTimeout

from .packages import six
from .packages.six.moves.http_client import HTTPConnection as _HTTPConnection
from .packages.six.moves.http_client import HTTPException  # noqa: F401
from .util.proxy import create_proxy_ssl_context

try:  # Compiled with SSL?
    import ssl

    BaseSSLError = ssl.SSLError
except (ImportError, AttributeError):  # Platform-specific: No SSL.
    ssl = None

    class BaseSSLError(BaseException):
        pass


try:
    # Python 3: not a no-op, we're adding this to the namespace so it can be imported.
    ConnectionError = ConnectionError
except NameError:
    # Python 2
    class ConnectionError(Exception):
        pass


try:  # Python 3:
    # Not a no-op, we're adding this to the namespace so it can be imported.
    BrokenPipeError = BrokenPipeError
except NameError:  # Python 2:

    class BrokenPipeError(Exception):
        pass


from ._collections import HTTPHeaderDict  # noqa (historical, removed in v2)
from ._version import __version__
from .exceptions import (
    ConnectTimeoutError,
    NewConnectionError,
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/connectionpool.py
from __future__ import absolute_import

import errno
import logging
import socket
import sys
import warnings
from socket import error as SocketError
from socket import timeout as SocketTimeout

from .connection import (
    BaseSSLError,
    BrokenPipeError,
    DummyConnection,
    HTTPConnection,
    HTTPException,
    HTTPSConnection,
    VerifiedHTTPSConnection,
    port_by_scheme,
)
from .exceptions import (
    ClosedPoolError,
    EmptyPoolError,
    HeaderParsingError,
    HostChangedError,
    InsecureRequestWarning,
    LocationValueError,
    MaxRetryError,
    NewConnectionError,
    ProtocolError,
    ProxyError,
    ReadTimeoutError,
    SSLError,
    TimeoutError,
)
from .packages import six
from .packages.six.moves import queue
from .packages.ssl_match_hostname import CertificateError
from .request import RequestMethods
from .response import HTTPResponse
from .util.connection import is_connection_dropped
from .util.proxy import connection_requires_http_tunnel
from .util.queue import LifoQueue
from .util.request import set_file_position
from .util.response import assert_header_parsing
from .util.retry import Retry
from .util.timeout import Timeout
from .util.url import Url, _encode_target
from .util.url import _normalize_host as normalize_host
from .util.url import get_host, parse_url
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/appengine.py
"""
This module provides a pool manager that uses Google App Engine's
`URLFetch Service <https://cloud.google.com/appengine/docs/python/urlfetch>`_.

Example usage::

    from pip._vendor.urllib3 import PoolManager
    from pip._vendor.urllib3.contrib.appengine import AppEngineManager, is_appengine_sandbox

    if is_appengine_sandbox():
        # AppEngineManager uses AppEngine's URLFetch API behind the scenes
        http = AppEngineManager()
    else:
        # PoolManager uses a socket-level API behind the scenes
        http = PoolManager()

    r = http.request('GET', 'https://google.com/')

There are `limitations <https://cloud.google.com/appengine/docs/python/\
urlfetch/#Python_Quotas_and_limits>`_ to the URLFetch service and it may not be
the best choice for your application. There are three options for using
urllib3 on Google App Engine:

1. You can use :class:`AppEngineManager` with URLFetch. URLFetch is
   cost-effective in many circumstances as long as your usage is within the
   limitations.
2. You can use a normal :class:`~urllib3.PoolManager` by enabling sockets.
   Sockets also have `limitations and restrictions
   <https://cloud.google.com/appengine/docs/python/sockets/\
   #limitations-and-restrictions>`_ and have a lower free quota than URLFetch.
   To use sockets, be sure to specify the following in your ``app.yaml``::

        env_variables:
            GAE_USE_SOCKETS_HTTPLIB : 'true'

3. If you are using `App Engine Flexible
<https://cloud.google.com/appengine/docs/flexible/>`_, you can use the standard
:class:`PoolManager` without any configuration or special environment variables.
"""

from __future__ import absolute_import

import io
import logging
import warnings

from ..exceptions import (
    HTTPError,
    HTTPWarning,
    MaxRetryError,
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/ntlmpool.py
"""
NTLM authenticating pool, contributed by erikcederstran

Issue #10, see: http://code.google.com/p/urllib3/issues/detail?id=10
"""
from __future__ import absolute_import

import warnings
from logging import getLogger

from ntlm import ntlm

from .. import HTTPSConnectionPool
from ..packages.six.moves.http_client import HTTPSConnection

warnings.warn(
    "The 'urllib3.contrib.ntlmpool' module is deprecated and will be removed "
    "in urllib3 v2.0 release, urllib3 is not able to support it properly due "
    "to reasons listed in issue: https://github.com/urllib3/urllib3/issues/2282. "
    "If you are a user of this module please comment in the mentioned issue.",
    DeprecationWarning,
)

log = getLogger(__name__)


class NTLMConnectionPool(HTTPSConnectionPool):
    """
    Implements an NTLM authentication version of an urllib3 connection pool
    """

    scheme = "https"

    def __init__(self, user, pw, authurl, *args, **kwargs):
        """
        authurl is a random URL on the server that is protected by NTLM.
        user is the Windows user, probably in the DOMAIN\\username format.
        pw is the password for the user.
        """
        super(NTLMConnectionPool, self).__init__(*args, **kwargs)
        self.authurl = authurl
        self.rawuser = user
        user_parts = user.split("\\", 1)
        self.domain = user_parts[0].upper()
        self.user = user_parts[1]
        self.pw = pw

    def _new_conn(self):
        # Performs the NTLM handshake that secures the connection. The socket
        # must be kept open while requests are performed.
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py
"""
TLS with SNI_-support for Python 2. Follow these instructions if you would
like to verify TLS certificates in Python 2. Note, the default libraries do
*not* do certificate checking; you need to do additional work to validate
certificates yourself.

This needs the following packages installed:

* `pyOpenSSL`_ (tested with 16.0.0)
* `cryptography`_ (minimum 1.3.4, from pyopenssl)
* `idna`_ (minimum 2.0, from cryptography)

However, pyopenssl depends on cryptography, which depends on idna, so while we
use all three directly here we end up having relatively few packages required.

You can install them with the following command:

.. code-block:: bash

    $ python -m pip install pyopenssl cryptography idna

To activate certificate checking, call
:func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code
before you begin making HTTP requests. This can be done in a ``sitecustomize``
module, or at any other time before your application begins using ``urllib3``,
like this:

.. code-block:: python

    try:
        import pip._vendor.urllib3.contrib.pyopenssl as pyopenssl
        pyopenssl.inject_into_urllib3()
    except ImportError:
        pass

Now you can use :mod:`urllib3` as you normally would, and it will support SNI
when the required modules are installed.

Activating this module also has the positive side effect of disabling SSL/TLS
compression in Python 2 (see `CRIME attack`_).

.. _sni: https://en.wikipedia.org/wiki/Server_Name_Indication
.. _crime attack: https://en.wikipedia.org/wiki/CRIME_(security_exploit)
.. _pyopenssl: https://www.pyopenssl.org
.. _cryptography: https://cryptography.io
.. _idna: https://github.com/kjd/idna
"""
from __future__ import absolute_import

import OpenSSL.SSL
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/securetransport.py
"""
SecureTranport support for urllib3 via ctypes.

This makes platform-native TLS available to urllib3 users on macOS without the
use of a compiler. This is an important feature because the Python Package
Index is moving to become a TLSv1.2-or-higher server, and the default OpenSSL
that ships with macOS is not capable of doing TLSv1.2. The only way to resolve
this is to give macOS users an alternative solution to the problem, and that
solution is to use SecureTransport.

We use ctypes here because this solution must not require a compiler. That's
because pip is not allowed to require a compiler either.

This is not intended to be a seriously long-term solution to this problem.
The hope is that PEP 543 will eventually solve this issue for us, at which
point we can retire this contrib module. But in the short term, we need to
solve the impending tire fire that is Python on Mac without this kind of
contrib module. So...here we are.

To use this module, simply import and inject it::

    import pip._vendor.urllib3.contrib.securetransport as securetransport
    securetransport.inject_into_urllib3()

Happy TLSing!

This code is a bastardised version of the code found in Will Bond's oscrypto
library. An enormous debt is owed to him for blazing this trail for us. For
that reason, this code should be considered to be covered both by urllib3's
license and by oscrypto's:

.. code-block::

    Copyright (c) 2015-2016 Will Bond <will@wbond.net>

    Permission is hereby granted, free of charge, to any person obtaining a
    copy of this software and associated documentation files (the "Software"),
    to deal in the Software without restriction, including without limitation
    the rights to use, copy, modify, merge, publish, distribute, sublicense,
    and/or sell copies of the Software, and to permit persons to whom the
    Software is furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in
    all copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/socks.py
# -*- coding: utf-8 -*-
"""
This module contains provisional support for SOCKS proxies from within
urllib3. This module supports SOCKS4, SOCKS4A (an extension of SOCKS4), and
SOCKS5. To enable its functionality, either install PySocks or install this
module with the ``socks`` extra.

The SOCKS implementation supports the full range of urllib3 features. It also
supports the following SOCKS features:

- SOCKS4A (``proxy_url='socks4a://...``)
- SOCKS4 (``proxy_url='socks4://...``)
- SOCKS5 with remote DNS (``proxy_url='socks5h://...``)
- SOCKS5 with local DNS (``proxy_url='socks5://...``)
- Usernames and passwords for the SOCKS proxy

.. note::
   It is recommended to use ``socks5h://`` or ``socks4a://`` schemes in
   your ``proxy_url`` to ensure that DNS resolution is done from the remote
   server instead of client-side when connecting to a domain name.

SOCKS4 supports IPv4 and domain names with the SOCKS4A extension. SOCKS5
supports IPv4, IPv6, and domain names.

When connecting to a SOCKS4 proxy the ``username`` portion of the ``proxy_url``
will be sent as the ``userid`` section of the SOCKS request:

.. code-block:: python

    proxy_url="socks4a://<userid>@proxy-host"

When connecting to a SOCKS5 proxy the ``username`` and ``password`` portion
of the ``proxy_url`` will be sent as the username/password to authenticate
with the proxy:

.. code-block:: python

    proxy_url="socks5h://<username>:<password>@proxy-host"

"""
from __future__ import absolute_import

try:
    import socks
except ImportError:
    import warnings

    from ..exceptions import DependencyWarning

    warnings.warn(
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/_appengine_environ.py
"""
This module provides means to detect the App Engine environment.
"""

import os


def is_appengine():
    return is_local_appengine() or is_prod_appengine()


def is_appengine_sandbox():
    """Reports if the app is running in the first generation sandbox.

    The second generation runtimes are technically still in a sandbox, but it
    is much less restrictive, so generally you shouldn't need to check for it.
    see https://cloud.google.com/appengine/docs/standard/runtimes
    """
    return is_appengine() and os.environ["APPENGINE_RUNTIME"] == "python27"


def is_local_appengine():
    return "APPENGINE_RUNTIME" in os.environ and os.environ.get(
        "SERVER_SOFTWARE", ""
    ).startswith("Development/")


def is_prod_appengine():
    return "APPENGINE_RUNTIME" in os.environ and os.environ.get(
        "SERVER_SOFTWARE", ""
    ).startswith("Google App Engine/")


def is_prod_appengine_mvms():
    """Deprecated."""
    return False
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/_securetransport/bindings.py
"""
This module uses ctypes to bind a whole bunch of functions and constants from
SecureTransport. The goal here is to provide the low-level API to
SecureTransport. These are essentially the C-level functions and constants, and
they're pretty gross to work with.

This code is a bastardised version of the code found in Will Bond's oscrypto
library. An enormous debt is owed to him for blazing this trail for us. For
that reason, this code should be considered to be covered both by urllib3's
license and by oscrypto's:

    Copyright (c) 2015-2016 Will Bond <will@wbond.net>

    Permission is hereby granted, free of charge, to any person obtaining a
    copy of this software and associated documentation files (the "Software"),
    to deal in the Software without restriction, including without limitation
    the rights to use, copy, modify, merge, publish, distribute, sublicense,
    and/or sell copies of the Software, and to permit persons to whom the
    Software is furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in
    all copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
    DEALINGS IN THE SOFTWARE.
"""
from __future__ import absolute_import

import platform
from ctypes import (
    CDLL,
    CFUNCTYPE,
    POINTER,
    c_bool,
    c_byte,
    c_char_p,
    c_int32,
    c_long,
    c_size_t,
    c_uint32,
    c_ulong,
    c_void_p,
)
from ctypes.util import find_library

FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py
"""
Low-level helpers for the SecureTransport bindings.

These are Python functions that are not directly related to the high-level APIs
but are necessary to get them to work. They include a whole bunch of low-level
CoreFoundation messing about and memory management. The concerns in this module
are almost entirely about trying to avoid memory leaks and providing
appropriate and useful assistance to the higher-level code.
"""
import base64
import ctypes
import itertools
import os
import re
import ssl
import struct
import tempfile

from .bindings import CFConst, CoreFoundation, Security

# This regular expression is used to grab PEM data out of a PEM bundle.
_PEM_CERTS_RE = re.compile(
    b"-----BEGIN CERTIFICATE-----\n(.*?)\n-----END CERTIFICATE-----", re.DOTALL
)


def _cf_data_from_bytes(bytestring):
    """
    Given a bytestring, create a CFData object from it. This CFData object must
    be CFReleased by the caller.
    """
    return CoreFoundation.CFDataCreate(
        CoreFoundation.kCFAllocatorDefault, bytestring, len(bytestring)
    )


def _cf_dictionary_from_tuples(tuples):
    """
    Given a list of Python tuples, create an associated CFDictionary.
    """
    dictionary_size = len(tuples)

    # We need to get the dictionary keys and values out in the same order.
    keys = (t[0] for t in tuples)
    values = (t[1] for t in tuples)
    cf_keys = (CoreFoundation.CFTypeRef * dictionary_size)(*keys)
    cf_values = (CoreFoundation.CFTypeRef * dictionary_size)(*values)

    return CoreFoundation.CFDictionaryCreate(
        CoreFoundation.kCFAllocatorDefault,
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/_securetransport/__init__.py
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/__init__.py
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/exceptions.py
from __future__ import absolute_import

from .packages.six.moves.http_client import IncompleteRead as httplib_IncompleteRead

# Base Exceptions


class HTTPError(Exception):
    """Base exception used by this module."""

    pass


class HTTPWarning(Warning):
    """Base warning used by this module."""

    pass


class PoolError(HTTPError):
    """Base exception for errors caused within a pool."""

    def __init__(self, pool, message):
        self.pool = pool
        HTTPError.__init__(self, "%s: %s" % (pool, message))

    def __reduce__(self):
        # For pickling purposes.
        return self.__class__, (None, None)


class RequestError(PoolError):
    """Base exception for PoolErrors that have associated URLs."""

    def __init__(self, pool, url, message):
        self.url = url
        PoolError.__init__(self, pool, message)

    def __reduce__(self):
        # For pickling purposes.
        return self.__class__, (None, self.url, None)


class SSLError(HTTPError):
    """Raised when SSL certificate fails in an HTTPS connection."""

    pass


class ProxyError(HTTPError):
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/fields.py
from __future__ import absolute_import

import email.utils
import mimetypes
import re

from .packages import six


def guess_content_type(filename, default="application/octet-stream"):
    """
    Guess the "Content-Type" of a file.

    :param filename:
        The filename to guess the "Content-Type" of using :mod:`mimetypes`.
    :param default:
        If no "Content-Type" can be guessed, default to `default`.
    """
    if filename:
        return mimetypes.guess_type(filename)[0] or default
    return default


def format_header_param_rfc2231(name, value):
    """
    Helper function to format and quote a single header parameter using the
    strategy defined in RFC 2231.

    Particularly useful for header parameters which might contain
    non-ASCII values, like file names. This follows
    `RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.

    :param name:
        The name of the parameter, a string expected to be ASCII only.
    :param value:
        The value of the parameter, provided as ``bytes`` or `str``.
    :ret:
        An RFC-2231-formatted unicode string.
    """
    if isinstance(value, six.binary_type):
        value = value.decode("utf-8")

    if not any(ch in value for ch in '"\\\r\n'):
        result = u'%s="%s"' % (name, value)
        try:
            result.encode("ascii")
        except (UnicodeEncodeError, UnicodeDecodeError):
            pass
        else:
            return result
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/filepost.py
from __future__ import absolute_import

import binascii
import codecs
import os
from io import BytesIO

from .fields import RequestField
from .packages import six
from .packages.six import b

writer = codecs.lookup("utf-8")[3]


def choose_boundary():
    """
    Our embarrassingly-simple replacement for mimetools.choose_boundary.
    """
    boundary = binascii.hexlify(os.urandom(16))
    if not six.PY2:
        boundary = boundary.decode("ascii")
    return boundary


def iter_field_objects(fields):
    """
    Iterate over fields.

    Supports list of (k, v) tuples and dicts, and lists of
    :class:`~urllib3.fields.RequestField`.

    """
    if isinstance(fields, dict):
        i = six.iteritems(fields)
    else:
        i = iter(fields)

    for field in i:
        if isinstance(field, RequestField):
            yield field
        else:
            yield RequestField.from_tuples(*field)


def iter_fields(fields):
    """
    .. deprecated:: 1.6

    Iterate over fields.

FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/packages/backports/makefile.py
# -*- coding: utf-8 -*-
"""
backports.makefile
~~~~~~~~~~~~~~~~~~

Backports the Python 3 ``socket.makefile`` method for use with anything that
wants to create a "fake" socket object.
"""
import io
from socket import SocketIO


def backport_makefile(
    self, mode="r", buffering=None, encoding=None, errors=None, newline=None
):
    """
    Backport of ``socket.makefile`` from Python 3.5.
    """
    if not set(mode) <= {"r", "w", "b"}:
        raise ValueError("invalid mode %r (only r, w, b allowed)" % (mode,))
    writing = "w" in mode
    reading = "r" in mode or not writing
    assert reading or writing
    binary = "b" in mode
    rawmode = ""
    if reading:
        rawmode += "r"
    if writing:
        rawmode += "w"
    raw = SocketIO(self, rawmode)
    self._makefile_refs += 1
    if buffering is None:
        buffering = -1
    if buffering < 0:
        buffering = io.DEFAULT_BUFFER_SIZE
    if buffering == 0:
        if not binary:
            raise ValueError("unbuffered streams must be binary")
        return raw
    if reading and writing:
        buffer = io.BufferedRWPair(raw, raw, buffering)
    elif reading:
        buffer = io.BufferedReader(raw, buffering)
    else:
        assert writing
        buffer = io.BufferedWriter(raw, buffering)
    if binary:
        return buffer
    text = io.TextIOWrapper(buffer, encoding, errors, newline)
    text.mode = mode
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/packages/backports/__init__.py
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/packages/six.py
# Copyright (c) 2010-2020 Benjamin Peterson
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

"""Utilities for writing code that runs on Python 2 and 3"""

from __future__ import absolute_import

import functools
import itertools
import operator
import sys
import types

__author__ = "Benjamin Peterson <benjamin@python.org>"
__version__ = "1.16.0"


# Useful for very coarse version differentiation.
PY2 = sys.version_info[0] == 2
PY3 = sys.version_info[0] == 3
PY34 = sys.version_info[0:2] >= (3, 4)

if PY3:
    string_types = (str,)
    integer_types = (int,)
    class_types = (type,)
    text_type = str
    binary_type = bytes

    MAXSIZE = sys.maxsize
else:
    string_types = (basestring,)
    integer_types = (int, long)
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/packages/ssl_match_hostname/_implementation.py
"""The match_hostname() function from Python 3.3.3, essential when using SSL."""

# Note: This file is under the PSF license as the code comes from the python
# stdlib.   http://docs.python.org/3/license.html

import re
import sys

# ipaddress has been backported to 2.6+ in pypi.  If it is installed on the
# system, use it to handle IPAddress ServerAltnames (this was added in
# python-3.5) otherwise only do DNS matching.  This allows
# backports.ssl_match_hostname to continue to be used in Python 2.7.
try:
    import ipaddress
except ImportError:
    ipaddress = None

__version__ = "3.5.0.1"


class CertificateError(ValueError):
    pass


def _dnsname_match(dn, hostname, max_wildcards=1):
    """Matching according to RFC 6125, section 6.4.3

    http://tools.ietf.org/html/rfc6125#section-6.4.3
    """
    pats = []
    if not dn:
        return False

    # Ported from python3-syntax:
    # leftmost, *remainder = dn.split(r'.')
    parts = dn.split(r".")
    leftmost = parts[0]
    remainder = parts[1:]

    wildcards = leftmost.count("*")
    if wildcards > max_wildcards:
        # Issue #17980: avoid denials of service by refusing more
        # than one wildcard per fragment.  A survey of established
        # policy among SSL implementations showed it to be a
        # reasonable choice.
        raise CertificateError(
            "too many wildcards in certificate DNS name: " + repr(dn)
        )

    # speed up common case w/o wildcards
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/packages/ssl_match_hostname/__init__.py
import sys

try:
    # Our match_hostname function is the same as 3.10's, so we only want to
    # import the match_hostname function if it's at least that good.
    # We also fallback on Python 3.10+ because our code doesn't emit
    # deprecation warnings and is the same as Python 3.10 otherwise.
    if sys.version_info < (3, 5) or sys.version_info >= (3, 10):
        raise ImportError("Fallback to vendored code")

    from ssl import CertificateError, match_hostname
except ImportError:
    try:
        # Backport of the function from a pypi module
        from backports.ssl_match_hostname import (  # type: ignore
            CertificateError,
            match_hostname,
        )
    except ImportError:
        # Our vendored copy
        from ._implementation import CertificateError, match_hostname  # type: ignore

# Not needed, but documenting what we provide.
__all__ = ("CertificateError", "match_hostname")
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/packages/__init__.py
from __future__ import absolute_import

from . import ssl_match_hostname

__all__ = ("ssl_match_hostname",)
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/poolmanager.py
from __future__ import absolute_import

import collections
import functools
import logging

from ._collections import RecentlyUsedContainer
from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, port_by_scheme
from .exceptions import (
    LocationValueError,
    MaxRetryError,
    ProxySchemeUnknown,
    ProxySchemeUnsupported,
    URLSchemeUnknown,
)
from .packages import six
from .packages.six.moves.urllib.parse import urljoin
from .request import RequestMethods
from .util.proxy import connection_requires_http_tunnel
from .util.retry import Retry
from .util.url import parse_url

__all__ = ["PoolManager", "ProxyManager", "proxy_from_url"]


log = logging.getLogger(__name__)

SSL_KEYWORDS = (
    "key_file",
    "cert_file",
    "cert_reqs",
    "ca_certs",
    "ssl_version",
    "ca_cert_dir",
    "ssl_context",
    "key_password",
)

# All known keyword arguments that could be provided to the pool manager, its
# pools, or the underlying connections. This is used to construct a pool key.
_key_fields = (
    "key_scheme",  # str
    "key_host",  # str
    "key_port",  # int
    "key_timeout",  # int or float or Timeout
    "key_retries",  # int or Retry
    "key_strict",  # bool
    "key_block",  # bool
    "key_source_address",  # str
    "key_key_file",  # str
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/request.py
from __future__ import absolute_import

from .filepost import encode_multipart_formdata
from .packages.six.moves.urllib.parse import urlencode

__all__ = ["RequestMethods"]


class RequestMethods(object):
    """
    Convenience mixin for classes who implement a :meth:`urlopen` method, such
    as :class:`urllib3.HTTPConnectionPool` and
    :class:`urllib3.PoolManager`.

    Provides behavior for making common types of HTTP request methods and
    decides which type of request field encoding to use.

    Specifically,

    :meth:`.request_encode_url` is for sending requests whose fields are
    encoded in the URL (such as GET, HEAD, DELETE).

    :meth:`.request_encode_body` is for sending requests whose fields are
    encoded in the *body* of the request using multipart or www-form-urlencoded
    (such as for POST, PUT, PATCH).

    :meth:`.request` is for making any kind of request, it will look up the
    appropriate encoding format and use one of the above two methods to make
    the request.

    Initializer parameters:

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.
    """

    _encode_url_methods = {"DELETE", "GET", "HEAD", "OPTIONS"}

    def __init__(self, headers=None):
        self.headers = headers or {}

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        encode_multipart=True,
        multipart_boundary=None,
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/response.py
from __future__ import absolute_import

import io
import logging
import zlib
from contextlib import contextmanager
from socket import error as SocketError
from socket import timeout as SocketTimeout

try:
    import brotli
except ImportError:
    brotli = None

from ._collections import HTTPHeaderDict
from .connection import BaseSSLError, HTTPException
from .exceptions import (
    BodyNotHttplibCompatible,
    DecodeError,
    HTTPError,
    IncompleteRead,
    InvalidChunkLength,
    InvalidHeader,
    ProtocolError,
    ReadTimeoutError,
    ResponseNotChunked,
    SSLError,
)
from .packages import six
from .util.response import is_fp_closed, is_response_to_head

log = logging.getLogger(__name__)


class DeflateDecoder(object):
    def __init__(self):
        self._first_try = True
        self._data = b""
        self._obj = zlib.decompressobj()

    def __getattr__(self, name):
        return getattr(self._obj, name)

    def decompress(self, data):
        if not data:
            return data

        if not self._first_try:
            return self._obj.decompress(data)

FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/connection.py
from __future__ import absolute_import

import socket

from pip._vendor.urllib3.exceptions import LocationParseError

from ..contrib import _appengine_environ
from ..packages import six
from .wait import NoWayToWaitForSocketError, wait_for_read


def is_connection_dropped(conn):  # Platform-specific
    """
    Returns True if the connection is dropped and should be closed.

    :param conn:
        :class:`http.client.HTTPConnection` object.

    Note: For platforms like AppEngine, this will always return ``False`` to
    let the platform handle connection recycling transparently for us.
    """
    sock = getattr(conn, "sock", False)
    if sock is False:  # Platform-specific: AppEngine
        return False
    if sock is None:  # Connection already closed (such as by httplib).
        return True
    try:
        # Returns True if readable, which here means it's been dropped
        return wait_for_read(sock, timeout=0.0)
    except NoWayToWaitForSocketError:  # Platform-specific: AppEngine
        return False


# This function is copied from socket.py in the Python 2.7 standard
# library test suite. Added to its signature is only `socket_options`.
# One additional modification is that we avoid binding to IPv6 servers
# discovered in DNS if the system doesn't have IPv6 functionality.
def create_connection(
    address,
    timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
    source_address=None,
    socket_options=None,
):
    """Connect to *address* and return the socket object.

    Convenience function.  Connect to *address* (a 2-tuple ``(host,
    port)``) and return the socket object.  Passing the optional
    *timeout* parameter will set the timeout on the socket instance
    before attempting to connect.  If no *timeout* is supplied, the
    global default timeout setting returned by :func:`socket.getdefaulttimeout`
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/proxy.py
from .ssl_ import create_urllib3_context, resolve_cert_reqs, resolve_ssl_version


def connection_requires_http_tunnel(
    proxy_url=None, proxy_config=None, destination_scheme=None
):
    """
    Returns True if the connection requires an HTTP CONNECT through the proxy.

    :param URL proxy_url:
        URL of the proxy.
    :param ProxyConfig proxy_config:
        Proxy configuration from poolmanager.py
    :param str destination_scheme:
        The scheme of the destination. (i.e https, http, etc)
    """
    # If we're not using a proxy, no way to use a tunnel.
    if proxy_url is None:
        return False

    # HTTP destinations never require tunneling, we always forward.
    if destination_scheme == "http":
        return False

    # Support for forwarding with HTTPS proxies and HTTPS destinations.
    if (
        proxy_url.scheme == "https"
        and proxy_config
        and proxy_config.use_forwarding_for_https
    ):
        return False

    # Otherwise always use a tunnel.
    return True


def create_proxy_ssl_context(
    ssl_version, cert_reqs, ca_certs=None, ca_cert_dir=None, ca_cert_data=None
):
    """
    Generates a default proxy ssl context if one hasn't been provided by the
    user.
    """
    ssl_context = create_urllib3_context(
        ssl_version=resolve_ssl_version(ssl_version),
        cert_reqs=resolve_cert_reqs(cert_reqs),
    )

    if (
        not ca_certs
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/queue.py
import collections

from ..packages import six
from ..packages.six.moves import queue

if six.PY2:
    # Queue is imported for side effects on MS Windows. See issue #229.
    import Queue as _unused_module_Queue  # noqa: F401


class LifoQueue(queue.Queue):
    def _init(self, _):
        self.queue = collections.deque()

    def _qsize(self, len=len):
        return len(self.queue)

    def _put(self, item):
        self.queue.append(item)

    def _get(self):
        return self.queue.pop()
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/request.py
from __future__ import absolute_import

from base64 import b64encode

from ..exceptions import UnrewindableBodyError
from ..packages.six import b, integer_types

# Pass as a value within ``headers`` to skip
# emitting some HTTP headers that are added automatically.
# The only headers that are supported are ``Accept-Encoding``,
# ``Host``, and ``User-Agent``.
SKIP_HEADER = "@@@SKIP_HEADER@@@"
SKIPPABLE_HEADERS = frozenset(["accept-encoding", "host", "user-agent"])

ACCEPT_ENCODING = "gzip,deflate"
try:
    import brotli as _unused_module_brotli  # noqa: F401
except ImportError:
    pass
else:
    ACCEPT_ENCODING += ",br"

_FAILEDTELL = object()


def make_headers(
    keep_alive=None,
    accept_encoding=None,
    user_agent=None,
    basic_auth=None,
    proxy_basic_auth=None,
    disable_cache=None,
):
    """
    Shortcuts for generating request headers.

    :param keep_alive:
        If ``True``, adds 'connection: keep-alive' header.

    :param accept_encoding:
        Can be a boolean, list, or string.
        ``True`` translates to 'gzip,deflate'.
        List will get joined by comma.
        String will be used as provided.

    :param user_agent:
        String representing the user-agent you want, such as
        "python-urllib3/0.6"

    :param basic_auth:
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/response.py
from __future__ import absolute_import

from email.errors import MultipartInvariantViolationDefect, StartBoundaryNotFoundDefect

from ..exceptions import HeaderParsingError
from ..packages.six.moves import http_client as httplib


def is_fp_closed(obj):
    """
    Checks whether a given file-like object is closed.

    :param obj:
        The file-like object to check.
    """

    try:
        # Check `isclosed()` first, in case Python3 doesn't set `closed`.
        # GH Issue #928
        return obj.isclosed()
    except AttributeError:
        pass

    try:
        # Check via the official file-like-object way.
        return obj.closed
    except AttributeError:
        pass

    try:
        # Check if the object is a container for another file-like object that
        # gets released on exhaustion (e.g. HTTPResponse).
        return obj.fp is None
    except AttributeError:
        pass

    raise ValueError("Unable to determine whether fp is closed.")


def assert_header_parsing(headers):
    """
    Asserts whether all headers have been successfully parsed.
    Extracts encountered errors from the result of parsing headers.

    Only works on Python 3.

    :param http.client.HTTPMessage headers: Headers to verify.

    :raises urllib3.exceptions.HeaderParsingError:
        If parsing errors are found.
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/retry.py
from __future__ import absolute_import

import email
import logging
import re
import time
import warnings
from collections import namedtuple
from itertools import takewhile

from ..exceptions import (
    ConnectTimeoutError,
    InvalidHeader,
    MaxRetryError,
    ProtocolError,
    ProxyError,
    ReadTimeoutError,
    ResponseError,
)
from ..packages import six

log = logging.getLogger(__name__)


# Data structure for representing the metadata of requests that result in a retry.
RequestHistory = namedtuple(
    "RequestHistory", ["method", "url", "error", "status", "redirect_location"]
)


# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
_Default = object()


class _RetryMeta(type):
    @property
    def DEFAULT_METHOD_WHITELIST(cls):
        warnings.warn(
            "Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and "
            "will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead",
            DeprecationWarning,
        )
        return cls.DEFAULT_ALLOWED_METHODS

    @DEFAULT_METHOD_WHITELIST.setter
    def DEFAULT_METHOD_WHITELIST(cls, value):
        warnings.warn(
            "Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and "
            "will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead",
            DeprecationWarning,
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/ssltransport.py
import io
import socket
import ssl

from pip._vendor.urllib3.exceptions import ProxySchemeUnsupported
from pip._vendor.urllib3.packages import six

SSL_BLOCKSIZE = 16384


class SSLTransport:
    """
    The SSLTransport wraps an existing socket and establishes an SSL connection.

    Contrary to Python's implementation of SSLSocket, it allows you to chain
    multiple TLS connections together. It's particularly useful if you need to
    implement TLS within TLS.

    The class supports most of the socket API operations.
    """

    @staticmethod
    def _validate_ssl_context_for_tls_in_tls(ssl_context):
        """
        Raises a ProxySchemeUnsupported if the provided ssl_context can't be used
        for TLS in TLS.

        The only requirement is that the ssl_context provides the 'wrap_bio'
        methods.
        """

        if not hasattr(ssl_context, "wrap_bio"):
            if six.PY2:
                raise ProxySchemeUnsupported(
                    "TLS in TLS requires SSLContext.wrap_bio() which isn't "
                    "supported on Python 2"
                )
            else:
                raise ProxySchemeUnsupported(
                    "TLS in TLS requires SSLContext.wrap_bio() which isn't "
                    "available on non-native SSLContext"
                )

    def __init__(
        self, socket, ssl_context, server_hostname=None, suppress_ragged_eofs=True
    ):
        """
        Create an SSLTransport around socket using the provided ssl_context.
        """
        self.incoming = ssl.MemoryBIO()
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/ssl_.py
from __future__ import absolute_import

import hmac
import os
import sys
import warnings
from binascii import hexlify, unhexlify
from hashlib import md5, sha1, sha256

from ..exceptions import (
    InsecurePlatformWarning,
    ProxySchemeUnsupported,
    SNIMissingWarning,
    SSLError,
)
from ..packages import six
from .url import BRACELESS_IPV6_ADDRZ_RE, IPV4_RE

SSLContext = None
SSLTransport = None
HAS_SNI = False
IS_PYOPENSSL = False
IS_SECURETRANSPORT = False
ALPN_PROTOCOLS = ["http/1.1"]

# Maps the length of a digest to a possible hash function producing this digest
HASHFUNC_MAP = {32: md5, 40: sha1, 64: sha256}


def _const_compare_digest_backport(a, b):
    """
    Compare two digests of equal length in constant time.

    The digests must be of type str/bytes.
    Returns True if the digests match, and False otherwise.
    """
    result = abs(len(a) - len(b))
    for left, right in zip(bytearray(a), bytearray(b)):
        result |= left ^ right
    return result == 0


_const_compare_digest = getattr(hmac, "compare_digest", _const_compare_digest_backport)

try:  # Test for SSL features
    import ssl
    from ssl import CERT_REQUIRED, wrap_socket
except ImportError:
    pass

FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/timeout.py
from __future__ import absolute_import

import time

# The default socket timeout, used by httplib to indicate that no timeout was
# specified by the user
from socket import _GLOBAL_DEFAULT_TIMEOUT

from ..exceptions import TimeoutStateError

# A sentinel value to indicate that no timeout was specified by the user in
# urllib3
_Default = object()


# Use time.monotonic if available.
current_time = getattr(time, "monotonic", time.time)


class Timeout(object):
    """Timeout configuration.

    Timeouts can be defined as a default for a pool:

    .. code-block:: python

       timeout = Timeout(connect=2.0, read=7.0)
       http = PoolManager(timeout=timeout)
       response = http.request('GET', 'http://example.com/')

    Or per-request (which overrides the default for the pool):

    .. code-block:: python

       response = http.request('GET', 'http://example.com/', timeout=Timeout(10))

    Timeouts can be disabled by setting all the parameters to ``None``:

    .. code-block:: python

       no_timeout = Timeout(connect=None, read=None)
       response = http.request('GET', 'http://example.com/, timeout=no_timeout)


    :param total:
        This combines the connect and read timeouts into one; the read timeout
        will be set to the time leftover from the connect attempt. In the
        event that both a connect timeout and a total are specified, or a read
        timeout and a total are specified, the shorter timeout will be applied.

FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/url.py
from __future__ import absolute_import

import re
from collections import namedtuple

from ..exceptions import LocationParseError
from ..packages import six

url_attrs = ["scheme", "auth", "host", "port", "path", "query", "fragment"]

# We only want to normalize urls with an HTTP(S) scheme.
# urllib3 infers URLs without a scheme (None) to be http.
NORMALIZABLE_SCHEMES = ("http", "https", None)

# Almost all of these patterns were derived from the
# 'rfc3986' module: https://github.com/python-hyper/rfc3986
PERCENT_RE = re.compile(r"%[a-fA-F0-9]{2}")
SCHEME_RE = re.compile(r"^(?:[a-zA-Z][a-zA-Z0-9+-]*:|/)")
URI_RE = re.compile(
    r"^(?:([a-zA-Z][a-zA-Z0-9+.-]*):)?"
    r"(?://([^\\/?#]*))?"
    r"([^?#]*)"
    r"(?:\?([^#]*))?"
    r"(?:#(.*))?$",
    re.UNICODE | re.DOTALL,
)

IPV4_PAT = r"(?:[0-9]{1,3}\.){3}[0-9]{1,3}"
HEX_PAT = "[0-9A-Fa-f]{1,4}"
LS32_PAT = "(?:{hex}:{hex}|{ipv4})".format(hex=HEX_PAT, ipv4=IPV4_PAT)
_subs = {"hex": HEX_PAT, "ls32": LS32_PAT}
_variations = [
    #                            6( h16 ":" ) ls32
    "(?:%(hex)s:){6}%(ls32)s",
    #                       "::" 5( h16 ":" ) ls32
    "::(?:%(hex)s:){5}%(ls32)s",
    # [               h16 ] "::" 4( h16 ":" ) ls32
    "(?:%(hex)s)?::(?:%(hex)s:){4}%(ls32)s",
    # [ *1( h16 ":" ) h16 ] "::" 3( h16 ":" ) ls32
    "(?:(?:%(hex)s:)?%(hex)s)?::(?:%(hex)s:){3}%(ls32)s",
    # [ *2( h16 ":" ) h16 ] "::" 2( h16 ":" ) ls32
    "(?:(?:%(hex)s:){0,2}%(hex)s)?::(?:%(hex)s:){2}%(ls32)s",
    # [ *3( h16 ":" ) h16 ] "::"    h16 ":"   ls32
    "(?:(?:%(hex)s:){0,3}%(hex)s)?::%(hex)s:%(ls32)s",
    # [ *4( h16 ":" ) h16 ] "::"              ls32
    "(?:(?:%(hex)s:){0,4}%(hex)s)?::%(ls32)s",
    # [ *5( h16 ":" ) h16 ] "::"              h16
    "(?:(?:%(hex)s:){0,5}%(hex)s)?::%(hex)s",
    # [ *6( h16 ":" ) h16 ] "::"
    "(?:(?:%(hex)s:){0,6}%(hex)s)?::",
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/wait.py
import errno
import select
import sys
from functools import partial

try:
    from time import monotonic
except ImportError:
    from time import time as monotonic

__all__ = ["NoWayToWaitForSocketError", "wait_for_read", "wait_for_write"]


class NoWayToWaitForSocketError(Exception):
    pass


# How should we wait on sockets?
#
# There are two types of APIs you can use for waiting on sockets: the fancy
# modern stateful APIs like epoll/kqueue, and the older stateless APIs like
# select/poll. The stateful APIs are more efficient when you have a lots of
# sockets to keep track of, because you can set them up once and then use them
# lots of times. But we only ever want to wait on a single socket at a time
# and don't want to keep track of state, so the stateless APIs are actually
# more efficient. So we want to use select() or poll().
#
# Now, how do we choose between select() and poll()? On traditional Unixes,
# select() has a strange calling convention that makes it slow, or fail
# altogether, for high-numbered file descriptors. The point of poll() is to fix
# that, so on Unixes, we prefer poll().
#
# On Windows, there is no poll() (or at least Python doesn't provide a wrapper
# for it), but that's OK, because on Windows, select() doesn't have this
# strange calling convention; plain select() works fine.
#
# So: on Windows we use select(), and everywhere else we use poll(). We also
# fall back to select() in case poll() is somehow broken or missing.

if sys.version_info >= (3, 5):
    # Modern Python, that retries syscalls by default
    def _retry_on_intr(fn, timeout):
        return fn(timeout)


else:
    # Old and broken Pythons.
    def _retry_on_intr(fn, timeout):
        if timeout is None:
            deadline = float("inf")
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/util/__init__.py
from __future__ import absolute_import

# For backwards compatibility, provide imports that used to be here.
from .connection import is_connection_dropped
from .request import SKIP_HEADER, SKIPPABLE_HEADERS, make_headers
from .response import is_fp_closed
from .retry import Retry
from .ssl_ import (
    ALPN_PROTOCOLS,
    HAS_SNI,
    IS_PYOPENSSL,
    IS_SECURETRANSPORT,
    PROTOCOL_TLS,
    SSLContext,
    assert_fingerprint,
    resolve_cert_reqs,
    resolve_ssl_version,
    ssl_wrap_socket,
)
from .timeout import Timeout, current_time
from .url import Url, get_host, parse_url, split_first
from .wait import wait_for_read, wait_for_write

__all__ = (
    "HAS_SNI",
    "IS_PYOPENSSL",
    "IS_SECURETRANSPORT",
    "SSLContext",
    "PROTOCOL_TLS",
    "ALPN_PROTOCOLS",
    "Retry",
    "Timeout",
    "Url",
    "assert_fingerprint",
    "current_time",
    "is_connection_dropped",
    "is_fp_closed",
    "get_host",
    "parse_url",
    "make_headers",
    "resolve_cert_reqs",
    "resolve_ssl_version",
    "split_first",
    "ssl_wrap_socket",
    "wait_for_read",
    "wait_for_write",
    "SKIP_HEADER",
    "SKIPPABLE_HEADERS",
)
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/_collections.py
from __future__ import absolute_import

try:
    from collections.abc import Mapping, MutableMapping
except ImportError:
    from collections import Mapping, MutableMapping
try:
    from threading import RLock
except ImportError:  # Platform-specific: No threads available

    class RLock:
        def __enter__(self):
            pass

        def __exit__(self, exc_type, exc_value, traceback):
            pass


from collections import OrderedDict

from .exceptions import InvalidHeader
from .packages import six
from .packages.six import iterkeys, itervalues

__all__ = ["RecentlyUsedContainer", "HTTPHeaderDict"]


_Null = object()


class RecentlyUsedContainer(MutableMapping):
    """
    Provides a thread-safe dict-like container which maintains up to
    ``maxsize`` keys while throwing away the least-recently-used keys beyond
    ``maxsize``.

    :param maxsize:
        Maximum number of recent elements to retain.

    :param dispose_func:
        Every time an item is evicted from the container,
        ``dispose_func(value)`` is called.  Callback which will get called
    """

    ContainerCls = OrderedDict

    def __init__(self, maxsize=10, dispose_func=None):
        self._maxsize = maxsize
        self.dispose_func = dispose_func

FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/_version.py
# This file is protected via CODEOWNERS
__version__ = "1.26.7"
FILE: ./venv/Lib/site-packages/pip/_vendor/urllib3/__init__.py
"""
Python HTTP library with thread-safe connection pooling, file post support, user friendly, and more
"""
from __future__ import absolute_import

# Set default logging handler to avoid "No handler found" warnings.
import logging
import warnings
from logging import NullHandler

from . import exceptions
from ._version import __version__
from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, connection_from_url
from .filepost import encode_multipart_formdata
from .poolmanager import PoolManager, ProxyManager, proxy_from_url
from .response import HTTPResponse
from .util.request import make_headers
from .util.retry import Retry
from .util.timeout import Timeout
from .util.url import get_host

__author__ = "Andrey Petrov (andrey.petrov@shazow.net)"
__license__ = "MIT"
__version__ = __version__

__all__ = (
    "HTTPConnectionPool",
    "HTTPSConnectionPool",
    "PoolManager",
    "ProxyManager",
    "HTTPResponse",
    "Retry",
    "Timeout",
    "add_stderr_logger",
    "connection_from_url",
    "disable_warnings",
    "encode_multipart_formdata",
    "get_host",
    "make_headers",
    "proxy_from_url",
)

logging.getLogger(__name__).addHandler(NullHandler())


def add_stderr_logger(level=logging.DEBUG):
    """
    Helper for quickly adding a StreamHandler to the logger. Useful for
    debugging.

FILE: ./venv/Lib/site-packages/pip/_vendor/webencodings/labels.py
"""

    webencodings.labels
    ~~~~~~~~~~~~~~~~~~~

    Map encoding labels to their name.

    :copyright: Copyright 2012 by Simon Sapin
    :license: BSD, see LICENSE for details.

"""

# XXX Do not edit!
# This file is automatically generated by mklabels.py

LABELS = {
    'unicode-1-1-utf-8':   'utf-8',
    'utf-8':               'utf-8',
    'utf8':                'utf-8',
    '866':                 'ibm866',
    'cp866':               'ibm866',
    'csibm866':            'ibm866',
    'ibm866':              'ibm866',
    'csisolatin2':         'iso-8859-2',
    'iso-8859-2':          'iso-8859-2',
    'iso-ir-101':          'iso-8859-2',
    'iso8859-2':           'iso-8859-2',
    'iso88592':            'iso-8859-2',
    'iso_8859-2':          'iso-8859-2',
    'iso_8859-2:1987':     'iso-8859-2',
    'l2':                  'iso-8859-2',
    'latin2':              'iso-8859-2',
    'csisolatin3':         'iso-8859-3',
    'iso-8859-3':          'iso-8859-3',
    'iso-ir-109':          'iso-8859-3',
    'iso8859-3':           'iso-8859-3',
    'iso88593':            'iso-8859-3',
    'iso_8859-3':          'iso-8859-3',
    'iso_8859-3:1988':     'iso-8859-3',
    'l3':                  'iso-8859-3',
    'latin3':              'iso-8859-3',
    'csisolatin4':         'iso-8859-4',
    'iso-8859-4':          'iso-8859-4',
    'iso-ir-110':          'iso-8859-4',
    'iso8859-4':           'iso-8859-4',
    'iso88594':            'iso-8859-4',
    'iso_8859-4':          'iso-8859-4',
    'iso_8859-4:1988':     'iso-8859-4',
    'l4':                  'iso-8859-4',
    'latin4':              'iso-8859-4',
FILE: ./venv/Lib/site-packages/pip/_vendor/webencodings/mklabels.py
"""

    webencodings.mklabels
    ~~~~~~~~~~~~~~~~~~~~~

    Regenarate the webencodings.labels module.

    :copyright: Copyright 2012 by Simon Sapin
    :license: BSD, see LICENSE for details.

"""

import json
try:
    from urllib import urlopen
except ImportError:
    from urllib.request import urlopen


def assert_lower(string):
    assert string == string.lower()
    return string


def generate(url):
    parts = ['''\
"""

    webencodings.labels
    ~~~~~~~~~~~~~~~~~~~

    Map encoding labels to their name.

    :copyright: Copyright 2012 by Simon Sapin
    :license: BSD, see LICENSE for details.

"""

# XXX Do not edit!
# This file is automatically generated by mklabels.py

LABELS = {
''']
    labels = [
        (repr(assert_lower(label)).lstrip('u'),
         repr(encoding['name']).lstrip('u'))
        for category in json.loads(urlopen(url).read().decode('ascii'))
        for encoding in category['encodings']
        for label in encoding['labels']]
    max_len = max(len(label) for label, name in labels)
FILE: ./venv/Lib/site-packages/pip/_vendor/webencodings/tests.py
# coding: utf-8
"""

    webencodings.tests
    ~~~~~~~~~~~~~~~~~~

    A basic test suite for Encoding.

    :copyright: Copyright 2012 by Simon Sapin
    :license: BSD, see LICENSE for details.

"""

from __future__ import unicode_literals

from . import (lookup, LABELS, decode, encode, iter_decode, iter_encode,
               IncrementalDecoder, IncrementalEncoder, UTF8)


def assert_raises(exception, function, *args, **kwargs):
    try:
        function(*args, **kwargs)
    except exception:
        return
    else:  # pragma: no cover
        raise AssertionError('Did not raise %s.' % exception)


def test_labels():
    assert lookup('utf-8').name == 'utf-8'
    assert lookup('Utf-8').name == 'utf-8'
    assert lookup('UTF-8').name == 'utf-8'
    assert lookup('utf8').name == 'utf-8'
    assert lookup('utf8').name == 'utf-8'
    assert lookup('utf8 ').name == 'utf-8'
    assert lookup(' \r\nutf8\t').name == 'utf-8'
    assert lookup('u8') is None  # Python label.
    assert lookup('utf-8 ') is None  # Non-ASCII white space.

    assert lookup('US-ASCII').name == 'windows-1252'
    assert lookup('iso-8859-1').name == 'windows-1252'
    assert lookup('latin1').name == 'windows-1252'
    assert lookup('LATIN1').name == 'windows-1252'
    assert lookup('latin-1') is None
    assert lookup('LATİN1') is None  # ASCII-only case insensitivity.


def test_all_labels():
    for label in LABELS:
        assert decode(b'', label) == ('', lookup(label))
FILE: ./venv/Lib/site-packages/pip/_vendor/webencodings/x_user_defined.py
# coding: utf-8
"""

    webencodings.x_user_defined
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~

    An implementation of the x-user-defined encoding.

    :copyright: Copyright 2012 by Simon Sapin
    :license: BSD, see LICENSE for details.

"""

from __future__ import unicode_literals

import codecs


### Codec APIs

class Codec(codecs.Codec):

    def encode(self, input, errors='strict'):
        return codecs.charmap_encode(input, errors, encoding_table)

    def decode(self, input, errors='strict'):
        return codecs.charmap_decode(input, errors, decoding_table)


class IncrementalEncoder(codecs.IncrementalEncoder):
    def encode(self, input, final=False):
        return codecs.charmap_encode(input, self.errors, encoding_table)[0]


class IncrementalDecoder(codecs.IncrementalDecoder):
    def decode(self, input, final=False):
        return codecs.charmap_decode(input, self.errors, decoding_table)[0]


class StreamWriter(Codec, codecs.StreamWriter):
    pass


class StreamReader(Codec, codecs.StreamReader):
    pass


### encodings module API

codec_info = codecs.CodecInfo(
FILE: ./venv/Lib/site-packages/pip/_vendor/webencodings/__init__.py
# coding: utf-8
"""

    webencodings
    ~~~~~~~~~~~~

    This is a Python implementation of the `WHATWG Encoding standard
    <http://encoding.spec.whatwg.org/>`. See README for details.

    :copyright: Copyright 2012 by Simon Sapin
    :license: BSD, see LICENSE for details.

"""

from __future__ import unicode_literals

import codecs

from .labels import LABELS


VERSION = '0.5.1'


# Some names in Encoding are not valid Python aliases. Remap these.
PYTHON_NAMES = {
    'iso-8859-8-i': 'iso-8859-8',
    'x-mac-cyrillic': 'mac-cyrillic',
    'macintosh': 'mac-roman',
    'windows-874': 'cp874'}

CACHE = {}


def ascii_lower(string):
    r"""Transform (only) ASCII letters to lower case: A-Z is mapped to a-z.

    :param string: An Unicode string.
    :returns: A new Unicode string.

    This is used for `ASCII case-insensitive
    <http://encoding.spec.whatwg.org/#ascii-case-insensitive>`_
    matching of encoding labels.
    The same matching is also used, among other things,
    for `CSS keywords <http://dev.w3.org/csswg/css-values/#keywords>`_.

    This is different from the :meth:`~py:str.lower` method of Unicode strings
    which also affect non-ASCII characters,
    sometimes mapping them into the ASCII range:

FILE: ./venv/Lib/site-packages/pip/_vendor/__init__.py
"""
pip._vendor is for vendoring dependencies of pip to prevent needing pip to
depend on something external.

Files inside of pip._vendor should be considered immutable and should only be
updated to versions from upstream.
"""
from __future__ import absolute_import

import glob
import os.path
import sys

# Downstream redistributors which have debundled our dependencies should also
# patch this value to be true. This will trigger the additional patching
# to cause things like "six" to be available as pip.
DEBUNDLED = False

# By default, look in this directory for a bunch of .whl files which we will
# add to the beginning of sys.path before attempting to import anything. This
# is done to support downstream re-distributors like Debian and Fedora who
# wish to create their own Wheels for our dependencies to aid in debundling.
WHEEL_DIR = os.path.abspath(os.path.dirname(__file__))


# Define a small helper function to alias our vendored modules to the real ones
# if the vendored ones do not exist. This idea of this was taken from
# https://github.com/kennethreitz/requests/pull/2567.
def vendored(modulename):
    vendored_name = "{0}.{1}".format(__name__, modulename)

    try:
        __import__(modulename, globals(), locals(), level=0)
    except ImportError:
        # We can just silently allow import failures to pass here. If we
        # got to this point it means that ``import pip._vendor.whatever``
        # failed and so did ``import whatever``. Since we're importing this
        # upfront in an attempt to alias imports, not erroring here will
        # just mean we get a regular import error whenever pip *actually*
        # tries to import one of these modules to use it, which actually
        # gives us a better error message than we would have otherwise
        # gotten.
        pass
    else:
        sys.modules[vendored_name] = sys.modules[modulename]
        base, head = vendored_name.rsplit(".", 1)
        setattr(sys.modules[base], head, sys.modules[modulename])


# If we're operating in a debundled setup, then we want to go ahead and trigger
FILE: ./venv/Lib/site-packages/pip/__init__.py
from typing import List, Optional

__version__ = "21.3.1"


def main(args: Optional[List[str]] = None) -> int:
    """This is an internal API only meant for use by pip's own console scripts.

    For additional details, see https://github.com/pypa/pip/issues/7498.
    """
    from pip._internal.utils.entrypoints import _wrapper

    return _wrapper(args)
FILE: ./venv/Lib/site-packages/pip/__main__.py
import os
import sys
import warnings

# Remove '' and current working directory from the first entry
# of sys.path, if present to avoid using current directory
# in pip commands check, freeze, install, list and show,
# when invoked as python -m pip <command>
if sys.path[0] in ("", os.getcwd()):
    sys.path.pop(0)

# If we are running from a wheel, add the wheel to sys.path
# This allows the usage python pip-*.whl/pip install pip-*.whl
if __package__ == "":
    # __file__ is pip-*.whl/pip/__main__.py
    # first dirname call strips of '/__main__.py', second strips off '/pip'
    # Resulting path is the name of the wheel itself
    # Add that to sys.path so we can import pip
    path = os.path.dirname(os.path.dirname(__file__))
    sys.path.insert(0, path)

if __name__ == "__main__":
    # Work around the error reported in #9540, pending a proper fix.
    # Note: It is essential the warning filter is set *before* importing
    #       pip, as the deprecation happens at import time, not runtime.
    warnings.filterwarnings(
        "ignore", category=DeprecationWarning, module=".*packaging\\.version"
    )
    from pip._internal.cli.main import main as _main

    sys.exit(_main())
FILE: ./venv/Lib/site-packages/pkg_resources/extern/__init__.py
import importlib.util
import sys


class VendorImporter:
    """
    A PEP 302 meta path importer for finding optionally-vendored
    or otherwise naturally-installed packages from root_name.
    """

    def __init__(self, root_name, vendored_names=(), vendor_pkg=None):
        self.root_name = root_name
        self.vendored_names = set(vendored_names)
        self.vendor_pkg = vendor_pkg or root_name.replace('extern', '_vendor')

    @property
    def search_path(self):
        """
        Search first the vendor package then as a natural package.
        """
        yield self.vendor_pkg + '.'
        yield ''

    def _module_matches_namespace(self, fullname):
        """Figure out if the target module is vendored."""
        root, base, target = fullname.partition(self.root_name + '.')
        return not root and any(map(target.startswith, self.vendored_names))

    def load_module(self, fullname):
        """
        Iterate over the search path to locate and load fullname.
        """
        root, base, target = fullname.partition(self.root_name + '.')
        for prefix in self.search_path:
            try:
                extant = prefix + target
                __import__(extant)
                mod = sys.modules[extant]
                sys.modules[fullname] = mod
                return mod
            except ImportError:
                pass
        else:
            raise ImportError(
                "The '{target}' package is required; "
                "normally this is bundled with this package so if you get "
                "this warning, consult the packager of your "
                "distribution.".format(**locals())
            )

FILE: ./venv/Lib/site-packages/pkg_resources/tests/data/my-test-package-source/setup.py
import setuptools
setuptools.setup(
    name="my-test-package",
    version="1.0",
    zip_safe=True,
)
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/appdirs.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright (c) 2005-2010 ActiveState Software Inc.
# Copyright (c) 2013 Eddy Petrișor

"""Utilities for determining application-specific dirs.

See <http://github.com/ActiveState/appdirs> for details and usage.
"""
# Dev Notes:
# - MSDN on where to store app data files:
#   http://support.microsoft.com/default.aspx?scid=kb;en-us;310294#XSLTH3194121123120121120120
# - Mac OS X: http://developer.apple.com/documentation/MacOSX/Conceptual/BPFileSystem/index.html
# - XDG spec for Un*x: http://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html

__version_info__ = (1, 4, 3)
__version__ = '.'.join(map(str, __version_info__))


import sys
import os

PY3 = sys.version_info[0] == 3

if PY3:
    unicode = str

if sys.platform.startswith('java'):
    import platform
    os_name = platform.java_ver()[3][0]
    if os_name.startswith('Windows'): # "Windows XP", "Windows 7", etc.
        system = 'win32'
    elif os_name.startswith('Mac'): # "Mac OS X", etc.
        system = 'darwin'
    else: # "Linux", "SunOS", "FreeBSD", etc.
        # Setting this to "linux2" is not ideal, but only Windows or Mac
        # are actually checked for and the rest of the module expects
        # *sys.platform* style strings.
        system = 'linux2'
else:
    system = sys.platform



def user_data_dir(appname=None, appauthor=None, version=None, roaming=False):
    r"""Return full path to the user-specific data dir for this application.

        "appname" is the name of application.
            If None, just the system directory is returned.
        "appauthor" (only used on Windows) is the name of the
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/markers.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import operator
import os
import platform
import sys
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

from pkg_resources.extern.pyparsing import (  # noqa: N817
    Forward,
    Group,
    Literal as L,
    ParseException,
    ParseResults,
    QuotedString,
    ZeroOrMore,
    stringEnd,
    stringStart,
)

from .specifiers import InvalidSpecifier, Specifier

__all__ = [
    "InvalidMarker",
    "UndefinedComparison",
    "UndefinedEnvironmentName",
    "Marker",
    "default_environment",
]

Operator = Callable[[str, str], bool]


class InvalidMarker(ValueError):
    """
    An invalid marker was found, users should refer to PEP 508.
    """


class UndefinedComparison(ValueError):
    """
    An invalid operation was attempted on a value that doesn't support it.
    """


class UndefinedEnvironmentName(ValueError):
    """
    A name was attempted to be used that does not exist inside of the
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/requirements.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import re
import string
import urllib.parse
from typing import List, Optional as TOptional, Set

from pkg_resources.extern.pyparsing import (  # noqa
    Combine,
    Literal as L,
    Optional,
    ParseException,
    Regex,
    Word,
    ZeroOrMore,
    originalTextFor,
    stringEnd,
    stringStart,
)

from .markers import MARKER_EXPR, Marker
from .specifiers import LegacySpecifier, Specifier, SpecifierSet


class InvalidRequirement(ValueError):
    """
    An invalid requirement was found, users should refer to PEP 508.
    """


ALPHANUM = Word(string.ascii_letters + string.digits)

LBRACKET = L("[").suppress()
RBRACKET = L("]").suppress()
LPAREN = L("(").suppress()
RPAREN = L(")").suppress()
COMMA = L(",").suppress()
SEMICOLON = L(";").suppress()
AT = L("@").suppress()

PUNCTUATION = Word("-_.")
IDENTIFIER_END = ALPHANUM | (ZeroOrMore(PUNCTUATION) + ALPHANUM)
IDENTIFIER = Combine(ALPHANUM + ZeroOrMore(IDENTIFIER_END))

NAME = IDENTIFIER("name")
EXTRA = IDENTIFIER

URI = Regex(r"[^ ]+")("url")
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/specifiers.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import abc
import functools
import itertools
import re
import warnings
from typing import (
    Callable,
    Dict,
    Iterable,
    Iterator,
    List,
    Optional,
    Pattern,
    Set,
    Tuple,
    TypeVar,
    Union,
)

from .utils import canonicalize_version
from .version import LegacyVersion, Version, parse

ParsedVersion = Union[Version, LegacyVersion]
UnparsedVersion = Union[Version, LegacyVersion, str]
VersionTypeVar = TypeVar("VersionTypeVar", bound=UnparsedVersion)
CallableOperator = Callable[[ParsedVersion, str], bool]


class InvalidSpecifier(ValueError):
    """
    An invalid specifier was found, users should refer to PEP 440.
    """


class BaseSpecifier(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def __str__(self) -> str:
        """
        Returns the str representation of this Specifier like object. This
        should be representative of the Specifier itself.
        """

    @abc.abstractmethod
    def __hash__(self) -> int:
        """
        Returns a hash value for this Specifier like object.
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/tags.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import logging
import platform
import sys
import sysconfig
from importlib.machinery import EXTENSION_SUFFIXES
from typing import (
    Dict,
    FrozenSet,
    Iterable,
    Iterator,
    List,
    Optional,
    Sequence,
    Tuple,
    Union,
    cast,
)

from . import _manylinux, _musllinux

logger = logging.getLogger(__name__)

PythonVersion = Sequence[int]
MacVersion = Tuple[int, int]

INTERPRETER_SHORT_NAMES: Dict[str, str] = {
    "python": "py",  # Generic.
    "cpython": "cp",
    "pypy": "pp",
    "ironpython": "ip",
    "jython": "jy",
}


_32_BIT_INTERPRETER = sys.maxsize <= 2 ** 32


class Tag:
    """
    A representation of the tag triple for a wheel.

    Instances are considered immutable and thus are hashable. Equality checking
    is also supported.
    """

    __slots__ = ["_interpreter", "_abi", "_platform", "_hash"]
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/utils.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import re
from typing import FrozenSet, NewType, Tuple, Union, cast

from .tags import Tag, parse_tag
from .version import InvalidVersion, Version

BuildTag = Union[Tuple[()], Tuple[int, str]]
NormalizedName = NewType("NormalizedName", str)


class InvalidWheelFilename(ValueError):
    """
    An invalid wheel filename was found, users should refer to PEP 427.
    """


class InvalidSdistFilename(ValueError):
    """
    An invalid sdist filename was found, users should refer to the packaging user guide.
    """


_canonicalize_regex = re.compile(r"[-_.]+")
# PEP 427: The build number must start with a digit.
_build_tag_regex = re.compile(r"(\d+)(.*)")


def canonicalize_name(name: str) -> NormalizedName:
    # This is taken from PEP 503.
    value = _canonicalize_regex.sub("-", name).lower()
    return cast(NormalizedName, value)


def canonicalize_version(version: Union[Version, str]) -> str:
    """
    This is very similar to Version.__str__, but has one subtle difference
    with the way it handles the release segment.
    """
    if isinstance(version, str):
        try:
            parsed = Version(version)
        except InvalidVersion:
            # Legacy versions cannot be normalized
            return version
    else:
        parsed = version
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/version.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import collections
import itertools
import re
import warnings
from typing import Callable, Iterator, List, Optional, SupportsInt, Tuple, Union

from ._structures import Infinity, InfinityType, NegativeInfinity, NegativeInfinityType

__all__ = ["parse", "Version", "LegacyVersion", "InvalidVersion", "VERSION_PATTERN"]

InfiniteTypes = Union[InfinityType, NegativeInfinityType]
PrePostDevType = Union[InfiniteTypes, Tuple[str, int]]
SubLocalType = Union[InfiniteTypes, int, str]
LocalType = Union[
    NegativeInfinityType,
    Tuple[
        Union[
            SubLocalType,
            Tuple[SubLocalType, str],
            Tuple[NegativeInfinityType, SubLocalType],
        ],
        ...,
    ],
]
CmpKey = Tuple[
    int, Tuple[int, ...], PrePostDevType, PrePostDevType, PrePostDevType, LocalType
]
LegacyCmpKey = Tuple[int, Tuple[str, ...]]
VersionComparisonMethod = Callable[
    [Union[CmpKey, LegacyCmpKey], Union[CmpKey, LegacyCmpKey]], bool
]

_Version = collections.namedtuple(
    "_Version", ["epoch", "release", "dev", "pre", "post", "local"]
)


def parse(version: str) -> Union["LegacyVersion", "Version"]:
    """
    Parse the given version string and return either a :class:`Version` object
    or a :class:`LegacyVersion` object depending on if the given version is
    a valid PEP 440 version or a legacy version.
    """
    try:
        return Version(version)
    except InvalidVersion:
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/_manylinux.py
import collections
import functools
import os
import re
import struct
import sys
import warnings
from typing import IO, Dict, Iterator, NamedTuple, Optional, Tuple


# Python does not provide platform information at sufficient granularity to
# identify the architecture of the running executable in some cases, so we
# determine it dynamically by reading the information from the running
# process. This only applies on Linux, which uses the ELF format.
class _ELFFileHeader:
    # https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#File_header
    class _InvalidELFFileHeader(ValueError):
        """
        An invalid ELF file header was found.
        """

    ELF_MAGIC_NUMBER = 0x7F454C46
    ELFCLASS32 = 1
    ELFCLASS64 = 2
    ELFDATA2LSB = 1
    ELFDATA2MSB = 2
    EM_386 = 3
    EM_S390 = 22
    EM_ARM = 40
    EM_X86_64 = 62
    EF_ARM_ABIMASK = 0xFF000000
    EF_ARM_ABI_VER5 = 0x05000000
    EF_ARM_ABI_FLOAT_HARD = 0x00000400

    def __init__(self, file: IO[bytes]) -> None:
        def unpack(fmt: str) -> int:
            try:
                data = file.read(struct.calcsize(fmt))
                result: Tuple[int, ...] = struct.unpack(fmt, data)
            except struct.error:
                raise _ELFFileHeader._InvalidELFFileHeader()
            return result[0]

        self.e_ident_magic = unpack(">I")
        if self.e_ident_magic != self.ELF_MAGIC_NUMBER:
            raise _ELFFileHeader._InvalidELFFileHeader()
        self.e_ident_class = unpack("B")
        if self.e_ident_class not in {self.ELFCLASS32, self.ELFCLASS64}:
            raise _ELFFileHeader._InvalidELFFileHeader()
        self.e_ident_data = unpack("B")
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/_musllinux.py
"""PEP 656 support.

This module implements logic to detect if the currently running Python is
linked against musl, and what musl version is used.
"""

import contextlib
import functools
import operator
import os
import re
import struct
import subprocess
import sys
from typing import IO, Iterator, NamedTuple, Optional, Tuple


def _read_unpacked(f: IO[bytes], fmt: str) -> Tuple[int, ...]:
    return struct.unpack(fmt, f.read(struct.calcsize(fmt)))


def _parse_ld_musl_from_elf(f: IO[bytes]) -> Optional[str]:
    """Detect musl libc location by parsing the Python executable.

    Based on: https://gist.github.com/lyssdod/f51579ae8d93c8657a5564aefc2ffbca
    ELF header: https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html
    """
    f.seek(0)
    try:
        ident = _read_unpacked(f, "16B")
    except struct.error:
        return None
    if ident[:4] != tuple(b"\x7fELF"):  # Invalid magic, not ELF.
        return None
    f.seek(struct.calcsize("HHI"), 1)  # Skip file type, machine, and version.

    try:
        # e_fmt: Format for program header.
        # p_fmt: Format for section header.
        # p_idx: Indexes to find p_type, p_offset, and p_filesz.
        e_fmt, p_fmt, p_idx = {
            1: ("IIIIHHH", "IIIIIIII", (0, 1, 4)),  # 32-bit.
            2: ("QQQIHHH", "IIQQQQQQ", (0, 2, 5)),  # 64-bit.
        }[ident[4]]
    except KeyError:
        return None
    else:
        p_get = operator.itemgetter(*p_idx)

    # Find the interpreter section and return its content.
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/_structures.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.


class InfinityType:
    def __repr__(self) -> str:
        return "Infinity"

    def __hash__(self) -> int:
        return hash(repr(self))

    def __lt__(self, other: object) -> bool:
        return False

    def __le__(self, other: object) -> bool:
        return False

    def __eq__(self, other: object) -> bool:
        return isinstance(other, self.__class__)

    def __ne__(self, other: object) -> bool:
        return not isinstance(other, self.__class__)

    def __gt__(self, other: object) -> bool:
        return True

    def __ge__(self, other: object) -> bool:
        return True

    def __neg__(self: object) -> "NegativeInfinityType":
        return NegativeInfinity


Infinity = InfinityType()


class NegativeInfinityType:
    def __repr__(self) -> str:
        return "-Infinity"

    def __hash__(self) -> int:
        return hash(repr(self))

    def __lt__(self, other: object) -> bool:
        return True

    def __le__(self, other: object) -> bool:
        return True

FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/__about__.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

__all__ = [
    "__title__",
    "__summary__",
    "__uri__",
    "__version__",
    "__author__",
    "__email__",
    "__license__",
    "__copyright__",
]

__title__ = "packaging"
__summary__ = "Core utilities for Python packages"
__uri__ = "https://github.com/pypa/packaging"

__version__ = "21.2"

__author__ = "Donald Stufft and individual contributors"
__email__ = "donald@stufft.io"

__license__ = "BSD-2-Clause or Apache-2.0"
__copyright__ = "2014-2019 %s" % __author__
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/packaging/__init__.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

from .__about__ import (
    __author__,
    __copyright__,
    __email__,
    __license__,
    __summary__,
    __title__,
    __uri__,
    __version__,
)

__all__ = [
    "__title__",
    "__summary__",
    "__uri__",
    "__version__",
    "__author__",
    "__email__",
    "__license__",
    "__copyright__",
]
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/pyparsing.py
# module pyparsing.py
#
# Copyright (c) 2003-2018  Paul T. McGuire
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#

__doc__ = \
"""
pyparsing module - Classes and methods to define and execute parsing grammars
=============================================================================

The pyparsing module is an alternative approach to creating and executing simple grammars,
vs. the traditional lex/yacc approach, or the use of regular expressions.  With pyparsing, you
don't need to learn a new syntax for defining grammars or matching expressions - the parsing module
provides a library of classes that you use to construct the grammar directly in Python.

Here is a program to parse "Hello, World!" (or any greeting of the form 
C{"<salutation>, <addressee>!"}), built up using L{Word}, L{Literal}, and L{And} elements 
(L{'+'<ParserElement.__add__>} operator gives L{And} expressions, strings are auto-converted to
L{Literal} expressions)::

    from pyparsing import Word, alphas

    # define grammar of a greeting
    greet = Word(alphas) + "," + Word(alphas) + "!"

    hello = "Hello, World!"
    print (hello, "->", greet.parseString(hello))

The program outputs the following::

    Hello, World! -> ['Hello', ',', 'World', '!']
FILE: ./venv/Lib/site-packages/pkg_resources/_vendor/__init__.py
FILE: ./venv/Lib/site-packages/pkg_resources/__init__.py
"""
Package resource API
--------------------

A resource is a logical file contained within a package, or a logical
subdirectory thereof.  The package resource API expects resource names
to have their path parts separated with ``/``, *not* whatever the local
path separator is.  Do not use os.path operations to manipulate resource
names being passed into the API.

The package resource API is designed to work with normal filesystem packages,
.egg files, and unpacked .egg files.  It can also work in a limited way with
.zip files and with custom PEP 302 loaders that support the ``get_data()``
method.
"""

import sys
import os
import io
import time
import re
import types
import zipfile
import zipimport
import warnings
import stat
import functools
import pkgutil
import operator
import platform
import collections
import plistlib
import email.parser
import errno
import tempfile
import textwrap
import itertools
import inspect
import ntpath
import posixpath
import importlib
from pkgutil import get_importer

try:
    import _imp
except ImportError:
    # Python 3.2 compatibility
    import imp as _imp

try:
FILE: ./venv/Lib/site-packages/setuptools/archive_util.py
"""Utilities for extracting common archive formats"""

import zipfile
import tarfile
import os
import shutil
import posixpath
import contextlib
from distutils.errors import DistutilsError

from pkg_resources import ensure_directory

__all__ = [
    "unpack_archive", "unpack_zipfile", "unpack_tarfile", "default_filter",
    "UnrecognizedFormat", "extraction_drivers", "unpack_directory",
]


class UnrecognizedFormat(DistutilsError):
    """Couldn't recognize the archive type"""


def default_filter(src, dst):
    """The default progress/filter callback; returns True for all files"""
    return dst


def unpack_archive(
        filename, extract_dir, progress_filter=default_filter,
        drivers=None):
    """Unpack `filename` to `extract_dir`, or raise ``UnrecognizedFormat``

    `progress_filter` is a function taking two arguments: a source path
    internal to the archive ('/'-separated), and a filesystem path where it
    will be extracted.  The callback must return the desired extract path
    (which may be the same as the one passed in), or else ``None`` to skip
    that file or directory.  The callback can thus be used to report on the
    progress of the extraction, as well as to filter the items extracted or
    alter their extraction paths.

    `drivers`, if supplied, must be a non-empty sequence of functions with the
    same signature as this function (minus the `drivers` argument), that raise
    ``UnrecognizedFormat`` if they do not support extracting the designated
    archive type.  The `drivers` are tried in sequence until one is found that
    does not raise an error, or until all are exhausted (in which case
    ``UnrecognizedFormat`` is raised).  If you do not supply a sequence of
    drivers, the module's ``extraction_drivers`` constant will be used, which
    means that ``unpack_zipfile`` and ``unpack_tarfile`` will be tried, in that
    order.
    """
FILE: ./venv/Lib/site-packages/setuptools/build_meta.py
"""A PEP 517 interface to setuptools

Previously, when a user or a command line tool (let's call it a "frontend")
needed to make a request of setuptools to take a certain action, for
example, generating a list of installation requirements, the frontend would
would call "setup.py egg_info" or "setup.py bdist_wheel" on the command line.

PEP 517 defines a different method of interfacing with setuptools. Rather
than calling "setup.py" directly, the frontend should:

  1. Set the current directory to the directory with a setup.py file
  2. Import this module into a safe python interpreter (one in which
     setuptools can potentially set global variables or crash hard).
  3. Call one of the functions defined in PEP 517.

What each function does is defined in PEP 517. However, here is a "casual"
definition of the functions (this definition should not be relied on for
bug reports or API stability):

  - `build_wheel`: build a wheel in the folder and return the basename
  - `get_requires_for_build_wheel`: get the `setup_requires` to build
  - `prepare_metadata_for_build_wheel`: get the `install_requires`
  - `build_sdist`: build an sdist in the folder and return the basename
  - `get_requires_for_build_sdist`: get the `setup_requires` to build

Again, this is not a formal definition! Just a "taste" of the module.
"""

import io
import os
import sys
import tokenize
import shutil
import contextlib
import tempfile
import warnings

import setuptools
import distutils

from pkg_resources import parse_requirements

__all__ = ['get_requires_for_build_sdist',
           'get_requires_for_build_wheel',
           'prepare_metadata_for_build_wheel',
           'build_wheel',
           'build_sdist',
           '__legacy__',
           'SetupRequirementsError']

FILE: ./venv/Lib/site-packages/setuptools/command/alias.py
from distutils.errors import DistutilsOptionError

from setuptools.command.setopt import edit_config, option_base, config_file


def shquote(arg):
    """Quote an argument for later parsing by shlex.split()"""
    for c in '"', "'", "\\", "#":
        if c in arg:
            return repr(arg)
    if arg.split() != [arg]:
        return repr(arg)
    return arg


class alias(option_base):
    """Define a shortcut that invokes one or more commands"""

    description = "define a shortcut to invoke one or more commands"
    command_consumes_arguments = True

    user_options = [
        ('remove', 'r', 'remove (unset) the alias'),
    ] + option_base.user_options

    boolean_options = option_base.boolean_options + ['remove']

    def initialize_options(self):
        option_base.initialize_options(self)
        self.args = None
        self.remove = None

    def finalize_options(self):
        option_base.finalize_options(self)
        if self.remove and len(self.args) != 1:
            raise DistutilsOptionError(
                "Must specify exactly one argument (the alias name) when "
                "using --remove"
            )

    def run(self):
        aliases = self.distribution.get_option_dict('aliases')

        if not self.args:
            print("Command Aliases")
            print("---------------")
            for alias in aliases:
                print("setup.py alias", format_alias(alias, aliases))
            return

FILE: ./venv/Lib/site-packages/setuptools/command/bdist_egg.py
"""setuptools.command.bdist_egg

Build .egg distributions"""

from distutils.dir_util import remove_tree, mkpath
from distutils import log
from types import CodeType
import sys
import os
import re
import textwrap
import marshal

from pkg_resources import get_build_platform, Distribution, ensure_directory
from setuptools.extension import Library
from setuptools import Command

from sysconfig import get_path, get_python_version


def _get_purelib():
    return get_path("purelib")


def strip_module(filename):
    if '.' in filename:
        filename = os.path.splitext(filename)[0]
    if filename.endswith('module'):
        filename = filename[:-6]
    return filename


def sorted_walk(dir):
    """Do os.walk in a reproducible way,
    independent of indeterministic filesystem readdir order
    """
    for base, dirs, files in os.walk(dir):
        dirs.sort()
        files.sort()
        yield base, dirs, files


def write_stub(resource, pyfile):
    _stub_template = textwrap.dedent("""
        def __bootstrap__():
            global __bootstrap__, __loader__, __file__
            import sys, pkg_resources, importlib.util
            __file__ = pkg_resources.resource_filename(__name__, %r)
            __loader__ = None; del __bootstrap__, __loader__
            spec = importlib.util.spec_from_file_location(__name__,__file__)
FILE: ./venv/Lib/site-packages/setuptools/command/bdist_rpm.py
import distutils.command.bdist_rpm as orig
import warnings

from setuptools import SetuptoolsDeprecationWarning


class bdist_rpm(orig.bdist_rpm):
    """
    Override the default bdist_rpm behavior to do the following:

    1. Run egg_info to ensure the name and version are properly calculated.
    2. Always run 'install' using --single-version-externally-managed to
       disable eggs in RPM distributions.
    """

    def run(self):
        warnings.warn(
            "bdist_rpm is deprecated and will be removed in a future "
            "version. Use bdist_wheel (wheel packages) instead.",
            SetuptoolsDeprecationWarning,
        )

        # ensure distro name is up-to-date
        self.run_command('egg_info')

        orig.bdist_rpm.run(self)

    def _make_spec_file(self):
        spec = orig.bdist_rpm._make_spec_file(self)
        spec = [
            line.replace(
                "setup.py install ",
                "setup.py install --single-version-externally-managed "
            ).replace(
                "%setup",
                "%setup -n %{name}-%{unmangled_version}"
            )
            for line in spec
        ]
        return spec
FILE: ./venv/Lib/site-packages/setuptools/command/build_clib.py
import distutils.command.build_clib as orig
from distutils.errors import DistutilsSetupError
from distutils import log
from setuptools.dep_util import newer_pairwise_group


class build_clib(orig.build_clib):
    """
    Override the default build_clib behaviour to do the following:

    1. Implement a rudimentary timestamp-based dependency system
       so 'compile()' doesn't run every time.
    2. Add more keys to the 'build_info' dictionary:
        * obj_deps - specify dependencies for each object compiled.
                     this should be a dictionary mapping a key
                     with the source filename to a list of
                     dependencies. Use an empty string for global
                     dependencies.
        * cflags   - specify a list of additional flags to pass to
                     the compiler.
    """

    def build_libraries(self, libraries):
        for (lib_name, build_info) in libraries:
            sources = build_info.get('sources')
            if sources is None or not isinstance(sources, (list, tuple)):
                raise DistutilsSetupError(
                    "in 'libraries' option (library '%s'), "
                    "'sources' must be present and must be "
                    "a list of source filenames" % lib_name)
            sources = list(sources)

            log.info("building '%s' library", lib_name)

            # Make sure everything is the correct type.
            # obj_deps should be a dictionary of keys as sources
            # and a list/tuple of files that are its dependencies.
            obj_deps = build_info.get('obj_deps', dict())
            if not isinstance(obj_deps, dict):
                raise DistutilsSetupError(
                    "in 'libraries' option (library '%s'), "
                    "'obj_deps' must be a dictionary of "
                    "type 'source: list'" % lib_name)
            dependencies = []

            # Get the global dependencies that are specified by the '' key.
            # These will go into every source's dependency list.
            global_deps = obj_deps.get('', list())
            if not isinstance(global_deps, (list, tuple)):
                raise DistutilsSetupError(
FILE: ./venv/Lib/site-packages/setuptools/command/build_ext.py
import os
import sys
import itertools
from importlib.machinery import EXTENSION_SUFFIXES
from distutils.command.build_ext import build_ext as _du_build_ext
from distutils.file_util import copy_file
from distutils.ccompiler import new_compiler
from distutils.sysconfig import customize_compiler, get_config_var
from distutils.errors import DistutilsError
from distutils import log

from setuptools.extension import Library

try:
    # Attempt to use Cython for building extensions, if available
    from Cython.Distutils.build_ext import build_ext as _build_ext
    # Additionally, assert that the compiler module will load
    # also. Ref #1229.
    __import__('Cython.Compiler.Main')
except ImportError:
    _build_ext = _du_build_ext

# make sure _config_vars is initialized
get_config_var("LDSHARED")
from distutils.sysconfig import _config_vars as _CONFIG_VARS  # noqa


def _customize_compiler_for_shlib(compiler):
    if sys.platform == "darwin":
        # building .dylib requires additional compiler flags on OSX; here we
        # temporarily substitute the pyconfig.h variables so that distutils'
        # 'customize_compiler' uses them before we build the shared libraries.
        tmp = _CONFIG_VARS.copy()
        try:
            # XXX Help!  I don't have any idea whether these are right...
            _CONFIG_VARS['LDSHARED'] = (
                "gcc -Wl,-x -dynamiclib -undefined dynamic_lookup")
            _CONFIG_VARS['CCSHARED'] = " -dynamiclib"
            _CONFIG_VARS['SO'] = ".dylib"
            customize_compiler(compiler)
        finally:
            _CONFIG_VARS.clear()
            _CONFIG_VARS.update(tmp)
    else:
        customize_compiler(compiler)


have_rtld = False
use_stubs = False
libtype = 'shared'
FILE: ./venv/Lib/site-packages/setuptools/command/build_py.py
from glob import glob
from distutils.util import convert_path
import distutils.command.build_py as orig
import os
import fnmatch
import textwrap
import io
import distutils.errors
import itertools
import stat
from setuptools.extern.more_itertools import unique_everseen


def make_writable(target):
    os.chmod(target, os.stat(target).st_mode | stat.S_IWRITE)


class build_py(orig.build_py):
    """Enhanced 'build_py' command that includes data files with packages

    The data files are specified via a 'package_data' argument to 'setup()'.
    See 'setuptools.dist.Distribution' for more details.

    Also, this version of the 'build_py' command allows you to specify both
    'py_modules' and 'packages' in the same setup operation.
    """

    def finalize_options(self):
        orig.build_py.finalize_options(self)
        self.package_data = self.distribution.package_data
        self.exclude_package_data = self.distribution.exclude_package_data or {}
        if 'data_files' in self.__dict__:
            del self.__dict__['data_files']
        self.__updated_files = []

    def run(self):
        """Build modules, packages, and copy data files to build directory"""
        if not self.py_modules and not self.packages:
            return

        if self.py_modules:
            self.build_modules()

        if self.packages:
            self.build_packages()
            self.build_package_data()

        # Only compile actual .py files, using our base class' idea of what our
        # output files are.
        self.byte_compile(orig.build_py.get_outputs(self, include_bytecode=0))
FILE: ./venv/Lib/site-packages/setuptools/command/develop.py
from distutils.util import convert_path
from distutils import log
from distutils.errors import DistutilsError, DistutilsOptionError
import os
import glob
import io

import pkg_resources
from setuptools.command.easy_install import easy_install
from setuptools import namespaces
import setuptools


class develop(namespaces.DevelopInstaller, easy_install):
    """Set up package for development"""

    description = "install package in 'development mode'"

    user_options = easy_install.user_options + [
        ("uninstall", "u", "Uninstall this source package"),
        ("egg-path=", None, "Set the path to be used in the .egg-link file"),
    ]

    boolean_options = easy_install.boolean_options + ['uninstall']

    command_consumes_arguments = False  # override base

    def run(self):
        if self.uninstall:
            self.multi_version = True
            self.uninstall_link()
            self.uninstall_namespaces()
        else:
            self.install_for_development()
        self.warn_deprecated_options()

    def initialize_options(self):
        self.uninstall = None
        self.egg_path = None
        easy_install.initialize_options(self)
        self.setup_path = None
        self.always_copy_from = '.'  # always copy eggs installed in curdir

    def finalize_options(self):
        ei = self.get_finalized_command("egg_info")
        if ei.broken_egg_info:
            template = "Please rename %r to %r before using 'develop'"
            args = ei.egg_info, ei.broken_egg_info
            raise DistutilsError(template % args)
        self.args = [ei.egg_name]
FILE: ./venv/Lib/site-packages/setuptools/command/dist_info.py
"""
Create a dist_info directory
As defined in the wheel specification
"""

import os

from distutils.core import Command
from distutils import log


class dist_info(Command):

    description = 'create a .dist-info directory'

    user_options = [
        ('egg-base=', 'e', "directory containing .egg-info directories"
                           " (default: top of the source tree)"),
    ]

    def initialize_options(self):
        self.egg_base = None

    def finalize_options(self):
        pass

    def run(self):
        egg_info = self.get_finalized_command('egg_info')
        egg_info.egg_base = self.egg_base
        egg_info.finalize_options()
        egg_info.run()
        dist_info_dir = egg_info.egg_info[:-len('.egg-info')] + '.dist-info'
        log.info("creating '{}'".format(os.path.abspath(dist_info_dir)))

        bdist_wheel = self.get_finalized_command('bdist_wheel')
        bdist_wheel.egg2dist(egg_info.egg_info, dist_info_dir)
FILE: ./venv/Lib/site-packages/setuptools/command/easy_install.py
"""
Easy Install
------------

A tool for doing automatic download/extract/build of distutils-based Python
packages.  For detailed documentation, see the accompanying EasyInstall.txt
file, or visit the `EasyInstall home page`__.

__ https://setuptools.pypa.io/en/latest/deprecated/easy_install.html

"""

from glob import glob
from distutils.util import get_platform
from distutils.util import convert_path, subst_vars
from distutils.errors import (
    DistutilsArgError, DistutilsOptionError,
    DistutilsError, DistutilsPlatformError,
)
from distutils import log, dir_util
from distutils.command.build_scripts import first_line_re
from distutils.spawn import find_executable
from distutils.command import install
import sys
import os
import zipimport
import shutil
import tempfile
import zipfile
import re
import stat
import random
import textwrap
import warnings
import site
import struct
import contextlib
import subprocess
import shlex
import io
import configparser


from sysconfig import get_config_vars, get_path

from setuptools import SetuptoolsDeprecationWarning

from setuptools import Command
from setuptools.sandbox import run_setup
from setuptools.command import setopt
FILE: ./venv/Lib/site-packages/setuptools/command/egg_info.py
"""setuptools.command.egg_info

Create a distribution's .egg-info directory and contents"""

from distutils.filelist import FileList as _FileList
from distutils.errors import DistutilsInternalError
from distutils.util import convert_path
from distutils import log
import distutils.errors
import distutils.filelist
import functools
import os
import re
import sys
import io
import warnings
import time
import collections

from setuptools import Command
from setuptools.command.sdist import sdist
from setuptools.command.sdist import walk_revctrl
from setuptools.command.setopt import edit_config
from setuptools.command import bdist_egg
from pkg_resources import (
    parse_requirements, safe_name, parse_version,
    safe_version, yield_lines, EntryPoint, iter_entry_points, to_filename)
import setuptools.unicode_utils as unicode_utils
from setuptools.glob import glob

from setuptools.extern import packaging
from setuptools import SetuptoolsDeprecationWarning


def translate_pattern(glob):  # noqa: C901  # is too complex (14)  # FIXME
    """
    Translate a file path glob like '*.txt' in to a regular expression.
    This differs from fnmatch.translate which allows wildcards to match
    directory separators. It also knows about '**/' which matches any number of
    directories.
    """
    pat = ''

    # This will split on '/' within [character classes]. This is deliberate.
    chunks = glob.split(os.path.sep)

    sep = re.escape(os.sep)
    valid_char = '[^%s]' % (sep,)

    for c, chunk in enumerate(chunks):
FILE: ./venv/Lib/site-packages/setuptools/command/install.py
from distutils.errors import DistutilsArgError
import inspect
import glob
import warnings
import platform
import distutils.command.install as orig

import setuptools

# Prior to numpy 1.9, NumPy relies on the '_install' name, so provide it for
# now. See https://github.com/pypa/setuptools/issues/199/
_install = orig.install


class install(orig.install):
    """Use easy_install to install the package, w/dependencies"""

    user_options = orig.install.user_options + [
        ('old-and-unmanageable', None, "Try not to use this!"),
        ('single-version-externally-managed', None,
         "used by system package builders to create 'flat' eggs"),
    ]
    boolean_options = orig.install.boolean_options + [
        'old-and-unmanageable', 'single-version-externally-managed',
    ]
    new_commands = [
        ('install_egg_info', lambda self: True),
        ('install_scripts', lambda self: True),
    ]
    _nc = dict(new_commands)

    def initialize_options(self):

        warnings.warn(
            "setup.py install is deprecated. "
            "Use build and pip and other standards-based tools.",
            setuptools.SetuptoolsDeprecationWarning,
        )

        orig.install.initialize_options(self)
        self.old_and_unmanageable = None
        self.single_version_externally_managed = None

    def finalize_options(self):
        orig.install.finalize_options(self)
        if self.root:
            self.single_version_externally_managed = True
        elif self.single_version_externally_managed:
            if not self.root and not self.record:
                raise DistutilsArgError(
FILE: ./venv/Lib/site-packages/setuptools/command/install_egg_info.py
from distutils import log, dir_util
import os

from setuptools import Command
from setuptools import namespaces
from setuptools.archive_util import unpack_archive
import pkg_resources


class install_egg_info(namespaces.Installer, Command):
    """Install an .egg-info directory for the package"""

    description = "Install an .egg-info directory for the package"

    user_options = [
        ('install-dir=', 'd', "directory to install to"),
    ]

    def initialize_options(self):
        self.install_dir = None

    def finalize_options(self):
        self.set_undefined_options('install_lib',
                                   ('install_dir', 'install_dir'))
        ei_cmd = self.get_finalized_command("egg_info")
        basename = pkg_resources.Distribution(
            None, None, ei_cmd.egg_name, ei_cmd.egg_version
        ).egg_name() + '.egg-info'
        self.source = ei_cmd.egg_info
        self.target = os.path.join(self.install_dir, basename)
        self.outputs = []

    def run(self):
        self.run_command('egg_info')
        if os.path.isdir(self.target) and not os.path.islink(self.target):
            dir_util.remove_tree(self.target, dry_run=self.dry_run)
        elif os.path.exists(self.target):
            self.execute(os.unlink, (self.target,), "Removing " + self.target)
        if not self.dry_run:
            pkg_resources.ensure_directory(self.target)
        self.execute(
            self.copytree, (), "Copying %s to %s" % (self.source, self.target)
        )
        self.install_namespaces()

    def get_outputs(self):
        return self.outputs

    def copytree(self):
        # Copy the .egg-info tree to site-packages
FILE: ./venv/Lib/site-packages/setuptools/command/install_lib.py
import os
import sys
from itertools import product, starmap
import distutils.command.install_lib as orig


class install_lib(orig.install_lib):
    """Don't add compiled flags to filenames of non-Python files"""

    def run(self):
        self.build()
        outfiles = self.install()
        if outfiles is not None:
            # always compile, in case we have any extension stubs to deal with
            self.byte_compile(outfiles)

    def get_exclusions(self):
        """
        Return a collections.Sized collections.Container of paths to be
        excluded for single_version_externally_managed installations.
        """
        all_packages = (
            pkg
            for ns_pkg in self._get_SVEM_NSPs()
            for pkg in self._all_packages(ns_pkg)
        )

        excl_specs = product(all_packages, self._gen_exclusion_paths())
        return set(starmap(self._exclude_pkg_path, excl_specs))

    def _exclude_pkg_path(self, pkg, exclusion_path):
        """
        Given a package name and exclusion path within that package,
        compute the full exclusion path.
        """
        parts = pkg.split('.') + [exclusion_path]
        return os.path.join(self.install_dir, *parts)

    @staticmethod
    def _all_packages(pkg_name):
        """
        >>> list(install_lib._all_packages('foo.bar.baz'))
        ['foo.bar.baz', 'foo.bar', 'foo']
        """
        while pkg_name:
            yield pkg_name
            pkg_name, sep, child = pkg_name.rpartition('.')

    def _get_SVEM_NSPs(self):
        """
FILE: ./venv/Lib/site-packages/setuptools/command/install_scripts.py
from distutils import log
import distutils.command.install_scripts as orig
from distutils.errors import DistutilsModuleError
import os
import sys

from pkg_resources import Distribution, PathMetadata, ensure_directory


class install_scripts(orig.install_scripts):
    """Do normal script install, plus any egg_info wrapper scripts"""

    def initialize_options(self):
        orig.install_scripts.initialize_options(self)
        self.no_ep = False

    def run(self):
        import setuptools.command.easy_install as ei

        self.run_command("egg_info")
        if self.distribution.scripts:
            orig.install_scripts.run(self)  # run first to set up self.outfiles
        else:
            self.outfiles = []
        if self.no_ep:
            # don't install entry point scripts into .egg file!
            return

        ei_cmd = self.get_finalized_command("egg_info")
        dist = Distribution(
            ei_cmd.egg_base, PathMetadata(ei_cmd.egg_base, ei_cmd.egg_info),
            ei_cmd.egg_name, ei_cmd.egg_version,
        )
        bs_cmd = self.get_finalized_command('build_scripts')
        exec_param = getattr(bs_cmd, 'executable', None)
        try:
            bw_cmd = self.get_finalized_command("bdist_wininst")
            is_wininst = getattr(bw_cmd, '_is_running', False)
        except (ImportError, DistutilsModuleError):
            is_wininst = False
        writer = ei.ScriptWriter
        if is_wininst:
            exec_param = "python.exe"
            writer = ei.WindowsScriptWriter
        if exec_param == sys.executable:
            # In case the path to the Python executable contains a space, wrap
            # it so it's not split up.
            exec_param = [exec_param]
        # resolve the writer to the environment
        writer = writer.best()
FILE: ./venv/Lib/site-packages/setuptools/command/py36compat.py
import os
from glob import glob
from distutils.util import convert_path
from distutils.command import sdist


class sdist_add_defaults:
    """
    Mix-in providing forward-compatibility for functionality as found in
    distutils on Python 3.7.

    Do not edit the code in this class except to update functionality
    as implemented in distutils. Instead, override in the subclass.
    """

    def add_defaults(self):
        """Add all the default files to self.filelist:
          - README or README.txt
          - setup.py
          - test/test*.py
          - all pure Python modules mentioned in setup script
          - all files pointed by package_data (build_py)
          - all files defined in data_files.
          - all files defined as scripts.
          - all C sources listed as part of extensions or C libraries
            in the setup script (doesn't catch C headers!)
        Warns if (README or README.txt) or setup.py are missing; everything
        else is optional.
        """
        self._add_defaults_standards()
        self._add_defaults_optional()
        self._add_defaults_python()
        self._add_defaults_data_files()
        self._add_defaults_ext()
        self._add_defaults_c_libs()
        self._add_defaults_scripts()

    @staticmethod
    def _cs_path_exists(fspath):
        """
        Case-sensitive path existence check

        >>> sdist_add_defaults._cs_path_exists(__file__)
        True
        >>> sdist_add_defaults._cs_path_exists(__file__.upper())
        False
        """
        if not os.path.exists(fspath):
            return False
        # make absolute so we always have a directory
FILE: ./venv/Lib/site-packages/setuptools/command/register.py
from distutils import log
import distutils.command.register as orig

from setuptools.errors import RemovedCommandError


class register(orig.register):
    """Formerly used to register packages on PyPI."""

    def run(self):
        msg = (
            "The register command has been removed, use twine to upload "
            + "instead (https://pypi.org/p/twine)"
        )

        self.announce("ERROR: " + msg, log.ERROR)

        raise RemovedCommandError(msg)
FILE: ./venv/Lib/site-packages/setuptools/command/rotate.py
from distutils.util import convert_path
from distutils import log
from distutils.errors import DistutilsOptionError
import os
import shutil

from setuptools import Command


class rotate(Command):
    """Delete older distributions"""

    description = "delete older distributions, keeping N newest files"
    user_options = [
        ('match=', 'm', "patterns to match (required)"),
        ('dist-dir=', 'd', "directory where the distributions are"),
        ('keep=', 'k', "number of matching distributions to keep"),
    ]

    boolean_options = []

    def initialize_options(self):
        self.match = None
        self.dist_dir = None
        self.keep = None

    def finalize_options(self):
        if self.match is None:
            raise DistutilsOptionError(
                "Must specify one or more (comma-separated) match patterns "
                "(e.g. '.zip' or '.egg')"
            )
        if self.keep is None:
            raise DistutilsOptionError("Must specify number of files to keep")
        try:
            self.keep = int(self.keep)
        except ValueError as e:
            raise DistutilsOptionError("--keep must be an integer") from e
        if isinstance(self.match, str):
            self.match = [
                convert_path(p.strip()) for p in self.match.split(',')
            ]
        self.set_undefined_options('bdist', ('dist_dir', 'dist_dir'))

    def run(self):
        self.run_command("egg_info")
        from glob import glob

        for pattern in self.match:
            pattern = self.distribution.get_name() + '*' + pattern
FILE: ./venv/Lib/site-packages/setuptools/command/saveopts.py
from setuptools.command.setopt import edit_config, option_base


class saveopts(option_base):
    """Save command-line options to a file"""

    description = "save supplied options to setup.cfg or other config file"

    def run(self):
        dist = self.distribution
        settings = {}

        for cmd in dist.command_options:

            if cmd == 'saveopts':
                continue  # don't save our own options!

            for opt, (src, val) in dist.get_option_dict(cmd).items():
                if src == "command line":
                    settings.setdefault(cmd, {})[opt] = val

        edit_config(self.filename, settings, self.dry_run)
FILE: ./venv/Lib/site-packages/setuptools/command/sdist.py
from distutils import log
import distutils.command.sdist as orig
import os
import sys
import io
import contextlib

from .py36compat import sdist_add_defaults

import pkg_resources

_default_revctrl = list


def walk_revctrl(dirname=''):
    """Find all files under revision control"""
    for ep in pkg_resources.iter_entry_points('setuptools.file_finders'):
        for item in ep.load()(dirname):
            yield item


class sdist(sdist_add_defaults, orig.sdist):
    """Smart sdist that finds anything supported by revision control"""

    user_options = [
        ('formats=', None,
         "formats for source distribution (comma-separated list)"),
        ('keep-temp', 'k',
         "keep the distribution tree around after creating " +
         "archive file(s)"),
        ('dist-dir=', 'd',
         "directory to put the source distribution archive(s) in "
         "[default: dist]"),
        ('owner=', 'u',
         "Owner name used when creating a tar file [default: current user]"),
        ('group=', 'g',
         "Group name used when creating a tar file [default: current group]"),
    ]

    negative_opt = {}

    README_EXTENSIONS = ['', '.rst', '.txt', '.md']
    READMES = tuple('README{0}'.format(ext) for ext in README_EXTENSIONS)

    def run(self):
        self.run_command('egg_info')
        ei_cmd = self.get_finalized_command('egg_info')
        self.filelist = ei_cmd.filelist
        self.filelist.append(os.path.join(ei_cmd.egg_info, 'SOURCES.txt'))
        self.check_readme()
FILE: ./venv/Lib/site-packages/setuptools/command/setopt.py
from distutils.util import convert_path
from distutils import log
from distutils.errors import DistutilsOptionError
import distutils
import os
import configparser

from setuptools import Command

__all__ = ['config_file', 'edit_config', 'option_base', 'setopt']


def config_file(kind="local"):
    """Get the filename of the distutils, local, global, or per-user config

    `kind` must be one of "local", "global", or "user"
    """
    if kind == 'local':
        return 'setup.cfg'
    if kind == 'global':
        return os.path.join(
            os.path.dirname(distutils.__file__), 'distutils.cfg'
        )
    if kind == 'user':
        dot = os.name == 'posix' and '.' or ''
        return os.path.expanduser(convert_path("~/%spydistutils.cfg" % dot))
    raise ValueError(
        "config_file() type must be 'local', 'global', or 'user'", kind
    )


def edit_config(filename, settings, dry_run=False):
    """Edit a configuration file to include `settings`

    `settings` is a dictionary of dictionaries or ``None`` values, keyed by
    command/section name.  A ``None`` value means to delete the entire section,
    while a dictionary lists settings to be changed or deleted in that section.
    A setting of ``None`` means to delete that setting.
    """
    log.debug("Reading configuration from %s", filename)
    opts = configparser.RawConfigParser()
    opts.optionxform = lambda x: x
    opts.read([filename])
    for section, options in settings.items():
        if options is None:
            log.info("Deleting section [%s] from %s", section, filename)
            opts.remove_section(section)
        else:
            if not opts.has_section(section):
                log.debug("Adding new section [%s] to %s", section, filename)
FILE: ./venv/Lib/site-packages/setuptools/command/test.py
import os
import operator
import sys
import contextlib
import itertools
import unittest
from distutils.errors import DistutilsError, DistutilsOptionError
from distutils import log
from unittest import TestLoader

from pkg_resources import (
    resource_listdir,
    resource_exists,
    normalize_path,
    working_set,
    evaluate_marker,
    add_activation_listener,
    require,
    EntryPoint,
)
from setuptools import Command
from setuptools.extern.more_itertools import unique_everseen


class ScanningLoader(TestLoader):
    def __init__(self):
        TestLoader.__init__(self)
        self._visited = set()

    def loadTestsFromModule(self, module, pattern=None):
        """Return a suite of all tests cases contained in the given module

        If the module is a package, load tests from all the modules in it.
        If the module has an ``additional_tests`` function, call it and add
        the return value to the tests.
        """
        if module in self._visited:
            return None
        self._visited.add(module)

        tests = []
        tests.append(TestLoader.loadTestsFromModule(self, module))

        if hasattr(module, "additional_tests"):
            tests.append(module.additional_tests())

        if hasattr(module, '__path__'):
            for file in resource_listdir(module.__name__, ''):
                if file.endswith('.py') and file != '__init__.py':
                    submodule = module.__name__ + '.' + file[:-3]
FILE: ./venv/Lib/site-packages/setuptools/command/upload.py
from distutils import log
from distutils.command import upload as orig

from setuptools.errors import RemovedCommandError


class upload(orig.upload):
    """Formerly used to upload packages to PyPI."""

    def run(self):
        msg = (
            "The upload command has been removed, use twine to upload "
            + "instead (https://pypi.org/p/twine)"
        )

        self.announce("ERROR: " + msg, log.ERROR)
        raise RemovedCommandError(msg)
FILE: ./venv/Lib/site-packages/setuptools/command/upload_docs.py
# -*- coding: utf-8 -*-
"""upload_docs

Implements a Distutils 'upload_docs' subcommand (upload documentation to
sites other than PyPi such as devpi).
"""

from base64 import standard_b64encode
from distutils import log
from distutils.errors import DistutilsOptionError
import os
import socket
import zipfile
import tempfile
import shutil
import itertools
import functools
import http.client
import urllib.parse

from pkg_resources import iter_entry_points
from .upload import upload


def _encode(s):
    return s.encode('utf-8', 'surrogateescape')


class upload_docs(upload):
    # override the default repository as upload_docs isn't
    # supported by Warehouse (and won't be).
    DEFAULT_REPOSITORY = 'https://pypi.python.org/pypi/'

    description = 'Upload documentation to sites other than PyPi such as devpi'

    user_options = [
        ('repository=', 'r',
         "url of repository [default: %s]" % upload.DEFAULT_REPOSITORY),
        ('show-response', None,
         'display full response text from server'),
        ('upload-dir=', None, 'directory to upload'),
    ]
    boolean_options = upload.boolean_options

    def has_sphinx(self):
        if self.upload_dir is None:
            for ep in iter_entry_points('distutils.commands', 'build_sphinx'):
                return True

    sub_commands = [('build_sphinx', has_sphinx)]
FILE: ./venv/Lib/site-packages/setuptools/command/__init__.py
from distutils.command.bdist import bdist
import sys

if 'egg' not in bdist.format_commands:
    bdist.format_command['egg'] = ('bdist_egg', "Python .egg file")
    bdist.format_commands.append('egg')

del bdist, sys
FILE: ./venv/Lib/site-packages/setuptools/config.py
import ast
import io
import os
import sys

import warnings
import functools
import importlib
from collections import defaultdict
from functools import partial
from functools import wraps
from glob import iglob
import contextlib

from distutils.errors import DistutilsOptionError, DistutilsFileError
from setuptools.extern.packaging.version import Version, InvalidVersion
from setuptools.extern.packaging.specifiers import SpecifierSet


class StaticModule:
    """
    Attempt to load the module by the name
    """

    def __init__(self, name):
        spec = importlib.util.find_spec(name)
        with open(spec.origin) as strm:
            src = strm.read()
        module = ast.parse(src)
        vars(self).update(locals())
        del self.self

    def __getattr__(self, attr):
        try:
            return next(
                ast.literal_eval(statement.value)
                for statement in self.module.body
                if isinstance(statement, ast.Assign)
                for target in statement.targets
                if isinstance(target, ast.Name) and target.id == attr
            )
        except Exception as e:
            raise AttributeError(
                "{self.name} has no attribute {attr}".format(**locals())
            ) from e


@contextlib.contextmanager
def patch_path(path):
    """
FILE: ./venv/Lib/site-packages/setuptools/depends.py
import sys
import marshal
import contextlib
import dis

from setuptools.extern.packaging import version

from ._imp import find_module, PY_COMPILED, PY_FROZEN, PY_SOURCE
from . import _imp


__all__ = [
    'Require', 'find_module', 'get_module_constant', 'extract_constant'
]


class Require:
    """A prerequisite to building or installing a distribution"""

    def __init__(
            self, name, requested_version, module, homepage='',
            attribute=None, format=None):

        if format is None and requested_version is not None:
            format = version.Version

        if format is not None:
            requested_version = format(requested_version)
            if attribute is None:
                attribute = '__version__'

        self.__dict__.update(locals())
        del self.self

    def full_name(self):
        """Return full package/distribution name, w/version"""
        if self.requested_version is not None:
            return '%s-%s' % (self.name, self.requested_version)
        return self.name

    def version_ok(self, version):
        """Is 'version' sufficiently up-to-date?"""
        return self.attribute is None or self.format is None or \
            str(version) != "unknown" and self.format(version) >= self.requested_version

    def get_version(self, paths=None, default="unknown"):
        """Get version number of installed module, 'None', or 'default'

        Search 'paths' for module.  If not found, return 'None'.  If found,
        return the extracted version attribute, or 'default' if no version
FILE: ./venv/Lib/site-packages/setuptools/dep_util.py
from distutils.dep_util import newer_group


# yes, this is was almost entirely copy-pasted from
# 'newer_pairwise()', this is just another convenience
# function.
def newer_pairwise_group(sources_groups, targets):
    """Walk both arguments in parallel, testing if each source group is newer
    than its corresponding target. Returns a pair of lists (sources_groups,
    targets) where sources is newer than target, according to the semantics
    of 'newer_group()'.
    """
    if len(sources_groups) != len(targets):
        raise ValueError(
            "'sources_group' and 'targets' must be the same length")

    # build a pair of lists (sources_groups, targets) where source is newer
    n_sources = []
    n_targets = []
    for i in range(len(sources_groups)):
        if newer_group(sources_groups[i], targets[i]):
            n_sources.append(sources_groups[i])
            n_targets.append(targets[i])

    return n_sources, n_targets
FILE: ./venv/Lib/site-packages/setuptools/dist.py
# -*- coding: utf-8 -*-
__all__ = ['Distribution']

import io
import sys
import re
import os
import warnings
import numbers
import distutils.log
import distutils.core
import distutils.cmd
import distutils.dist
import distutils.command
from distutils.util import strtobool
from distutils.debug import DEBUG
from distutils.fancy_getopt import translate_longopt
from glob import iglob
import itertools
import textwrap
from typing import List, Optional, TYPE_CHECKING

from collections import defaultdict
from email import message_from_file

from distutils.errors import DistutilsOptionError, DistutilsSetupError
from distutils.util import rfc822_escape

from setuptools.extern import packaging
from setuptools.extern import ordered_set
from setuptools.extern.more_itertools import unique_everseen

from . import SetuptoolsDeprecationWarning

import setuptools
import setuptools.command
from setuptools import windows_support
from setuptools.monkey import get_unpatched
from setuptools.config import parse_configuration
import pkg_resources
from setuptools.extern.packaging import version

if TYPE_CHECKING:
    from email.message import Message

__import__('setuptools.extern.packaging.specifiers')
__import__('setuptools.extern.packaging.version')


def _get_unpatched(cls):
FILE: ./venv/Lib/site-packages/setuptools/errors.py
"""setuptools.errors

Provides exceptions used by setuptools modules.
"""

from distutils import errors as _distutils_errors
from distutils.errors import DistutilsError


class RemovedCommandError(DistutilsError, RuntimeError):
    """Error used for commands that have been removed in setuptools.

    Since ``setuptools`` is built on ``distutils``, simply removing a command
    from ``setuptools`` will make the behavior fall back to ``distutils``; this
    error is raised if a command exists in ``distutils`` but has been actively
    removed in ``setuptools``.
    """


# Re-export errors from distutils to facilitate the migration to PEP632

ByteCompileError = _distutils_errors.DistutilsByteCompileError
CCompilerError = _distutils_errors.CCompilerError
ClassError = _distutils_errors.DistutilsClassError
CompileError = _distutils_errors.CompileError
ExecError = _distutils_errors.DistutilsExecError
FileError = _distutils_errors.DistutilsFileError
InternalError = _distutils_errors.DistutilsInternalError
LibError = _distutils_errors.LibError
LinkError = _distutils_errors.LinkError
ModuleError = _distutils_errors.DistutilsModuleError
OptionError = _distutils_errors.DistutilsOptionError
PlatformError = _distutils_errors.DistutilsPlatformError
PreprocessError = _distutils_errors.PreprocessError
SetupError = _distutils_errors.DistutilsSetupError
TemplateError = _distutils_errors.DistutilsTemplateError
UnknownFileError = _distutils_errors.UnknownFileError

# The root error class in the hierarchy
BaseError = _distutils_errors.DistutilsError
FILE: ./venv/Lib/site-packages/setuptools/extension.py
import re
import functools
import distutils.core
import distutils.errors
import distutils.extension

from .monkey import get_unpatched


def _have_cython():
    """
    Return True if Cython can be imported.
    """
    cython_impl = 'Cython.Distutils.build_ext'
    try:
        # from (cython_impl) import build_ext
        __import__(cython_impl, fromlist=['build_ext']).build_ext
        return True
    except Exception:
        pass
    return False


# for compatibility
have_pyrex = _have_cython

_Extension = get_unpatched(distutils.core.Extension)


class Extension(_Extension):
    """Extension that uses '.c' files in place of '.pyx' files"""

    def __init__(self, name, sources, *args, **kw):
        # The *args is needed for compatibility as calls may use positional
        # arguments. py_limited_api may be set only via keyword.
        self.py_limited_api = kw.pop("py_limited_api", False)
        _Extension.__init__(self, name, sources, *args, **kw)

    def _convert_pyx_sources_to_lang(self):
        """
        Replace sources with .pyx extensions to sources with the target
        language extension. This mechanism allows language authors to supply
        pre-converted sources but to prefer the .pyx sources.
        """
        if _have_cython():
            # the build has Cython, so allow it to compile the .pyx files
            return
        lang = self.language or ''
        target_ext = '.cpp' if lang.lower() == 'c++' else '.c'
        sub = functools.partial(re.sub, '.pyx$', target_ext)
FILE: ./venv/Lib/site-packages/setuptools/extern/__init__.py
import importlib.util
import sys


class VendorImporter:
    """
    A PEP 302 meta path importer for finding optionally-vendored
    or otherwise naturally-installed packages from root_name.
    """

    def __init__(self, root_name, vendored_names=(), vendor_pkg=None):
        self.root_name = root_name
        self.vendored_names = set(vendored_names)
        self.vendor_pkg = vendor_pkg or root_name.replace('extern', '_vendor')

    @property
    def search_path(self):
        """
        Search first the vendor package then as a natural package.
        """
        yield self.vendor_pkg + '.'
        yield ''

    def _module_matches_namespace(self, fullname):
        """Figure out if the target module is vendored."""
        root, base, target = fullname.partition(self.root_name + '.')
        return not root and any(map(target.startswith, self.vendored_names))

    def load_module(self, fullname):
        """
        Iterate over the search path to locate and load fullname.
        """
        root, base, target = fullname.partition(self.root_name + '.')
        for prefix in self.search_path:
            try:
                extant = prefix + target
                __import__(extant)
                mod = sys.modules[extant]
                sys.modules[fullname] = mod
                return mod
            except ImportError:
                pass
        else:
            raise ImportError(
                "The '{target}' package is required; "
                "normally this is bundled with this package so if you get "
                "this warning, consult the packager of your "
                "distribution.".format(**locals())
            )

FILE: ./venv/Lib/site-packages/setuptools/glob.py
"""
Filename globbing utility. Mostly a copy of `glob` from Python 3.5.

Changes include:
 * `yield from` and PEP3102 `*` removed.
 * Hidden files are not ignored.
"""

import os
import re
import fnmatch

__all__ = ["glob", "iglob", "escape"]


def glob(pathname, recursive=False):
    """Return a list of paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. However, unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns.

    If recursive is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    """
    return list(iglob(pathname, recursive=recursive))


def iglob(pathname, recursive=False):
    """Return an iterator which yields the paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. However, unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns.

    If recursive is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    """
    it = _iglob(pathname, recursive)
    if recursive and _isrecursive(pathname):
        s = next(it)  # skip empty string
        assert not s
    return it


def _iglob(pathname, recursive):
    dirname, basename = os.path.split(pathname)
    glob_in_dir = glob2 if recursive and _isrecursive(basename) else glob1
FILE: ./venv/Lib/site-packages/setuptools/installer.py
import glob
import os
import subprocess
import sys
import tempfile
import warnings
from distutils import log
from distutils.errors import DistutilsError

import pkg_resources
from setuptools.wheel import Wheel
from ._deprecation_warning import SetuptoolsDeprecationWarning


def _fixup_find_links(find_links):
    """Ensure find-links option end-up being a list of strings."""
    if isinstance(find_links, str):
        return find_links.split()
    assert isinstance(find_links, (tuple, list))
    return find_links


def fetch_build_egg(dist, req):  # noqa: C901  # is too complex (16)  # FIXME
    """Fetch an egg needed for building.

    Use pip/wheel to fetch/build a wheel."""
    warnings.warn(
        "setuptools.installer is deprecated. Requirements should "
        "be satisfied by a PEP 517 installer.",
        SetuptoolsDeprecationWarning,
    )
    # Warn if wheel is not available
    try:
        pkg_resources.get_distribution('wheel')
    except pkg_resources.DistributionNotFound:
        dist.announce('WARNING: The wheel package is not available.', log.WARN)
    # Ignore environment markers; if supplied, it is required.
    req = strip_marker(req)
    # Take easy_install options into account, but do not override relevant
    # pip environment variables (like PIP_INDEX_URL or PIP_QUIET); they'll
    # take precedence.
    opts = dist.get_option_dict('easy_install')
    if 'allow_hosts' in opts:
        raise DistutilsError('the `allow-hosts` option is not supported '
                             'when using pip to install requirements.')
    quiet = 'PIP_QUIET' not in os.environ and 'PIP_VERBOSE' not in os.environ
    if 'PIP_INDEX_URL' in os.environ:
        index_url = None
    elif 'index_url' in opts:
        index_url = opts['index_url'][1]
FILE: ./venv/Lib/site-packages/setuptools/launch.py
"""
Launch the Python script on the command line after
setuptools is bootstrapped via import.
"""

# Note that setuptools gets imported implicitly by the
# invocation of this script using python -m setuptools.launch

import tokenize
import sys


def run():
    """
    Run the script in sys.argv[1] as if it had
    been invoked naturally.
    """
    __builtins__
    script_name = sys.argv[1]
    namespace = dict(
        __file__=script_name,
        __name__='__main__',
        __doc__=None,
    )
    sys.argv[:] = sys.argv[1:]

    open_ = getattr(tokenize, 'open', open)
    with open_(script_name) as fid:
        script = fid.read()
    norm_script = script.replace('\\r\\n', '\\n')
    code = compile(norm_script, script_name, 'exec')
    exec(code, namespace)


if __name__ == '__main__':
    run()
FILE: ./venv/Lib/site-packages/setuptools/logging.py
import sys
import logging
import distutils.log
from . import monkey


def _not_warning(record):
    return record.levelno < logging.WARNING


def configure():
    """
    Configure logging to emit warning and above to stderr
    and everything else to stdout. This behavior is provided
    for compatibilty with distutils.log but may change in
    the future.
    """
    err_handler = logging.StreamHandler()
    err_handler.setLevel(logging.WARNING)
    out_handler = logging.StreamHandler(sys.stdout)
    out_handler.addFilter(_not_warning)
    handlers = err_handler, out_handler
    logging.basicConfig(
        format="{message}", style='{', handlers=handlers, level=logging.DEBUG)
    monkey.patch_func(set_threshold, distutils.log, 'set_threshold')


def set_threshold(level):
    logging.root.setLevel(level*10)
    return set_threshold.unpatched(level)
FILE: ./venv/Lib/site-packages/setuptools/monkey.py
"""
Monkey patching of distutils.
"""

import sys
import distutils.filelist
import platform
import types
import functools
from importlib import import_module
import inspect

import setuptools

__all__ = []
"""
Everything is private. Contact the project team
if you think you need this functionality.
"""


def _get_mro(cls):
    """
    Returns the bases classes for cls sorted by the MRO.

    Works around an issue on Jython where inspect.getmro will not return all
    base classes if multiple classes share the same name. Instead, this
    function will return a tuple containing the class itself, and the contents
    of cls.__bases__. See https://github.com/pypa/setuptools/issues/1024.
    """
    if platform.python_implementation() == "Jython":
        return (cls,) + cls.__bases__
    return inspect.getmro(cls)


def get_unpatched(item):
    lookup = (
        get_unpatched_class if isinstance(item, type) else
        get_unpatched_function if isinstance(item, types.FunctionType) else
        lambda item: None
    )
    return lookup(item)


def get_unpatched_class(cls):
    """Protect against re-patching the distutils if reloaded

    Also ensures that no other distutils extension monkeypatched the distutils
    first.
    """
FILE: ./venv/Lib/site-packages/setuptools/msvc.py
"""
Improved support for Microsoft Visual C++ compilers.

Known supported compilers:
--------------------------
Microsoft Visual C++ 9.0:
    Microsoft Visual C++ Compiler for Python 2.7 (x86, amd64)
    Microsoft Windows SDK 6.1 (x86, x64, ia64)
    Microsoft Windows SDK 7.0 (x86, x64, ia64)

Microsoft Visual C++ 10.0:
    Microsoft Windows SDK 7.1 (x86, x64, ia64)

Microsoft Visual C++ 14.X:
    Microsoft Visual C++ Build Tools 2015 (x86, x64, arm)
    Microsoft Visual Studio Build Tools 2017 (x86, x64, arm, arm64)
    Microsoft Visual Studio Build Tools 2019 (x86, x64, arm, arm64)

This may also support compilers shipped with compatible Visual Studio versions.
"""

import json
from io import open
from os import listdir, pathsep
from os.path import join, isfile, isdir, dirname
import sys
import contextlib
import platform
import itertools
import subprocess
import distutils.errors
from setuptools.extern.packaging.version import LegacyVersion
from setuptools.extern.more_itertools import unique_everseen

from .monkey import get_unpatched

if platform.system() == 'Windows':
    import winreg
    from os import environ
else:
    # Mock winreg and environ so the module can be imported on this platform.

    class winreg:
        HKEY_USERS = None
        HKEY_CURRENT_USER = None
        HKEY_LOCAL_MACHINE = None
        HKEY_CLASSES_ROOT = None

    environ = dict()

FILE: ./venv/Lib/site-packages/setuptools/namespaces.py
import os
from distutils import log
import itertools


flatten = itertools.chain.from_iterable


class Installer:

    nspkg_ext = '-nspkg.pth'

    def install_namespaces(self):
        nsp = self._get_all_ns_packages()
        if not nsp:
            return
        filename, ext = os.path.splitext(self._get_target())
        filename += self.nspkg_ext
        self.outputs.append(filename)
        log.info("Installing %s", filename)
        lines = map(self._gen_nspkg_line, nsp)

        if self.dry_run:
            # always generate the lines, even in dry run
            list(lines)
            return

        with open(filename, 'wt') as f:
            f.writelines(lines)

    def uninstall_namespaces(self):
        filename, ext = os.path.splitext(self._get_target())
        filename += self.nspkg_ext
        if not os.path.exists(filename):
            return
        log.info("Removing %s", filename)
        os.remove(filename)

    def _get_target(self):
        return self.target

    _nspkg_tmpl = (
        "import sys, types, os",
        "has_mfs = sys.version_info > (3, 5)",
        "p = os.path.join(%(root)s, *%(pth)r)",
        "importlib = has_mfs and __import__('importlib.util')",
        "has_mfs and __import__('importlib.machinery')",
        (
            "m = has_mfs and "
            "sys.modules.setdefault(%(pkg)r, "
FILE: ./venv/Lib/site-packages/setuptools/package_index.py
"""PyPI and direct package downloading"""
import sys
import os
import re
import io
import shutil
import socket
import base64
import hashlib
import itertools
import warnings
import configparser
import html
import http.client
import urllib.parse
import urllib.request
import urllib.error
from functools import wraps

import setuptools
from pkg_resources import (
    CHECKOUT_DIST, Distribution, BINARY_DIST, normalize_path, SOURCE_DIST,
    Environment, find_distributions, safe_name, safe_version,
    to_filename, Requirement, DEVELOP_DIST, EGG_DIST, parse_version,
)
from distutils import log
from distutils.errors import DistutilsError
from fnmatch import translate
from setuptools.wheel import Wheel
from setuptools.extern.more_itertools import unique_everseen


EGG_FRAGMENT = re.compile(r'^egg=([-A-Za-z0-9_.+!]+)$')
HREF = re.compile(r"""href\s*=\s*['"]?([^'"> ]+)""", re.I)
PYPI_MD5 = re.compile(
    r'<a href="([^"#]+)">([^<]+)</a>\n\s+\(<a (?:title="MD5 hash"\n\s+)'
    r'href="[^?]+\?:action=show_md5&amp;digest=([0-9a-f]{32})">md5</a>\)'
)
URL_SCHEME = re.compile('([-+.a-z0-9]{2,}):', re.I).match
EXTENSIONS = ".tar.gz .tar.bz2 .tar .zip .tgz".split()

__all__ = [
    'PackageIndex', 'distros_for_url', 'parse_bdist_wininst',
    'interpret_distro_name',
]

_SOCKET_TIMEOUT = 15

_tmpl = "setuptools/{setuptools.__version__} Python-urllib/{py_major}"
user_agent = _tmpl.format(
FILE: ./venv/Lib/site-packages/setuptools/py34compat.py
import importlib

try:
    import importlib.util
except ImportError:
    pass


try:
    module_from_spec = importlib.util.module_from_spec
except AttributeError:
    def module_from_spec(spec):
        return spec.loader.load_module(spec.name)
FILE: ./venv/Lib/site-packages/setuptools/sandbox.py
import os
import sys
import tempfile
import operator
import functools
import itertools
import re
import contextlib
import pickle
import textwrap
import builtins

import pkg_resources
from distutils.errors import DistutilsError
from pkg_resources import working_set

if sys.platform.startswith('java'):
    import org.python.modules.posix.PosixModule as _os
else:
    _os = sys.modules[os.name]
try:
    _file = file
except NameError:
    _file = None
_open = open


__all__ = [
    "AbstractSandbox",
    "DirectorySandbox",
    "SandboxViolation",
    "run_setup",
]


def _execfile(filename, globals, locals=None):
    """
    Python 3 implementation of execfile.
    """
    mode = 'rb'
    with open(filename, mode) as stream:
        script = stream.read()
    if locals is None:
        locals = globals
    code = compile(script, filename, 'exec')
    exec(code, globals, locals)


@contextlib.contextmanager
def save_argv(repl=None):
FILE: ./venv/Lib/site-packages/setuptools/unicode_utils.py
import unicodedata
import sys


# HFS Plus uses decomposed UTF-8
def decompose(path):
    if isinstance(path, str):
        return unicodedata.normalize('NFD', path)
    try:
        path = path.decode('utf-8')
        path = unicodedata.normalize('NFD', path)
        path = path.encode('utf-8')
    except UnicodeError:
        pass  # Not UTF-8
    return path


def filesys_decode(path):
    """
    Ensure that the given path is decoded,
    NONE when no expected encoding works
    """

    if isinstance(path, str):
        return path

    fs_enc = sys.getfilesystemencoding() or 'utf-8'
    candidates = fs_enc, 'utf-8'

    for enc in candidates:
        try:
            return path.decode(enc)
        except UnicodeDecodeError:
            continue


def try_encode(string, enc):
    "turn unicode encoding into a functional routine"
    try:
        return string.encode(enc)
    except UnicodeEncodeError:
        return None
FILE: ./venv/Lib/site-packages/setuptools/version.py
import pkg_resources

try:
    __version__ = pkg_resources.get_distribution('setuptools').version
except Exception:
    __version__ = 'unknown'
FILE: ./venv/Lib/site-packages/setuptools/wheel.py
"""Wheels support."""

from distutils.util import get_platform
from distutils import log
import email
import itertools
import os
import posixpath
import re
import zipfile

import pkg_resources
import setuptools
from pkg_resources import parse_version
from setuptools.extern.packaging.tags import sys_tags
from setuptools.extern.packaging.utils import canonicalize_name
from setuptools.command.egg_info import write_requirements


WHEEL_NAME = re.compile(
    r"""^(?P<project_name>.+?)-(?P<version>\d.*?)
    ((-(?P<build>\d.*?))?-(?P<py_version>.+?)-(?P<abi>.+?)-(?P<platform>.+?)
    )\.whl$""",
    re.VERBOSE).match

NAMESPACE_PACKAGE_INIT = \
    "__import__('pkg_resources').declare_namespace(__name__)\n"


def unpack(src_dir, dst_dir):
    '''Move everything under `src_dir` to `dst_dir`, and delete the former.'''
    for dirpath, dirnames, filenames in os.walk(src_dir):
        subdir = os.path.relpath(dirpath, src_dir)
        for f in filenames:
            src = os.path.join(dirpath, f)
            dst = os.path.join(dst_dir, subdir, f)
            os.renames(src, dst)
        for n, d in reversed(list(enumerate(dirnames))):
            src = os.path.join(dirpath, d)
            dst = os.path.join(dst_dir, subdir, d)
            if not os.path.exists(dst):
                # Directory does not exist in destination,
                # rename it and prune it from os.walk list.
                os.renames(src, dst)
                del dirnames[n]
    # Cleanup.
    for dirpath, dirnames, filenames in os.walk(src_dir, topdown=True):
        assert not filenames
        os.rmdir(dirpath)

FILE: ./venv/Lib/site-packages/setuptools/windows_support.py
import platform
import ctypes


def windows_only(func):
    if platform.system() != 'Windows':
        return lambda *args, **kwargs: None
    return func


@windows_only
def hide_file(path):
    """
    Set the hidden attribute on a file or directory.

    From http://stackoverflow.com/questions/19622133/

    `path` must be text.
    """
    __import__('ctypes.wintypes')
    SetFileAttributes = ctypes.windll.kernel32.SetFileAttributesW
    SetFileAttributes.argtypes = ctypes.wintypes.LPWSTR, ctypes.wintypes.DWORD
    SetFileAttributes.restype = ctypes.wintypes.BOOL

    FILE_ATTRIBUTE_HIDDEN = 0x02

    ret = SetFileAttributes(path, FILE_ATTRIBUTE_HIDDEN)
    if not ret:
        raise ctypes.WinError()
FILE: ./venv/Lib/site-packages/setuptools/_deprecation_warning.py
class SetuptoolsDeprecationWarning(Warning):
    """
    Base class for warning deprecations in ``setuptools``

    This class is not derived from ``DeprecationWarning``, and as such is
    visible by default.
    """
FILE: ./venv/Lib/site-packages/setuptools/_distutils/archive_util.py
"""distutils.archive_util

Utility functions for creating archive files (tarballs, zip files,
that sort of thing)."""

import os
from warnings import warn
import sys

try:
    import zipfile
except ImportError:
    zipfile = None


from distutils.errors import DistutilsExecError
from distutils.spawn import spawn
from distutils.dir_util import mkpath
from distutils import log

try:
    from pwd import getpwnam
except ImportError:
    getpwnam = None

try:
    from grp import getgrnam
except ImportError:
    getgrnam = None

def _get_gid(name):
    """Returns a gid, given a group name."""
    if getgrnam is None or name is None:
        return None
    try:
        result = getgrnam(name)
    except KeyError:
        result = None
    if result is not None:
        return result[2]
    return None

def _get_uid(name):
    """Returns an uid, given a user name."""
    if getpwnam is None or name is None:
        return None
    try:
        result = getpwnam(name)
    except KeyError:
        result = None
FILE: ./venv/Lib/site-packages/setuptools/_distutils/bcppcompiler.py
"""distutils.bcppcompiler

Contains BorlandCCompiler, an implementation of the abstract CCompiler class
for the Borland C++ compiler.
"""

# This implementation by Lyle Johnson, based on the original msvccompiler.py
# module and using the directions originally published by Gordon Williams.

# XXX looks like there's a LOT of overlap between these two classes:
# someone should sit down and factor out the common code as
# WindowsCCompiler!  --GPW


import os
from distutils.errors import \
     DistutilsExecError, \
     CompileError, LibError, LinkError, UnknownFileError
from distutils.ccompiler import \
     CCompiler, gen_preprocess_options
from distutils.file_util import write_file
from distutils.dep_util import newer
from distutils import log

class BCPPCompiler(CCompiler) :
    """Concrete class that implements an interface to the Borland C/C++
    compiler, as defined by the CCompiler abstract class.
    """

    compiler_type = 'bcpp'

    # Just set this so CCompiler's constructor doesn't barf.  We currently
    # don't use the 'set_executables()' bureaucracy provided by CCompiler,
    # as it really isn't necessary for this sort of single-compiler class.
    # Would be nice to have a consistent interface with UnixCCompiler,
    # though, so it's worth thinking about.
    executables = {}

    # Private class data (need to distinguish C from C++ source for compiler)
    _c_extensions = ['.c']
    _cpp_extensions = ['.cc', '.cpp', '.cxx']

    # Needed for the filename generation methods provided by the
    # base class, CCompiler.
    src_extensions = _c_extensions + _cpp_extensions
    obj_extension = '.obj'
    static_lib_extension = '.lib'
    shared_lib_extension = '.dll'
    static_lib_format = shared_lib_format = '%s%s'
    exe_extension = '.exe'
FILE: ./venv/Lib/site-packages/setuptools/_distutils/ccompiler.py
"""distutils.ccompiler

Contains CCompiler, an abstract base class that defines the interface
for the Distutils compiler abstraction model."""

import sys, os, re
from distutils.errors import *
from distutils.spawn import spawn
from distutils.file_util import move_file
from distutils.dir_util import mkpath
from distutils.dep_util import newer_group
from distutils.util import split_quoted, execute
from distutils import log

class CCompiler:
    """Abstract base class to define the interface that must be implemented
    by real compiler classes.  Also has some utility methods used by
    several compiler classes.

    The basic idea behind a compiler abstraction class is that each
    instance can be used for all the compile/link steps in building a
    single project.  Thus, attributes common to all of those compile and
    link steps -- include directories, macros to define, libraries to link
    against, etc. -- are attributes of the compiler instance.  To allow for
    variability in how individual files are treated, most of those
    attributes may be varied on a per-compilation or per-link basis.
    """

    # 'compiler_type' is a class attribute that identifies this class.  It
    # keeps code that wants to know what kind of compiler it's dealing with
    # from having to import all possible compiler classes just to do an
    # 'isinstance'.  In concrete CCompiler subclasses, 'compiler_type'
    # should really, really be one of the keys of the 'compiler_class'
    # dictionary (see below -- used by the 'new_compiler()' factory
    # function) -- authors of new compiler interface classes are
    # responsible for updating 'compiler_class'!
    compiler_type = None

    # XXX things not handled by this compiler abstraction model:
    #   * client can't provide additional options for a compiler,
    #     e.g. warning, optimization, debugging flags.  Perhaps this
    #     should be the domain of concrete compiler abstraction classes
    #     (UnixCCompiler, MSVCCompiler, etc.) -- or perhaps the base
    #     class should have methods for the common ones.
    #   * can't completely override the include or library searchg
    #     path, ie. no "cc -I -Idir1 -Idir2" or "cc -L -Ldir1 -Ldir2".
    #     I'm not sure how widely supported this is even by Unix
    #     compilers, much less on other platforms.  And I'm even less
    #     sure how useful it is; maybe for cross-compiling, but
    #     support for that is a ways off.  (And anyways, cross
FILE: ./venv/Lib/site-packages/setuptools/_distutils/cmd.py
"""distutils.cmd

Provides the Command class, the base class for the command classes
in the distutils.command package.
"""

import sys, os, re
from distutils.errors import DistutilsOptionError
from distutils import util, dir_util, file_util, archive_util, dep_util
from distutils import log

class Command:
    """Abstract base class for defining command classes, the "worker bees"
    of the Distutils.  A useful analogy for command classes is to think of
    them as subroutines with local variables called "options".  The options
    are "declared" in 'initialize_options()' and "defined" (given their
    final values, aka "finalized") in 'finalize_options()', both of which
    must be defined by every command class.  The distinction between the
    two is necessary because option values might come from the outside
    world (command line, config file, ...), and any options dependent on
    other options must be computed *after* these outside influences have
    been processed -- hence 'finalize_options()'.  The "body" of the
    subroutine, where it does all its work based on the values of its
    options, is the 'run()' method, which must also be implemented by every
    command class.
    """

    # 'sub_commands' formalizes the notion of a "family" of commands,
    # eg. "install" as the parent with sub-commands "install_lib",
    # "install_headers", etc.  The parent of a family of commands
    # defines 'sub_commands' as a class attribute; it's a list of
    #    (command_name : string, predicate : unbound_method | string | None)
    # tuples, where 'predicate' is a method of the parent command that
    # determines whether the corresponding command is applicable in the
    # current situation.  (Eg. we "install_headers" is only applicable if
    # we have any C header files to install.)  If 'predicate' is None,
    # that command is always applicable.
    #
    # 'sub_commands' is usually defined at the *end* of a class, because
    # predicates can be unbound methods, so they must already have been
    # defined.  The canonical example is the "install" command.
    sub_commands = []


    # -- Creation/initialization methods -------------------------------

    def __init__(self, dist):
        """Create and initialize a new Command object.  Most importantly,
        invokes the 'initialize_options()' method, which is the real
        initializer and depends on the actual command being
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/bdist.py
"""distutils.command.bdist

Implements the Distutils 'bdist' command (create a built [binary]
distribution)."""

import os
from distutils.core import Command
from distutils.errors import *
from distutils.util import get_platform


def show_formats():
    """Print list of available formats (arguments to "--format" option).
    """
    from distutils.fancy_getopt import FancyGetopt
    formats = []
    for format in bdist.format_commands:
        formats.append(("formats=" + format, None,
                        bdist.format_command[format][1]))
    pretty_printer = FancyGetopt(formats)
    pretty_printer.print_help("List of available distribution formats:")


class bdist(Command):

    description = "create a built (binary) distribution"

    user_options = [('bdist-base=', 'b',
                     "temporary directory for creating built distributions"),
                    ('plat-name=', 'p',
                     "platform name to embed in generated filenames "
                     "(default: %s)" % get_platform()),
                    ('formats=', None,
                     "formats for distribution (comma-separated list)"),
                    ('dist-dir=', 'd',
                     "directory to put final built distributions in "
                     "[default: dist]"),
                    ('skip-build', None,
                     "skip rebuilding everything (for testing/debugging)"),
                    ('owner=', 'u',
                     "Owner name used when creating a tar file"
                     " [default: current user]"),
                    ('group=', 'g',
                     "Group name used when creating a tar file"
                     " [default: current group]"),
                   ]

    boolean_options = ['skip-build']

    help_options = [
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/bdist_dumb.py
"""distutils.command.bdist_dumb

Implements the Distutils 'bdist_dumb' command (create a "dumb" built
distribution -- i.e., just an archive to be unpacked under $prefix or
$exec_prefix)."""

import os
from distutils.core import Command
from distutils.util import get_platform
from distutils.dir_util import remove_tree, ensure_relative
from distutils.errors import *
from distutils.sysconfig import get_python_version
from distutils import log

class bdist_dumb(Command):

    description = "create a \"dumb\" built distribution"

    user_options = [('bdist-dir=', 'd',
                     "temporary directory for creating the distribution"),
                    ('plat-name=', 'p',
                     "platform name to embed in generated filenames "
                     "(default: %s)" % get_platform()),
                    ('format=', 'f',
                     "archive format to create (tar, gztar, bztar, xztar, "
                     "ztar, zip)"),
                    ('keep-temp', 'k',
                     "keep the pseudo-installation tree around after " +
                     "creating the distribution archive"),
                    ('dist-dir=', 'd',
                     "directory to put final built distributions in"),
                    ('skip-build', None,
                     "skip rebuilding everything (for testing/debugging)"),
                    ('relative', None,
                     "build the archive using relative paths "
                     "(default: false)"),
                    ('owner=', 'u',
                     "Owner name used when creating a tar file"
                     " [default: current user]"),
                    ('group=', 'g',
                     "Group name used when creating a tar file"
                     " [default: current group]"),
                   ]

    boolean_options = ['keep-temp', 'skip-build', 'relative']

    default_format = { 'posix': 'gztar',
                       'nt': 'zip' }

    def initialize_options(self):
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/bdist_msi.py
# Copyright (C) 2005, 2006 Martin von Löwis
# Licensed to PSF under a Contributor Agreement.
# The bdist_wininst command proper
# based on bdist_wininst
"""
Implements the bdist_msi command.
"""

import os
import sys
import warnings
from distutils.core import Command
from distutils.dir_util import remove_tree
from distutils.sysconfig import get_python_version
from distutils.version import StrictVersion
from distutils.errors import DistutilsOptionError
from distutils.util import get_platform
from distutils import log
import msilib
from msilib import schema, sequence, text
from msilib import Directory, Feature, Dialog, add_data

class PyDialog(Dialog):
    """Dialog class with a fixed layout: controls at the top, then a ruler,
    then a list of buttons: back, next, cancel. Optionally a bitmap at the
    left."""
    def __init__(self, *args, **kw):
        """Dialog(database, name, x, y, w, h, attributes, title, first,
        default, cancel, bitmap=true)"""
        Dialog.__init__(self, *args)
        ruler = self.h - 36
        bmwidth = 152*ruler/328
        #if kw.get("bitmap", True):
        #    self.bitmap("Bitmap", 0, 0, bmwidth, ruler, "PythonWin")
        self.line("BottomLine", 0, ruler, self.w, 0)

    def title(self, title):
        "Set the title text of the dialog at the top."
        # name, x, y, w, h, flags=Visible|Enabled|Transparent|NoPrefix,
        # text, in VerdanaBold10
        self.text("Title", 15, 10, 320, 60, 0x30003,
                  r"{\VerdanaBold10}%s" % title)

    def back(self, title, next, name = "Back", active = 1):
        """Add a back button with a given title, the tab-next button,
        its name in the Control table, possibly initially disabled.

        Return the button, so that events can be associated"""
        if active:
            flags = 3 # Visible|Enabled
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/bdist_rpm.py
"""distutils.command.bdist_rpm

Implements the Distutils 'bdist_rpm' command (create RPM source and binary
distributions)."""

import subprocess, sys, os
from distutils.core import Command
from distutils.debug import DEBUG
from distutils.file_util import write_file
from distutils.errors import *
from distutils.sysconfig import get_python_version
from distutils import log

class bdist_rpm(Command):

    description = "create an RPM distribution"

    user_options = [
        ('bdist-base=', None,
         "base directory for creating built distributions"),
        ('rpm-base=', None,
         "base directory for creating RPMs (defaults to \"rpm\" under "
         "--bdist-base; must be specified for RPM 2)"),
        ('dist-dir=', 'd',
         "directory to put final RPM files in "
         "(and .spec files if --spec-only)"),
        ('python=', None,
         "path to Python interpreter to hard-code in the .spec file "
         "(default: \"python\")"),
        ('fix-python', None,
         "hard-code the exact path to the current Python interpreter in "
         "the .spec file"),
        ('spec-only', None,
         "only regenerate spec file"),
        ('source-only', None,
         "only generate source RPM"),
        ('binary-only', None,
         "only generate binary RPM"),
        ('use-bzip2', None,
         "use bzip2 instead of gzip to create source distribution"),

        # More meta-data: too RPM-specific to put in the setup script,
        # but needs to go in the .spec file -- so we make these options
        # to "bdist_rpm".  The idea is that packagers would put this
        # info in setup.cfg, although they are of course free to
        # supply it on the command line.
        ('distribution-name=', None,
         "name of the (Linux) distribution to which this "
         "RPM applies (*not* the name of the module distribution!)"),
        ('group=', None,
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/bdist_wininst.py
"""distutils.command.bdist_wininst

Implements the Distutils 'bdist_wininst' command: create a windows installer
exe-program."""

import os
import sys
import warnings
from distutils.core import Command
from distutils.util import get_platform
from distutils.dir_util import remove_tree
from distutils.errors import *
from distutils.sysconfig import get_python_version
from distutils import log

class bdist_wininst(Command):

    description = "create an executable installer for MS Windows"

    user_options = [('bdist-dir=', None,
                     "temporary directory for creating the distribution"),
                    ('plat-name=', 'p',
                     "platform name to embed in generated filenames "
                     "(default: %s)" % get_platform()),
                    ('keep-temp', 'k',
                     "keep the pseudo-installation tree around after " +
                     "creating the distribution archive"),
                    ('target-version=', None,
                     "require a specific python version" +
                     " on the target system"),
                    ('no-target-compile', 'c',
                     "do not compile .py to .pyc on the target system"),
                    ('no-target-optimize', 'o',
                     "do not compile .py to .pyo (optimized) "
                     "on the target system"),
                    ('dist-dir=', 'd',
                     "directory to put final built distributions in"),
                    ('bitmap=', 'b',
                     "bitmap to use for the installer instead of python-powered logo"),
                    ('title=', 't',
                     "title to display on the installer background instead of default"),
                    ('skip-build', None,
                     "skip rebuilding everything (for testing/debugging)"),
                    ('install-script=', None,
                     "basename of installation script to be run after "
                     "installation or before deinstallation"),
                    ('pre-install-script=', None,
                     "Fully qualified filename of a script to be run before "
                     "any files are installed.  This script need not be in the "
                     "distribution"),
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/build.py
"""distutils.command.build

Implements the Distutils 'build' command."""

import sys, os
from distutils.core import Command
from distutils.errors import DistutilsOptionError
from distutils.util import get_platform


def show_compilers():
    from distutils.ccompiler import show_compilers
    show_compilers()


class build(Command):

    description = "build everything needed to install"

    user_options = [
        ('build-base=', 'b',
         "base directory for build library"),
        ('build-purelib=', None,
         "build directory for platform-neutral distributions"),
        ('build-platlib=', None,
         "build directory for platform-specific distributions"),
        ('build-lib=', None,
         "build directory for all distribution (defaults to either " +
         "build-purelib or build-platlib"),
        ('build-scripts=', None,
         "build directory for scripts"),
        ('build-temp=', 't',
         "temporary build directory"),
        ('plat-name=', 'p',
         "platform name to build for, if supported "
         "(default: %s)" % get_platform()),
        ('compiler=', 'c',
         "specify the compiler type"),
        ('parallel=', 'j',
         "number of parallel build jobs"),
        ('debug', 'g',
         "compile extensions and libraries with debugging information"),
        ('force', 'f',
         "forcibly build everything (ignore file timestamps)"),
        ('executable=', 'e',
         "specify final destination interpreter path (build.py)"),
        ]

    boolean_options = ['debug', 'force']

FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/build_clib.py
"""distutils.command.build_clib

Implements the Distutils 'build_clib' command, to build a C/C++ library
that is included in the module distribution and needed by an extension
module."""


# XXX this module has *lots* of code ripped-off quite transparently from
# build_ext.py -- not surprisingly really, as the work required to build
# a static library from a collection of C source files is not really all
# that different from what's required to build a shared object file from
# a collection of C source files.  Nevertheless, I haven't done the
# necessary refactoring to account for the overlap in code between the
# two modules, mainly because a number of subtle details changed in the
# cut 'n paste.  Sigh.

import os
from distutils.core import Command
from distutils.errors import *
from distutils.sysconfig import customize_compiler
from distutils import log

def show_compilers():
    from distutils.ccompiler import show_compilers
    show_compilers()


class build_clib(Command):

    description = "build C/C++ libraries used by Python extensions"

    user_options = [
        ('build-clib=', 'b',
         "directory to build C/C++ libraries to"),
        ('build-temp=', 't',
         "directory to put temporary build by-products"),
        ('debug', 'g',
         "compile with debugging information"),
        ('force', 'f',
         "forcibly build everything (ignore file timestamps)"),
        ('compiler=', 'c',
         "specify the compiler type"),
        ]

    boolean_options = ['debug', 'force']

    help_options = [
        ('help-compiler', None,
         "list available compilers", show_compilers),
        ]
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/build_ext.py
"""distutils.command.build_ext

Implements the Distutils 'build_ext' command, for building extension
modules (currently limited to C extensions, should accommodate C++
extensions ASAP)."""

import contextlib
import os
import re
import sys
from distutils.core import Command
from distutils.errors import *
from distutils.sysconfig import customize_compiler, get_python_version
from distutils.sysconfig import get_config_h_filename
from distutils.dep_util import newer_group
from distutils.extension import Extension
from distutils.util import get_platform
from distutils import log
from . import py37compat

from site import USER_BASE

# An extension name is just a dot-separated list of Python NAMEs (ie.
# the same as a fully-qualified module name).
extension_name_re = re.compile \
    (r'^[a-zA-Z_][a-zA-Z_0-9]*(\.[a-zA-Z_][a-zA-Z_0-9]*)*$')


def show_compilers ():
    from distutils.ccompiler import show_compilers
    show_compilers()


class build_ext(Command):

    description = "build C/C++ extensions (compile/link to build directory)"

    # XXX thoughts on how to deal with complex command-line options like
    # these, i.e. how to make it so fancy_getopt can suck them off the
    # command line and make it look like setup.py defined the appropriate
    # lists of tuples of what-have-you.
    #   - each command needs a callback to process its command-line options
    #   - Command.__init__() needs access to its share of the whole
    #     command line (must ultimately come from
    #     Distribution.parse_command_line())
    #   - it then calls the current command class' option-parsing
    #     callback to deal with weird options like -D, which have to
    #     parse the option text and churn out some custom data
    #     structure
    #   - that data structure (in this case, a list of 2-tuples)
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/build_py.py
"""distutils.command.build_py

Implements the Distutils 'build_py' command."""

import os
import importlib.util
import sys
import glob

from distutils.core import Command
from distutils.errors import *
from distutils.util import convert_path
from distutils import log

class build_py (Command):

    description = "\"build\" pure Python modules (copy to build directory)"

    user_options = [
        ('build-lib=', 'd', "directory to \"build\" (copy) to"),
        ('compile', 'c', "compile .py to .pyc"),
        ('no-compile', None, "don't compile .py files [default]"),
        ('optimize=', 'O',
         "also compile with optimization: -O1 for \"python -O\", "
         "-O2 for \"python -OO\", and -O0 to disable [default: -O0]"),
        ('force', 'f', "forcibly build everything (ignore file timestamps)"),
        ]

    boolean_options = ['compile', 'force']
    negative_opt = {'no-compile' : 'compile'}

    def initialize_options(self):
        self.build_lib = None
        self.py_modules = None
        self.package = None
        self.package_data = None
        self.package_dir = None
        self.compile = 0
        self.optimize = 0
        self.force = None

    def finalize_options(self):
        self.set_undefined_options('build',
                                   ('build_lib', 'build_lib'),
                                   ('force', 'force'))

        # Get the distribution options that are aliases for build_py
        # options -- list of packages and list of modules.
        self.packages = self.distribution.packages
        self.py_modules = self.distribution.py_modules
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/build_scripts.py
"""distutils.command.build_scripts

Implements the Distutils 'build_scripts' command."""

import os, re
from stat import ST_MODE
from distutils import sysconfig
from distutils.core import Command
from distutils.dep_util import newer
from distutils.util import convert_path
from distutils import log
import tokenize

# check if Python is called on the first line with this expression
first_line_re = re.compile(b'^#!.*python[0-9.]*([ \t].*)?$')

class build_scripts(Command):

    description = "\"build\" scripts (copy and fixup #! line)"

    user_options = [
        ('build-dir=', 'd', "directory to \"build\" (copy) to"),
        ('force', 'f', "forcibly build everything (ignore file timestamps"),
        ('executable=', 'e', "specify final destination interpreter path"),
        ]

    boolean_options = ['force']


    def initialize_options(self):
        self.build_dir = None
        self.scripts = None
        self.force = None
        self.executable = None
        self.outfiles = None

    def finalize_options(self):
        self.set_undefined_options('build',
                                   ('build_scripts', 'build_dir'),
                                   ('force', 'force'),
                                   ('executable', 'executable'))
        self.scripts = self.distribution.scripts

    def get_source_files(self):
        return self.scripts

    def run(self):
        if not self.scripts:
            return
        self.copy_scripts()
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/check.py
"""distutils.command.check

Implements the Distutils 'check' command.
"""
from distutils.core import Command
from distutils.errors import DistutilsSetupError

try:
    # docutils is installed
    from docutils.utils import Reporter
    from docutils.parsers.rst import Parser
    from docutils import frontend
    from docutils import nodes

    class SilentReporter(Reporter):

        def __init__(self, source, report_level, halt_level, stream=None,
                     debug=0, encoding='ascii', error_handler='replace'):
            self.messages = []
            Reporter.__init__(self, source, report_level, halt_level, stream,
                              debug, encoding, error_handler)

        def system_message(self, level, message, *children, **kwargs):
            self.messages.append((level, message, children, kwargs))
            return nodes.system_message(message, level=level,
                                        type=self.levels[level],
                                        *children, **kwargs)

    HAS_DOCUTILS = True
except Exception:
    # Catch all exceptions because exceptions besides ImportError probably
    # indicate that docutils is not ported to Py3k.
    HAS_DOCUTILS = False

class check(Command):
    """This command checks the meta-data of the package.
    """
    description = ("perform some checks on the package")
    user_options = [('metadata', 'm', 'Verify meta-data'),
                    ('restructuredtext', 'r',
                     ('Checks if long string meta-data syntax '
                      'are reStructuredText-compliant')),
                    ('strict', 's',
                     'Will exit with an error if a check fails')]

    boolean_options = ['metadata', 'restructuredtext', 'strict']

    def initialize_options(self):
        """Sets default values for options."""
        self.restructuredtext = 0
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/clean.py
"""distutils.command.clean

Implements the Distutils 'clean' command."""

# contributed by Bastian Kleineidam <calvin@cs.uni-sb.de>, added 2000-03-18

import os
from distutils.core import Command
from distutils.dir_util import remove_tree
from distutils import log

class clean(Command):

    description = "clean up temporary files from 'build' command"
    user_options = [
        ('build-base=', 'b',
         "base build directory (default: 'build.build-base')"),
        ('build-lib=', None,
         "build directory for all modules (default: 'build.build-lib')"),
        ('build-temp=', 't',
         "temporary build directory (default: 'build.build-temp')"),
        ('build-scripts=', None,
         "build directory for scripts (default: 'build.build-scripts')"),
        ('bdist-base=', None,
         "temporary directory for built distributions"),
        ('all', 'a',
         "remove all build output, not just temporary by-products")
    ]

    boolean_options = ['all']

    def initialize_options(self):
        self.build_base = None
        self.build_lib = None
        self.build_temp = None
        self.build_scripts = None
        self.bdist_base = None
        self.all = None

    def finalize_options(self):
        self.set_undefined_options('build',
                                   ('build_base', 'build_base'),
                                   ('build_lib', 'build_lib'),
                                   ('build_scripts', 'build_scripts'),
                                   ('build_temp', 'build_temp'))
        self.set_undefined_options('bdist',
                                   ('bdist_base', 'bdist_base'))

    def run(self):
        # remove the build/temp.<plat> directory (unless it's already
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/config.py
"""distutils.command.config

Implements the Distutils 'config' command, a (mostly) empty command class
that exists mainly to be sub-classed by specific module distributions and
applications.  The idea is that while every "config" command is different,
at least they're all named the same, and users always see "config" in the
list of standard commands.  Also, this is a good place to put common
configure-like tasks: "try to compile this C code", or "figure out where
this header file lives".
"""

import os, re

from distutils.core import Command
from distutils.errors import DistutilsExecError
from distutils.sysconfig import customize_compiler
from distutils import log

LANG_EXT = {"c": ".c", "c++": ".cxx"}

class config(Command):

    description = "prepare to build"

    user_options = [
        ('compiler=', None,
         "specify the compiler type"),
        ('cc=', None,
         "specify the compiler executable"),
        ('include-dirs=', 'I',
         "list of directories to search for header files"),
        ('define=', 'D',
         "C preprocessor macros to define"),
        ('undef=', 'U',
         "C preprocessor macros to undefine"),
        ('libraries=', 'l',
         "external C libraries to link with"),
        ('library-dirs=', 'L',
         "directories to search for external C libraries"),

        ('noisy', None,
         "show every action (compile, link, run, ...) taken"),
        ('dump-source', None,
         "dump generated source files before attempting to compile them"),
        ]


    # The three standard command methods: since the "config" command
    # does nothing by default, these are empty.

FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/install.py
"""distutils.command.install

Implements the Distutils 'install' command."""

import sys
import os
import contextlib
import sysconfig
import itertools

from distutils import log
from distutils.core import Command
from distutils.debug import DEBUG
from distutils.sysconfig import get_config_vars
from distutils.errors import DistutilsPlatformError
from distutils.file_util import write_file
from distutils.util import convert_path, subst_vars, change_root
from distutils.util import get_platform
from distutils.errors import DistutilsOptionError

from site import USER_BASE
from site import USER_SITE
HAS_USER_SITE = True

WINDOWS_SCHEME = {
    'purelib': '{base}/Lib/site-packages',
    'platlib': '{base}/Lib/site-packages',
    'headers': '{base}/Include/{dist_name}',
    'scripts': '{base}/Scripts',
    'data'   : '{base}',
}

INSTALL_SCHEMES = {
    'posix_prefix': {
        'purelib': '{base}/lib/{implementation_lower}{py_version_short}/site-packages',
        'platlib': '{platbase}/{platlibdir}/{implementation_lower}{py_version_short}/site-packages',
        'headers': '{base}/include/{implementation_lower}{py_version_short}{abiflags}/{dist_name}',
        'scripts': '{base}/bin',
        'data'   : '{base}',
        },
    'posix_home': {
        'purelib': '{base}/lib/{implementation_lower}',
        'platlib': '{base}/{platlibdir}/{implementation_lower}',
        'headers': '{base}/include/{implementation_lower}/{dist_name}',
        'scripts': '{base}/bin',
        'data'   : '{base}',
        },
    'nt': WINDOWS_SCHEME,
    'pypy': {
        'purelib': '{base}/site-packages',
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/install_data.py
"""distutils.command.install_data

Implements the Distutils 'install_data' command, for installing
platform-independent data files."""

# contributed by Bastian Kleineidam

import os
from distutils.core import Command
from distutils.util import change_root, convert_path

class install_data(Command):

    description = "install data files"

    user_options = [
        ('install-dir=', 'd',
         "base directory for installing data files "
         "(default: installation base dir)"),
        ('root=', None,
         "install everything relative to this alternate root directory"),
        ('force', 'f', "force installation (overwrite existing files)"),
        ]

    boolean_options = ['force']

    def initialize_options(self):
        self.install_dir = None
        self.outfiles = []
        self.root = None
        self.force = 0
        self.data_files = self.distribution.data_files
        self.warn_dir = 1

    def finalize_options(self):
        self.set_undefined_options('install',
                                   ('install_data', 'install_dir'),
                                   ('root', 'root'),
                                   ('force', 'force'),
                                  )

    def run(self):
        self.mkpath(self.install_dir)
        for f in self.data_files:
            if isinstance(f, str):
                # it's a simple file, so copy it
                f = convert_path(f)
                if self.warn_dir:
                    self.warn("setup script did not provide a directory for "
                              "'%s' -- installing right in '%s'" %
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/install_egg_info.py
"""distutils.command.install_egg_info

Implements the Distutils 'install_egg_info' command, for installing
a package's PKG-INFO metadata."""


from distutils.cmd import Command
from distutils import log, dir_util
import os, sys, re

class install_egg_info(Command):
    """Install an .egg-info file for the package"""

    description = "Install package's PKG-INFO metadata as an .egg-info file"
    user_options = [
        ('install-dir=', 'd', "directory to install to"),
    ]

    def initialize_options(self):
        self.install_dir = None

    @property
    def basename(self):
        """
        Allow basename to be overridden by child class.
        Ref pypa/distutils#2.
        """
        return "%s-%s-py%d.%d.egg-info" % (
            to_filename(safe_name(self.distribution.get_name())),
            to_filename(safe_version(self.distribution.get_version())),
            *sys.version_info[:2]
        )

    def finalize_options(self):
        self.set_undefined_options('install_lib',('install_dir','install_dir'))
        self.target = os.path.join(self.install_dir, self.basename)
        self.outputs = [self.target]

    def run(self):
        target = self.target
        if os.path.isdir(target) and not os.path.islink(target):
            dir_util.remove_tree(target, dry_run=self.dry_run)
        elif os.path.exists(target):
            self.execute(os.unlink,(self.target,),"Removing "+target)
        elif not os.path.isdir(self.install_dir):
            self.execute(os.makedirs, (self.install_dir,),
                         "Creating "+self.install_dir)
        log.info("Writing %s", target)
        if not self.dry_run:
            with open(target, 'w', encoding='UTF-8') as f:
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/install_headers.py
"""distutils.command.install_headers

Implements the Distutils 'install_headers' command, to install C/C++ header
files to the Python include directory."""

from distutils.core import Command


# XXX force is never used
class install_headers(Command):

    description = "install C/C++ header files"

    user_options = [('install-dir=', 'd',
                     "directory to install header files to"),
                    ('force', 'f',
                     "force installation (overwrite existing files)"),
                   ]

    boolean_options = ['force']

    def initialize_options(self):
        self.install_dir = None
        self.force = 0
        self.outfiles = []

    def finalize_options(self):
        self.set_undefined_options('install',
                                   ('install_headers', 'install_dir'),
                                   ('force', 'force'))


    def run(self):
        headers = self.distribution.headers
        if not headers:
            return

        self.mkpath(self.install_dir)
        for header in headers:
            (out, _) = self.copy_file(header, self.install_dir)
            self.outfiles.append(out)

    def get_inputs(self):
        return self.distribution.headers or []

    def get_outputs(self):
        return self.outfiles
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/install_lib.py
"""distutils.command.install_lib

Implements the Distutils 'install_lib' command
(install all Python modules)."""

import os
import importlib.util
import sys

from distutils.core import Command
from distutils.errors import DistutilsOptionError


# Extension for Python source files.
PYTHON_SOURCE_EXTENSION = ".py"

class install_lib(Command):

    description = "install all Python modules (extensions and pure Python)"

    # The byte-compilation options are a tad confusing.  Here are the
    # possible scenarios:
    #   1) no compilation at all (--no-compile --no-optimize)
    #   2) compile .pyc only (--compile --no-optimize; default)
    #   3) compile .pyc and "opt-1" .pyc (--compile --optimize)
    #   4) compile "opt-1" .pyc only (--no-compile --optimize)
    #   5) compile .pyc and "opt-2" .pyc (--compile --optimize-more)
    #   6) compile "opt-2" .pyc only (--no-compile --optimize-more)
    #
    # The UI for this is two options, 'compile' and 'optimize'.
    # 'compile' is strictly boolean, and only decides whether to
    # generate .pyc files.  'optimize' is three-way (0, 1, or 2), and
    # decides both whether to generate .pyc files and what level of
    # optimization to use.

    user_options = [
        ('install-dir=', 'd', "directory to install to"),
        ('build-dir=','b', "build directory (where to install from)"),
        ('force', 'f', "force installation (overwrite existing files)"),
        ('compile', 'c', "compile .py to .pyc [default]"),
        ('no-compile', None, "don't compile .py files"),
        ('optimize=', 'O',
         "also compile with optimization: -O1 for \"python -O\", "
         "-O2 for \"python -OO\", and -O0 to disable [default: -O0]"),
        ('skip-build', None, "skip the build steps"),
        ]

    boolean_options = ['force', 'compile', 'skip-build']
    negative_opt = {'no-compile' : 'compile'}

FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/install_scripts.py
"""distutils.command.install_scripts

Implements the Distutils 'install_scripts' command, for installing
Python scripts."""

# contributed by Bastian Kleineidam

import os
from distutils.core import Command
from distutils import log
from stat import ST_MODE


class install_scripts(Command):

    description = "install scripts (Python or otherwise)"

    user_options = [
        ('install-dir=', 'd', "directory to install scripts to"),
        ('build-dir=','b', "build directory (where to install from)"),
        ('force', 'f', "force installation (overwrite existing files)"),
        ('skip-build', None, "skip the build steps"),
    ]

    boolean_options = ['force', 'skip-build']

    def initialize_options(self):
        self.install_dir = None
        self.force = 0
        self.build_dir = None
        self.skip_build = None

    def finalize_options(self):
        self.set_undefined_options('build', ('build_scripts', 'build_dir'))
        self.set_undefined_options('install',
                                   ('install_scripts', 'install_dir'),
                                   ('force', 'force'),
                                   ('skip_build', 'skip_build'),
                                  )

    def run(self):
        if not self.skip_build:
            self.run_command('build_scripts')
        self.outfiles = self.copy_tree(self.build_dir, self.install_dir)
        if os.name == 'posix':
            # Set the executable bits (owner, group, and world) on
            # all the scripts we just installed.
            for file in self.get_outputs():
                if self.dry_run:
                    log.info("changing mode of %s", file)
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/py37compat.py
import sys


def _pythonlib_compat():
    """
    On Python 3.7 and earlier, distutils would include the Python
    library. See pypa/distutils#9.
    """
    from distutils import sysconfig
    if not sysconfig.get_config_var('Py_ENABLED_SHARED'):
        return

    yield 'python{}.{}{}'.format(
        sys.hexversion >> 24,
        (sys.hexversion >> 16) & 0xff,
        sysconfig.get_config_var('ABIFLAGS'),
    )


def compose(f1, f2):
    return lambda *args, **kwargs: f1(f2(*args, **kwargs))


pythonlib = (
    compose(list, _pythonlib_compat)
    if sys.version_info < (3, 8)
    and sys.platform != 'darwin'
    and sys.platform[:3] != 'aix'
    else list
)
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/register.py
"""distutils.command.register

Implements the Distutils 'register' command (register with the repository).
"""

# created 2002/10/21, Richard Jones

import getpass
import io
import urllib.parse, urllib.request
from warnings import warn

from distutils.core import PyPIRCCommand
from distutils.errors import *
from distutils import log

class register(PyPIRCCommand):

    description = ("register the distribution with the Python package index")
    user_options = PyPIRCCommand.user_options + [
        ('list-classifiers', None,
         'list the valid Trove classifiers'),
        ('strict', None ,
         'Will stop the registering if the meta-data are not fully compliant')
        ]
    boolean_options = PyPIRCCommand.boolean_options + [
        'verify', 'list-classifiers', 'strict']

    sub_commands = [('check', lambda self: True)]

    def initialize_options(self):
        PyPIRCCommand.initialize_options(self)
        self.list_classifiers = 0
        self.strict = 0

    def finalize_options(self):
        PyPIRCCommand.finalize_options(self)
        # setting options for the `check` subcommand
        check_options = {'strict': ('register', self.strict),
                         'restructuredtext': ('register', 1)}
        self.distribution.command_options['check'] = check_options

    def run(self):
        self.finalize_options()
        self._set_config()

        # Run sub commands
        for cmd_name in self.get_sub_commands():
            self.run_command(cmd_name)

FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/sdist.py
"""distutils.command.sdist

Implements the Distutils 'sdist' command (create a source distribution)."""

import os
import sys
from glob import glob
from warnings import warn

from distutils.core import Command
from distutils import dir_util
from distutils import file_util
from distutils import archive_util
from distutils.text_file import TextFile
from distutils.filelist import FileList
from distutils import log
from distutils.util import convert_path
from distutils.errors import DistutilsTemplateError, DistutilsOptionError


def show_formats():
    """Print all possible values for the 'formats' option (used by
    the "--help-formats" command-line option).
    """
    from distutils.fancy_getopt import FancyGetopt
    from distutils.archive_util import ARCHIVE_FORMATS
    formats = []
    for format in ARCHIVE_FORMATS.keys():
        formats.append(("formats=" + format, None,
                        ARCHIVE_FORMATS[format][2]))
    formats.sort()
    FancyGetopt(formats).print_help(
        "List of available source distribution formats:")


class sdist(Command):

    description = "create a source distribution (tarball, zip file, etc.)"

    def checking_metadata(self):
        """Callable used for the check sub-command.

        Placed here so user_options can view it"""
        return self.metadata_check

    user_options = [
        ('template=', 't',
         "name of manifest template file [default: MANIFEST.in]"),
        ('manifest=', 'm',
         "name of manifest file [default: MANIFEST]"),
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/upload.py
"""
distutils.command.upload

Implements the Distutils 'upload' subcommand (upload package to a package
index).
"""

import os
import io
import hashlib
from base64 import standard_b64encode
from urllib.request import urlopen, Request, HTTPError
from urllib.parse import urlparse
from distutils.errors import DistutilsError, DistutilsOptionError
from distutils.core import PyPIRCCommand
from distutils.spawn import spawn
from distutils import log


# PyPI Warehouse supports MD5, SHA256, and Blake2 (blake2-256)
# https://bugs.python.org/issue40698
_FILE_CONTENT_DIGESTS = {
    "md5_digest": getattr(hashlib, "md5", None),
    "sha256_digest": getattr(hashlib, "sha256", None),
    "blake2_256_digest": getattr(hashlib, "blake2b", None),
}


class upload(PyPIRCCommand):

    description = "upload binary package to PyPI"

    user_options = PyPIRCCommand.user_options + [
        ('sign', 's',
         'sign files to upload using gpg'),
        ('identity=', 'i', 'GPG identity used to sign files'),
        ]

    boolean_options = PyPIRCCommand.boolean_options + ['sign']

    def initialize_options(self):
        PyPIRCCommand.initialize_options(self)
        self.username = ''
        self.password = ''
        self.show_response = 0
        self.sign = False
        self.identity = None

    def finalize_options(self):
        PyPIRCCommand.finalize_options(self)
FILE: ./venv/Lib/site-packages/setuptools/_distutils/command/__init__.py
"""distutils.command

Package containing implementation of all the standard Distutils
commands."""

__all__ = ['build',
           'build_py',
           'build_ext',
           'build_clib',
           'build_scripts',
           'clean',
           'install',
           'install_lib',
           'install_headers',
           'install_scripts',
           'install_data',
           'sdist',
           'register',
           'bdist',
           'bdist_dumb',
           'bdist_rpm',
           'bdist_wininst',
           'check',
           'upload',
           # These two are reserved for future use:
           #'bdist_sdux',
           #'bdist_pkgtool',
           # Note:
           # bdist_packager is not included because it only provides
           # an abstract base class
          ]
FILE: ./venv/Lib/site-packages/setuptools/_distutils/config.py
"""distutils.pypirc

Provides the PyPIRCCommand class, the base class for the command classes
that uses .pypirc in the distutils.command package.
"""
import os
from configparser import RawConfigParser

from distutils.cmd import Command

DEFAULT_PYPIRC = """\
[distutils]
index-servers =
    pypi

[pypi]
username:%s
password:%s
"""

class PyPIRCCommand(Command):
    """Base command that knows how to handle the .pypirc file
    """
    DEFAULT_REPOSITORY = 'https://upload.pypi.org/legacy/'
    DEFAULT_REALM = 'pypi'
    repository = None
    realm = None

    user_options = [
        ('repository=', 'r',
         "url of repository [default: %s]" % \
            DEFAULT_REPOSITORY),
        ('show-response', None,
         'display full response text from server')]

    boolean_options = ['show-response']

    def _get_rc_file(self):
        """Returns rc file path."""
        return os.path.join(os.path.expanduser('~'), '.pypirc')

    def _store_pypirc(self, username, password):
        """Creates a default .pypirc file."""
        rc = self._get_rc_file()
        with os.fdopen(os.open(rc, os.O_CREAT | os.O_WRONLY, 0o600), 'w') as f:
            f.write(DEFAULT_PYPIRC % (username, password))

    def _read_pypirc(self):
        """Reads the .pypirc file."""
        rc = self._get_rc_file()
FILE: ./venv/Lib/site-packages/setuptools/_distutils/core.py
"""distutils.core

The only module that needs to be imported to use the Distutils; provides
the 'setup' function (which is to be called from the setup script).  Also
indirectly provides the Distribution and Command classes, although they are
really defined in distutils.dist and distutils.cmd.
"""

import os
import sys
import tokenize

from distutils.debug import DEBUG
from distutils.errors import *

# Mainly import these so setup scripts can "from distutils.core import" them.
from distutils.dist import Distribution
from distutils.cmd import Command
from distutils.config import PyPIRCCommand
from distutils.extension import Extension

# This is a barebones help message generated displayed when the user
# runs the setup script with no arguments at all.  More useful help
# is generated with various --help options: global help, list commands,
# and per-command help.
USAGE = """\
usage: %(script)s [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
   or: %(script)s --help [cmd1 cmd2 ...]
   or: %(script)s --help-commands
   or: %(script)s cmd --help
"""

def gen_usage (script_name):
    script = os.path.basename(script_name)
    return USAGE % vars()


# Some mild magic to control the behaviour of 'setup()' from 'run_setup()'.
_setup_stop_after = None
_setup_distribution = None

# Legal keyword arguments for the setup() function
setup_keywords = ('distclass', 'script_name', 'script_args', 'options',
                  'name', 'version', 'author', 'author_email',
                  'maintainer', 'maintainer_email', 'url', 'license',
                  'description', 'long_description', 'keywords',
                  'platforms', 'classifiers', 'download_url',
                  'requires', 'provides', 'obsoletes',
                  )

FILE: ./venv/Lib/site-packages/setuptools/_distutils/cygwinccompiler.py
"""distutils.cygwinccompiler

Provides the CygwinCCompiler class, a subclass of UnixCCompiler that
handles the Cygwin port of the GNU C compiler to Windows.  It also contains
the Mingw32CCompiler class which handles the mingw32 port of GCC (same as
cygwin in no-cygwin mode).
"""

# problems:
#
# * if you use a msvc compiled python version (1.5.2)
#   1. you have to insert a __GNUC__ section in its config.h
#   2. you have to generate an import library for its dll
#      - create a def-file for python??.dll
#      - create an import library using
#             dlltool --dllname python15.dll --def python15.def \
#                       --output-lib libpython15.a
#
#   see also http://starship.python.net/crew/kernr/mingw32/Notes.html
#
# * We put export_symbols in a def-file, and don't use
#   --export-all-symbols because it doesn't worked reliable in some
#   tested configurations. And because other windows compilers also
#   need their symbols specified this no serious problem.
#
# tested configurations:
#
# * cygwin gcc 2.91.57/ld 2.9.4/dllwrap 0.2.4 works
#   (after patching python's config.h and for C++ some other include files)
#   see also http://starship.python.net/crew/kernr/mingw32/Notes.html
# * mingw32 gcc 2.95.2/ld 2.9.4/dllwrap 0.2.4 works
#   (ld doesn't support -shared, so we use dllwrap)
# * cygwin gcc 2.95.2/ld 2.10.90/dllwrap 2.10.90 works now
#   - its dllwrap doesn't work, there is a bug in binutils 2.10.90
#     see also http://sources.redhat.com/ml/cygwin/2000-06/msg01274.html
#   - using gcc -mdll instead dllwrap doesn't work without -static because
#     it tries to link against dlls instead their import libraries. (If
#     it finds the dll first.)
#     By specifying -static we force ld to link against the import libraries,
#     this is windows standard and there are normally not the necessary symbols
#     in the dlls.
#   *** only the version of June 2000 shows these problems
# * cygwin gcc 3.2/ld 2.13.90 works
#   (ld supports -shared)
# * mingw gcc 3.2/ld 2.13 works
#   (ld supports -shared)
# * llvm-mingw with Clang 11 works
#   (lld supports -shared)

import os
FILE: ./venv/Lib/site-packages/setuptools/_distutils/debug.py
import os

# If DISTUTILS_DEBUG is anything other than the empty string, we run in
# debug mode.
DEBUG = os.environ.get('DISTUTILS_DEBUG')
FILE: ./venv/Lib/site-packages/setuptools/_distutils/dep_util.py
"""distutils.dep_util

Utility functions for simple, timestamp-based dependency of files
and groups of files; also, function based entirely on such
timestamp dependency analysis."""

import os
from distutils.errors import DistutilsFileError


def newer (source, target):
    """Return true if 'source' exists and is more recently modified than
    'target', or if 'source' exists and 'target' doesn't.  Return false if
    both exist and 'target' is the same age or younger than 'source'.
    Raise DistutilsFileError if 'source' does not exist.
    """
    if not os.path.exists(source):
        raise DistutilsFileError("file '%s' does not exist" %
                                 os.path.abspath(source))
    if not os.path.exists(target):
        return 1

    from stat import ST_MTIME
    mtime1 = os.stat(source)[ST_MTIME]
    mtime2 = os.stat(target)[ST_MTIME]

    return mtime1 > mtime2

# newer ()


def newer_pairwise (sources, targets):
    """Walk two filename lists in parallel, testing if each source is newer
    than its corresponding target.  Return a pair of lists (sources,
    targets) where source is newer than target, according to the semantics
    of 'newer()'.
    """
    if len(sources) != len(targets):
        raise ValueError("'sources' and 'targets' must be same length")

    # build a pair of lists (sources, targets) where  source is newer
    n_sources = []
    n_targets = []
    for i in range(len(sources)):
        if newer(sources[i], targets[i]):
            n_sources.append(sources[i])
            n_targets.append(targets[i])

    return (n_sources, n_targets)

FILE: ./venv/Lib/site-packages/setuptools/_distutils/dir_util.py
"""distutils.dir_util

Utility functions for manipulating directories and directory trees."""

import os
import errno
from distutils.errors import DistutilsFileError, DistutilsInternalError
from distutils import log

# cache for by mkpath() -- in addition to cheapening redundant calls,
# eliminates redundant "creating /foo/bar/baz" messages in dry-run mode
_path_created = {}

# I don't use os.makedirs because a) it's new to Python 1.5.2, and
# b) it blows up if the directory already exists (I want to silently
# succeed in that case).
def mkpath(name, mode=0o777, verbose=1, dry_run=0):
    """Create a directory and any missing ancestor directories.

    If the directory already exists (or if 'name' is the empty string, which
    means the current directory, which of course exists), then do nothing.
    Raise DistutilsFileError if unable to create some directory along the way
    (eg. some sub-path exists, but is a file rather than a directory).
    If 'verbose' is true, print a one-line summary of each mkdir to stdout.
    Return the list of directories actually created.
    """

    global _path_created

    # Detect a common bug -- name is None
    if not isinstance(name, str):
        raise DistutilsInternalError(
              "mkpath: 'name' must be a string (got %r)" % (name,))

    # XXX what's the better way to handle verbosity? print as we create
    # each directory in the path (the current behaviour), or only announce
    # the creation of the whole path? (quite easy to do the latter since
    # we're not using a recursive algorithm)

    name = os.path.normpath(name)
    created_dirs = []
    if os.path.isdir(name) or name == '':
        return created_dirs
    if _path_created.get(os.path.abspath(name)):
        return created_dirs

    (head, tail) = os.path.split(name)
    tails = [tail]                      # stack of lone dirs to create

    while head and tail and not os.path.isdir(head):
FILE: ./venv/Lib/site-packages/setuptools/_distutils/dist.py
"""distutils.dist

Provides the Distribution class, which represents the module distribution
being built/installed/distributed.
"""

import sys
import os
import re
from email import message_from_file

try:
    import warnings
except ImportError:
    warnings = None

from distutils.errors import *
from distutils.fancy_getopt import FancyGetopt, translate_longopt
from distutils.util import check_environ, strtobool, rfc822_escape
from distutils import log
from distutils.debug import DEBUG

# Regex to define acceptable Distutils command names.  This is not *quite*
# the same as a Python NAME -- I don't allow leading underscores.  The fact
# that they're very similar is no coincidence; the default naming scheme is
# to look for a Python module named after the command.
command_re = re.compile(r'^[a-zA-Z]([a-zA-Z0-9_]*)$')


def _ensure_list(value, fieldname):
    if isinstance(value, str):
        # a string containing comma separated values is okay.  It will
        # be converted to a list by Distribution.finalize_options().
        pass
    elif not isinstance(value, list):
        # passing a tuple or an iterator perhaps, warn and convert
        typename = type(value).__name__
        msg = "Warning: '{fieldname}' should be a list, got type '{typename}'"
        msg = msg.format(**locals())
        log.log(log.WARN, msg)
        value = list(value)
    return value


class Distribution:
    """The core of the Distutils.  Most of the work hiding behind 'setup'
    is really done within a Distribution instance, which farms the work out
    to the Distutils commands specified on the command line.

    Setup scripts will almost never instantiate Distribution directly,
FILE: ./venv/Lib/site-packages/setuptools/_distutils/errors.py
"""distutils.errors

Provides exceptions used by the Distutils modules.  Note that Distutils
modules may raise standard exceptions; in particular, SystemExit is
usually raised for errors that are obviously the end-user's fault
(eg. bad command-line arguments).

This module is safe to use in "from ... import *" mode; it only exports
symbols whose names start with "Distutils" and end with "Error"."""

class DistutilsError (Exception):
    """The root of all Distutils evil."""
    pass

class DistutilsModuleError (DistutilsError):
    """Unable to load an expected module, or to find an expected class
    within some module (in particular, command modules and classes)."""
    pass

class DistutilsClassError (DistutilsError):
    """Some command class (or possibly distribution class, if anyone
    feels a need to subclass Distribution) is found not to be holding
    up its end of the bargain, ie. implementing some part of the
    "command "interface."""
    pass

class DistutilsGetoptError (DistutilsError):
    """The option table provided to 'fancy_getopt()' is bogus."""
    pass

class DistutilsArgError (DistutilsError):
    """Raised by fancy_getopt in response to getopt.error -- ie. an
    error in the command line usage."""
    pass

class DistutilsFileError (DistutilsError):
    """Any problems in the filesystem: expected file not found, etc.
    Typically this is for problems that we detect before OSError
    could be raised."""
    pass

class DistutilsOptionError (DistutilsError):
    """Syntactic/semantic errors in command options, such as use of
    mutually conflicting options, or inconsistent options,
    badly-spelled values, etc.  No distinction is made between option
    values originating in the setup script, the command line, config
    files, or what-have-you -- but if we *know* something originated in
    the setup script, we'll raise DistutilsSetupError instead."""
    pass

FILE: ./venv/Lib/site-packages/setuptools/_distutils/extension.py
"""distutils.extension

Provides the Extension class, used to describe C/C++ extension
modules in setup scripts."""

import os
import warnings

# This class is really only used by the "build_ext" command, so it might
# make sense to put it in distutils.command.build_ext.  However, that
# module is already big enough, and I want to make this class a bit more
# complex to simplify some common cases ("foo" module in "foo.c") and do
# better error-checking ("foo.c" actually exists).
#
# Also, putting this in build_ext.py means every setup script would have to
# import that large-ish module (indirectly, through distutils.core) in
# order to do anything.

class Extension:
    """Just a collection of attributes that describes an extension
    module and everything needed to build it (hopefully in a portable
    way, but there are hooks that let you be as unportable as you need).

    Instance attributes:
      name : string
        the full name of the extension, including any packages -- ie.
        *not* a filename or pathname, but Python dotted name
      sources : [string]
        list of source filenames, relative to the distribution root
        (where the setup script lives), in Unix form (slash-separated)
        for portability.  Source files may be C, C++, SWIG (.i),
        platform-specific resource files, or whatever else is recognized
        by the "build_ext" command as source for a Python extension.
      include_dirs : [string]
        list of directories to search for C/C++ header files (in Unix
        form for portability)
      define_macros : [(name : string, value : string|None)]
        list of macros to define; each macro is defined using a 2-tuple,
        where 'value' is either the string to define it to or None to
        define it without a particular value (equivalent of "#define
        FOO" in source or -DFOO on Unix C compiler command line)
      undef_macros : [string]
        list of macros to undefine explicitly
      library_dirs : [string]
        list of directories to search for C/C++ libraries at link time
      libraries : [string]
        list of library names (not filenames or paths) to link against
      runtime_library_dirs : [string]
        list of directories to search for C/C++ libraries at run time
        (for shared extensions, this is when the extension is loaded)
FILE: ./venv/Lib/site-packages/setuptools/_distutils/fancy_getopt.py
"""distutils.fancy_getopt

Wrapper around the standard getopt module that provides the following
additional features:
  * short and long options are tied together
  * options have help strings, so fancy_getopt could potentially
    create a complete usage summary
  * options set attributes of a passed-in object
"""

import sys, string, re
import getopt
from distutils.errors import *

# Much like command_re in distutils.core, this is close to but not quite
# the same as a Python NAME -- except, in the spirit of most GNU
# utilities, we use '-' in place of '_'.  (The spirit of LISP lives on!)
# The similarities to NAME are again not a coincidence...
longopt_pat = r'[a-zA-Z](?:[a-zA-Z0-9-]*)'
longopt_re = re.compile(r'^%s$' % longopt_pat)

# For recognizing "negative alias" options, eg. "quiet=!verbose"
neg_alias_re = re.compile("^(%s)=!(%s)$" % (longopt_pat, longopt_pat))

# This is used to translate long options to legitimate Python identifiers
# (for use as attributes of some object).
longopt_xlate = str.maketrans('-', '_')

class FancyGetopt:
    """Wrapper around the standard 'getopt()' module that provides some
    handy extra functionality:
      * short and long options are tied together
      * options have help strings, and help text can be assembled
        from them
      * options set attributes of a passed-in object
      * boolean options can have "negative aliases" -- eg. if
        --quiet is the "negative alias" of --verbose, then "--quiet"
        on the command line sets 'verbose' to false
    """

    def __init__(self, option_table=None):
        # The option table is (currently) a list of tuples.  The
        # tuples may have 3 or four values:
        #   (long_option, short_option, help_string [, repeatable])
        # if an option takes an argument, its long_option should have '='
        # appended; short_option should just be a single character, no ':'
        # in any case.  If a long_option doesn't have a corresponding
        # short_option, short_option should be None.  All option tuples
        # must have long options.
        self.option_table = option_table
FILE: ./venv/Lib/site-packages/setuptools/_distutils/filelist.py
"""distutils.filelist

Provides the FileList class, used for poking about the filesystem
and building lists of files.
"""

import os
import re
import fnmatch
import functools

from distutils.util import convert_path
from distutils.errors import DistutilsTemplateError, DistutilsInternalError
from distutils import log


class FileList:
    """A list of files built by on exploring the filesystem and filtered by
    applying various patterns to what we find there.

    Instance attributes:
      dir
        directory from which files will be taken -- only used if
        'allfiles' not supplied to constructor
      files
        list of filenames currently being built/filtered/manipulated
      allfiles
        complete list of files under consideration (ie. without any
        filtering applied)
    """

    def __init__(self, warn=None, debug_print=None):
        # ignore argument to FileList, but keep them for backwards
        # compatibility
        self.allfiles = None
        self.files = []

    def set_allfiles(self, allfiles):
        self.allfiles = allfiles

    def findall(self, dir=os.curdir):
        self.allfiles = findall(dir)

    def debug_print(self, msg):
        """Print 'msg' to stdout if the global DEBUG (taken from the
        DISTUTILS_DEBUG environment variable) flag is true.
        """
        from distutils.debug import DEBUG
        if DEBUG:
            print(msg)
FILE: ./venv/Lib/site-packages/setuptools/_distutils/file_util.py
"""distutils.file_util

Utility functions for operating on single files.
"""

import os
from distutils.errors import DistutilsFileError
from distutils import log

# for generating verbose output in 'copy_file()'
_copy_action = { None:   'copying',
                 'hard': 'hard linking',
                 'sym':  'symbolically linking' }


def _copy_file_contents(src, dst, buffer_size=16*1024):
    """Copy the file 'src' to 'dst'; both must be filenames.  Any error
    opening either file, reading from 'src', or writing to 'dst', raises
    DistutilsFileError.  Data is read/written in chunks of 'buffer_size'
    bytes (default 16k).  No attempt is made to handle anything apart from
    regular files.
    """
    # Stolen from shutil module in the standard library, but with
    # custom error-handling added.
    fsrc = None
    fdst = None
    try:
        try:
            fsrc = open(src, 'rb')
        except OSError as e:
            raise DistutilsFileError("could not open '%s': %s" % (src, e.strerror))

        if os.path.exists(dst):
            try:
                os.unlink(dst)
            except OSError as e:
                raise DistutilsFileError(
                      "could not delete '%s': %s" % (dst, e.strerror))

        try:
            fdst = open(dst, 'wb')
        except OSError as e:
            raise DistutilsFileError(
                  "could not create '%s': %s" % (dst, e.strerror))

        while True:
            try:
                buf = fsrc.read(buffer_size)
            except OSError as e:
                raise DistutilsFileError(
FILE: ./venv/Lib/site-packages/setuptools/_distutils/log.py
"""A simple log mechanism styled after PEP 282."""

# The class here is styled after PEP 282 so that it could later be
# replaced with a standard Python logging implementation.

import sys

DEBUG = 1
INFO = 2
WARN = 3
ERROR = 4
FATAL = 5


class Log:

    def __init__(self, threshold=WARN):
        self.threshold = threshold

    def _log(self, level, msg, args):
        if level not in (DEBUG, INFO, WARN, ERROR, FATAL):
            raise ValueError('%s wrong log level' % str(level))

        if level >= self.threshold:
            if args:
                msg = msg % args
            if level in (WARN, ERROR, FATAL):
                stream = sys.stderr
            else:
                stream = sys.stdout
            try:
                stream.write('%s\n' % msg)
            except UnicodeEncodeError:
                # emulate backslashreplace error handler
                encoding = stream.encoding
                msg = msg.encode(encoding, "backslashreplace").decode(encoding)
                stream.write('%s\n' % msg)
            stream.flush()

    def log(self, level, msg, *args):
        self._log(level, msg, args)

    def debug(self, msg, *args):
        self._log(DEBUG, msg, args)

    def info(self, msg, *args):
        self._log(INFO, msg, args)

    def warn(self, msg, *args):
        self._log(WARN, msg, args)
FILE: ./venv/Lib/site-packages/setuptools/_distutils/msvc9compiler.py
"""distutils.msvc9compiler

Contains MSVCCompiler, an implementation of the abstract CCompiler class
for the Microsoft Visual Studio 2008.

The module is compatible with VS 2005 and VS 2008. You can find legacy support
for older versions of VS in distutils.msvccompiler.
"""

# Written by Perry Stoll
# hacked by Robin Becker and Thomas Heller to do a better job of
#   finding DevStudio (through the registry)
# ported to VS2005 and VS 2008 by Christian Heimes

import os
import subprocess
import sys
import re

from distutils.errors import DistutilsExecError, DistutilsPlatformError, \
                             CompileError, LibError, LinkError
from distutils.ccompiler import CCompiler, gen_lib_options
from distutils import log
from distutils.util import get_platform

import winreg

RegOpenKeyEx = winreg.OpenKeyEx
RegEnumKey = winreg.EnumKey
RegEnumValue = winreg.EnumValue
RegError = winreg.error

HKEYS = (winreg.HKEY_USERS,
         winreg.HKEY_CURRENT_USER,
         winreg.HKEY_LOCAL_MACHINE,
         winreg.HKEY_CLASSES_ROOT)

NATIVE_WIN64 = (sys.platform == 'win32' and sys.maxsize > 2**32)
if NATIVE_WIN64:
    # Visual C++ is a 32-bit application, so we need to look in
    # the corresponding registry branch, if we're running a
    # 64-bit Python on Win64
    VS_BASE = r"Software\Wow6432Node\Microsoft\VisualStudio\%0.1f"
    WINSDK_BASE = r"Software\Wow6432Node\Microsoft\Microsoft SDKs\Windows"
    NET_BASE = r"Software\Wow6432Node\Microsoft\.NETFramework"
else:
    VS_BASE = r"Software\Microsoft\VisualStudio\%0.1f"
    WINSDK_BASE = r"Software\Microsoft\Microsoft SDKs\Windows"
    NET_BASE = r"Software\Microsoft\.NETFramework"

FILE: ./venv/Lib/site-packages/setuptools/_distutils/msvccompiler.py
"""distutils.msvccompiler

Contains MSVCCompiler, an implementation of the abstract CCompiler class
for the Microsoft Visual Studio.
"""

# Written by Perry Stoll
# hacked by Robin Becker and Thomas Heller to do a better job of
#   finding DevStudio (through the registry)

import sys, os
from distutils.errors import \
     DistutilsExecError, DistutilsPlatformError, \
     CompileError, LibError, LinkError
from distutils.ccompiler import \
     CCompiler, gen_lib_options
from distutils import log

_can_read_reg = False
try:
    import winreg

    _can_read_reg = True
    hkey_mod = winreg

    RegOpenKeyEx = winreg.OpenKeyEx
    RegEnumKey = winreg.EnumKey
    RegEnumValue = winreg.EnumValue
    RegError = winreg.error

except ImportError:
    try:
        import win32api
        import win32con
        _can_read_reg = True
        hkey_mod = win32con

        RegOpenKeyEx = win32api.RegOpenKeyEx
        RegEnumKey = win32api.RegEnumKey
        RegEnumValue = win32api.RegEnumValue
        RegError = win32api.error
    except ImportError:
        log.info("Warning: Can't read registry to find the "
                 "necessary compiler setting\n"
                 "Make sure that Python modules winreg, "
                 "win32api or win32con are installed.")
        pass

if _can_read_reg:
    HKEYS = (hkey_mod.HKEY_USERS,
FILE: ./venv/Lib/site-packages/setuptools/_distutils/py35compat.py
import sys
import subprocess


def __optim_args_from_interpreter_flags():
    """Return a list of command-line arguments reproducing the current
    optimization settings in sys.flags."""
    args = []
    value = sys.flags.optimize
    if value > 0:
        args.append("-" + "O" * value)
    return args


_optim_args_from_interpreter_flags = getattr(
    subprocess,
    "_optim_args_from_interpreter_flags",
    __optim_args_from_interpreter_flags,
)
FILE: ./venv/Lib/site-packages/setuptools/_distutils/py38compat.py
def aix_platform(osname, version, release):
    try:
        import _aix_support
        return _aix_support.aix_platform()
    except ImportError:
        pass
    return "%s-%s.%s" % (osname, version, release)
FILE: ./venv/Lib/site-packages/setuptools/_distutils/spawn.py
"""distutils.spawn

Provides the 'spawn()' function, a front-end to various platform-
specific functions for launching another program in a sub-process.
Also provides the 'find_executable()' to search the path for a given
executable name.
"""

import sys
import os
import subprocess

from distutils.errors import DistutilsPlatformError, DistutilsExecError
from distutils.debug import DEBUG
from distutils import log


def spawn(cmd, search_path=1, verbose=0, dry_run=0, env=None):
    """Run another program, specified as a command list 'cmd', in a new process.

    'cmd' is just the argument list for the new process, ie.
    cmd[0] is the program to run and cmd[1:] are the rest of its arguments.
    There is no way to run a program with a name different from that of its
    executable.

    If 'search_path' is true (the default), the system's executable
    search path will be used to find the program; otherwise, cmd[0]
    must be the exact path to the executable.  If 'dry_run' is true,
    the command will not actually be run.

    Raise DistutilsExecError if running the program fails in any way; just
    return on success.
    """
    # cmd is documented as a list, but just in case some code passes a tuple
    # in, protect our %-formatting code against horrible death
    cmd = list(cmd)

    log.info(subprocess.list2cmdline(cmd))
    if dry_run:
        return

    if search_path:
        executable = find_executable(cmd[0])
        if executable is not None:
            cmd[0] = executable

    env = env if env is not None else dict(os.environ)

    if sys.platform == 'darwin':
        from distutils.util import MACOSX_VERSION_VAR, get_macosx_target_ver
FILE: ./venv/Lib/site-packages/setuptools/_distutils/sysconfig.py
"""Provide access to Python's configuration information.  The specific
configuration variables available depend heavily on the platform and
configuration.  The values may be retrieved using
get_config_var(name), and the list of variables is available via
get_config_vars().keys().  Additional convenience functions are also
available.

Written by:   Fred L. Drake, Jr.
Email:        <fdrake@acm.org>
"""

import _imp
import os
import re
import sys
import sysconfig

from .errors import DistutilsPlatformError

IS_PYPY = '__pypy__' in sys.builtin_module_names

# These are needed in a couple of spots, so just compute them once.
PREFIX = os.path.normpath(sys.prefix)
EXEC_PREFIX = os.path.normpath(sys.exec_prefix)
BASE_PREFIX = os.path.normpath(sys.base_prefix)
BASE_EXEC_PREFIX = os.path.normpath(sys.base_exec_prefix)

# Path to the base directory of the project. On Windows the binary may
# live in project/PCbuild/win32 or project/PCbuild/amd64.
# set for cross builds
if "_PYTHON_PROJECT_BASE" in os.environ:
    project_base = os.path.abspath(os.environ["_PYTHON_PROJECT_BASE"])
else:
    if sys.executable:
        project_base = os.path.dirname(os.path.abspath(sys.executable))
    else:
        # sys.executable can be empty if argv[0] has been changed and Python is
        # unable to retrieve the real program name
        project_base = os.getcwd()


# python_build: (Boolean) if true, we're either building Python or
# building an extension with an un-installed Python, so we use
# different (hard-wired) directories.
def _is_python_source_dir(d):
    for fn in ("Setup", "Setup.local"):
        if os.path.isfile(os.path.join(d, "Modules", fn)):
            return True
    return False

FILE: ./venv/Lib/site-packages/setuptools/_distutils/text_file.py
"""text_file

provides the TextFile class, which gives an interface to text files
that (optionally) takes care of stripping comments, ignoring blank
lines, and joining lines with backslashes."""

import sys, io


class TextFile:
    """Provides a file-like object that takes care of all the things you
       commonly want to do when processing a text file that has some
       line-by-line syntax: strip comments (as long as "#" is your
       comment character), skip blank lines, join adjacent lines by
       escaping the newline (ie. backslash at end of line), strip
       leading and/or trailing whitespace.  All of these are optional
       and independently controllable.

       Provides a 'warn()' method so you can generate warning messages that
       report physical line number, even if the logical line in question
       spans multiple physical lines.  Also provides 'unreadline()' for
       implementing line-at-a-time lookahead.

       Constructor is called as:

           TextFile (filename=None, file=None, **options)

       It bombs (RuntimeError) if both 'filename' and 'file' are None;
       'filename' should be a string, and 'file' a file object (or
       something that provides 'readline()' and 'close()' methods).  It is
       recommended that you supply at least 'filename', so that TextFile
       can include it in warning messages.  If 'file' is not supplied,
       TextFile creates its own using 'io.open()'.

       The options are all boolean, and affect the value returned by
       'readline()':
         strip_comments [default: true]
           strip from "#" to end-of-line, as well as any whitespace
           leading up to the "#" -- unless it is escaped by a backslash
         lstrip_ws [default: false]
           strip leading whitespace from each line before returning it
         rstrip_ws [default: true]
           strip trailing whitespace (including line terminator!) from
           each line before returning it
         skip_blanks [default: true}
           skip lines that are empty *after* stripping comments and
           whitespace.  (If both lstrip_ws and rstrip_ws are false,
           then some lines may consist of solely whitespace: these will
           *not* be skipped, even if 'skip_blanks' is true.)
         join_lines [default: false]
FILE: ./venv/Lib/site-packages/setuptools/_distutils/unixccompiler.py
"""distutils.unixccompiler

Contains the UnixCCompiler class, a subclass of CCompiler that handles
the "typical" Unix-style command-line C compiler:
  * macros defined with -Dname[=value]
  * macros undefined with -Uname
  * include search directories specified with -Idir
  * libraries specified with -lllib
  * library search directories specified with -Ldir
  * compile handled by 'cc' (or similar) executable with -c option:
    compiles .c to .o
  * link static library handled by 'ar' command (possibly with 'ranlib')
  * link shared library handled by 'cc -shared'
"""

import os, sys, re, shlex

from distutils import sysconfig
from distutils.dep_util import newer
from distutils.ccompiler import \
     CCompiler, gen_preprocess_options, gen_lib_options
from distutils.errors import \
     DistutilsExecError, CompileError, LibError, LinkError
from distutils import log

if sys.platform == 'darwin':
    import _osx_support

# XXX Things not currently handled:
#   * optimization/debug/warning flags; we just use whatever's in Python's
#     Makefile and live with it.  Is this adequate?  If not, we might
#     have to have a bunch of subclasses GNUCCompiler, SGICCompiler,
#     SunCCompiler, and I suspect down that road lies madness.
#   * even if we don't know a warning flag from an optimization flag,
#     we need some way for outsiders to feed preprocessor/compiler/linker
#     flags in to us -- eg. a sysadmin might want to mandate certain flags
#     via a site config file, or a user might want to set something for
#     compiling this module distribution only via the setup.py command
#     line, whatever.  As long as these options come from something on the
#     current system, they can be as system-dependent as they like, and we
#     should just happily stuff them into the preprocessor/compiler/linker
#     options and carry on.


class UnixCCompiler(CCompiler):

    compiler_type = 'unix'

    # These are used by CCompiler in two places: the constructor sets
    # instance attributes 'preprocessor', 'compiler', etc. from them, and
FILE: ./venv/Lib/site-packages/setuptools/_distutils/util.py
"""distutils.util

Miscellaneous utility functions -- anything that doesn't fit into
one of the other *util.py modules.
"""

import os
import re
import importlib.util
import string
import sys
from distutils.errors import DistutilsPlatformError
from distutils.dep_util import newer
from distutils.spawn import spawn
from distutils import log
from distutils.errors import DistutilsByteCompileError
from .py35compat import _optim_args_from_interpreter_flags


def get_host_platform():
    """Return a string that identifies the current platform.  This is used mainly to
    distinguish platform-specific build directories and platform-specific built
    distributions.  Typically includes the OS name and version and the
    architecture (as supplied by 'os.uname()'), although the exact information
    included depends on the OS; eg. on Linux, the kernel version isn't
    particularly important.

    Examples of returned values:
       linux-i586
       linux-alpha (?)
       solaris-2.6-sun4u

    Windows will return one of:
       win-amd64 (64bit Windows on AMD64 (aka x86_64, Intel64, EM64T, etc)
       win32 (all others - specifically, sys.platform is returned)

    For other non-POSIX platforms, currently just returns 'sys.platform'.

    """
    if os.name == 'nt':
        if 'amd64' in sys.version.lower():
            return 'win-amd64'
        if '(arm)' in sys.version.lower():
            return 'win-arm32'
        if '(arm64)' in sys.version.lower():
            return 'win-arm64'
        return sys.platform

    # Set for cross builds explicitly
    if "_PYTHON_HOST_PLATFORM" in os.environ:
FILE: ./venv/Lib/site-packages/setuptools/_distutils/version.py
#
# distutils/version.py
#
# Implements multiple version numbering conventions for the
# Python Module Distribution Utilities.
#
# $Id$
#

"""Provides classes to represent module version numbers (one class for
each style of version numbering).  There are currently two such classes
implemented: StrictVersion and LooseVersion.

Every version number class implements the following interface:
  * the 'parse' method takes a string and parses it to some internal
    representation; if the string is an invalid version number,
    'parse' raises a ValueError exception
  * the class constructor takes an optional string argument which,
    if supplied, is passed to 'parse'
  * __str__ reconstructs the string that was passed to 'parse' (or
    an equivalent string -- ie. one that will generate an equivalent
    version number instance)
  * __repr__ generates Python code to recreate the version number instance
  * _cmp compares the current instance with either another instance
    of the same class or a string (which will be parsed to an instance
    of the same class, thus must follow the same rules)
"""

import re
import warnings
import contextlib


@contextlib.contextmanager
def suppress_known_deprecation():
    with warnings.catch_warnings(record=True) as ctx:
        warnings.filterwarnings(
            action='default',
            category=DeprecationWarning,
            message="distutils Version classes are deprecated.",
        )
        yield ctx


class Version:
    """Abstract base class for version numbering classes.  Just provides
    constructor (__init__) and reproducer (__repr__), because those
    seem to be the same for all version numbering classes; and route
    rich comparisons to _cmp.
    """
FILE: ./venv/Lib/site-packages/setuptools/_distutils/versionpredicate.py
"""Module for parsing and testing package version predicate strings.
"""
import re
import distutils.version
import operator


re_validPackage = re.compile(r"(?i)^\s*([a-z_]\w*(?:\.[a-z_]\w*)*)(.*)",
    re.ASCII)
# (package) (rest)

re_paren = re.compile(r"^\s*\((.*)\)\s*$") # (list) inside of parentheses
re_splitComparison = re.compile(r"^\s*(<=|>=|<|>|!=|==)\s*([^\s,]+)\s*$")
# (comp) (version)


def splitUp(pred):
    """Parse a single version comparison.

    Return (comparison string, StrictVersion)
    """
    res = re_splitComparison.match(pred)
    if not res:
        raise ValueError("bad package restriction syntax: %r" % pred)
    comp, verStr = res.groups()
    with distutils.version.suppress_known_deprecation():
        other = distutils.version.StrictVersion(verStr)
    return (comp, other)

compmap = {"<": operator.lt, "<=": operator.le, "==": operator.eq,
           ">": operator.gt, ">=": operator.ge, "!=": operator.ne}

class VersionPredicate:
    """Parse and test package version predicates.

    >>> v = VersionPredicate('pyepat.abc (>1.0, <3333.3a1, !=1555.1b3)')

    The `name` attribute provides the full dotted name that is given::

    >>> v.name
    'pyepat.abc'

    The str() of a `VersionPredicate` provides a normalized
    human-readable version of the expression::

    >>> print(v)
    pyepat.abc (> 1.0, < 3333.3a1, != 1555.1b3)

    The `satisfied_by()` method can be used to determine with a given
    version number is included in the set described by the version
FILE: ./venv/Lib/site-packages/setuptools/_distutils/_msvccompiler.py
"""distutils._msvccompiler

Contains MSVCCompiler, an implementation of the abstract CCompiler class
for Microsoft Visual Studio 2015.

The module is compatible with VS 2015 and later. You can find legacy support
for older versions in distutils.msvc9compiler and distutils.msvccompiler.
"""

# Written by Perry Stoll
# hacked by Robin Becker and Thomas Heller to do a better job of
#   finding DevStudio (through the registry)
# ported to VS 2005 and VS 2008 by Christian Heimes
# ported to VS 2015 by Steve Dower

import os
import subprocess
import contextlib
import warnings
import unittest.mock
with contextlib.suppress(ImportError):
    import winreg

from distutils.errors import DistutilsExecError, DistutilsPlatformError, \
                             CompileError, LibError, LinkError
from distutils.ccompiler import CCompiler, gen_lib_options
from distutils import log
from distutils.util import get_platform

from itertools import count

def _find_vc2015():
    try:
        key = winreg.OpenKeyEx(
            winreg.HKEY_LOCAL_MACHINE,
            r"Software\Microsoft\VisualStudio\SxS\VC7",
            access=winreg.KEY_READ | winreg.KEY_WOW64_32KEY
        )
    except OSError:
        log.debug("Visual C++ is not registered")
        return None, None

    best_version = 0
    best_dir = None
    with key:
        for i in count():
            try:
                v, vc_dir, vt = winreg.EnumValue(key, i)
            except OSError:
                break
FILE: ./venv/Lib/site-packages/setuptools/_distutils/__init__.py
"""distutils

The main package for the Python Module Distribution Utilities.  Normally
used from a setup script as

   from distutils.core import setup

   setup (...)
"""

import sys
import importlib

__version__ = sys.version[:sys.version.index(' ')]


try:
    # Allow Debian and pkgsrc (only) to customize system
    # behavior. Ref pypa/distutils#2 and pypa/distutils#16.
    # This hook is deprecated and no other environments
    # should use it.
    importlib.import_module('_distutils_system_mod')
except ImportError:
    pass
FILE: ./venv/Lib/site-packages/setuptools/_imp.py
"""
Re-implementation of find_module and get_frozen_object
from the deprecated imp module.
"""

import os
import importlib.util
import importlib.machinery

from .py34compat import module_from_spec


PY_SOURCE = 1
PY_COMPILED = 2
C_EXTENSION = 3
C_BUILTIN = 6
PY_FROZEN = 7


def find_spec(module, paths):
    finder = (
        importlib.machinery.PathFinder().find_spec
        if isinstance(paths, list) else
        importlib.util.find_spec
    )
    return finder(module, paths)


def find_module(module, paths=None):
    """Just like 'imp.find_module()', but with package support"""
    spec = find_spec(module, paths)
    if spec is None:
        raise ImportError("Can't find %s" % module)
    if not spec.has_location and hasattr(spec, 'submodule_search_locations'):
        spec = importlib.util.spec_from_loader('__init__.py', spec.loader)

    kind = -1
    file = None
    static = isinstance(spec.loader, type)
    if spec.origin == 'frozen' or static and issubclass(
            spec.loader, importlib.machinery.FrozenImporter):
        kind = PY_FROZEN
        path = None  # imp compabilty
        suffix = mode = ''  # imp compatibility
    elif spec.origin == 'built-in' or static and issubclass(
            spec.loader, importlib.machinery.BuiltinImporter):
        kind = C_BUILTIN
        path = None  # imp compabilty
        suffix = mode = ''  # imp compatibility
    elif spec.has_location:
FILE: ./venv/Lib/site-packages/setuptools/_vendor/more_itertools/more.py
import warnings

from collections import Counter, defaultdict, deque, abc
from collections.abc import Sequence
from concurrent.futures import ThreadPoolExecutor
from functools import partial, reduce, wraps
from heapq import merge, heapify, heapreplace, heappop
from itertools import (
    chain,
    compress,
    count,
    cycle,
    dropwhile,
    groupby,
    islice,
    repeat,
    starmap,
    takewhile,
    tee,
    zip_longest,
)
from math import exp, factorial, floor, log
from queue import Empty, Queue
from random import random, randrange, uniform
from operator import itemgetter, mul, sub, gt, lt
from sys import hexversion, maxsize
from time import monotonic

from .recipes import (
    consume,
    flatten,
    pairwise,
    powerset,
    take,
    unique_everseen,
)

__all__ = [
    'AbortThread',
    'adjacent',
    'always_iterable',
    'always_reversible',
    'bucket',
    'callback_iter',
    'chunked',
    'circular_shifts',
    'collapse',
    'collate',
    'consecutive_groups',
    'consumer',
FILE: ./venv/Lib/site-packages/setuptools/_vendor/more_itertools/recipes.py
"""Imported from the recipes section of the itertools documentation.

All functions taken from the recipes section of the itertools library docs
[1]_.
Some backward-compatible usability improvements have been made.

.. [1] http://docs.python.org/library/itertools.html#recipes

"""
import warnings
from collections import deque
from itertools import (
    chain,
    combinations,
    count,
    cycle,
    groupby,
    islice,
    repeat,
    starmap,
    tee,
    zip_longest,
)
import operator
from random import randrange, sample, choice

__all__ = [
    'all_equal',
    'consume',
    'convolve',
    'dotproduct',
    'first_true',
    'flatten',
    'grouper',
    'iter_except',
    'ncycles',
    'nth',
    'nth_combination',
    'padnone',
    'pad_none',
    'pairwise',
    'partition',
    'powerset',
    'prepend',
    'quantify',
    'random_combination_with_replacement',
    'random_combination',
    'random_permutation',
    'random_product',
    'repeatfunc',
FILE: ./venv/Lib/site-packages/setuptools/_vendor/more_itertools/__init__.py
from .more import *  # noqa
from .recipes import *  # noqa

__version__ = '8.8.0'
FILE: ./venv/Lib/site-packages/setuptools/_vendor/ordered_set.py
"""
An OrderedSet is a custom MutableSet that remembers its order, so that every
entry has an index that can be looked up.

Based on a recipe originally posted to ActiveState Recipes by Raymond Hettiger,
and released under the MIT license.
"""
import itertools as it
from collections import deque

try:
    # Python 3
    from collections.abc import MutableSet, Sequence
except ImportError:
    # Python 2.7
    from collections import MutableSet, Sequence

SLICE_ALL = slice(None)
__version__ = "3.1"


def is_iterable(obj):
    """
    Are we being asked to look up a list of things, instead of a single thing?
    We check for the `__iter__` attribute so that this can cover types that
    don't have to be known by this module, such as NumPy arrays.

    Strings, however, should be considered as atomic values to look up, not
    iterables. The same goes for tuples, since they are immutable and therefore
    valid entries.

    We don't need to check for the Python 2 `unicode` type, because it doesn't
    have an `__iter__` attribute anyway.
    """
    return (
        hasattr(obj, "__iter__")
        and not isinstance(obj, str)
        and not isinstance(obj, tuple)
    )


class OrderedSet(MutableSet, Sequence):
    """
    An OrderedSet is a custom MutableSet that remembers its order, so that
    every entry has an index that can be looked up.

    Example:
        >>> OrderedSet([1, 1, 2, 3, 2])
        OrderedSet([1, 2, 3])
    """
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/markers.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import operator
import os
import platform
import sys
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

from setuptools.extern.pyparsing import (  # noqa: N817
    Forward,
    Group,
    Literal as L,
    ParseException,
    ParseResults,
    QuotedString,
    ZeroOrMore,
    stringEnd,
    stringStart,
)

from .specifiers import InvalidSpecifier, Specifier

__all__ = [
    "InvalidMarker",
    "UndefinedComparison",
    "UndefinedEnvironmentName",
    "Marker",
    "default_environment",
]

Operator = Callable[[str, str], bool]


class InvalidMarker(ValueError):
    """
    An invalid marker was found, users should refer to PEP 508.
    """


class UndefinedComparison(ValueError):
    """
    An invalid operation was attempted on a value that doesn't support it.
    """


class UndefinedEnvironmentName(ValueError):
    """
    A name was attempted to be used that does not exist inside of the
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/requirements.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import re
import string
import urllib.parse
from typing import List, Optional as TOptional, Set

from setuptools.extern.pyparsing import (  # noqa
    Combine,
    Literal as L,
    Optional,
    ParseException,
    Regex,
    Word,
    ZeroOrMore,
    originalTextFor,
    stringEnd,
    stringStart,
)

from .markers import MARKER_EXPR, Marker
from .specifiers import LegacySpecifier, Specifier, SpecifierSet


class InvalidRequirement(ValueError):
    """
    An invalid requirement was found, users should refer to PEP 508.
    """


ALPHANUM = Word(string.ascii_letters + string.digits)

LBRACKET = L("[").suppress()
RBRACKET = L("]").suppress()
LPAREN = L("(").suppress()
RPAREN = L(")").suppress()
COMMA = L(",").suppress()
SEMICOLON = L(";").suppress()
AT = L("@").suppress()

PUNCTUATION = Word("-_.")
IDENTIFIER_END = ALPHANUM | (ZeroOrMore(PUNCTUATION) + ALPHANUM)
IDENTIFIER = Combine(ALPHANUM + ZeroOrMore(IDENTIFIER_END))

NAME = IDENTIFIER("name")
EXTRA = IDENTIFIER

URI = Regex(r"[^ ]+")("url")
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/specifiers.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import abc
import functools
import itertools
import re
import warnings
from typing import (
    Callable,
    Dict,
    Iterable,
    Iterator,
    List,
    Optional,
    Pattern,
    Set,
    Tuple,
    TypeVar,
    Union,
)

from .utils import canonicalize_version
from .version import LegacyVersion, Version, parse

ParsedVersion = Union[Version, LegacyVersion]
UnparsedVersion = Union[Version, LegacyVersion, str]
VersionTypeVar = TypeVar("VersionTypeVar", bound=UnparsedVersion)
CallableOperator = Callable[[ParsedVersion, str], bool]


class InvalidSpecifier(ValueError):
    """
    An invalid specifier was found, users should refer to PEP 440.
    """


class BaseSpecifier(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def __str__(self) -> str:
        """
        Returns the str representation of this Specifier like object. This
        should be representative of the Specifier itself.
        """

    @abc.abstractmethod
    def __hash__(self) -> int:
        """
        Returns a hash value for this Specifier like object.
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/tags.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import logging
import platform
import sys
import sysconfig
from importlib.machinery import EXTENSION_SUFFIXES
from typing import (
    Dict,
    FrozenSet,
    Iterable,
    Iterator,
    List,
    Optional,
    Sequence,
    Tuple,
    Union,
    cast,
)

from . import _manylinux, _musllinux

logger = logging.getLogger(__name__)

PythonVersion = Sequence[int]
MacVersion = Tuple[int, int]

INTERPRETER_SHORT_NAMES: Dict[str, str] = {
    "python": "py",  # Generic.
    "cpython": "cp",
    "pypy": "pp",
    "ironpython": "ip",
    "jython": "jy",
}


_32_BIT_INTERPRETER = sys.maxsize <= 2 ** 32


class Tag:
    """
    A representation of the tag triple for a wheel.

    Instances are considered immutable and thus are hashable. Equality checking
    is also supported.
    """

    __slots__ = ["_interpreter", "_abi", "_platform", "_hash"]
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/utils.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import re
from typing import FrozenSet, NewType, Tuple, Union, cast

from .tags import Tag, parse_tag
from .version import InvalidVersion, Version

BuildTag = Union[Tuple[()], Tuple[int, str]]
NormalizedName = NewType("NormalizedName", str)


class InvalidWheelFilename(ValueError):
    """
    An invalid wheel filename was found, users should refer to PEP 427.
    """


class InvalidSdistFilename(ValueError):
    """
    An invalid sdist filename was found, users should refer to the packaging user guide.
    """


_canonicalize_regex = re.compile(r"[-_.]+")
# PEP 427: The build number must start with a digit.
_build_tag_regex = re.compile(r"(\d+)(.*)")


def canonicalize_name(name: str) -> NormalizedName:
    # This is taken from PEP 503.
    value = _canonicalize_regex.sub("-", name).lower()
    return cast(NormalizedName, value)


def canonicalize_version(version: Union[Version, str]) -> str:
    """
    This is very similar to Version.__str__, but has one subtle difference
    with the way it handles the release segment.
    """
    if isinstance(version, str):
        try:
            parsed = Version(version)
        except InvalidVersion:
            # Legacy versions cannot be normalized
            return version
    else:
        parsed = version
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/version.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

import collections
import itertools
import re
import warnings
from typing import Callable, Iterator, List, Optional, SupportsInt, Tuple, Union

from ._structures import Infinity, InfinityType, NegativeInfinity, NegativeInfinityType

__all__ = ["parse", "Version", "LegacyVersion", "InvalidVersion", "VERSION_PATTERN"]

InfiniteTypes = Union[InfinityType, NegativeInfinityType]
PrePostDevType = Union[InfiniteTypes, Tuple[str, int]]
SubLocalType = Union[InfiniteTypes, int, str]
LocalType = Union[
    NegativeInfinityType,
    Tuple[
        Union[
            SubLocalType,
            Tuple[SubLocalType, str],
            Tuple[NegativeInfinityType, SubLocalType],
        ],
        ...,
    ],
]
CmpKey = Tuple[
    int, Tuple[int, ...], PrePostDevType, PrePostDevType, PrePostDevType, LocalType
]
LegacyCmpKey = Tuple[int, Tuple[str, ...]]
VersionComparisonMethod = Callable[
    [Union[CmpKey, LegacyCmpKey], Union[CmpKey, LegacyCmpKey]], bool
]

_Version = collections.namedtuple(
    "_Version", ["epoch", "release", "dev", "pre", "post", "local"]
)


def parse(version: str) -> Union["LegacyVersion", "Version"]:
    """
    Parse the given version string and return either a :class:`Version` object
    or a :class:`LegacyVersion` object depending on if the given version is
    a valid PEP 440 version or a legacy version.
    """
    try:
        return Version(version)
    except InvalidVersion:
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/_manylinux.py
import collections
import functools
import os
import re
import struct
import sys
import warnings
from typing import IO, Dict, Iterator, NamedTuple, Optional, Tuple


# Python does not provide platform information at sufficient granularity to
# identify the architecture of the running executable in some cases, so we
# determine it dynamically by reading the information from the running
# process. This only applies on Linux, which uses the ELF format.
class _ELFFileHeader:
    # https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#File_header
    class _InvalidELFFileHeader(ValueError):
        """
        An invalid ELF file header was found.
        """

    ELF_MAGIC_NUMBER = 0x7F454C46
    ELFCLASS32 = 1
    ELFCLASS64 = 2
    ELFDATA2LSB = 1
    ELFDATA2MSB = 2
    EM_386 = 3
    EM_S390 = 22
    EM_ARM = 40
    EM_X86_64 = 62
    EF_ARM_ABIMASK = 0xFF000000
    EF_ARM_ABI_VER5 = 0x05000000
    EF_ARM_ABI_FLOAT_HARD = 0x00000400

    def __init__(self, file: IO[bytes]) -> None:
        def unpack(fmt: str) -> int:
            try:
                data = file.read(struct.calcsize(fmt))
                result: Tuple[int, ...] = struct.unpack(fmt, data)
            except struct.error:
                raise _ELFFileHeader._InvalidELFFileHeader()
            return result[0]

        self.e_ident_magic = unpack(">I")
        if self.e_ident_magic != self.ELF_MAGIC_NUMBER:
            raise _ELFFileHeader._InvalidELFFileHeader()
        self.e_ident_class = unpack("B")
        if self.e_ident_class not in {self.ELFCLASS32, self.ELFCLASS64}:
            raise _ELFFileHeader._InvalidELFFileHeader()
        self.e_ident_data = unpack("B")
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/_musllinux.py
"""PEP 656 support.

This module implements logic to detect if the currently running Python is
linked against musl, and what musl version is used.
"""

import contextlib
import functools
import operator
import os
import re
import struct
import subprocess
import sys
from typing import IO, Iterator, NamedTuple, Optional, Tuple


def _read_unpacked(f: IO[bytes], fmt: str) -> Tuple[int, ...]:
    return struct.unpack(fmt, f.read(struct.calcsize(fmt)))


def _parse_ld_musl_from_elf(f: IO[bytes]) -> Optional[str]:
    """Detect musl libc location by parsing the Python executable.

    Based on: https://gist.github.com/lyssdod/f51579ae8d93c8657a5564aefc2ffbca
    ELF header: https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html
    """
    f.seek(0)
    try:
        ident = _read_unpacked(f, "16B")
    except struct.error:
        return None
    if ident[:4] != tuple(b"\x7fELF"):  # Invalid magic, not ELF.
        return None
    f.seek(struct.calcsize("HHI"), 1)  # Skip file type, machine, and version.

    try:
        # e_fmt: Format for program header.
        # p_fmt: Format for section header.
        # p_idx: Indexes to find p_type, p_offset, and p_filesz.
        e_fmt, p_fmt, p_idx = {
            1: ("IIIIHHH", "IIIIIIII", (0, 1, 4)),  # 32-bit.
            2: ("QQQIHHH", "IIQQQQQQ", (0, 2, 5)),  # 64-bit.
        }[ident[4]]
    except KeyError:
        return None
    else:
        p_get = operator.itemgetter(*p_idx)

    # Find the interpreter section and return its content.
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/_structures.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.


class InfinityType:
    def __repr__(self) -> str:
        return "Infinity"

    def __hash__(self) -> int:
        return hash(repr(self))

    def __lt__(self, other: object) -> bool:
        return False

    def __le__(self, other: object) -> bool:
        return False

    def __eq__(self, other: object) -> bool:
        return isinstance(other, self.__class__)

    def __ne__(self, other: object) -> bool:
        return not isinstance(other, self.__class__)

    def __gt__(self, other: object) -> bool:
        return True

    def __ge__(self, other: object) -> bool:
        return True

    def __neg__(self: object) -> "NegativeInfinityType":
        return NegativeInfinity


Infinity = InfinityType()


class NegativeInfinityType:
    def __repr__(self) -> str:
        return "-Infinity"

    def __hash__(self) -> int:
        return hash(repr(self))

    def __lt__(self, other: object) -> bool:
        return True

    def __le__(self, other: object) -> bool:
        return True

FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/__about__.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

__all__ = [
    "__title__",
    "__summary__",
    "__uri__",
    "__version__",
    "__author__",
    "__email__",
    "__license__",
    "__copyright__",
]

__title__ = "packaging"
__summary__ = "Core utilities for Python packages"
__uri__ = "https://github.com/pypa/packaging"

__version__ = "21.2"

__author__ = "Donald Stufft and individual contributors"
__email__ = "donald@stufft.io"

__license__ = "BSD-2-Clause or Apache-2.0"
__copyright__ = "2014-2019 %s" % __author__
FILE: ./venv/Lib/site-packages/setuptools/_vendor/packaging/__init__.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

from .__about__ import (
    __author__,
    __copyright__,
    __email__,
    __license__,
    __summary__,
    __title__,
    __uri__,
    __version__,
)

__all__ = [
    "__title__",
    "__summary__",
    "__uri__",
    "__version__",
    "__author__",
    "__email__",
    "__license__",
    "__copyright__",
]
FILE: ./venv/Lib/site-packages/setuptools/_vendor/pyparsing.py
# module pyparsing.py
#
# Copyright (c) 2003-2018  Paul T. McGuire
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#

__doc__ = \
"""
pyparsing module - Classes and methods to define and execute parsing grammars
=============================================================================

The pyparsing module is an alternative approach to creating and executing simple grammars,
vs. the traditional lex/yacc approach, or the use of regular expressions.  With pyparsing, you
don't need to learn a new syntax for defining grammars or matching expressions - the parsing module
provides a library of classes that you use to construct the grammar directly in Python.

Here is a program to parse "Hello, World!" (or any greeting of the form 
C{"<salutation>, <addressee>!"}), built up using L{Word}, L{Literal}, and L{And} elements 
(L{'+'<ParserElement.__add__>} operator gives L{And} expressions, strings are auto-converted to
L{Literal} expressions)::

    from pyparsing import Word, alphas

    # define grammar of a greeting
    greet = Word(alphas) + "," + Word(alphas) + "!"

    hello = "Hello, World!"
    print (hello, "->", greet.parseString(hello))

The program outputs the following::

    Hello, World! -> ['Hello', ',', 'World', '!']
FILE: ./venv/Lib/site-packages/setuptools/_vendor/__init__.py
FILE: ./venv/Lib/site-packages/setuptools/__init__.py
"""Extensions to the 'distutils' for large or complex distributions"""

from fnmatch import fnmatchcase
import functools
import os
import re

import _distutils_hack.override  # noqa: F401

import distutils.core
from distutils.errors import DistutilsOptionError
from distutils.util import convert_path

from ._deprecation_warning import SetuptoolsDeprecationWarning

import setuptools.version
from setuptools.extension import Extension
from setuptools.dist import Distribution
from setuptools.depends import Require
from . import monkey
from . import logging


__all__ = [
    'setup',
    'Distribution',
    'Command',
    'Extension',
    'Require',
    'SetuptoolsDeprecationWarning',
    'find_packages',
    'find_namespace_packages',
]

__version__ = setuptools.version.__version__

bootstrap_install_from = None


class PackageFinder:
    """
    Generate a list of all Python packages found within a directory
    """

    @classmethod
    def find(cls, where='.', exclude=(), include=('*',)):
        """Return a list all Python packages found within directory 'where'

        'where' is the root directory which will be searched for packages.  It
        should be supplied as a "cross-platform" (i.e. URL-style) path; it will
FILE: ./venv/Lib/site-packages/wheel/bdist_wheel.py
"""
Create a wheel (.whl) distribution.

A wheel is a built archive format.
"""

import distutils
import os
import shutil
import stat
import sys
import re
import warnings
from collections import OrderedDict
from distutils.core import Command
from distutils import log as logger
from io import BytesIO
from glob import iglob
from shutil import rmtree
from sysconfig import get_config_var
from zipfile import ZIP_DEFLATED, ZIP_STORED

import pkg_resources

from .pkginfo import write_pkg_info
from .macosx_libfile import calculate_macosx_platform_tag
from .metadata import pkginfo_to_metadata
from .vendored.packaging import tags
from .wheelfile import WheelFile
from . import __version__ as wheel_version

if sys.version_info < (3,):
    from email.generator import Generator as BytesGenerator
else:
    from email.generator import BytesGenerator

safe_name = pkg_resources.safe_name
safe_version = pkg_resources.safe_version

PY_LIMITED_API_PATTERN = r'cp3\d'


def python_tag():
    return 'py{}'.format(sys.version_info[0])


def get_platform(archive_root):
    """Return our platform name 'win32', 'linux_x86_64'"""
    # XXX remove distutils dependency
    result = distutils.util.get_platform()
FILE: ./venv/Lib/site-packages/wheel/cli/convert.py
import os.path
import re
import shutil
import sys
import tempfile
import zipfile
from distutils import dist
from glob import iglob

from ..bdist_wheel import bdist_wheel
from ..wheelfile import WheelFile
from . import WheelError, require_pkgresources

egg_info_re = re.compile(r'''
    (?P<name>.+?)-(?P<ver>.+?)
    (-(?P<pyver>py\d\.\d+)
     (-(?P<arch>.+?))?
    )?.egg$''', re.VERBOSE)


class _bdist_wheel_tag(bdist_wheel):
    # allow the client to override the default generated wheel tag
    # The default bdist_wheel implementation uses python and abi tags
    # of the running python process. This is not suitable for
    # generating/repackaging prebuild binaries.

    full_tag_supplied = False
    full_tag = None  # None or a (pytag, soabitag, plattag) triple

    def get_tag(self):
        if self.full_tag_supplied and self.full_tag is not None:
            return self.full_tag
        else:
            return bdist_wheel.get_tag(self)


def egg2wheel(egg_path, dest_dir):
    filename = os.path.basename(egg_path)
    match = egg_info_re.match(filename)
    if not match:
        raise WheelError('Invalid egg file name: {}'.format(filename))

    egg_info = match.groupdict()
    dir = tempfile.mkdtemp(suffix="_e2w")
    if os.path.isfile(egg_path):
        # assume we have a bdist_egg otherwise
        with zipfile.ZipFile(egg_path) as egg:
            egg.extractall(dir)
    else:
        # support buildout-style installed eggs directories
FILE: ./venv/Lib/site-packages/wheel/cli/pack.py
from __future__ import print_function

import os.path
import re
import sys

from wheel.cli import WheelError
from wheel.wheelfile import WheelFile

DIST_INFO_RE = re.compile(r"^(?P<namever>(?P<name>.+?)-(?P<ver>\d.*?))\.dist-info$")
BUILD_NUM_RE = re.compile(br'Build: (\d\w*)$')


def pack(directory, dest_dir, build_number):
    """Repack a previously unpacked wheel directory into a new wheel file.

    The .dist-info/WHEEL file must contain one or more tags so that the target
    wheel file name can be determined.

    :param directory: The unpacked wheel directory
    :param dest_dir: Destination directory (defaults to the current directory)
    """
    # Find the .dist-info directory
    dist_info_dirs = [fn for fn in os.listdir(directory)
                      if os.path.isdir(os.path.join(directory, fn)) and DIST_INFO_RE.match(fn)]
    if len(dist_info_dirs) > 1:
        raise WheelError('Multiple .dist-info directories found in {}'.format(directory))
    elif not dist_info_dirs:
        raise WheelError('No .dist-info directories found in {}'.format(directory))

    # Determine the target wheel filename
    dist_info_dir = dist_info_dirs[0]
    name_version = DIST_INFO_RE.match(dist_info_dir).group('namever')

    # Read the tags and the existing build number from .dist-info/WHEEL
    existing_build_number = None
    wheel_file_path = os.path.join(directory, dist_info_dir, 'WHEEL')
    with open(wheel_file_path) as f:
        tags = []
        for line in f:
            if line.startswith('Tag: '):
                tags.append(line.split(' ')[1].rstrip())
            elif line.startswith('Build: '):
                existing_build_number = line.split(' ')[1].rstrip()

        if not tags:
            raise WheelError('No tags present in {}/WHEEL; cannot determine target wheel filename'
                             .format(dist_info_dir))

    # Set the wheel file name and add/replace/remove the Build tag in .dist-info/WHEEL
FILE: ./venv/Lib/site-packages/wheel/cli/unpack.py
from __future__ import print_function

import os.path
import sys

from ..wheelfile import WheelFile


def unpack(path, dest='.'):
    """Unpack a wheel.

    Wheel content will be unpacked to {dest}/{name}-{ver}, where {name}
    is the package name and {ver} its version.

    :param path: The path to the wheel.
    :param dest: Destination directory (default to current directory).
    """
    with WheelFile(path) as wf:
        namever = wf.parsed_filename.group('namever')
        destination = os.path.join(dest, namever)
        print("Unpacking to: {}...".format(destination), end='')
        sys.stdout.flush()
        wf.extractall(destination)

    print('OK')
FILE: ./venv/Lib/site-packages/wheel/cli/__init__.py
"""
Wheel command-line utility.
"""

from __future__ import print_function

import argparse
import os
import sys


def require_pkgresources(name):
    try:
        import pkg_resources  # noqa: F401
    except ImportError:
        raise RuntimeError("'{0}' needs pkg_resources (part of setuptools).".format(name))


class WheelError(Exception):
    pass


def unpack_f(args):
    from .unpack import unpack
    unpack(args.wheelfile, args.dest)


def pack_f(args):
    from .pack import pack
    pack(args.directory, args.dest_dir, args.build_number)


def convert_f(args):
    from .convert import convert
    convert(args.files, args.dest_dir, args.verbose)


def version_f(args):
    from .. import __version__
    print("wheel %s" % __version__)


def parser():
    p = argparse.ArgumentParser()
    s = p.add_subparsers(help="commands")

    unpack_parser = s.add_parser('unpack', help='Unpack wheel')
    unpack_parser.add_argument('--dest', '-d', help='Destination directory',
                               default='.')
    unpack_parser.add_argument('wheelfile', help='Wheel file')
FILE: ./venv/Lib/site-packages/wheel/macosx_libfile.py
"""
This module contains function to analyse dynamic library
headers to extract system information

Currently only for MacOSX

Library file on macosx system starts with Mach-O or Fat field.
This can be distinguish by first 32 bites and it is called magic number.
Proper value of magic number is with suffix _MAGIC. Suffix _CIGAM means
reversed bytes order.
Both fields can occur in two types: 32 and 64 bytes.

FAT field inform that this library contains few version of library
(typically for different types version). It contains
information where Mach-O headers starts.

Each section started with Mach-O header contains one library
(So if file starts with this field it contains only one version).

After filed Mach-O there are section fields.
Each of them starts with two fields:
cmd - magic number for this command
cmdsize - total size occupied by this section information.

In this case only sections LC_VERSION_MIN_MACOSX (for macosx 10.13 and earlier)
and LC_BUILD_VERSION (for macosx 10.14 and newer) are interesting,
because them contains information about minimal system version.

Important remarks:
- For fat files this implementation looks for maximum number version.
  It not check if it is 32 or 64 and do not compare it with currently built package.
  So it is possible to false report higher version that needed.
- All structures signatures are taken form macosx header files.
- I think that binary format will be more stable than `otool` output.
  and if apple introduce some changes both implementation will need to be updated.
- The system compile will set the deployment target no lower than
  11.0 for arm64 builds. For "Universal 2" builds use the x86_64 deployment
  target when the arm64 target is 11.0.
"""

import ctypes
import os
import sys

"""here the needed const and struct from mach-o header files"""

FAT_MAGIC = 0xcafebabe
FAT_CIGAM = 0xbebafeca
FAT_MAGIC_64 = 0xcafebabf
FAT_CIGAM_64 = 0xbfbafeca
FILE: ./venv/Lib/site-packages/wheel/metadata.py
"""
Tools for converting old- to new-style metadata.
"""

import os.path
import textwrap

import pkg_resources

from .pkginfo import read_pkg_info


def requires_to_requires_dist(requirement):
    """Return the version specifier for a requirement in PEP 345/566 fashion."""
    if getattr(requirement, 'url', None):
        return " @ " + requirement.url

    requires_dist = []
    for op, ver in requirement.specs:
        requires_dist.append(op + ver)
    if not requires_dist:
        return ''
    return " (%s)" % ','.join(sorted(requires_dist))


def convert_requirements(requirements):
    """Yield Requires-Dist: strings for parsed requirements strings."""
    for req in requirements:
        parsed_requirement = pkg_resources.Requirement.parse(req)
        spec = requires_to_requires_dist(parsed_requirement)
        extras = ",".join(sorted(parsed_requirement.extras))
        if extras:
            extras = "[%s]" % extras
        yield (parsed_requirement.project_name + extras + spec)


def generate_requirements(extras_require):
    """
    Convert requirements from a setup()-style dictionary to ('Requires-Dist', 'requirement')
    and ('Provides-Extra', 'extra') tuples.

    extras_require is a dictionary of {extra: [requirements]} as passed to setup(),
    using the empty extra {'': [requirements]} to hold install_requires.
    """
    for extra, depends in extras_require.items():
        condition = ''
        extra = extra or ''
        if ':' in extra:  # setuptools extra:condition syntax
            extra, condition = extra.split(':', 1)

FILE: ./venv/Lib/site-packages/wheel/pkginfo.py
"""Tools for reading and writing PKG-INFO / METADATA without caring
about the encoding."""

from email.parser import Parser

try:
    unicode
    _PY3 = False
except NameError:
    _PY3 = True

if not _PY3:
    from email.generator import Generator

    def read_pkg_info_bytes(bytestr):
        return Parser().parsestr(bytestr)

    def read_pkg_info(path):
        with open(path, "r") as headers:
            message = Parser().parse(headers)
        return message

    def write_pkg_info(path, message):
        with open(path, 'w') as metadata:
            Generator(metadata, mangle_from_=False, maxheaderlen=0).flatten(message)
else:
    from email.generator import BytesGenerator

    def read_pkg_info_bytes(bytestr):
        headers = bytestr.decode(encoding="ascii", errors="surrogateescape")
        message = Parser().parsestr(headers)
        return message

    def read_pkg_info(path):
        with open(path, "r",
                  encoding="ascii",
                  errors="surrogateescape") as headers:
            message = Parser().parse(headers)
        return message

    def write_pkg_info(path, message):
        with open(path, "wb") as out:
            BytesGenerator(out, mangle_from_=False, maxheaderlen=0).flatten(message)
FILE: ./venv/Lib/site-packages/wheel/util.py
import base64
import io
import sys


if sys.version_info[0] < 3:
    text_type = unicode  # noqa: F821

    StringIO = io.BytesIO

    def native(s, encoding='utf-8'):
        if isinstance(s, unicode):  # noqa: F821
            return s.encode(encoding)
        return s
else:
    text_type = str

    StringIO = io.StringIO

    def native(s, encoding='utf-8'):
        if isinstance(s, bytes):
            return s.decode(encoding)
        return s


def urlsafe_b64encode(data):
    """urlsafe_b64encode without padding"""
    return base64.urlsafe_b64encode(data).rstrip(b'=')


def urlsafe_b64decode(data):
    """urlsafe_b64decode without padding"""
    pad = b'=' * (4 - (len(data) & 3))
    return base64.urlsafe_b64decode(data + pad)


def as_unicode(s):
    if isinstance(s, bytes):
        return s.decode('utf-8')
    return s


def as_bytes(s):
    if isinstance(s, text_type):
        return s.encode('utf-8')
    return s
FILE: ./venv/Lib/site-packages/wheel/vendored/packaging/tags.py
# This file is dual licensed under the terms of the Apache License, Version
# 2.0, and the BSD License. See the LICENSE file in the root of this repository
# for complete details.

from __future__ import absolute_import

import distutils.util

try:
    from importlib.machinery import EXTENSION_SUFFIXES
except ImportError:  # pragma: no cover
    import imp

    EXTENSION_SUFFIXES = [x[0] for x in imp.get_suffixes()]
    del imp
import collections
import logging
import os
import platform
import re
import struct
import sys
import sysconfig
import warnings

from ._typing import TYPE_CHECKING, cast

if TYPE_CHECKING:  # pragma: no cover
    from typing import (
        Dict,
        FrozenSet,
        IO,
        Iterable,
        Iterator,
        List,
        Optional,
        Sequence,
        Tuple,
        Union,
    )

    PythonVersion = Sequence[int]
    MacVersion = Tuple[int, int]
    GlibcVersion = Tuple[int, int]


logger = logging.getLogger(__name__)

INTERPRETER_SHORT_NAMES = {
    "python": "py",  # Generic.
FILE: ./venv/Lib/site-packages/wheel/vendored/packaging/_typing.py
"""For neatly implementing static typing in packaging.

`mypy` - the static type analysis tool we use - uses the `typing` module, which
provides core functionality fundamental to mypy's functioning.

Generally, `typing` would be imported at runtime and used in that fashion -
it acts as a no-op at runtime and does not have any run-time overhead by
design.

As it turns out, `typing` is not vendorable - it uses separate sources for
Python 2/Python 3. Thus, this codebase can not expect it to be present.
To work around this, mypy allows the typing import to be behind a False-y
optional to prevent it from running at runtime and type-comments can be used
to remove the need for the types to be accessible directly during runtime.

This module provides the False-y guard in a nicely named fashion so that a
curious maintainer can reach here to read this.

In packaging, all static-typing related imports should be guarded as follows:

    from packaging._typing import TYPE_CHECKING

    if TYPE_CHECKING:
        from typing import ...

Ref: https://github.com/python/mypy/issues/3216
"""

__all__ = ["TYPE_CHECKING", "cast"]

# The TYPE_CHECKING constant defined by the typing module is False at runtime
# but True while type checking.
if False:  # pragma: no cover
    from typing import TYPE_CHECKING
else:
    TYPE_CHECKING = False

# typing's cast syntax requires calling typing.cast at runtime, but we don't
# want to import typing at runtime. Here, we inform the type checkers that
# we're importing `typing.cast` as `cast` and re-implement typing.cast's
# runtime behavior in a block that is ignored by type checkers.
if TYPE_CHECKING:  # pragma: no cover
    # not executed at runtime
    from typing import cast
else:
    # executed at runtime
    def cast(type_, value):  # noqa
        return value
FILE: ./venv/Lib/site-packages/wheel/vendored/packaging/__init__.py
FILE: ./venv/Lib/site-packages/wheel/vendored/__init__.py
FILE: ./venv/Lib/site-packages/wheel/wheelfile.py
from __future__ import print_function

import csv
import hashlib
import os.path
import re
import stat
import sys
import time
from collections import OrderedDict
from distutils import log as logger
from zipfile import ZIP_DEFLATED, ZipInfo, ZipFile

from wheel.cli import WheelError
from wheel.util import urlsafe_b64decode, as_unicode, native, urlsafe_b64encode, as_bytes, StringIO

if sys.version_info >= (3,):
    from io import TextIOWrapper

    def read_csv(fp):
        return csv.reader(TextIOWrapper(fp, newline='', encoding='utf-8'))
else:
    def read_csv(fp):
        for line in csv.reader(fp):
            yield [column.decode('utf-8') for column in line]

# Non-greedy matching of an optional build number may be too clever (more
# invalid wheel filenames will match). Separate regex for .dist-info?
WHEEL_INFO_RE = re.compile(
    r"""^(?P<namever>(?P<name>.+?)-(?P<ver>.+?))(-(?P<build>\d[^-]*))?
     -(?P<pyver>.+?)-(?P<abi>.+?)-(?P<plat>.+?)\.whl$""",
    re.VERBOSE)


def get_zipinfo_datetime(timestamp=None):
    # Some applications need reproducible .whl files, but they can't do this without forcing
    # the timestamp of the individual ZipInfo objects. See issue #143.
    timestamp = int(os.environ.get('SOURCE_DATE_EPOCH', timestamp or time.time()))
    return time.gmtime(timestamp)[0:6]


class WheelFile(ZipFile):
    """A ZipFile derivative class that also reads SHA-256 hashes from
    .dist-info/RECORD and checks any read files against those.
    """

    _default_algorithm = hashlib.sha256

    def __init__(self, file, mode='r', compression=ZIP_DEFLATED):
        basename = os.path.basename(file)
FILE: ./venv/Lib/site-packages/wheel/__init__.py
__version__ = '0.37.1'
FILE: ./venv/Lib/site-packages/wheel/__main__.py
"""
Wheel command line tool (enable python -m wheel syntax)
"""

import sys


def main():  # needed for console script
    if __package__ == '':
        # To be able to run 'python wheel-0.9.whl/wheel':
        import os.path
        path = os.path.dirname(os.path.dirname(__file__))
        sys.path[0:0] = [path]
    import wheel.cli
    sys.exit(wheel.cli.main())


if __name__ == "__main__":
    sys.exit(main())
FILE: ./venv/Lib/site-packages/_distutils_hack/override.py
__import__('_distutils_hack').do_override()
FILE: ./venv/Lib/site-packages/_distutils_hack/__init__.py
import sys
import os
import re
import importlib
import warnings
import contextlib


is_pypy = '__pypy__' in sys.builtin_module_names


warnings.filterwarnings('ignore',
                        r'.+ distutils\b.+ deprecated',
                        DeprecationWarning)


def warn_distutils_present():
    if 'distutils' not in sys.modules:
        return
    if is_pypy and sys.version_info < (3, 7):
        # PyPy for 3.6 unconditionally imports distutils, so bypass the warning
        # https://foss.heptapod.net/pypy/pypy/-/blob/be829135bc0d758997b3566062999ee8b23872b4/lib-python/3/site.py#L250
        return
    warnings.warn(
        "Distutils was imported before Setuptools, but importing Setuptools "
        "also replaces the `distutils` module in `sys.modules`. This may lead "
        "to undesirable behaviors or errors. To avoid these issues, avoid "
        "using distutils directly, ensure that setuptools is installed in the "
        "traditional way (e.g. not an editable install), and/or make sure "
        "that setuptools is always imported before distutils.")


def clear_distutils():
    if 'distutils' not in sys.modules:
        return
    warnings.warn("Setuptools is replacing distutils.")
    mods = [name for name in sys.modules if re.match(r'distutils\b', name)]
    for name in mods:
        del sys.modules[name]


def enabled():
    """
    Allow selection of distutils by environment variable.
    """
    which = os.environ.get('SETUPTOOLS_USE_DISTUTILS', 'local')
    return which == 'local'


def ensure_local_distutils():
FILE: ./venv/Lib/site-packages/_virtualenv.py
"""Patches that are applied at runtime to the virtual environment"""
# -*- coding: utf-8 -*-

import os
import sys

VIRTUALENV_PATCH_FILE = os.path.join(__file__)


def patch_dist(dist):
    """
    Distutils allows user to configure some arguments via a configuration file:
    https://docs.python.org/3/install/index.html#distutils-configuration-files

    Some of this arguments though don't make sense in context of the virtual environment files, let's fix them up.
    """
    # we cannot allow some install config as that would get packages installed outside of the virtual environment
    old_parse_config_files = dist.Distribution.parse_config_files

    def parse_config_files(self, *args, **kwargs):
        result = old_parse_config_files(self, *args, **kwargs)
        install = self.get_option_dict("install")

        if "prefix" in install:  # the prefix governs where to install the libraries
            install["prefix"] = VIRTUALENV_PATCH_FILE, os.path.abspath(sys.prefix)
        for base in ("purelib", "platlib", "headers", "scripts", "data"):
            key = "install_{}".format(base)
            if key in install:  # do not allow global configs to hijack venv paths
                install.pop(key, None)
        return result

    dist.Distribution.parse_config_files = parse_config_files


# Import hook that patches some modules to ignore configuration values that break package installation in case
# of virtual environments.
_DISTUTILS_PATCH = "distutils.dist", "setuptools.dist"
if sys.version_info > (3, 4):
    # https://docs.python.org/3/library/importlib.html#setting-up-an-importer
    from functools import partial
    from importlib.abc import MetaPathFinder
    from importlib.util import find_spec

    class _Finder(MetaPathFinder):
        """A meta path finder that allows patching the imported distutils modules"""

        fullname = None

        # lock[0] is threading.Lock(), but initialized lazily to avoid importing threading very early at startup,
        # because there are gevent-based applications that need to be first to import threading by themselves.
FILE: ./venv/Scripts/activate_this.py
# -*- coding: utf-8 -*-
"""Activate virtualenv for current interpreter:

Use exec(open(this_file).read(), {'__file__': this_file}).

This can be used when you must use an existing Python interpreter, not the virtualenv bin/python.
"""
import os
import site
import sys

try:
    abs_file = os.path.abspath(__file__)
except NameError:
    raise AssertionError("You must use exec(open(this_file).read(), {'__file__': this_file}))")

bin_dir = os.path.dirname(abs_file)
base = bin_dir[: -len("Scripts") - 1]  # strip away the bin part from the __file__, plus the path separator

# prepend bin to PATH (this file is inside the bin directory)
os.environ["PATH"] = os.pathsep.join([bin_dir] + os.environ.get("PATH", "").split(os.pathsep))
os.environ["VIRTUAL_ENV"] = base  # virtual env is right above bin directory

# add the virtual environments libraries to the host python import mechanism
prev_length = len(sys.path)
for lib in "..\Lib\site-packages".split(os.pathsep):
    path = os.path.realpath(os.path.join(bin_dir, lib))
    site.addsitedir(path.decode("utf-8") if "" else path)
sys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]

sys.real_prefix = sys.prefix
sys.prefix = base
FILE: ./websocket_listener_service/config.json
{"connection_id": "4cd94429-3e01-45d8-85f2-33ebea3dad9e"}FILE: ./websocket_listener_service/controllers/listener_controller.py
import logging
import httpx
from fastapi import APIRouter, HTTPException, Depends, Request
from websocket_listener_service.models.envelope import Envelope
from websocket_listener_service.models.register_request import RegisterRequest
from websocket_listener_service.models.deregister_request import DeregisterRequest
from websocket_listener_service.services.forward_service import ForwardService
from websocket_listener_service.services.registry_service import RegistryService

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()

def get_services(request: Request):
    logger.info("Retrieving services from app state")
    service_registry = request.app.state.service_registry
    connection_id = request.app.state.connection_id

    forward_service = ForwardService("http://localhost:8010")
    registry_service = RegistryService(service_registry, connection_id)
    logger.info("Services retrieved successfully")
    return forward_service, registry_service

@router.post("/forward")
async def forward_request(envelope: Envelope, services=Depends(get_services)):
    forward_service, _ = services
    logger.info(f"Received forward request: {envelope}")
    response = await forward_service.forward_request(envelope)
    logger.info(f"Forward request response: {response}")
    return response

@router.post("/register")
async def register_service(request: RegisterRequest, services=Depends(get_services)):
    _, registry_service = services
    logger.info(f"Received register service request: {request}")
    response = await registry_service.register_service(request)
    logger.info(f"Register service response: {response}")
    return response

@router.post("/deregister")
async def deregister_service(request: DeregisterRequest, services=Depends(get_services)):
    _, registry_service = services
    logger.info(f"Received deregister service request: {request}")
    response = await registry_service.deregister_service(request)
    logger.info(f"Deregister service response: {response}")
    return response

@router.get("/get_registered_services")
FILE: ./websocket_listener_service/controllers/__init__.py

FILE: ./websocket_listener_service/main.py
import logging
import asyncio
from fastapi import FastAPI, WebSocket
from websocket_listener_service.controllers import listener_controller
from websocket_listener_service.websocket.websocket_handler import WebSocketHandler
from websocket_listener_service.models.register_request import RegisterRequest
from websocket_listener_service.services.config_service import ConfigService
from websocket_listener_service.services.registry_service import RegistryService

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()

async def register_service():
    openapi_schema = app.openapi()

    # Hardcoding the servers field
    openapi_schema['servers'] = [{"url": f"http://localhost:8010"}]
    app.openapi_schema = openapi_schema

    await asyncio.sleep(10)  # Wait for the server to be fully up and running

    registry_service = app.state.registry_service
    openapi_url = "http://localhost:8010/openapi.json"

    register_request = RegisterRequest(
        service_name="websocket_listener_service",
        openapi_url=openapi_url
    )
    await registry_service.register_service(register_request)
    logger.info("Service 'websocket_listener_service' registered successfully.")

@app.on_event("startup")
async def startup_event():
    # Setup initial services and state
    service_registry = {}
    config_service = ConfigService()
    connection_id = config_service.get_connection_id()
    host = "localhost"
    port = 8010
    path = ""

    registry_service = RegistryService(service_registry, connection_id)
    app.state.service_registry = service_registry
    app.state.connection_id = connection_id
    app.state.registry_service = registry_service
    app.state.host = host
    app.state.port = port
    app.state.path = path
FILE: ./websocket_listener_service/models/deregister_request.py
from pydantic import BaseModel

class DeregisterRequest(BaseModel):
    service_name: str
FILE: ./websocket_listener_service/models/envelope.py
from pydantic import BaseModel, Field
from typing import Any, Optional


class Envelope(BaseModel):
    endpoint_service_name: str = Field(..., description="Name of the service to forward the request to")
    endpoint_path: str = Field(..., description="Path of the service endpoint")
    endpoint_request_type: str = Field(..., description="HTTP method of the request (GET, POST, etc.)")
    endpoint_headers: Any = Field(default={}, description="Headers to include in the forwarded request")
    endpoint_params: Any = Field(default={}, description="Query parameters to include in the forwarded request")
    endpoint_body: Any = Field(default={}, description="Body of the forwarded request")
    connection_id: Optional[str] = Field(None, description="Connection ID for WebSocket listener")
    endpoint_url: str = Field(..., description="URL of the service to register")FILE: ./websocket_listener_service/models/register_request.py
from typing import Optional, Dict, Any
from pydantic import BaseModel

class RegisterRequest(BaseModel):
    service_name: str
    openapi_url: Optional[str] = None  # Make this field optional
    openapi_json: Optional[Dict[str, Any]] = None  # Make this field optional and ensure it's a dictionary
FILE: ./websocket_listener_service/models/__init__.py

FILE: ./websocket_listener_service/services/config_service.py
import json
import logging
import os
import uuid

class ConfigService:
    CONFIG_FILE = "websocket_listener_service/config.json"

    def load_config(self):
        if os.path.exists(self.CONFIG_FILE):
            with open(self.CONFIG_FILE, "r") as file:
                logging.info("Loading configuration from file")
                return json.load(file)
        return {}

    def save_config(self, config):
        with open(self.CONFIG_FILE, "w") as file:
            json.dump(config, file)

    def get_connection_id(self):
        config = self.load_config()
        if "connection_id" not in config:
            config["connection_id"] = str(uuid.uuid4())
            self.save_config(config)
        return config["connection_id"]
FILE: ./websocket_listener_service/services/forward_service.py
import httpx
import logging
from fastapi import HTTPException
from websocket_listener_service.models.envelope import Envelope

class ForwardService:
    def __init__(self, registry_service_url):
        self.registry_service_url = registry_service_url

    async def forward_request(self, envelope: Envelope):
        logging.debug(f"forward_request: Received envelope : {envelope}")
        service_name = envelope.endpoint_service_name
        logging.debug(f"forward_request: service_name : {service_name}")

        # Call the get_service_url endpoint to get the service URL
        async with httpx.AsyncClient() as client:
            try:
                response = await client.get(f"{self.registry_service_url}/get_service_url/{service_name}")
                response.raise_for_status()
                service_url = response.json().get("url").get("url")  # Extract the URL correctly from JSON response
                if not service_url:
                    raise ValueError("Service URL not found in response")
            except (httpx.HTTPStatusError, ValueError) as e:
                logging.error(f"Failed to retrieve service URL for {service_name}: {str(e)}")
                # raise HTTPException(status_code=500, detail="Failed to retrieve service URL")

        if service_url:
            # Ensure service_url is a string and construct the full URL
            endpoint_full_url = f"{service_url}{envelope.endpoint_path}"  # Construct the full URL as a string
            logging.info(f"Attempting to call: {endpoint_full_url}")

            try:
                async with httpx.AsyncClient() as client:
                    response = await client.request(
                        method=envelope.endpoint_request_type,
                        url=endpoint_full_url,  # Use the constructed full URL
                        headers=envelope.endpoint_headers,
                        params=envelope.endpoint_params,
                        json=envelope.endpoint_body
                    )
                    response.raise_for_status()
                    logging.info(f"forward_request: response: {response.json()}")

                    return response.json()
            except httpx.RequestError as e:
                logging.error(f"Request to {endpoint_full_url} failed: {str(e)}")
                raise HTTPException(status_code=500, detail=str(e))
        else:
            logging.error(f"forward_request: service_name : {service_name} not found")
            raise HTTPException(status_code=404, detail="Service not found")
FILE: ./websocket_listener_service/services/registry_service.py
import logging
import httpx
import asyncio
from fastapi import HTTPException
from websocket_listener_service.models.register_request import RegisterRequest
from websocket_listener_service.models.deregister_request import DeregisterRequest

class RegistryService:
    PROXY_URL = "http://localhost:8080/register"
    DEREGISTER_PROXY_URL = "http://localhost:8080/deregister"

    def __init__(self, service_registry, connection_id):
        self.service_registry = service_registry
        self.connection_id = connection_id

    async def fetch_openapi_json(self, openapi_url: str):
        retries = 5

        for attempt in range(retries):
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get(openapi_url)
                    response.raise_for_status()
                    openapi_json = response.json()
                    logging.info(f"Successfully loaded OpenAPI JSON from {openapi_url}")
                    return openapi_json
            except (httpx.ConnectError, httpx.HTTPStatusError, Exception) as e:
                logging.error(f"Failed to load OpenAPI JSON: {e}")
                if attempt < retries - 1:
                    logging.info(f"Retrying to fetch OpenAPI JSON (Attempt {attempt + 1}/{retries})...")
                    await asyncio.sleep(2)
        logging.warning("OpenAPI JSON could not be loaded. Proceeding with registration without OpenAPI JSON.")
        return None

    async def register_service(self, request: RegisterRequest):
        logging.info(f"Registering service: {request.service_name} with OpenAPI URL: {request.openapi_url}")
        if not request.openapi_url:
            raise HTTPException(status_code=400, detail="OpenAPI URL is required")

        openapi_json = await self.fetch_openapi_json(request.openapi_url)
        logging.info(f"OpenAPI Contents: {openapi_json}")

        if not openapi_json or 'servers' not in openapi_json or not openapi_json['servers']:
            logging.error("OpenAPI JSON must include servers information")
            raise HTTPException(status_code=400, detail="OpenAPI JSON must include servers information")

        request.openapi_json = openapi_json

        service_info = {
            'openapi_url': request.openapi_url,
FILE: ./websocket_listener_service/services/__init__.py

FILE: ./websocket_listener_service/tests/test_config_service.py
import os
import json
import pytest
from unittest.mock import patch, mock_open
from websocket_listener_service.services.config_service import ConfigService

@pytest.fixture
def config_service():
    return ConfigService()

def test_load_config(config_service):
    with patch("os.path.exists", return_value=True):
        with patch("builtins.open", mock_open(read_data="{\"connection_id\": \"12345\"}")):
            config = config_service.load_config()
            assert config["connection_id"] == "12345"

def test_save_config(config_service):
    with patch("builtins.open", mock_open()) as mocked_file:
        config = {"connection_id": "12345"}
        config_service.save_config(config)
        mocked_file().write.assert_called_once_with(json.dumps(config))

def test_get_connection_id_existing(config_service):
    with patch("os.path.exists", return_value=True):
        with patch("builtins.open", mock_open(read_data="{\"connection_id\": \"12345\"}")):
            connection_id = config_service.get_connection_id()
            assert connection_id == "12345"

def test_get_connection_id_new(config_service):
    with patch("os.path.exists", return_value=False):
        with patch("builtins.open", mock_open()):
            with patch("uuid.uuid4", return_value="12345"):
                connection_id = config_service.get_connection_id()
                assert connection_id == "12345"

FILE: ./websocket_listener_service/tests/__init__.py

FILE: ./websocket_listener_service/websocket/websocket_handler.py
import asyncio
import httpx
import json
from fastapi import WebSocket, WebSocketDisconnect, HTTPException
import websockets
import logging
from websocket_listener_service.models.envelope import Envelope
from websocket_listener_service.services.forward_service import ForwardService
from websocket_listener_service.services.config_service import ConfigService

class WebSocketHandler:
    def __init__(self):
        self.websocket_clients = {}
        self.config_service = ConfigService()
        self.connection_id = self.config_service.get_connection_id()
        self.forward_service = ForwardService("http://localhost:8010")

    async def websocket_endpoint(self, websocket: WebSocket, connection_id: str):
        await websocket.accept()
        self.websocket_clients[connection_id] = {
            "websocket": websocket,
            "response_future": asyncio.Future()
        }
        try:
            while True:
                data = await websocket.receive_text()
                if connection_id in self.websocket_clients:
                    self.websocket_clients[connection_id]["response_future"].set_result(data)
                    self.websocket_clients[connection_id]["response_future"] = asyncio.Future()
        except WebSocketDisconnect:
            if connection_id in self.websocket_clients:
                del self.websocket_clients[connection_id]

    async def subscribe_to_proxy(self, proxy_url, connection_id):
        logging.info(f"listener: subscribe_to_proxy: Attempting to connect to proxy at {proxy_url} with connection ID {connection_id}")
        try:
            async with websockets.connect(proxy_url) as websocket:
                logging.info(f"Listener: Connected to proxy, sending registration with connection ID {connection_id}")
                await websocket.send(json.dumps({"action": "register", "connection_id": connection_id}))
                logging.info(f"Listener: Registered with proxy {proxy_url} using connection ID {connection_id}")

                try:
                    while True:
                        envelope_str = await websocket.recv()
                        logging.info(f"Listener: Received envelope from proxy: {envelope_str}")
                        envelope = Envelope.parse_raw(envelope_str)
                        try:
                            response = await self.forward_service.forward_request(envelope)
                            logging.info(f"Listener: Received response from forward_request: {response}")
                            await websocket.send(json.dumps(response))
FILE: ./websocket_listener_service/websocket/__init__.py

FILE: ./websocket_listener_service/__init__.py

, stderr: 
2024-08-02 11:57:21,679 custom_logger INFO Handling command: find . -type f \( -name '*.py' -o -name '*.json' -o -name '*.yaml' -o -name '*.yml' \) in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:57:21,680 custom_logger INFO Running command: find . -type f \( -name '*.py' -o -name '*.json' -o -name '*.yaml' -o -name '*.yml' \) in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:57:22,467 custom_logger INFO Command succeeded: stdout: ./docker-compose.yaml
./legacy/handle_base.py
./legacy/handle_command.py
./legacy/handle_command_dev.py
./legacy/handle_elastic.py
./legacy/handle_piston.py
./legacy/handle_replit.py
./legacy/listener.py
./legacy/listener_config.json
./legacy/listener_dev.py
./legacy/listener_dev_config.json
./legacy/logging_config.py
./legacy/openapi.json
./legacy/proxy.py
./legacy/query_logs.py
./legacy/sample_logging.py
./microservices/command_service/config/config.json
./microservices/command_service/config/config.py
./microservices/command_service/config/__init__.py
./microservices/command_service/controllers/command_controller.py
./microservices/command_service/controllers/__init__.py
./microservices/command_service/main.py
./microservices/command_service/models/command_message.py
./microservices/command_service/models/register_request.py
./microservices/command_service/models/__init__.py
./microservices/command_service/services/command_service.py
./microservices/command_service/services/logger.py
./microservices/command_service/services/registration_service.py
./microservices/command_service/services/__init__.py
./microservices/command_service/__init__.py
./microservices/tests/test_command_service.py
./microservices/tests/test_config.py
./microservices/tests/test_logger.py
./microservices/tests/test_registration_service.py
./microservices/__init__.py
./proxy_service/proxy.py
./scripts/register_services.py
./venv/common.py
./venv/Lib/site-packages/pip/_internal/build_env.py
./venv/Lib/site-packages/pip/_internal/cache.py
./venv/Lib/site-packages/pip/_internal/cli/autocompletion.py
./venv/Lib/site-packages/pip/_internal/cli/base_command.py
./venv/Lib/site-packages/pip/_internal/cli/cmdoptions.py
./venv/Lib/site-packages/pip/_internal/cli/command_context.py
./venv/Lib/site-packages/pip/_internal/cli/main.py
./venv/Lib/site-packages/pip/_internal/cli/main_parser.py
./venv/Lib/site-packages/pip/_internal/cli/parser.py
./venv/Lib/site-packages/pip/_internal/cli/progress_bars.py
./venv/Lib/site-packages/pip/_internal/cli/req_command.py
./venv/Lib/site-packages/pip/_internal/cli/spinners.py
./venv/Lib/site-packages/pip/_internal/cli/status_codes.py
./venv/Lib/site-packages/pip/_internal/cli/__init__.py
./venv/Lib/site-packages/pip/_internal/commands/cache.py
./venv/Lib/site-packages/pip/_internal/commands/check.py
./venv/Lib/site-packages/pip/_internal/commands/completion.py
./venv/Lib/site-packages/pip/_internal/commands/configuration.py
./venv/Lib/site-packages/pip/_internal/commands/debug.py
./venv/Lib/site-packages/pip/_internal/commands/download.py
./venv/Lib/site-packages/pip/_internal/commands/freeze.py
./venv/Lib/site-packages/pip/_internal/commands/hash.py
./venv/Lib/site-packages/pip/_internal/commands/help.py
./venv/Lib/site-packages/pip/_internal/commands/index.py
./venv/Lib/site-packages/pip/_internal/commands/install.py
./venv/Lib/site-packages/pip/_internal/commands/list.py
./venv/Lib/site-packages/pip/_internal/commands/search.py
./venv/Lib/site-packages/pip/_internal/commands/show.py
./venv/Lib/site-packages/pip/_internal/commands/uninstall.py
./venv/Lib/site-packages/pip/_internal/commands/wheel.py
./venv/Lib/site-packages/pip/_internal/commands/__init__.py
./venv/Lib/site-packages/pip/_internal/configuration.py
./venv/Lib/site-packages/pip/_internal/distributions/base.py
./venv/Lib/site-packages/pip/_internal/distributions/installed.py
./venv/Lib/site-packages/pip/_internal/distributions/sdist.py
./venv/Lib/site-packages/pip/_internal/distributions/wheel.py
./venv/Lib/site-packages/pip/_internal/distributions/__init__.py
./venv/Lib/site-packages/pip/_internal/exceptions.py
./venv/Lib/site-packages/pip/_internal/index/collector.py
./venv/Lib/site-packages/pip/_internal/index/package_finder.py
./venv/Lib/site-packages/pip/_internal/index/sources.py
./venv/Lib/site-packages/pip/_internal/index/__init__.py
./venv/Lib/site-packages/pip/_internal/locations/base.py
./venv/Lib/site-packages/pip/_internal/locations/_distutils.py
./venv/Lib/site-packages/pip/_internal/locations/_sysconfig.py
./venv/Lib/site-packages/pip/_internal/locations/__init__.py
./venv/Lib/site-packages/pip/_internal/main.py
./venv/Lib/site-packages/pip/_internal/metadata/base.py
./venv/Lib/site-packages/pip/_internal/metadata/pkg_resources.py
./venv/Lib/site-packages/pip/_internal/metadata/__init__.py
./venv/Lib/site-packages/pip/_internal/models/candidate.py
./venv/Lib/site-packages/pip/_internal/models/direct_url.py
./venv/Lib/site-packages/pip/_internal/models/format_control.py
./venv/Lib/site-packages/pip/_internal/models/index.py
./venv/Lib/site-packages/pip/_internal/models/link.py
./venv/Lib/site-packages/pip/_internal/models/scheme.py
./venv/Lib/site-packages/pip/_internal/models/search_scope.py
./venv/Lib/site-packages/pip/_internal/models/selection_prefs.py
./venv/Lib/site-packages/pip/_internal/models/target_python.py
./venv/Lib/site-packages/pip/_internal/models/wheel.py
./venv/Lib/site-packages/pip/_internal/models/__init__.py
./venv/Lib/site-packages/pip/_internal/network/auth.py
./venv/Lib/site-packages/pip/_internal/network/cache.py
./venv/Lib/site-packages/pip/_internal/network/download.py
./venv/Lib/site-packages/pip/_internal/network/lazy_wheel.py
./venv/Lib/site-packages/pip/_internal/network/session.py
./venv/Lib/site-packages/pip/_internal/network/utils.py
./venv/Lib/site-packages/pip/_internal/network/xmlrpc.py
./venv/Lib/site-packages/pip/_internal/network/__init__.py
./venv/Lib/site-packages/pip/_internal/operations/build/metadata.py
./venv/Lib/site-packages/pip/_internal/operations/build/metadata_editable.py
./venv/Lib/site-packages/pip/_internal/operations/build/metadata_legacy.py
./venv/Lib/site-packages/pip/_internal/operations/build/wheel.py
./venv/Lib/site-packages/pip/_internal/operations/build/wheel_editable.py
./venv/Lib/site-packages/pip/_internal/operations/build/wheel_legacy.py
./venv/Lib/site-packages/pip/_internal/operations/build/__init__.py
./venv/Lib/site-packages/pip/_internal/operations/check.py
./venv/Lib/site-packages/pip/_internal/operations/freeze.py
./venv/Lib/site-packages/pip/_internal/operations/install/editable_legacy.py
./venv/Lib/site-packages/pip/_internal/operations/install/legacy.py
./venv/Lib/site-packages/pip/_internal/operations/install/wheel.py
./venv/Lib/site-packages/pip/_internal/operations/install/__init__.py
./venv/Lib/site-packages/pip/_internal/operations/prepare.py
./venv/Lib/site-packages/pip/_internal/operations/__init__.py
./venv/Lib/site-packages/pip/_internal/pyproject.py
./venv/Lib/site-packages/pip/_internal/req/constructors.py
./venv/Lib/site-packages/pip/_internal/req/req_file.py
./venv/Lib/site-packages/pip/_internal/req/req_install.py
./venv/Lib/site-packages/pip/_internal/req/req_set.py
./venv/Lib/site-packages/pip/_internal/req/req_tracker.py
./venv/Lib/site-packages/pip/_internal/req/req_uninstall.py
./venv/Lib/site-packages/pip/_internal/req/__init__.py
./venv/Lib/site-packages/pip/_internal/resolution/base.py
./venv/Lib/site-packages/pip/_internal/resolution/legacy/resolver.py
./venv/Lib/site-packages/pip/_internal/resolution/legacy/__init__.py
./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/base.py
./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/candidates.py
./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/factory.py
./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py
./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/provider.py
./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/reporter.py
./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/requirements.py
./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/resolver.py
./venv/Lib/site-packages/pip/_internal/resolution/resolvelib/__init__.py
./venv/Lib/site-packages/pip/_internal/resolution/__init__.py
./venv/Lib/site-packages/pip/_internal/self_outdated_check.py
./venv/Lib/site-packages/pip/_internal/utils/appdirs.py
./venv/Lib/site-packages/pip/_internal/utils/compat.py
./venv/Lib/site-packages/pip/_internal/utils/compatibility_tags.py
./venv/Lib/site-packages/pip/_internal/utils/datetime.py
./venv/Lib/site-packages/pip/_internal/utils/deprecation.py
./venv/Lib/site-packages/pip/_internal/utils/direct_url_helpers.py
./venv/Lib/site-packages/pip/_internal/utils/distutils_args.py
./venv/Lib/site-packages/pip/_internal/utils/egg_link.py
./venv/Lib/site-packages/pip/_internal/utils/encoding.py
./venv/Lib/site-packages/pip/_internal/utils/entrypoints.py
./venv/Lib/site-packages/pip/_internal/utils/filesystem.py
./venv/Lib/site-packages/pip/_internal/utils/filetypes.py
./venv/Lib/site-packages/pip/_internal/utils/glibc.py
./venv/Lib/site-packages/pip/_internal/utils/hashes.py
./venv/Lib/site-packages/pip/_internal/utils/inject_securetransport.py
./venv/Lib/site-packages/pip/_internal/utils/logging.py
./venv/Lib/site-packages/pip/_internal/utils/misc.py
./venv/Lib/site-packages/pip/_internal/utils/models.py
./venv/Lib/site-packages/pip/_internal/utils/packaging.py
./venv/Lib/site-packages/pip/_internal/utils/parallel.py
./venv/Lib/site-packages/pip/_internal/utils/pkg_resources.py
./venv/Lib/site-packages/pip/_internal/utils/setuptools_build.py
./venv/Lib/site-packages/pip/_internal/utils/subprocess.py
./venv/Lib/site-packages/pip/_internal/utils/temp_dir.py
./venv/Lib/site-packages/pip/_internal/utils/unpacking.py
./venv/Lib/site-packages/pip/_internal/utils/urls.py
./venv/Lib/site-packages/pip/_internal/utils/virtualenv.py
./venv/Lib/site-packages/pip/_internal/utils/wheel.py
./venv/Lib/site-packages/pip/_internal/utils/_log.py
./venv/Lib/site-packages/pip/_internal/utils/__init__.py
./venv/Lib/site-packages/pip/_internal/vcs/bazaar.py
./venv/Lib/site-packages/pip/_internal/vcs/git.py
./venv/Lib/site-packages/pip/_internal/vcs/mercurial.py
./venv/Lib/site-packages/pip/_internal/vcs/subversion.py
./venv/Lib/site-packages/pip/_internal/vcs/versioncontrol.py
./venv/Lib/site-packages/pip/_internal/vcs/__init__.py
./venv/Lib/site-packages/pip/_internal/wheel_builder.py
./venv/Lib/site-packages/pip/_internal/__init__.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/adapter.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/cache.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/caches/file_cache.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/caches/redis_cache.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/caches/__init__.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/compat.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/controller.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/filewrapper.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/heuristics.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/serialize.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/wrapper.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/_cmd.py
./venv/Lib/site-packages/pip/_vendor/cachecontrol/__init__.py
./venv/Lib/site-packages/pip/_vendor/certifi/core.py
./venv/Lib/site-packages/pip/_vendor/certifi/__init__.py
./venv/Lib/site-packages/pip/_vendor/certifi/__main__.py
./venv/Lib/site-packages/pip/_vendor/chardet/big5freq.py
./venv/Lib/site-packages/pip/_vendor/chardet/big5prober.py
./venv/Lib/site-packages/pip/_vendor/chardet/chardistribution.py
./venv/Lib/site-packages/pip/_vendor/chardet/charsetgroupprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/charsetprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/cli/chardetect.py
./venv/Lib/site-packages/pip/_vendor/chardet/cli/__init__.py
./venv/Lib/site-packages/pip/_vendor/chardet/codingstatemachine.py
./venv/Lib/site-packages/pip/_vendor/chardet/compat.py
./venv/Lib/site-packages/pip/_vendor/chardet/cp949prober.py
./venv/Lib/site-packages/pip/_vendor/chardet/enums.py
./venv/Lib/site-packages/pip/_vendor/chardet/escprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/escsm.py
./venv/Lib/site-packages/pip/_vendor/chardet/eucjpprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/euckrfreq.py
./venv/Lib/site-packages/pip/_vendor/chardet/euckrprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/euctwfreq.py
./venv/Lib/site-packages/pip/_vendor/chardet/euctwprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/gb2312freq.py
./venv/Lib/site-packages/pip/_vendor/chardet/gb2312prober.py
./venv/Lib/site-packages/pip/_vendor/chardet/hebrewprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/jisfreq.py
./venv/Lib/site-packages/pip/_vendor/chardet/jpcntx.py
./venv/Lib/site-packages/pip/_vendor/chardet/langbulgarianmodel.py
./venv/Lib/site-packages/pip/_vendor/chardet/langgreekmodel.py
./venv/Lib/site-packages/pip/_vendor/chardet/langhebrewmodel.py
./venv/Lib/site-packages/pip/_vendor/chardet/langhungarianmodel.py
./venv/Lib/site-packages/pip/_vendor/chardet/langrussianmodel.py
./venv/Lib/site-packages/pip/_vendor/chardet/langthaimodel.py
./venv/Lib/site-packages/pip/_vendor/chardet/langturkishmodel.py
./venv/Lib/site-packages/pip/_vendor/chardet/latin1prober.py
./venv/Lib/site-packages/pip/_vendor/chardet/mbcharsetprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/mbcsgroupprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/mbcssm.py
./venv/Lib/site-packages/pip/_vendor/chardet/metadata/languages.py
./venv/Lib/site-packages/pip/_vendor/chardet/metadata/__init__.py
./venv/Lib/site-packages/pip/_vendor/chardet/sbcharsetprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/sbcsgroupprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/sjisprober.py
./venv/Lib/site-packages/pip/_vendor/chardet/universaldetector.py
./venv/Lib/site-packages/pip/_vendor/chardet/utf8prober.py
./venv/Lib/site-packages/pip/_vendor/chardet/version.py
./venv/Lib/site-packages/pip/_vendor/chardet/__init__.py
./venv/Lib/site-packages/pip/_vendor/colorama/ansi.py
./venv/Lib/site-packages/pip/_vendor/colorama/ansitowin32.py
./venv/Lib/site-packages/pip/_vendor/colorama/initialise.py
./venv/Lib/site-packages/pip/_vendor/colorama/win32.py
./venv/Lib/site-packages/pip/_vendor/colorama/winterm.py
./venv/Lib/site-packages/pip/_vendor/colorama/__init__.py
./venv/Lib/site-packages/pip/_vendor/distlib/compat.py
./venv/Lib/site-packages/pip/_vendor/distlib/database.py
./venv/Lib/site-packages/pip/_vendor/distlib/index.py
./venv/Lib/site-packages/pip/_vendor/distlib/locators.py
./venv/Lib/site-packages/pip/_vendor/distlib/manifest.py
./venv/Lib/site-packages/pip/_vendor/distlib/markers.py
./venv/Lib/site-packages/pip/_vendor/distlib/metadata.py
./venv/Lib/site-packages/pip/_vendor/distlib/resources.py
./venv/Lib/site-packages/pip/_vendor/distlib/scripts.py
./venv/Lib/site-packages/pip/_vendor/distlib/util.py
./venv/Lib/site-packages/pip/_vendor/distlib/version.py
./venv/Lib/site-packages/pip/_vendor/distlib/wheel.py
./venv/Lib/site-packages/pip/_vendor/distlib/_backport/misc.py
./venv/Lib/site-packages/pip/_vendor/distlib/_backport/shutil.py
./venv/Lib/site-packages/pip/_vendor/distlib/_backport/sysconfig.py
./venv/Lib/site-packages/pip/_vendor/distlib/_backport/tarfile.py
./venv/Lib/site-packages/pip/_vendor/distlib/_backport/__init__.py
./venv/Lib/site-packages/pip/_vendor/distlib/__init__.py
./venv/Lib/site-packages/pip/_vendor/distro.py
./venv/Lib/site-packages/pip/_vendor/html5lib/constants.py
./venv/Lib/site-packages/pip/_vendor/html5lib/filters/alphabeticalattributes.py
./venv/Lib/site-packages/pip/_vendor/html5lib/filters/base.py
./venv/Lib/site-packages/pip/_vendor/html5lib/filters/inject_meta_charset.py
./venv/Lib/site-packages/pip/_vendor/html5lib/filters/lint.py
./venv/Lib/site-packages/pip/_vendor/html5lib/filters/optionaltags.py
./venv/Lib/site-packages/pip/_vendor/html5lib/filters/sanitizer.py
./venv/Lib/site-packages/pip/_vendor/html5lib/filters/whitespace.py
./venv/Lib/site-packages/pip/_vendor/html5lib/filters/__init__.py
./venv/Lib/site-packages/pip/_vendor/html5lib/html5parser.py
./venv/Lib/site-packages/pip/_vendor/html5lib/serializer.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treeadapters/genshi.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treeadapters/sax.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treeadapters/__init__.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/base.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/dom.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/etree.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/etree_lxml.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treebuilders/__init__.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/base.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/dom.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/etree.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/etree_lxml.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/genshi.py
./venv/Lib/site-packages/pip/_vendor/html5lib/treewalkers/__init__.py
./venv/Lib/site-packages/pip/_vendor/html5lib/_ihatexml.py
./venv/Lib/site-packages/pip/_vendor/html5lib/_inputstream.py
./venv/Lib/site-packages/pip/_vendor/html5lib/_tokenizer.py
./venv/Lib/site-packages/pip/_vendor/html5lib/_trie/py.py
./venv/Lib/site-packages/pip/_vendor/html5lib/_trie/_base.py
./venv/Lib/site-packages/pip/_vendor/html5lib/_trie/__init__.py
./venv/Lib/site-packages/pip/_vendor/html5lib/_utils.py
./venv/Lib/site-packages/pip/_vendor/html5lib/__init__.py
./venv/Lib/site-packages/pip/_vendor/idna/codec.py
./venv/Lib/site-packages/pip/_vendor/idna/compat.py
./venv/Lib/site-packages/pip/_vendor/idna/core.py
./venv/Lib/site-packages/pip/_vendor/idna/idnadata.py
./venv/Lib/site-packages/pip/_vendor/idna/intranges.py
./venv/Lib/site-packages/pip/_vendor/idna/package_data.py
./venv/Lib/site-packages/pip/_vendor/idna/uts46data.py
./venv/Lib/site-packages/pip/_vendor/idna/__init__.py
./venv/Lib/site-packages/pip/_vendor/msgpack/exceptions.py
./venv/Lib/site-packages/pip/_vendor/msgpack/ext.py
./venv/Lib/site-packages/pip/_vendor/msgpack/fallback.py
./venv/Lib/site-packages/pip/_vendor/msgpack/_version.py
./venv/Lib/site-packages/pip/_vendor/msgpack/__init__.py
./venv/Lib/site-packages/pip/_vendor/packaging/markers.py
./venv/Lib/site-packages/pip/_vendor/packaging/requirements.py
./venv/Lib/site-packages/pip/_vendor/packaging/specifiers.py
./venv/Lib/site-packages/pip/_vendor/packaging/tags.py
./venv/Lib/site-packages/pip/_vendor/packaging/utils.py
./venv/Lib/site-packages/pip/_vendor/packaging/version.py
./venv/Lib/site-packages/pip/_vendor/packaging/_manylinux.py
./venv/Lib/site-packages/pip/_vendor/packaging/_musllinux.py
./venv/Lib/site-packages/pip/_vendor/packaging/_structures.py
./venv/Lib/site-packages/pip/_vendor/packaging/__about__.py
./venv/Lib/site-packages/pip/_vendor/packaging/__init__.py
./venv/Lib/site-packages/pip/_vendor/pep517/build.py
./venv/Lib/site-packages/pip/_vendor/pep517/check.py
./venv/Lib/site-packages/pip/_vendor/pep517/colorlog.py
./venv/Lib/site-packages/pip/_vendor/pep517/compat.py
./venv/Lib/site-packages/pip/_vendor/pep517/dirtools.py
./venv/Lib/site-packages/pip/_vendor/pep517/envbuild.py
./venv/Lib/site-packages/pip/_vendor/pep517/in_process/_in_process.py
./venv/Lib/site-packages/pip/_vendor/pep517/in_process/__init__.py
./venv/Lib/site-packages/pip/_vendor/pep517/meta.py
./venv/Lib/site-packages/pip/_vendor/pep517/wrappers.py
./venv/Lib/site-packages/pip/_vendor/pep517/__init__.py
./venv/Lib/site-packages/pip/_vendor/pkg_resources/py31compat.py
./venv/Lib/site-packages/pip/_vendor/pkg_resources/__init__.py
./venv/Lib/site-packages/pip/_vendor/platformdirs/android.py
./venv/Lib/site-packages/pip/_vendor/platformdirs/api.py
./venv/Lib/site-packages/pip/_vendor/platformdirs/macos.py
./venv/Lib/site-packages/pip/_vendor/platformdirs/unix.py
./venv/Lib/site-packages/pip/_vendor/platformdirs/version.py
./venv/Lib/site-packages/pip/_vendor/platformdirs/windows.py
./venv/Lib/site-packages/pip/_vendor/platformdirs/__init__.py
./venv/Lib/site-packages/pip/_vendor/platformdirs/__main__.py
./venv/Lib/site-packages/pip/_vendor/progress/bar.py
./venv/Lib/site-packages/pip/_vendor/progress/colors.py
./venv/Lib/site-packages/pip/_vendor/progress/counter.py
./venv/Lib/site-packages/pip/_vendor/progress/spinner.py
./venv/Lib/site-packages/pip/_vendor/progress/__init__.py
./venv/Lib/site-packages/pip/_vendor/pyparsing.py
./venv/Lib/site-packages/pip/_vendor/requests/adapters.py
./venv/Lib/site-packages/pip/_vendor/requests/api.py
./venv/Lib/site-packages/pip/_vendor/requests/auth.py
./venv/Lib/site-packages/pip/_vendor/requests/certs.py
./venv/Lib/site-packages/pip/_vendor/requests/compat.py
./venv/Lib/site-packages/pip/_vendor/requests/cookies.py
./venv/Lib/site-packages/pip/_vendor/requests/exceptions.py
./venv/Lib/site-packages/pip/_vendor/requests/help.py
./venv/Lib/site-packages/pip/_vendor/requests/hooks.py
./venv/Lib/site-packages/pip/_vendor/requests/models.py
./venv/Lib/site-packages/pip/_vendor/requests/packages.py
./venv/Lib/site-packages/pip/_vendor/requests/sessions.py
./venv/Lib/site-packages/pip/_vendor/requests/status_codes.py
./venv/Lib/site-packages/pip/_vendor/requests/structures.py
./venv/Lib/site-packages/pip/_vendor/requests/utils.py
./venv/Lib/site-packages/pip/_vendor/requests/_internal_utils.py
./venv/Lib/site-packages/pip/_vendor/requests/__init__.py
./venv/Lib/site-packages/pip/_vendor/requests/__version__.py
./venv/Lib/site-packages/pip/_vendor/resolvelib/compat/collections_abc.py
./venv/Lib/site-packages/pip/_vendor/resolvelib/compat/__init__.py
./venv/Lib/site-packages/pip/_vendor/resolvelib/providers.py
./venv/Lib/site-packages/pip/_vendor/resolvelib/reporters.py
./venv/Lib/site-packages/pip/_vendor/resolvelib/resolvers.py
./venv/Lib/site-packages/pip/_vendor/resolvelib/structs.py
./venv/Lib/site-packages/pip/_vendor/resolvelib/__init__.py
./venv/Lib/site-packages/pip/_vendor/six.py
./venv/Lib/site-packages/pip/_vendor/tenacity/after.py
./venv/Lib/site-packages/pip/_vendor/tenacity/before.py
./venv/Lib/site-packages/pip/_vendor/tenacity/before_sleep.py
./venv/Lib/site-packages/pip/_vendor/tenacity/nap.py
./venv/Lib/site-packages/pip/_vendor/tenacity/retry.py
./venv/Lib/site-packages/pip/_vendor/tenacity/stop.py
./venv/Lib/site-packages/pip/_vendor/tenacity/tornadoweb.py
./venv/Lib/site-packages/pip/_vendor/tenacity/wait.py
./venv/Lib/site-packages/pip/_vendor/tenacity/_asyncio.py
./venv/Lib/site-packages/pip/_vendor/tenacity/_utils.py
./venv/Lib/site-packages/pip/_vendor/tenacity/__init__.py
./venv/Lib/site-packages/pip/_vendor/tomli/_parser.py
./venv/Lib/site-packages/pip/_vendor/tomli/_re.py
./venv/Lib/site-packages/pip/_vendor/tomli/__init__.py
./venv/Lib/site-packages/pip/_vendor/urllib3/connection.py
./venv/Lib/site-packages/pip/_vendor/urllib3/connectionpool.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/appengine.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/ntlmpool.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/securetransport.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/socks.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/_appengine_environ.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/_securetransport/bindings.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/_securetransport/low_level.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/_securetransport/__init__.py
./venv/Lib/site-packages/pip/_vendor/urllib3/contrib/__init__.py
./venv/Lib/site-packages/pip/_vendor/urllib3/exceptions.py
./venv/Lib/site-packages/pip/_vendor/urllib3/fields.py
./venv/Lib/site-packages/pip/_vendor/urllib3/filepost.py
./venv/Lib/site-packages/pip/_vendor/urllib3/packages/backports/makefile.py
./venv/Lib/site-packages/pip/_vendor/urllib3/packages/backports/__init__.py
./venv/Lib/site-packages/pip/_vendor/urllib3/packages/six.py
./venv/Lib/site-packages/pip/_vendor/urllib3/packages/ssl_match_hostname/_implementation.py
./venv/Lib/site-packages/pip/_vendor/urllib3/packages/ssl_match_hostname/__init__.py
./venv/Lib/site-packages/pip/_vendor/urllib3/packages/__init__.py
./venv/Lib/site-packages/pip/_vendor/urllib3/poolmanager.py
./venv/Lib/site-packages/pip/_vendor/urllib3/request.py
./venv/Lib/site-packages/pip/_vendor/urllib3/response.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/connection.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/proxy.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/queue.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/request.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/response.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/retry.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/ssltransport.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/ssl_.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/timeout.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/url.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/wait.py
./venv/Lib/site-packages/pip/_vendor/urllib3/util/__init__.py
./venv/Lib/site-packages/pip/_vendor/urllib3/_collections.py
./venv/Lib/site-packages/pip/_vendor/urllib3/_version.py
./venv/Lib/site-packages/pip/_vendor/urllib3/__init__.py
./venv/Lib/site-packages/pip/_vendor/webencodings/labels.py
./venv/Lib/site-packages/pip/_vendor/webencodings/mklabels.py
./venv/Lib/site-packages/pip/_vendor/webencodings/tests.py
./venv/Lib/site-packages/pip/_vendor/webencodings/x_user_defined.py
./venv/Lib/site-packages/pip/_vendor/webencodings/__init__.py
./venv/Lib/site-packages/pip/_vendor/__init__.py
./venv/Lib/site-packages/pip/__init__.py
./venv/Lib/site-packages/pip/__main__.py
./venv/Lib/site-packages/pkg_resources/extern/__init__.py
./venv/Lib/site-packages/pkg_resources/tests/data/my-test-package-source/setup.py
./venv/Lib/site-packages/pkg_resources/_vendor/appdirs.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/markers.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/requirements.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/specifiers.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/tags.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/utils.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/version.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/_manylinux.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/_musllinux.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/_structures.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/__about__.py
./venv/Lib/site-packages/pkg_resources/_vendor/packaging/__init__.py
./venv/Lib/site-packages/pkg_resources/_vendor/pyparsing.py
./venv/Lib/site-packages/pkg_resources/_vendor/__init__.py
./venv/Lib/site-packages/pkg_resources/__init__.py
./venv/Lib/site-packages/setuptools/archive_util.py
./venv/Lib/site-packages/setuptools/build_meta.py
./venv/Lib/site-packages/setuptools/command/alias.py
./venv/Lib/site-packages/setuptools/command/bdist_egg.py
./venv/Lib/site-packages/setuptools/command/bdist_rpm.py
./venv/Lib/site-packages/setuptools/command/build_clib.py
./venv/Lib/site-packages/setuptools/command/build_ext.py
./venv/Lib/site-packages/setuptools/command/build_py.py
./venv/Lib/site-packages/setuptools/command/develop.py
./venv/Lib/site-packages/setuptools/command/dist_info.py
./venv/Lib/site-packages/setuptools/command/easy_install.py
./venv/Lib/site-packages/setuptools/command/egg_info.py
./venv/Lib/site-packages/setuptools/command/install.py
./venv/Lib/site-packages/setuptools/command/install_egg_info.py
./venv/Lib/site-packages/setuptools/command/install_lib.py
./venv/Lib/site-packages/setuptools/command/install_scripts.py
./venv/Lib/site-packages/setuptools/command/py36compat.py
./venv/Lib/site-packages/setuptools/command/register.py
./venv/Lib/site-packages/setuptools/command/rotate.py
./venv/Lib/site-packages/setuptools/command/saveopts.py
./venv/Lib/site-packages/setuptools/command/sdist.py
./venv/Lib/site-packages/setuptools/command/setopt.py
./venv/Lib/site-packages/setuptools/command/test.py
./venv/Lib/site-packages/setuptools/command/upload.py
./venv/Lib/site-packages/setuptools/command/upload_docs.py
./venv/Lib/site-packages/setuptools/command/__init__.py
./venv/Lib/site-packages/setuptools/config.py
./venv/Lib/site-packages/setuptools/depends.py
./venv/Lib/site-packages/setuptools/dep_util.py
./venv/Lib/site-packages/setuptools/dist.py
./venv/Lib/site-packages/setuptools/errors.py
./venv/Lib/site-packages/setuptools/extension.py
./venv/Lib/site-packages/setuptools/extern/__init__.py
./venv/Lib/site-packages/setuptools/glob.py
./venv/Lib/site-packages/setuptools/installer.py
./venv/Lib/site-packages/setuptools/launch.py
./venv/Lib/site-packages/setuptools/logging.py
./venv/Lib/site-packages/setuptools/monkey.py
./venv/Lib/site-packages/setuptools/msvc.py
./venv/Lib/site-packages/setuptools/namespaces.py
./venv/Lib/site-packages/setuptools/package_index.py
./venv/Lib/site-packages/setuptools/py34compat.py
./venv/Lib/site-packages/setuptools/sandbox.py
./venv/Lib/site-packages/setuptools/unicode_utils.py
./venv/Lib/site-packages/setuptools/version.py
./venv/Lib/site-packages/setuptools/wheel.py
./venv/Lib/site-packages/setuptools/windows_support.py
./venv/Lib/site-packages/setuptools/_deprecation_warning.py
./venv/Lib/site-packages/setuptools/_distutils/archive_util.py
./venv/Lib/site-packages/setuptools/_distutils/bcppcompiler.py
./venv/Lib/site-packages/setuptools/_distutils/ccompiler.py
./venv/Lib/site-packages/setuptools/_distutils/cmd.py
./venv/Lib/site-packages/setuptools/_distutils/command/bdist.py
./venv/Lib/site-packages/setuptools/_distutils/command/bdist_dumb.py
./venv/Lib/site-packages/setuptools/_distutils/command/bdist_msi.py
./venv/Lib/site-packages/setuptools/_distutils/command/bdist_rpm.py
./venv/Lib/site-packages/setuptools/_distutils/command/bdist_wininst.py
./venv/Lib/site-packages/setuptools/_distutils/command/build.py
./venv/Lib/site-packages/setuptools/_distutils/command/build_clib.py
./venv/Lib/site-packages/setuptools/_distutils/command/build_ext.py
./venv/Lib/site-packages/setuptools/_distutils/command/build_py.py
./venv/Lib/site-packages/setuptools/_distutils/command/build_scripts.py
./venv/Lib/site-packages/setuptools/_distutils/command/check.py
./venv/Lib/site-packages/setuptools/_distutils/command/clean.py
./venv/Lib/site-packages/setuptools/_distutils/command/config.py
./venv/Lib/site-packages/setuptools/_distutils/command/install.py
./venv/Lib/site-packages/setuptools/_distutils/command/install_data.py
./venv/Lib/site-packages/setuptools/_distutils/command/install_egg_info.py
./venv/Lib/site-packages/setuptools/_distutils/command/install_headers.py
./venv/Lib/site-packages/setuptools/_distutils/command/install_lib.py
./venv/Lib/site-packages/setuptools/_distutils/command/install_scripts.py
./venv/Lib/site-packages/setuptools/_distutils/command/py37compat.py
./venv/Lib/site-packages/setuptools/_distutils/command/register.py
./venv/Lib/site-packages/setuptools/_distutils/command/sdist.py
./venv/Lib/site-packages/setuptools/_distutils/command/upload.py
./venv/Lib/site-packages/setuptools/_distutils/command/__init__.py
./venv/Lib/site-packages/setuptools/_distutils/config.py
./venv/Lib/site-packages/setuptools/_distutils/core.py
./venv/Lib/site-packages/setuptools/_distutils/cygwinccompiler.py
./venv/Lib/site-packages/setuptools/_distutils/debug.py
./venv/Lib/site-packages/setuptools/_distutils/dep_util.py
./venv/Lib/site-packages/setuptools/_distutils/dir_util.py
./venv/Lib/site-packages/setuptools/_distutils/dist.py
./venv/Lib/site-packages/setuptools/_distutils/errors.py
./venv/Lib/site-packages/setuptools/_distutils/extension.py
./venv/Lib/site-packages/setuptools/_distutils/fancy_getopt.py
./venv/Lib/site-packages/setuptools/_distutils/filelist.py
./venv/Lib/site-packages/setuptools/_distutils/file_util.py
./venv/Lib/site-packages/setuptools/_distutils/log.py
./venv/Lib/site-packages/setuptools/_distutils/msvc9compiler.py
./venv/Lib/site-packages/setuptools/_distutils/msvccompiler.py
./venv/Lib/site-packages/setuptools/_distutils/py35compat.py
./venv/Lib/site-packages/setuptools/_distutils/py38compat.py
./venv/Lib/site-packages/setuptools/_distutils/spawn.py
./venv/Lib/site-packages/setuptools/_distutils/sysconfig.py
./venv/Lib/site-packages/setuptools/_distutils/text_file.py
./venv/Lib/site-packages/setuptools/_distutils/unixccompiler.py
./venv/Lib/site-packages/setuptools/_distutils/util.py
./venv/Lib/site-packages/setuptools/_distutils/version.py
./venv/Lib/site-packages/setuptools/_distutils/versionpredicate.py
./venv/Lib/site-packages/setuptools/_distutils/_msvccompiler.py
./venv/Lib/site-packages/setuptools/_distutils/__init__.py
./venv/Lib/site-packages/setuptools/_imp.py
./venv/Lib/site-packages/setuptools/_vendor/more_itertools/more.py
./venv/Lib/site-packages/setuptools/_vendor/more_itertools/recipes.py
./venv/Lib/site-packages/setuptools/_vendor/more_itertools/__init__.py
./venv/Lib/site-packages/setuptools/_vendor/ordered_set.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/markers.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/requirements.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/specifiers.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/tags.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/utils.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/version.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/_manylinux.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/_musllinux.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/_structures.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/__about__.py
./venv/Lib/site-packages/setuptools/_vendor/packaging/__init__.py
./venv/Lib/site-packages/setuptools/_vendor/pyparsing.py
./venv/Lib/site-packages/setuptools/_vendor/__init__.py
./venv/Lib/site-packages/setuptools/__init__.py
./venv/Lib/site-packages/wheel/bdist_wheel.py
./venv/Lib/site-packages/wheel/cli/convert.py
./venv/Lib/site-packages/wheel/cli/pack.py
./venv/Lib/site-packages/wheel/cli/unpack.py
./venv/Lib/site-packages/wheel/cli/__init__.py
./venv/Lib/site-packages/wheel/macosx_libfile.py
./venv/Lib/site-packages/wheel/metadata.py
./venv/Lib/site-packages/wheel/pkginfo.py
./venv/Lib/site-packages/wheel/util.py
./venv/Lib/site-packages/wheel/vendored/packaging/tags.py
./venv/Lib/site-packages/wheel/vendored/packaging/_typing.py
./venv/Lib/site-packages/wheel/vendored/packaging/__init__.py
./venv/Lib/site-packages/wheel/vendored/__init__.py
./venv/Lib/site-packages/wheel/wheelfile.py
./venv/Lib/site-packages/wheel/__init__.py
./venv/Lib/site-packages/wheel/__main__.py
./venv/Lib/site-packages/_distutils_hack/override.py
./venv/Lib/site-packages/_distutils_hack/__init__.py
./venv/Lib/site-packages/_virtualenv.py
./venv/Scripts/activate_this.py
./websocket_listener_service/config.json
./websocket_listener_service/controllers/listener_controller.py
./websocket_listener_service/controllers/__init__.py
./websocket_listener_service/main.py
./websocket_listener_service/models/deregister_request.py
./websocket_listener_service/models/envelope.py
./websocket_listener_service/models/register_request.py
./websocket_listener_service/models/__init__.py
./websocket_listener_service/services/config_service.py
./websocket_listener_service/services/forward_service.py
./websocket_listener_service/services/registry_service.py
./websocket_listener_service/services/__init__.py
./websocket_listener_service/tests/test_config_service.py
./websocket_listener_service/tests/__init__.py
./websocket_listener_service/websocket/websocket_handler.py
./websocket_listener_service/websocket/__init__.py
./websocket_listener_service/__init__.py
, stderr: 
2024-08-02 11:58:15,249 custom_logger INFO Handling command: head -n 50 ./legacy/handle_base.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:58:15,250 custom_logger INFO Running command: head -n 50 ./legacy/handle_base.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:58:15,276 custom_logger INFO Command succeeded: stdout: from fastapi import APIRouter

class HandleBase:
    def __init__(self):
        self.router = APIRouter()

        @self.router.get("/example")
        async def example_endpoint():
            return {"message": "This is an example endpoint"}
, stderr: 
2024-08-02 11:58:27,435 custom_logger INFO Handling command: head -n 50 ./legacy/handle_command.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:58:27,436 custom_logger INFO Running command: head -n 50 ./legacy/handle_command.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:58:27,453 custom_logger INFO Command succeeded: stdout: from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
import asyncio
import logging
import os
import requests
from contextlib import asynccontextmanager
from handle_base import HandleBase

app = FastAPI()
logging.basicConfig(level=logging.INFO)

class CommandMessage(BaseModel):
    command: str
    path: str = ""

class RegisterRequest(BaseModel):
    service_name: str
    url: str

PROXY_URL = "http://localhost:8010/register"

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Registration logic
    registration_data = {
        "service_name": "handle-command",
        "url": "http://localhost:8003"
    }
    try:
        logging.info(f"Registering service with the proxy...{registration_data}")
        response = requests.post(PROXY_URL, json=registration_data)
        response.raise_for_status()
        logging.info("Service registered successfully with the proxy.")
    except requests.RequestException as e:
        logging.error(f"Failed to register service with proxy: {e}")
        raise HTTPException(status_code=500, detail="Failed to register service with proxy")
    yield
    # Any cleanup logic here if needed

app = FastAPI(lifespan=lifespan)

async def run_command(command: str, path: str):
    logger = logging.getLogger(__name__)
    logger.info(f"Running command: {command} in path: {path}")

    full_path = os.path.abspath(path) if path else os.getcwd()

    process = await asyncio.create_subprocess_shell(
        command,
, stderr: 
2024-08-02 11:58:51,289 custom_logger INFO Handling command: head -n 50 ./legacy/handle_command_dev.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:58:51,289 custom_logger INFO Running command: head -n 50 ./legacy/handle_command_dev.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:58:51,306 custom_logger INFO Command succeeded: stdout: from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
import subprocess
import logging
import os
import requests
from contextlib import asynccontextmanager
from handle_base import HandleBase

app = FastAPI()
logging.basicConfig(level=logging.INFO)

class CommandMessage(BaseModel):
    command: str
    path: str = ""

class RegisterRequest(BaseModel):
    service_name: str
    url: str

PROXY_URL = "http://localhost:8005/register"

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Registration logic
    registration_data = {
        "service_name": "handle-command-dev",
        "url": "http://localhost:8004"
    }
    try:
        logging.info("Registering service with the proxy...")
        response = requests.post(PROXY_URL, json=registration_data)
        response.raise_for_status()
        logging.info("Service registered successfully with the proxy.")
    except requests.RequestException as e:
        logging.error(f"Failed to register service with proxy: {e}")
        raise HTTPException(status_code=500, detail="Failed to register service with proxy")
    yield
    # Any cleanup logic here if needed

app = FastAPI(lifespan=lifespan)

@app.post("/handle-command-dev")
async def handle_command(message: CommandMessage):
    logger = logging.getLogger(__name__)
    logger.info(f"Handling command: {message} ")


    logger.info(f"Handling command: {message.command} in path: {message.path}")

, stderr: 
2024-08-02 11:59:13,836 custom_logger INFO Handling command: head -n 50 ./legacy/handle_elastic.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:59:13,836 custom_logger INFO Running command: head -n 50 ./legacy/handle_elastic.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:59:13,856 custom_logger INFO Command succeeded: stdout: from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
import logging
import requests
import traceback

app = FastAPI()
logging.basicConfig(level=logging.DEBUG)


class ElasticQueryMessage(BaseModel):
    connection_string: str
    index: str
    query: dict


class RegisterRequest(BaseModel):
    service_name: str
    url: str


PROXY_URL = "http://localhost:8080/register"


@app.on_event("startup")
async def startup_event():
    registration_data = {
        "service_name": "handle-elastic",
        "url": "http://localhost:8007"
    }
    try:
        logging.info("Registering service with the proxy...")
        response = requests.post(PROXY_URL, json=registration_data)
        response.raise_for_status()
        logging.info("Service registered successfully with the proxy.")
    except requests.RequestException as e:
        logging.error(f"Failed to register service with proxy: {e}")
        raise HTTPException(status_code=500, detail="Failed to register service with proxy")


@app.post("/handle-elastic")
async def handle_elastic(message: ElasticQueryMessage):
    logger = logging.getLogger(__name__)
    logger.info(f"Handling ElasticSearch query: {message}")

    try:
        query_url = f"{message.connection_string}/{message.index}/_search"
        logger.debug(f"Query URL: {query_url}")
        logger.debug(f"Query Body: {message.query}")

, stderr: 
2024-08-02 11:59:38,676 custom_logger INFO Handling command: head -n 50 ./legacy/handle_piston.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:59:38,677 custom_logger INFO Running command: head -n 50 ./legacy/handle_piston.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 11:59:38,706 custom_logger INFO Command succeeded: stdout: import requests
from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel
import json

app = FastAPI()

class CodeExecutionRequest(BaseModel):
    language: str
    version: str
    code: str

@app.post("/execute")
def execute_code(request: CodeExecutionRequest):
    url = "https://emkc.org/api/v2/piston/execute"
    payload = {
        "language": request.language,
        "version": request.version,
        "files": [{"name": "main", "content": request.code}]
    }
    headers = {"Content-Type": "application/json"}

    response = requests.post(url, json=payload, headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        raise HTTPException(status_code=response.status_code, detail="Error executing code")


def register_service():
    service_name = "handle_piston"
    service_url = "http://localhost:8002"
    proxy_url = "http://localhost:8080/register_service"
    payload = {
        "service_name": service_name,
        "url": service_url
    }
    headers = {"Content-Type": "application/json"}
    response = requests.post(proxy_url, json=payload, headers=headers)
    if response.status_code == 200:
        print(f"Service {service_name} registered successfully.")
    else:
        print(f"Failed to register service {service_name}: {response.status_code}")

if __name__ == "__main__":
    register_service()
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)
, stderr: 
2024-08-02 12:00:06,169 custom_logger INFO Handling command: head -n 50 ./legacy/handle_replit.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 12:00:06,170 custom_logger INFO Running command: head -n 50 ./legacy/handle_replit.py in path: /mnt/c/Users/Richa/PycharmProjects/Proxy_Services
2024-08-02 12:00:06,187 custom_logger INFO Command succeeded: stdout: from fastapi import FastAPI, HTTPException, File, UploadFile, Form
from pydantic import BaseModel
import logging
import os
import traceback
import requests
from contextlib import asynccontextmanager

app = FastAPI()
logging.basicConfig(level=logging.INFO)

class RegisterRequest(BaseModel):
    service_name: str
    url: str

PROXY_URL = "http://localhost:8001/register"

@asynccontextmanager
async def lifespan(app: FastAPI):
    registration_data = {
        "service_name": "handle-replit",
        "url": "http://localhost:8007/handle-replit"
    }
    try:
        logging.info("Registering service with the proxy...")
        response = requests.post(PROXY_URL, json=registration_data)
        response.raise_for_status()
        logging.info("Service registered successfully with the proxy.")
    except requests.RequestException as e:
        logging.error(f"Failed to register service with proxy: {e}")
        raise HTTPException(status_code=500, detail="Failed to register service with proxy")

    yield
    logging.info("Shutting down...")

app = FastAPI(lifespan=lifespan)

@app.post("/handle-replit")
async def handle_replit(file: UploadFile = File(...), repl_name: str = Form(...), repl_url: str = Form(...)):
    logger = logging.getLogger(__name__)
    logger.info(f"Handling file upload: {file.filename}")
    logger.info(f"Received repl_name: {repl_name}")
    logger.info(f"Received repl_url: {repl_url}")

    try:
        file_path = os.path.join(f"/home/runner/{repl_name}/", file.filename)
        with open(file_path, "wb") as buffer:
            buffer.write(file.file.read())

        file_url = f"https://{repl_url}/{file.filename}"
, stderr: 
